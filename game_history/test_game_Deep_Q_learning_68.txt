 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.2503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000365 

action type: buy - action 0.0
Learning step: -120012.6953125
desired expected reward: -120060.28125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.66557 ]
 [108.58985 ]
 [102.66332 ]
 [ 82.398346]
 [107.16792 ]
 [110.7193  ]
 [106.695175]
 [114.52023 ]
 [ 90.04163 ]
 [100.8228  ]
 [100.04664 ]
 [102.5955  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.983642578125



buy possibilites: [-1] 
expected returns: [[97.333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 114.52022552490234






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[98.18481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.33300018310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 93.96353 ]
 [103.76646 ]
 [ 98.01177 ]
 [ 78.302666]
 [105.929825]
 [101.854256]
 [ 96.11114 ]
 [ 99.0405  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.5831298828125



buy possibilites: [-1] 
expected returns: [[115.2573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 105.9298324584961






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[111.11286]
 [114.6178 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.2573013305664



action possibilites: [-1] 
expected returns: [[122.64002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 130.8699493408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[115.003654]
 [125.16338 ]
 [119.39722 ]
 [ 98.39883 ]
 [127.535164]
 [123.116295]
 [117.35012 ]
 [122.40293 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.64002227783203



buy possibilites: [-1] 
expected returns: [[104.589485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 127.53516387939453






Player: 1 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[129.33968]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.58948516845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[120.2078  ]
 [132.58955 ]
 [125.60296 ]
 [100.087494]
 [135.51003 ]
 [130.11488 ]
 [123.12829 ]
 [129.53033 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.3267822265625



buy possibilites: [-1] 
expected returns: [[125.29748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 135.51002502441406






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3. 29.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3. 29.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3. 29.  3.  3.  0.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[112.63685]
 [118.57392]
 [122.96424]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.29747772216797



action possibilites: [-1. 11. 11.] 
expected returns: [[123.18116]
 [128.94319]
 [128.94319]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.31108856201172



action possibilites: [-1] 
expected returns: [[123.46067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.3939666748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[117.16188 ]
 [127.65682 ]
 [121.61816 ]
 [ 99.97312 ]
 [130.05829 ]
 [125.60203 ]
 [119.56333 ]
 [123.741264]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.4606704711914



buy possibilites: [-1] 
expected returns: [[115.148476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 130.0582733154297






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.48121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3. 29.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 115.14847564697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[101.81179 ]
 [111.92246 ]
 [105.8395  ]
 [ 86.07921 ]
 [110.453156]
 [114.10926 ]
 [109.98296 ]
 [117.84474 ]
 [ 93.68161 ]
 [103.93386 ]
 [103.14734 ]
 [107.13368 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3. 29.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.72663116455078



buy possibilites: [-1] 
expected returns: [[132.35504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 11. 29. 11.  0.  3.  0. 11. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3. 29.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.84473419189453






Player: 1 
cards in hand: [ 0. 14.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3. 29.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [ 0.  0.  0.  3.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[118.930504]
 [124.04356 ]
 [114.22588 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 132.35504150390625



action possibilites: [-1] 
expected returns: [[123.84809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 129.2128143310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.58749 ]
 [126.544685]
 [102.08005 ]
 [131.6038  ]
 [126.39509 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6. 10. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.84809112548828



buy possibilites: [-1] 
expected returns: [[105.74465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 131.6038055419922






Player: 1 
cards in hand: [ 0.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[131.94684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 261   0] 
sum of rewards: 226 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 175.38902282714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.563255]
 [129.95554 ]
 [109.94002 ]
 [133.82484 ]
 [132.30078 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  9. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.7649383544922



buy possibilites: [-1] 
expected returns: [[130.19612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  8. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [ 0. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 133.82481384277344






Player: 1 
cards in hand: [ 3.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 14.] 
cards in discard: [ 0. 14.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  8. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 14.] 
cards in discard: [ 0. 14.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  8. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 14.] 
cards in discard: [ 0. 14.  0.  3.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  3.  0.  0.] 
adversary cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[119.79669 ]
 [127.276405]
 [112.37051 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.1961212158203



action possibilites: [-1] 
expected returns: [[125.869896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.07798767089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[115.50946 ]
 [122.14255 ]
 [ 92.187386]
 [127.388176]
 [128.45331 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10.  8. 11.  0. 10.  3.  0. 11. 29.  8.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.8698959350586






Player: 1 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[123.729836]
 [121.37603 ]
 [132.82457 ]
 [129.75932 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.4533233642578



action possibilites: [-1. 10. 11.] 
expected returns: [[148.6527 ]
 [144.3674 ]
 [154.14172]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.2543487548828



action possibilites: [-1] 
expected returns: [[158.79042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 160.2381591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[156.19186]
 [165.27238]
 [160.13617]
 [141.39677]
 [163.91664]
 [167.40755]
 [163.46327]
 [170.60751]
 [148.66602]
 [158.32704]
 [157.7465 ]
 [162.93913]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.79042053222656



buy possibilites: [-1] 
expected returns: [[142.88344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 170.6074981689453






Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  3. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  3. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  3. 29.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 10.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[117.04833]
 [113.42392]
 [113.42392]
 [118.5773 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.  8.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 11 11 10 11 29 10  8  8 10 10 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  8.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.88343811035156



action possibilites: [-1] 
expected returns: [[142.39903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  8.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 124.81290435791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[136.6704  ]
 [122.570885]
 [143.03355 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0. 14.  8.] 
adversary cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.39903259277344






Player: 1 
cards in hand: [14.  0.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 14.  8.] 
cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3 14 14  0  8 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0.  0.  3. 29.  0.  3.  0.  3.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
expected returns: [[125.79328]
 [129.12175]
 [133.90181]
 [137.70113]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 29.  3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.03355407714844



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[129.1588 ]
 [126.94639]
 [131.40828]
 [131.40828]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.12911987304688



action possibilites: [-1] 
expected returns: [[146.5877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 136.7307891845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.25572]
 [142.75337]
 [117.27122]
 [147.25508]
 [148.27962]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 11.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.58770751953125






Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3.  9. 10.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[118.45945 ]
 [114.701454]
 [123.43334 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  3.  9. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 148.27960205078125



action possibilites: [-1] 
expected returns: [[181.16974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.56314086914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[174.70189]
 [179.32288]
 [158.74864]
 [183.26332]
 [183.16933]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 181.16973876953125



buy possibilites: [-1] 
expected returns: [[151.28433]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0. 10.  0.  0.  8.  0. 10. 29. 11.  8.  0.  3. 11. 10.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 183.26332092285156






Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [ 0. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [ 0. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [ 0. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [22. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [ 0. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[140.5437 ]
 [149.35764]
 [137.82997]
 [142.79216]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 151.28433227539062



action possibilites: [-1. 10.  8. 11.] 
expected returns: [[139.78145]
 [133.97665]
 [139.29105]
 [143.5633 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  2.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 148.41876220703125



action possibilites: [-1] 
expected returns: [[134.48615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 149.01954650878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[127.719536]
 [132.29463 ]
 [110.38089 ]
 [136.25095 ]
 [136.22202 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  6. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.48614501953125



buy possibilites: [-1] 
expected returns: [[105.25305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3.] 
cards in discard: [10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  5. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 136.2509307861328






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  5. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 10.  3. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  5. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 10.  3. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 10.  3. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[120.847694]
 [116.97018 ]
 [116.97018 ]
 [116.97018 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3. 10.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 22.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.2530517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.413826]
 [ 97.86504 ]
 [120.55962 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3. 10.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 22.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22  8] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 125.0116958618164



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  8.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 22.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0 22  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[136.43188]
 [139.18759]
 [135.42819]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  1.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.55960845947266



action possibilites: [-1] 
expected returns: [[145.6855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.8751983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[141.2217  ]
 [150.02757 ]
 [144.8796  ]
 [123.762825]
 [152.4303  ]
 [148.27773 ]
 [145.70367 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.6855010986328



buy possibilites: [-1] 
expected returns: [[169.79034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -51 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 152.43028259277344






Player: 1 
cards in hand: [29.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  3.  0.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  3.] 
cards in discard: [8. 0. 0. 3. 0. 3. 3. 8. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [11.  8.  0. 10. 11.] 
adversary cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  8.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 11.] 
expected returns: [[128.67139 ]
 [130.83813 ]
 [127.175285]
 [123.12609 ]
 [130.83813 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 10. 11.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.79034423828125



action possibilites: [-1] 
expected returns: [[175.24847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 135.2394561767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[170.61089]
 [157.52043]
 [175.02193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 11.] 
cards in discard: [10.  8. 29. 11.  0. 10.  8.  3. 10.  0. 10.  3. 10. 10. 11. 11.  0.  0.
  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 175.24847412109375






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  5.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [10. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 11. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 29.] 
expected returns: [[161.69217]
 [155.18362]
 [164.44946]
 [167.67912]
 [167.67912]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.02194213867188



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[161.19868]
 [153.48471]
 [165.0664 ]
 [153.48471]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 159.6018524169922



action possibilites: [-1] 
expected returns: [[159.33888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [29. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -51 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 171.16661071777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.19753]
 [154.79182]
 [134.4293 ]
 [158.07004]
 [160.86214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [29. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  8. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.33888244628906






Player: 1 
cards in hand: [ 0.  8. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[112.819275]
 [108.18594 ]
 [116.91375 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.8621368408203



action possibilites: [-1] 
expected returns: [[139.09416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.4213638305664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[134.8329 ]
 [138.03781]
 [122.83036]
 [140.72427]
 [140.57338]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  4. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.0941619873047



buy possibilites: [-1] 
expected returns: [[173.20033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  3. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -119 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 140.72425842285156






Player: 1 
cards in hand: [ 3. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  3. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8] -> size -> 32 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  3. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8] -> size -> 32 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  3. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8] -> size -> 32 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.  8. 29.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  8.  0. 11.  8.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8] -> size -> 32 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
expected returns: [[188.4338 ]
 [189.90584]
 [189.90584]
 [193.28378]
 [189.90584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 11.  8.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  3. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 173.20033264160156



action possibilites: [-1] 
expected returns: [[212.62454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 3.  3. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 197.88133239746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[208.54033]
 [196.95824]
 [213.20253]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 8.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 3.  3. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 212.62454223632812






Player: 1 
cards in hand: [ 3.  3. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  6.] 
adversary cards in hand: [11.  0.  8. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15] -> size -> 33 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  6.] 
adversary cards in hand: [11.  0.  8. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15] -> size -> 33 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  6.] 
adversary cards in hand: [11.  0.  8. 10. 11.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15] -> size -> 33 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  0.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 11.] 
expected returns: [[159.96878]
 [160.81912]
 [156.47882]
 [151.66267]
 [160.81912]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 10. 11.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  6.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 8.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 213.2025604248047



action possibilites: [-1] 
expected returns: [[185.48624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 8.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 165.777587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[179.54712]
 [168.34673]
 [186.18102]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [11.  0. 29.  3.  3.] 
adversary cards in discard: [ 8.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 185.48623657226562






Player: 1 
cards in hand: [11.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  3.] 
cards in discard: [ 8.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [15. 10.  0.  3.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8. 15. 11.  0.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  3.  3.] 
cards in discard: [ 8.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [15. 10.  0.  3.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8. 15. 11.  0.  8. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [15. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[185.96616]
 [180.1494 ]
 [180.4948 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  3.  0.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8. 15. 11.  0.  8. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  3. 10.  3. 11.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 186.18101501464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[178.6882 ]
 [182.24855]
 [166.66682]
 [184.55338]
 [186.01714]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  3.  0.] 
cards in discard: [29. 15. 29. 11. 10.  0. 10. 15.  8. 11.  3. 10.  0.  0. 15. 11.  8.  8.
  0.  8. 15. 11.  0.  8. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 8.  3. 10.  3. 11.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 185.96615600585938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  3. 10.  3. 11.  0. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  3. 10.  3. 11.  0. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 8.  3. 10.  3. 11.  0. 29.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8. 10. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 10. 29.] 
expected returns: [[166.06496]
 [165.46117]
 [159.42542]
 [159.42542]
 [159.42542]
 [174.0153 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 186.01710510253906



action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[178.16086]
 [170.99336]
 [170.99336]
 [170.99336]
 [182.3542 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 29.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 165.68362426757812



action possibilites: [-1. 10. 10.] 
expected returns: [[205.2628 ]
 [200.22829]
 [200.22829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 177.2632598876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[197.95436]
 [207.23335]
 [201.93977]
 [182.7635 ]
 [209.36961]
 [205.38417]
 [204.7998 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  4.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 205.26280212402344



buy possibilites: [-1] 
expected returns: [[181.00563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 10. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -61 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 209.36961364746094






Player: 1 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11] -> size -> 35 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11] -> size -> 35 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10. 11.  0.  0. 11.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11] -> size -> 35 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[198.6585 ]
 [193.34904]
 [203.32616]
 [203.32616]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0. 11.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  5.] 
adversary cards in hand: [29.  8.  3. 10.  0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1
Learning step: 0
desired expected reward: 181.00563049316406



action possibilites: [-1] 
expected returns: [[160.6555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [29.  8.  3. 10.  0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -10    0    0
   64    0] 
sum of rewards: -111 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 209.2853546142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[156.23479]
 [159.43822]
 [144.48996]
 [162.56209]
 [161.9644 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  2. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [29.  8.  3. 10.  0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.65550231933594



buy possibilites: [-1] 
expected returns: [[164.66467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [29.  8.  3. 10.  0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -20    0    0
   16    0] 
sum of rewards: -169 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 162.5620574951172






Player: 1 
cards in hand: [29.  8.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 10.  0.] 
cards in discard: [3. 3. 3. 8. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0. 29. 10.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  0.  0.] 
cards in discard: [3. 3. 3. 8. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0. 29. 10.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [3. 3. 3. 8. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0. 29. 10.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 3. 3. 8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 29.] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0. 29. 10.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3. 3. 8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8. 29.] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8.  0. 29. 10.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.  8.] 
expected returns: [[182.17357]
 [181.52383]
 [188.0513 ]
 [176.99452]
 [181.52383]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 10.  8.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 3.  3.  3.  8.  0.  0.  3. 10.  8. 29.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.6646728515625



action possibilites: [-1. 10.  8. 15.] 
expected returns: [[151.99153]
 [147.32439]
 [152.05307]
 [146.81023]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 15.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15 15  8 15 15 11 15  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 3.  3.  3.  8.  0.  0.  3. 10.  8. 29.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 183.22201538085938



action possibilites: [-1] 
expected returns: [[197.19792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 3.  3.  3.  8.  0.  0.  3. 10.  8. 29.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 153.18829345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[192.98888]
 [196.66444]
 [179.89906]
 [199.55348]
 [200.21483]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 3.  3. 11.  8.  0.] 
adversary cards in discard: [ 3.  3.  3.  8.  0.  0.  3. 10.  8. 29.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.1979217529297






Player: 1 
cards in hand: [ 3.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  8.  0.] 
cards in discard: [ 3.  3.  3.  8.  0.  0.  3. 10.  8. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [15.  0. 11. 10. 10.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8] -> size -> 36 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  8.  0.] 
cards in discard: [ 3.  3.  3.  8.  0.  0.  3. 10.  8. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [15.  0. 11. 10. 10.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8] -> size -> 36 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [15.  0. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 10.] 
expected returns: [[188.9731 ]
 [183.23999]
 [189.73917]
 [183.50055]
 [183.50055]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11. 10. 10.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  4.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 200.21481323242188



action possibilites: [-1] 
expected returns: [[151.64386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  3.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -91 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 193.0551300048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[143.50471]
 [129.64473]
 [151.11693]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  3.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.64385986328125






Player: 1 
cards in hand: [10.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  3.] 
adversary cards in hand: [15.  3. 11.  3. 15.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15] -> size -> 37 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  3.] 
adversary cards in hand: [15.  3. 11.  3. 15.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15] -> size -> 37 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [15.  3. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.] 
expected returns: [[206.67207]
 [202.8889 ]
 [207.9182 ]
 [202.8889 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 11.  3. 15.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  3.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [10.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.11692810058594



action possibilites: [-1] 
expected returns: [[164.65013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3. 15.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [10.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0  -30    0    0
   64    0] 
sum of rewards: -101 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 210.4208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[158.44722]
 [143.69084]
 [166.0449 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3. 15.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [10.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 164.65013122558594






Player: 1 
cards in hand: [3. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [10.  3. 29.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 15.  0.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15. 11. 15.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  3. 29.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 15.  0.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15. 11. 15.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  3. 29.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 15.  0.  8.] 
adversary cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15. 11. 15.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
expected returns: [[161.73424]
 [161.38676]
 [157.20659]
 [161.38676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.  8.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15. 11. 15.  3.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [10.  3. 29.  3.  0.  8.  3.] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.04490661621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[156.01852]
 [158.89842]
 [146.30434]
 [161.38676]
 [161.73424]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  0.  8.] 
cards in discard: [ 8. 10. 11. 29. 29. 10. 10.  0. 15.  8. 11. 10.  0.  0. 11.  8. 29.  8.
  0. 10. 15. 11. 15.  0. 10. 10. 15. 11. 15.  3.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [10.  3. 29.  3.  0.  8.  3.] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 161.73423767089844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  3.] 
cards in discard: [10.  3. 29.  3.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [10.  3. 29.  3.  0.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [10.  3. 29.  3.  0.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [15.  0. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29. 11.] 
expected returns: [[236.81989]
 [230.11833]
 [230.11833]
 [242.34938]
 [239.26723]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15. 29. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.73423767089844



action possibilites: [-1. 15. 11. 15.] 
expected returns: [[184.41621]
 [174.59285]
 [187.3593 ]
 [174.59285]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 15.] 
cards in discard: [15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  2.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 235.95431518554688



action possibilites: [-1] 
expected returns: [[226.50497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.] 
cards in discard: [15. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -40    0    0
   64    0] 
sum of rewards: -61 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 193.9248504638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.3919 ]
 [222.63486]
 [204.3337 ]
 [226.08612]
 [226.41957]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.] 
cards in discard: [15. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 226.50497436523438






Player: 1 
cards in hand: [10.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [11.  0. 29. 11. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [11.  0. 29. 11. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [11.  0. 29. 11. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 8.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [11.  0. 29. 11. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 15.] 
expected returns: [[172.44029]
 [175.39598]
 [178.44722]
 [175.39598]
 [166.31686]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11. 15.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0.  3.  3. 29.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  8.  8.] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 226.41954040527344



action possibilites: [-1. 11. 11. 15. 10.] 
expected returns: [[180.69559]
 [183.39784]
 [183.39784]
 [172.96658]
 [173.38911]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15. 10.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  1.] 
adversary cards in hand: [ 3.  0.  3.  3. 29.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  8.  8.] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 173.29527282714844



action possibilites: [-1] 
expected returns: [[236.53264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0.  3.  3. 29.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  8.  8.] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0  -50    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 188.7810516357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[228.4027 ]
 [212.7923 ]
 [236.74394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 10.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0.  3.  3. 29.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  8.  8.] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 236.5326385498047






Player: 1 
cards in hand: [ 3.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 29.] 
cards in discard: [ 0. 10.  3.  0.  3.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8. 10. 10.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 0. 10.  3.  0.  3.  8.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8. 10. 10.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.] 
cards in discard: [ 0. 10.  3.  0.  3.  8.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8. 10. 10.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29.  8. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 10.  8.] 
expected returns: [[216.9111 ]
 [222.41754]
 [216.99307]
 [213.06429]
 [213.06429]
 [216.99307]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10. 10.  8.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 236.74391174316406



action possibilites: [-1. 10.  8. 10.] 
expected returns: [[232.2861 ]
 [228.1102 ]
 [232.27766]
 [228.1102 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 218.3773651123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[226.33896]
 [215.59526]
 [232.07922]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 232.2860870361328






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  8 10  3  0  8  3  3 11  8  3  3  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 10. 11.  0. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  0  8  3 11  8  3  3  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 10. 11.  0. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  0  8  3 11  8  3  3  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 10. 11.  0. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  0  8  3 11  8  3  3  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 10. 11.  0. 15.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[160.02502]
 [153.7219 ]
 [160.68861]
 [153.42947]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 15.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 8. 8. 3. 3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [29  8 10  0  8  3 11  8  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 232.07923889160156



action possibilites: [-1] 
expected returns: [[187.12926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 8. 8. 3. 3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [29  8 10  0  8  3 11  8  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: -78 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 159.00010681152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.10971]
 [182.86034]
 [171.85214]
 [184.94214]
 [187.39958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 8. 8. 3. 3.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [29  8 10  0  8  3 11  8  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 187.12925720214844






Player: 1 
cards in hand: [0. 8. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 3.] 
cards in discard: [0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  0  8  3 11  8  3  3  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11.  3. 15.  3.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11.  3. 15.  3.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11.  3. 15.  3.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[179.31355]
 [173.87027]
 [179.21864]
 [173.70851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 15.  3.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 10. 11.  3. 29.] 
adversary cards in discard: [0. 8. 8. 8. 3.] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 187.3995819091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[172.60878]
 [164.92378]
 [179.31355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3. 15.  3.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 10. 11.  3. 29.] 
adversary cards in discard: [0. 8. 8. 8. 3.] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 179.3135528564453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3. 29.] 
cards in discard: [0. 8. 8. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  8.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.  3.] 
cards in discard: [0. 8. 8. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  8.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  8.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 2 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10. 11. 15.  8.  8.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10. 11. 15.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.  8.  8.] 
expected returns: [[142.4327 ]
 [140.34865]
 [143.58714]
 [140.09953]
 [142.28934]
 [142.28934]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15.  8.  8.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 179.3135528564453



action possibilites: [-1] 
expected returns: [[180.64664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  8.  8.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 142.8830108642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[172.5902 ]
 [162.22958]
 [180.64668]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  8.  8.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 180.64663696289062






Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  8 11  8  3  3  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1. 11. 10. 15.  8.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1. 11. 10. 15.  8.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1. 11. 10. 15.  8.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[134.12752]
 [134.27315]
 [134.27315]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1. 11. 10. 15.  8.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8  8 10 10 29 10 10  8
 10  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 29.] 
adversary cards in discard: [8. 0. 3. 8.] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 180.64663696289062



action possibilites: [-1] 
expected returns: [[122.735344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1. 11. 10. 15.  8.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 29.] 
adversary cards in discard: [8. 0. 3. 8.] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 135.48477172851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[111.77533 ]
 [116.792496]
 [114.633896]
 [105.87342 ]
 [118.45576 ]
 [115.59721 ]
 [122.73533 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [15. 15. 29. 11.  0. 15. 15.  0. 15. 29. 11. 11. 15. 10.  8. 10. 29. 10.
  8. 10.  1. 11.  0. 10.  0. 15. 10. 11.  3. 15.  3.  1. 11. 10. 15.  8.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 10.  3.  3. 29.] 
adversary cards in discard: [8. 0. 3. 8.] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.73534393310547






Player: 1 
cards in hand: [11. 10.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3. 29.] 
cards in discard: [8. 0. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 15.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  3. 29.] 
cards in discard: [8. 0. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 15.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 15.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.  8.] 
expected returns: [[207.92555]
 [209.42719]
 [197.1811 ]
 [203.90958]
 [203.90958]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.73534393310547



action possibilites: [-1] 
expected returns: [[187.68611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  8.] 
cards in discard: [1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 208.9966583251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[176.28958]
 [157.81401]
 [188.08324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  8.  8.] 
cards in discard: [1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  3.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 187.6861114501953






Player: 1 
cards in hand: [10.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 10  8 11  8  3  3  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 29. 15. 15. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 29. 15. 15. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 29. 15. 15. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 29. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15. 15. 15.] 
expected returns: [[180.36046]
 [184.83623]
 [188.30632]
 [175.01495]
 [175.01495]
 [175.01495]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15. 15. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11.  3. 29.  8.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 188.083251953125



action possibilites: [-1. 15. 15. 11.] 
expected returns: [[172.85112]
 [166.0891 ]
 [166.0891 ]
 [180.10806]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11.  3. 29.  8.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 182.4424285888672



action possibilites: [-1] 
expected returns: [[187.94069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11.  3. 29.  8.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 177.08355712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[181.33258]
 [166.82086]
 [188.1742 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8. 11.  3. 29.  8.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 187.94068908691406






Player: 1 
cards in hand: [ 8. 11.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 29.  8.] 
cards in discard: [8. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 1. 11. 10. 15. 29.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3. 29.  8.] 
cards in discard: [8. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  3  0] -> size -> 9 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 1. 11. 10. 15. 29.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3. 29.  8.] 
cards in discard: [8. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 1. 11. 10. 15. 29.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 10. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 29.] 
expected returns: [[162.97467]
 [166.27942]
 [156.55432]
 [156.05112]
 [169.81001]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10. 15. 29.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 188.17420959472656



action possibilites: [-1. 10. 11.] 
expected returns: [[205.01942]
 [202.23402]
 [210.441  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 11.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 163.8915557861328



action possibilites: [-1] 
expected returns: [[210.0418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -58 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 208.46778869628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[202.21922]
 [211.41585]
 [206.36511]
 [187.2152 ]
 [213.66682]
 [209.52103]
 [210.80566]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  3.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 210.0417938232422



buy possibilites: [-1] 
expected returns: [[194.9919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 213.66685485839844






Player: 1 
cards in hand: [29.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  3.  0.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8.] 
cards in discard: [0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8  8 11  8  3  3  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  3.  0.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8 11  8  3  3  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  3.  0.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  8  8 11  8  3  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  3.  0.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[151.44751]
 [148.57156]
 [145.3466 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 194.9918975830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.53932]
 [146.45844]
 [135.45796]
 [148.2907 ]
 [151.15247]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 151.447509765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8. 10. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 8.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  8 11  8  3  3  0  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8.  9. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8.] 
cards in discard: [6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  8 11  8  3  3  0  0  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 23. 30.  8.  9. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8.] 
cards in discard: [6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [10.  1. 10. 10.  0.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [10.  1. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[130.12553]
 [124.82487]
 [124.82487]
 [124.82487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10. 10.  0.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.15245056152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[123.21224]
 [129.57104]
 [126.17666]
 [113.37112]
 [131.18365]
 [128.21927]
 [130.1255 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 10.  0.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  2.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.1255340576172



buy possibilites: [-1] 
expected returns: [[167.3899]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 10.  0.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  0.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0 -110    0    0
   54    0] 
sum of rewards: -31 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 131.18368530273438






Player: 1 
cards in hand: [ 0.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 15.  8. 10.  0.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 15.  8. 10.  0.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[145.24516]
 [139.22633]
 [143.25371]
 [139.5605 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 10.  0.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8.  8.  6.  3. 11.] 
adversary cards in discard: [ 0.  0.  0.  8. 29.] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.389892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.79553]
 [140.99745]
 [127.83903]
 [143.25371]
 [145.24516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 10.  0.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 8.  8.  6.  3. 11.] 
adversary cards in discard: [ 0.  0.  0.  8. 29.] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 145.2451629638672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  8.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  6.  3. 11.] 
cards in discard: [ 0.  0.  0.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 10.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.  0. 15.  8. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  6.  3. 11.] 
cards in discard: [ 0.  0.  0.  8. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 10.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.  0. 15.  8. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  6.  3. 11.] 
cards in discard: [ 0.  0.  0.  8. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 3.  0. 10.  8. 15.] 
adversary cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.  0. 15.  8. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[117.97177 ]
 [113.651505]
 [116.898636]
 [113.31345 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.  0. 15.  8. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 145.2451629638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.18495]
 [102.66219]
 [117.97177]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8. 15.] 
cards in discard: [ 1. 11. 15.  0.  8.  8. 11. 15.  1. 29. 11. 15. 15. 15. 11.  1. 11. 29.
 11.  1. 10.  0.  3.  0.  8. 15. 11. 10.  1. 10. 10.  0.  0. 15.  8. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 117.97177124023438



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 11. 15. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [11. 11. 15. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11. 11. 15. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 10. 29.] 
expected returns: [[159.62407]
 [161.63466]
 [161.63466]
 [150.80571]
 [151.2607 ]
 [164.92809]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15. 10. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 117.97177124023438



action possibilites: [-1. 11. 15. 15.] 
expected returns: [[121.56078 ]
 [121.246574]
 [110.262054]
 [110.262054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15.] 
cards in discard: [11. 10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 158.9143829345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[107.56054 ]
 [ 92.187035]
 [121.18003 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 15.] 
cards in discard: [11. 10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [8. 8. 0. 8. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3.] 
adversary owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 121.56080627441406






Player: 1 
cards in hand: [8. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 8. 0.] 
cards in discard: [0. 0. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8 11  8  3  3  0  0  6  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  1. 11.  0. 29.] 
adversary cards in discard: [11. 10. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [0. 0. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  1. 11.  0. 29.] 
adversary cards in discard: [11. 10. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0. 0. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  1. 11.  0. 29.] 
adversary cards in discard: [11. 10. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[140.4565 ]
 [143.24536]
 [145.67125]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0. 29.] 
cards in discard: [11. 10. 29. 11. 15. 15.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  8.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.18004608154297



action possibilites: [-1. 11.] 
expected returns: [[146.97728]
 [150.27922]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.] 
cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  8.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 141.5795135498047



action possibilites: [-1] 
expected returns: [[157.81306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  8.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 148.4469451904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
expected returns: [[155.16165]
 [156.07512]
 [155.96642]
 [153.7284 ]
 [156.10254]
 [156.2116 ]
 [156.03987]
 [157.44102]
 [154.65756]
 [156.78258]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  1. 10.  6.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  8.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 157.8130645751953



buy possibilites: [-1] 
expected returns: [[162.66586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1. 29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  1. 10.  5.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0.  8.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -130    0    0
  128    0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 157.44105529785156






Player: 1 
cards in hand: [ 0.  8.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  1. 10.  5.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  1.  8.  0. 11.] 
adversary cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1. 29. 29. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1 29] -> size -> 48 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  1. 10.  5.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  1.  8.  0. 11.] 
adversary cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1. 29. 29. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1 29] -> size -> 48 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.] 
cards in discard: [8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8 11  8  3  3  0  6  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  1. 10.  5.  8. 10.  0.  9.  0.] 
adversary cards in hand: [29.  1.  8.  0. 11.] 
adversary cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1. 29. 29. 11.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1 29] -> size -> 48 
adversary victory points: 2
player victory points: 1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 6 
Witch: 0 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  1.  8.  0. 11.] 
cards in discard: [11. 10. 29. 11. 15. 15.  0. 10.  1. 29. 29. 11.  1.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29 11 11 11 11 29 10  8 10 10 29 10 10  8 10
  8 10 11 15 15  8 15 15 11 15  8 15 15 15 15  1  1  1  1  1 11 11  1 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 23. 30.  8.  9. 10.  1.  0. 10.  5.  8. 10.  0.  9.  0.] 
adversary cards in hand: [ 0. 11.  3.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [29  8 11  8  3  3  0  6  0  0  8] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1
Learning step: 119994.484375
desired expected reward: 120157.1484375



