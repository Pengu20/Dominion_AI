 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.309822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.691731452941895
desired expected reward: 2.366011619567871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.948448]
 [23.52331 ]
 [23.482342]
 [22.536877]
 [23.144514]
 [24.537107]
 [24.003218]
 [24.403536]
 [23.591644]
 [23.962246]
 [24.166502]
 [24.563467]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6390969157218933
desired expected reward: 24.030384063720703



buy possibilites: [-1] 
expected returns: [[25.092285]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5310012698173523
desired expected reward: 22.951339721679688






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [14.  3.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.9511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6279433965682983
desired expected reward: 24.46434211730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.87969 ]
 [25.454548]
 [25.41358 ]
 [24.468117]
 [26.468348]
 [25.934454]
 [25.893486]
 [26.494709]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6643184423446655
desired expected reward: 25.509502410888672



buy possibilites: [-1] 
expected returns: [[26.767914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.1229873076081276
desired expected reward: 26.345359802246094






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.813375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.6508151888847351
desired expected reward: 25.51606559753418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.334915]
 [24.92334 ]
 [26.949934]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6891971826553345
desired expected reward: 26.37663459777832



buy possibilites: [-1] 
expected returns: [[28.736847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0. 11.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [25. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.595963478088379
desired expected reward: 15.327376365661621






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 11.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 11.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25. 14.  0.  1.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 11.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.381159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 11.  6.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7335574626922607
desired expected reward: 28.0032901763916





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.973627]
 [25.548485]
 [25.507515]
 [24.562052]
 [26.562283]
 [26.028393]
 [25.987427]
 [26.588646]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 11.  6.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6739686727523804
desired expected reward: 25.85440444946289



buy possibilites: [-1] 
expected returns: [[25.48173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 11.  6.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.122064508497715
desired expected reward: 25.865358352661133






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.85231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0. 25.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6196640133857727
desired expected reward: 24.8620662689209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.442337]
 [27.017199]
 [26.976233]
 [26.030766]
 [28.030996]
 [27.497107]
 [27.456135]
 [28.05736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0. 25.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7049469351768494
desired expected reward: 27.370084762573242



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0. 25.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0. 25.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9. 10.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0. 25.] 
cards in discard: [10.  0.  0.  0.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.612404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6895474195480347
desired expected reward: 27.367815017700195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.117317]
 [27.651207]
 [26.705742]
 [28.172081]
 [28.732338]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7205384969711304
desired expected reward: 28.057880401611328



buy possibilites: [-1] 
expected returns: [[26.767988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.629154205322266
desired expected reward: 15.711437225341797






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3.  0.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 6. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[28.475246]
 [27.889519]
 [28.448814]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6542032361030579
desired expected reward: 26.113784790039062



action possibilites: [-1] 
expected returns: [[27.94183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.14039233326911926
desired expected reward: 29.24028778076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.65168 ]
 [27.169891]
 [26.249054]
 [27.678078]
 [28.222721]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1005551666021347
desired expected reward: 27.84127426147461



buy possibilites: [-1] 
expected returns: [[27.64679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.] 
cards in discard: [10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  0.  8.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.059259165078401566
desired expected reward: 26.592422485351562






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 15. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.  8.] 
cards in discard: [16.  0.  1. 14.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [16.  0.  1. 14.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [16.  0.  1. 14.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [16.  0.  1. 14.  3.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.627201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [10.  0. 11.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0. 15. 15. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6774963140487671
desired expected reward: 26.96929359436035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.041246]
 [27.55946 ]
 [26.638626]
 [28.067646]
 [28.612291]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [10.  0. 11.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0. 15. 15. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7208021879196167
desired expected reward: 28.03227996826172



buy possibilites: [-1] 
expected returns: [[26.588154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [10.  0. 11.  6. 10.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [16.  0.  1. 14.  3.  0. 15. 15. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.47285374999046326
desired expected reward: 27.594791412353516






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [16.  0.  1. 14.  3.  0. 15. 15. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.  8.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [16.  0.  1. 14.  3.  0. 15. 15. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.  8.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [16.  0.  1. 14.  3.  0. 15. 15. 10.  0.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [10.  0. 11.  6. 10.  0.  0.  8.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.787968]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [10.  0. 11.  6. 10.  0.  0.  8.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6646215915679932
desired expected reward: 25.923532485961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.441702]
 [26.000998]
 [25.959911]
 [25.039076]
 [26.98631 ]
 [26.468098]
 [26.427011]
 [27.012745]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [10.  0. 11.  6. 10.  0.  0.  8.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.68210768699646
desired expected reward: 26.272462844848633



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.229963]
 [28.644232]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  1. 14. 15.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6541680693626404
desired expected reward: 26.35857582092285



action possibilites: [-1.] 
expected returns: [[29.25391]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  1. 14. 15.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.10718850791454315
desired expected reward: 28.70462989807129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.690496]
 [28.24979 ]
 [28.208704]
 [27.28787 ]
 [27.881653]
 [29.235098]
 [28.716888]
 [29.10581 ]
 [28.314268]
 [28.675808]
 [28.873566]
 [29.261538]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  1. 14. 15.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1271170824766159
desired expected reward: 29.126792907714844



buy possibilites: [-1] 
expected returns: [[31.126438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 10.  1. 14. 15.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 15.0
Learning step: 0.8706206679344177
desired expected reward: 29.744184494018555






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 14. 15.] 
cards in discard: [ 0.  8.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 15.] 
cards in discard: [ 0.  8.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 15.] 
cards in discard: [ 0.  8.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 15.] 
cards in discard: [ 0.  8.  0. 25.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.43268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 15. 11.  0. 16.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.  1. 14.  0. 10.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -600
   13    0] 
sum of rewards: -592 

action type: discard_down_to_3_cards - action 2
Learning step: -18.1051025390625
desired expected reward: 2.707021713256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.114414]
 [24.711527]
 [26.681482]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 15. 11.  0. 16.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.  1. 14.  0. 10.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6776378750801086
desired expected reward: 25.918689727783203



buy possibilites: [-1] 
expected returns: [[26.218061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 3. 15. 11.  0. 16.] 
adversary cards in discard: [ 0.  8.  0. 25.  3.  1. 14.  0. 10.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6281427145004272
desired expected reward: 24.486268997192383






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3. 15. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  0. 16.] 
cards in discard: [ 0.  8.  0. 25.  3.  1. 14.  0. 10.  1. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 10.  3. 11.  0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11.  0. 16.] 
cards in discard: [ 0.  8.  0. 25.  3.  1. 14.  0. 10.  1. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 10.  3. 11.  0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11.  0. 16.] 
cards in discard: [ 0.  8.  0. 25.  3.  1. 14.  0. 10.  1. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 10.  3. 11.  0.] 
adversary cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0] -> size -> 20 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 8. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[27.187239]
 [26.644941]
 [26.603342]
 [27.161896]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 11.  0.] 
cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6523358821868896
desired expected reward: 25.565725326538086



action possibilites: [-1] 
expected returns: [[32.56024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.  6.  6.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.15214891731739044
desired expected reward: 25.47660255432129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.106504]
 [30.703617]
 [32.673573]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  0.] 
cards in discard: [15. 10.  0.  0.  0.  0.  3.  3.  0.  0.  6.  6.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1936383843421936
desired expected reward: 32.36660385131836






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  8.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  8.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  7. 10.  7.] 
adversary cards in hand: [11.  8.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  8.  0.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [11.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[28.908092]
 [28.88275 ]
 [28.365793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 10. 16.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: -9.8265380859375
desired expected reward: 22.84703826904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.510935]
 [28.02789 ]
 [27.10805 ]
 [28.535707]
 [29.078003]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 10. 16.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7254677414894104
desired expected reward: 28.346843719482422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10. 16.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15 10  8 16 15 11  1  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  8.  7.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  7.  7.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  7.  7.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[29.004103]
 [28.617203]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 14. 11.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.717681884765625
desired expected reward: 28.360321044921875



action possibilites: [-1] 
expected returns: [[29.371012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 14. 11.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.10509201139211655
desired expected reward: 28.67782974243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.942942]
 [28.501493]
 [28.459894]
 [27.582516]
 [27.54005 ]
 [28.133556]
 [29.484667]
 [28.96771 ]
 [29.716887]
 [29.355326]
 [28.564548]
 [28.288948]
 [28.926111]
 [27.730392]
 [29.123106]
 [29.510008]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 29. 30.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 14. 11.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.12836511433124542
desired expected reward: 29.242647171020508



buy possibilites: [-1] 
expected returns: [[27.239122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1.  0.  3. 14. 11.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 4.0
Learning step: 1.408535361289978
desired expected reward: 28.99104881286621






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 14. 11.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11.] 
cards in discard: [10. 25.  0.  0.  3.  0. 15.  0. 11.  8. 16.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.283625]
 [30.699728]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.5970277190208435
desired expected reward: 25.19603729248047



action possibilites: [-1.] 
expected returns: [[31.382338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.1339917778968811
desired expected reward: 30.636070251464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.986452]
 [30.536453]
 [30.493734]
 [29.589958]
 [31.504007]
 [30.996729]
 [30.954006]
 [31.522976]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  6.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.16740834712982178
desired expected reward: 31.214929580688477



buy possibilites: [-1] 
expected returns: [[30.763435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.0968857929110527
desired expected reward: 30.899843215942383






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 15.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 10.  8.  3.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 10.  8.  3.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 10.  8.  3.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  3. 10.  8.  3.] 
adversary cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 6.  3. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[28.287315]
 [27.718346]
 [27.761065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  8.  3.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7789528369903564
desired expected reward: 29.984481811523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.73698 ]
 [26.340483]
 [28.273504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  8.  3.] 
cards in discard: [ 6. 11.  8.  0.  0.  3.  4. 15.  0.  3.  0.  0.  6.  8. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7114623188972473
desired expected reward: 27.575851440429688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 3. 15. 11.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 3. 15. 11.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  5.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[27.30023 ]
 [26.773983]
 [26.73126 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 10.  0.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.712963342666626
desired expected reward: 27.5605411529541





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.872057]
 [26.379332]
 [25.475557]
 [26.88233 ]
 [27.408577]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  0. 14. 10.  0.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6943901777267456
desired expected reward: 26.7635498046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 10.  0.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  6.  8.  0.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14. 10.  0.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  6.  8.  0.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[27.496618]
 [27.477648]
 [26.970371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  8.  0.] 
cards in discard: [ 0.  8. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 11. 25.  1. 16.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6836870908737183
desired expected reward: 26.724891662597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.26732 ]
 [26.774597]
 [25.870821]
 [27.277596]
 [27.803843]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  8.  0.] 
cards in discard: [ 0.  8. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 11. 25.  1. 16.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6953500509262085
desired expected reward: 26.93292808532715



buy possibilites: [-1] 
expected returns: [[27.919867]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  8.  0.] 
cards in discard: [ 0.  8. 10.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 11. 25.  1. 16.] 
adversary cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.42007923126220703
desired expected reward: 26.354515075683594






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 1. 11. 25.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 16.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 25.  1. 16.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  7.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3. 3. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3] -> size -> 24 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1. 16.  0.  0.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3. 3. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1. 16.  0.  0.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  9. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3. 3. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  1. 16.  0.  0.] 
cards in discard: [ 3. 15. 11.  8.  3.  8.  0.  8.  0.  0.  3.  3.  0. 14. 10.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3. 3. 6.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [3. 6. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.281498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 6.] 
cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  3. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.711640357971191
desired expected reward: 18.20822525024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.813347]
 [24.416847]
 [26.349869]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 6.] 
cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  3. 25. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6714860200881958
desired expected reward: 25.61001205444336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 25. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 15.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 15.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 15.] 
cards in discard: [0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [4. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.289408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6644573211669922
desired expected reward: 25.685413360595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.132954]
 [25.682951]
 [25.640232]
 [24.736456]
 [25.319555]
 [26.650505]
 [26.143229]
 [26.522657]
 [25.743338]
 [26.100506]
 [26.293337]
 [26.669476]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 27. 29.  8.  6.  9.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6652316451072693
desired expected reward: 25.624176025390625



buy possibilites: [-1] 
expected returns: [[29.236677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 10.  0.  3.  3. 11.  0.  6.  8.  0.  6.  3.  6.  3.  3.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.35739850997924805
desired expected reward: 25.676952362060547






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8
 14  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6 16] -> size -> 26 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6 16] -> size -> 26 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6 16] -> size -> 26 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[27.843332]
 [27.317083]
 [27.467194]
 [27.274363]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8. 15. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11  6 10  6 10  0  8 15  0  8  6  4  8  3
  6 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7361049652099609
desired expected reward: 28.500572204589844



action possibilites: [-1] 
expected returns: [[30.958508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 12
Learning step: -0.01692037470638752
desired expected reward: 26.382570266723633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.519108]
 [29.126942]
 [31.027735]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  6.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.16251039505004883
desired expected reward: 30.795997619628906



buy possibilites: [-1] 
expected returns: [[27.985783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  5.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [1. 8. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -9.129958152770996
desired expected reward: 19.99698257446289






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [1. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  5.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [16.  8. 10.  4.  3.] 
adversary cards in discard: [ 6.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6] -> size -> 24 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 27. 29.  8.  5.  8.  7.  4.  9. 10.  8. 10.  6. 10.  7.] 
adversary cards in hand: [16.  8. 10.  4.  3.] 
adversary cards in discard: [ 6.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6] -> size -> 24 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0. 0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 27. 29.  8.  5.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [16.  8. 10.  4.  3.] 
adversary cards in discard: [ 6.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6] -> size -> 24 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [16.  8. 10.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
expected returns: [[25.914164]
 [24.588747]
 [25.40617 ]
 [25.36156 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 10.  4.  3.] 
cards in discard: [ 6.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  5.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [11.  3. 10. 16.  8.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7211183309555054
desired expected reward: 27.264663696289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.571007]
 [24.17884 ]
 [26.079632]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 10.  4.  3.] 
cards in discard: [ 6.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  5.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [11.  3. 10. 16.  8.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6670409440994263
desired expected reward: 25.377315521240234



buy possibilites: [-1] 
expected returns: [[29.080322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 10.  4.  3.] 
cards in discard: [ 6.  8. 15.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [11.  3. 10. 16.  8.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.570021629333496
desired expected reward: 14.608819007873535






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [11.  3. 10. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 16.  8.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  6. 11.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10. 16.  8.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  6. 11.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[26.838568]
 [26.330572]
 [26.829714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  6. 11.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [15. 14.  1. 14.  0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0. 11.  3. 10. 16.
  8.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7418882846832275
desired expected reward: 28.33843421936035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.4896  ]
 [25.988743]
 [25.097433]
 [26.49023 ]
 [26.998226]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  6. 11.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [15. 14.  1. 14.  0.] 
adversary cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0. 11.  3. 10. 16.
  8.] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6804202795028687
desired expected reward: 26.173728942871094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [15. 14.  1. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  1. 14.  0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0. 11.  3. 10. 16.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 14.  0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0. 11.  3. 10. 16.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 14.  0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0. 11.  3. 10. 16.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 27. 29.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 14.  0.] 
cards in discard: [ 0.  0. 11.  0.  3. 25. 15.  8. 29.  1.  8.  0.  0.  0. 11.  3. 10. 16.
  8.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29
  4] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 28.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.599297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 28.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [25. 15.  1.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29
  4] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -1500    37     0] 
sum of rewards: -1468 

action type: discard_down_to_3_cards - action 2
Learning step: -44.47091293334961
desired expected reward: -20.447315216064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.137842]
 [25.745678]
 [27.64647 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 27. 28.  8.  4.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [25. 15.  1.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29
  4] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6972373127937317
desired expected reward: 26.90205955505371



buy possibilites: [-1] 
expected returns: [[25.740364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 28.  8.  3.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [25. 15.  1.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29
  4] -> size -> 25 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.652095794677734
desired expected reward: 16.093582153320312






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [25. 15.  1.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  1.  3. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25 15  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29
  4] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 28.  8.  3.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.  3.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.  3.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  4.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.  3.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  3.] 
cards in discard: [1. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.  3.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.261211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.  3.
  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [11. 15. 14.  8. 11.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8] -> size -> 26 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6779682040214539
desired expected reward: 25.062395095825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.02431 ]
 [22.56806 ]
 [22.523449]
 [21.632145]
 [23.524082]
 [23.024942]
 [22.98033 ]
 [23.532936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 6.  8. 15.  6. 16.  8. 10.  4.  3.  8.  0.  0.  6. 11.  3.  0.  6.  3.
  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [11. 15. 14.  8. 11.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8] -> size -> 26 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.607516348361969
desired expected reward: 22.65369415283203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11. 15. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 14.  8. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 14.  8. 11.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  8. 11.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8. 15.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  8. 11.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 27. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8. 15.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  8. 11.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  8. 15.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 6.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[27.924915]
 [27.41692 ]
 [27.5607  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15.] 
cards in discard: [3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8 15  0  8  6  4  8  3  6 16  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  4.  0.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 4
Learning step: -0.7146448493003845
desired expected reward: 27.83713150024414



action possibilites: [-1] 
expected returns: [[26.373352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  4.  0.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.02796827256679535
desired expected reward: 25.134981155395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.058777]
 [24.677378]
 [26.519808]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8.  3.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  4.  0.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07199226319789886
desired expected reward: 26.301359176635742



buy possibilites: [-1] 
expected returns: [[27.264645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [3. 0. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  4.  0.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -9.00404167175293
desired expected reward: 15.673336029052734






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  4.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  4.  0.  0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [3. 0. 6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6] -> size -> 26 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  4.  0.  0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 26. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [3. 0. 6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6] -> size -> 26 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  4.  0.  0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 26. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 3.  6.  0.  0. 11.] 
adversary cards in discard: [3. 0. 6. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6] -> size -> 26 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 3.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.43241 ]
 [25.428177]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  0. 11.] 
cards in discard: [3. 0. 6. 8. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7009167671203613
desired expected reward: 26.56372833251953



action possibilites: [-1] 
expected returns: [[23.722017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [3. 0. 6. 8. 6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.10128828138113022
desired expected reward: 24.02771759033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.489042]
 [22.97242 ]
 [22.107643]
 [23.462465]
 [23.950075]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [3. 0. 6. 8. 6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.018196163699030876
desired expected reward: 23.703821182250977



buy possibilites: [-1] 
expected returns: [[24.745617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [3. 0. 6. 8. 6. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.035157620906829834
desired expected reward: 22.524202346801758






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4
  1  8  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0] -> size -> 28 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0] -> size -> 28 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 6.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0] -> size -> 28 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [6. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.468534]
 [23.980927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 6.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 14.  1.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.
  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.637496829032898
desired expected reward: 24.10811996459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.98431]
 [22.60291]
 [24.44534]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6. 6.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 25. 28.  8.  2.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 14.  1.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.
  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6366296410560608
desired expected reward: 23.831905364990234



buy possibilites: [-1] 
expected returns: [[25.358685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6. 6.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 29. 14.  1.  0.] 
adversary cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.
  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.561820030212402
desired expected reward: 13.041092872619629






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 14.  1.  0.] 
cards in discard: [ 1.  8. 16. 25.  1.  3.  3. 14. 11. 15.  8. 11.  0.  3. 10.  4.  0.  0.
  8.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  3.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0. 11.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.97847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [25.  1.  0.  8. 14.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6799865961074829
desired expected reward: 24.67869758605957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.494654]
 [20.978027]
 [20.113255]
 [21.468075]
 [21.955685]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [25.  1.  0.  8. 14.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5868307948112488
desired expected reward: 21.391639709472656



buy possibilites: [-1] 
expected returns: [[23.067446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [25.  1.  0.  8. 14.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5226314067840576
desired expected reward: 19.972023010253906






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [25.  1.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  8. 14.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 4.  3. 16.  0. 10.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  8.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 4. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  8.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 25. 28.  8.  1.  8.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 4. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  8.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 25. 28.  8.  1.  7.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 4. 16.  0.] 
adversary cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6  0] -> size -> 30 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 4. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[21.686739]
 [20.410961]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 16.  0.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  4  8  3  6 16  6  6
  6  6  3  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8.  1.  7.  7.  2.  9.  9.  8. 10.  6. 10.  7.] 
adversary cards in hand: [ 4. 11. 16.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8 16] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -2400    12     0] 
sum of rewards: -2393 

action type: discard_down_to_3_cards - action 7
Learning step: -72.14757537841797
desired expected reward: -52.816436767578125



action possibilites: [-1] 
expected returns: [[23.1809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 28.  8.  1.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 4. 11. 16.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8 16] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 25  0] 
sum of rewards: 40 

action type: gain_card_n - action 12
Learning step: 0.7764793038368225
desired expected reward: 23.007150650024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.923996]
 [21.545424]
 [23.376534]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 25. 28.  8.  1.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 4. 11. 16.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8 16] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.009167633019387722
desired expected reward: 23.171733856201172



buy possibilites: [-1] 
expected returns: [[24.218376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  6.  8.  6.  3.  0. 11.  3.  6.  0.  0.  6.  6.  8.  0.  6.  6.
  0.  6.  0.  3.  0.  3.  3. 10. 23.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 25. 28.  8.  1.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 4. 11. 16.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8 16] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.046573102474212646
desired expected reward: 21.970569610595703






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 4. 11. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 11. 16.  3.  0.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  1 25  8 16 15 11  1  0 10 11  8  0  3  8 14  0  0 29  4  1
  8  3  0  8 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  1.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 0.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 0.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 10.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 3. 10.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[26.158487]
 [25.625286]
 [25.66937 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  8.  3.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6047496199607849
desired expected reward: 23.61362648010254



action possibilites: [-1.  8.] 
expected returns: [[25.540493]
 [25.051376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  8.  3.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.052637729793787
desired expected reward: 25.572649002075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.10326 ]
 [25.555801]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  8.  8.  3.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.053979549556970596
desired expected reward: 25.486513137817383






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  8.  3.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 3.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 3.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[24.128872]
 [22.853096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.  0.  0.] 
cards in discard: [10.  3.  3.  6.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [0. 1. 0. 8. 0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0. 15.  3.  8.  8.  3.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6686790585517883
desired expected reward: 24.887121200561523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[22.79809 ]
 [23.27725 ]
 [23.761513]
 [24.25063 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.  0.  0.] 
cards in discard: [10.  3.  3.  6.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [0. 1. 0. 8. 0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0. 15.  3.  8.  8.  3.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6253560185432434
desired expected reward: 23.50351333618164



buy possibilites: [-1] 
expected returns: [[23.797735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.  0.  0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [0. 1. 0. 8. 0.] 
adversary cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0. 15.  3.  8.  8.  3.] 
adversary owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5840665102005005
desired expected reward: 22.21402359008789






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 0.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0. 15.  3.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 14  1 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8
  3  0  8 16  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 23.  0.  6.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0. 15.  3.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 23.  0.  6.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 29.  0. 14.  1.  0. 11. 16. 14. 25.  1.  0.  8.  6. 16.  4.  3.  0.
  0. 15.  3.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 23.  0.  6.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0. 23.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[21.677435]
 [20.540754]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 23.  0.  6.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [25. 15.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6410930156707764
desired expected reward: 23.15664291381836



action possibilites: [-1.] 
expected returns: [[22.023819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [25. 15.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.06502744555473328
desired expected reward: 20.60578155517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.7092  ]
 [21.232445]
 [21.18836 ]
 [20.885965]
 [22.151781]
 [21.672623]
 [22.032564]
 [21.288475]
 [21.628538]
 [21.811718]
 [22.161741]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0] -> size -> 32 
action values: 0 
buys: 2 
player value: 4 
card supply: [18. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [25. 15.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.01662626303732395
desired expected reward: 22.04044532775879



buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.568828]
 [16.08949 ]
 [16.045658]
 [15.745   ]
 [17.004726]
 [16.527897]
 [16.887772]
 [16.147099]
 [16.484062]
 [16.667763]
 [17.017473]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  7.] 
adversary cards in hand: [25. 15.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.006476325914263725
desired expected reward: 20.71567726135254



buy possibilites: [-1] 
expected returns: [[26.870073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [25. 15.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 15.0
Learning step: 1.1921029090881348
desired expected reward: 17.859865188598633






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [25. 15.  6. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 16. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15.  6. 16. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15] -> size -> 34 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 16. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15] -> size -> 34 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6. 16. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15] -> size -> 34 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.41284 ]
 [17.923265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 11.  1. 16.  8.] 
adversary cards in discard: [15. 25.  6. 16. 10.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7648235559463501
desired expected reward: 26.105249404907227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.014647]
 [17.491476]
 [17.973719]
 [18.463291]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  2.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 11.  1. 16.  8.] 
adversary cards in discard: [15. 25.  6. 16. 10.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5146316289901733
desired expected reward: 17.89820671081543



buy possibilites: [-1] 
expected returns: [[20.535858]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 11.  1. 16.  8.] 
adversary cards in discard: [15. 25.  6. 16. 10.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.23358501493930817
desired expected reward: 17.740131378173828






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  1. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1. 16.  8.] 
cards in discard: [15. 25.  6. 16. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10 11  8  0  3  8 14  0  0 29  4  1  8  3  0
  8 16  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8] -> size -> 35 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8.] 
cards in discard: [15. 25.  6. 16. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8] -> size -> 35 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8.] 
cards in discard: [15. 25.  6. 16. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 0. 6. 6. 8.] 
adversary cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.  0.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8] -> size -> 35 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.275251]
 [17.785679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 8.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.  0.  6.  3.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29. 14. 14.  3.  0.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5762418508529663
desired expected reward: 19.95961570739746





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.855944]
 [18.304586]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 8.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.  0.  6.  3.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29. 14. 14.  3.  0.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5121436715126038
desired expected reward: 17.763107299804688



buy possibilites: [-1] 
expected returns: [[16.14931]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 8.] 
cards in discard: [10.  3.  3.  6.  8.  0.  0.  3.  6. 16.  0.  0.  0. 15. 23.  6.  0.  0.
  6.  0.  8.  0.  6.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29. 14. 14.  3.  0.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: -6.0 

action type: buy - action 0.0
Learning step: -0.5161104798316956
desired expected reward: 16.33983039855957






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [29. 14. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14. 14.  3.  0.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1. 14. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  3.  8.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  3.  8.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1] -> size -> 28 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  3.  8.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  6.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.805948]
 [21.793203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4055703580379486
desired expected reward: 15.743739128112793





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.45102 ]
 [21.899664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6.  3. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.] 
adversary owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5803163051605225
desired expected reward: 21.22563362121582



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 14 25  8 16 15  1  0 10  8  0  3  8 14  0  0 29  4  1  8  3  0  8
 16  6  0  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.589457]
 [19.056047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  3.] 
cards in discard: [ 6.  0.  6.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 0. 4. 8. 0.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.  8.
  3.] 
adversary owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6035408973693848
desired expected reward: 21.296123504638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.222916]
 [18.699743]
 [19.181984]
 [19.671556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  3.] 
cards in discard: [ 6.  0.  6.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 0. 4. 8. 0.] 
adversary cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.  8.
  3.] 
adversary owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5372433662414551
desired expected reward: 19.052213668823242



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 0. 4. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 8. 0.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.  8.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 8. 0.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.  8.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  1.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 8. 0.] 
cards in discard: [15. 25.  6. 16. 10.  1. 16.  8.  1.  8.  0.  0. 29. 14. 14.  3.  8.  8.
  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [8. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.568216]
 [23.078646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [16. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0  8] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4947366714477539
desired expected reward: 19.176822662353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.30402 ]
 [22.780848]
 [23.752666]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [16. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0  8] -> size -> 27 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6144207715988159
desired expected reward: 22.95379638671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [16. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 25  8 16 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0
  1  0  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  9.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 25. 28.  8.  0.  7.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [29. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 3.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.240253]
 [18.75068 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 3.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  8. 14.  0.  3.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6626134514808655
desired expected reward: 23.090051651000977





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.82397 ]
 [19.272615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 3.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  8. 14.  0.  3.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5309295058250427
desired expected reward: 18.709325790405273



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0.  3.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  6.  8. 23.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0.  3.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  6.  8. 23.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0.  3.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  6.  8. 23.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  6.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
expected returns: [[19.027643]
 [18.53807 ]
 [17.895037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  8. 23.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 8. 3. 1. 8.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.532930314540863
desired expected reward: 18.73968505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.93572 ]
 [17.40387 ]
 [18.356926]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  8. 23.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 8. 3. 1. 8.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5149248242378235
desired expected reward: 17.852563858032227



buy possibilites: [-1] 
expected returns: [[16.264977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  8. 23.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [3. 8. 3. 1. 8.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -0.5472893118858337
desired expected reward: 16.388429641723633






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 1. 8.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0  0] -> size -> 37 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 8.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0  0] -> size -> 37 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 8.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0  0] -> size -> 37 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[16.3545  ]
 [15.877882]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6
  6  3  0  6  0 23  0  0  0 15  8  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 29.  8.  0.  1.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.468228816986084
desired expected reward: 15.796747207641602



action possibilites: [-1] 
expected returns: [[15.064287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 29.  8.  0.  1.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.15244874358177185
desired expected reward: 15.343324661254883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.762279]
 [14.230429]
 [15.183487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 29.  8.  0.  1.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0  0] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15085001289844513
desired expected reward: 15.215137481689453






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8.  0.  1.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 15.  6.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0  0 29  4  1  8  3  0  8 16  6  0  1
  0  8 29 16  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 15.  6.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 15.  6.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  8.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 15.  6.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  3. 15.  6.] 
adversary cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[14.26506 ]
 [13.925018]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  6.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3
  0  6  0 23  0  0  0 15  8  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  6. 25.  4. 14.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4571496248245239
desired expected reward: 14.726337432861328



action possibilites: [-1] 
expected returns: [[18.06176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  6. 25.  4. 14.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.2218979299068451
desired expected reward: 14.146915435791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[16.645208]
 [17.15728 ]
 [17.113361]
 [16.81766 ]
 [18.057945]
 [17.942743]
 [17.2143  ]
 [17.545876]
 [17.726372]
 [18.066416]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  7.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  6. 25.  4. 14.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09248782694339752
desired expected reward: 18.154247283935547



buy possibilites: [-1] 
expected returns: [[18.634312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 6.  0.  6.  3. 11.  0. 10.  6.  0.  3.  8.  0.  6.  0.  3.  6.  6.  0.
  8.  3.  0.  0.  0.  6.  8. 23.  8.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 8.  6. 25.  4. 14.] 
adversary cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: 0.2389218509197235
desired expected reward: 18.2968692779541






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8.  6. 25.  4. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 25.  4. 14.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 25.  4. 14.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 25.  4. 14.] 
cards in discard: [29. 16. 10. 16.  0.  0.  1.  0.  0.  8. 14.  0.  3.  0.  3.  8.  3.  1.
  8.  8.  1. 29. 29. 15.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 11.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
expected returns: [[17.932417]
 [17.923948]
 [17.4558  ]
 [16.683662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 1. 16.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29  0] -> size -> 31 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5243800282478333
desired expected reward: 18.10993194580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.536016]
 [17.957222]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 1. 16.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29  0] -> size -> 31 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5053907632827759
desired expected reward: 17.42702865600586



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 1. 16.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25  8 15  1 10  8  3  8 14  0 29  4  1  8  3  0  8 16  6  0  1  0
  8 29 16  0  0 29  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [6. 6. 0. 8. 8.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [6. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[13.809403]
 [13.335838]
 [13.335838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 8.] 
cards in discard: [ 3. 11.  8.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 1. 8. 6. 0.] 
adversary cards in discard: [0. 8. 1.] 
adversary owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5463699698448181
desired expected reward: 17.41085433959961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.366745]
 [13.778085]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 8.] 
cards in discard: [ 3. 11.  8.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 1. 8. 6. 0.] 
adversary cards in discard: [0. 8. 1.] 
adversary owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.42553985118865967
desired expected reward: 13.38386344909668



buy possibilites: [-1] 
expected returns: [[17.022533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 8. 8.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 1. 8. 6. 0.] 
adversary cards in discard: [0. 8. 1.] 
adversary owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: -6.0 

action type: buy - action 0.0
Learning step: -0.3722657561302185
desired expected reward: 11.99448013305664






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 6. 0.] 
cards in discard: [0. 8. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25 15  1 10  8  3  8 14 29  4  1  8  3  0  8  6  0  1  0  8 29 16
  0  0 29  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  6.  0. 23.  3.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [0. 8. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  6.  0. 23.  3.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [0. 8. 1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  6.  0. 23.  3.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 6.  6.  0. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[13.269705]
 [12.162863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 23.  3.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29. 14.  8.  4. 29.] 
adversary cards in discard: [0. 8. 1. 8. 6. 0.] 
adversary owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0] -> size -> 27 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5259928107261658
desired expected reward: 16.496540069580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.422028]
 [12.814505]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 23.  3.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [29. 14.  8.  4. 29.] 
adversary cards in discard: [0. 8. 1. 8. 6. 0.] 
adversary owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0] -> size -> 27 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4055176079273224
desired expected reward: 12.40186595916748



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [29. 14.  8.  4. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  8.  4. 29.] 
cards in discard: [0. 8. 1. 8. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  8.  4. 29.] 
cards in discard: [0. 8. 1. 8. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  8.  4. 29.] 
cards in discard: [0. 8. 1. 8. 6. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  3.  6. 11.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[13.388013]
 [13.384448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 11.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  8.] 
adversary cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
adversary owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.39387592673301697
desired expected reward: 12.42062759399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.996609]
 [13.397974]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  6. 11.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  8.] 
adversary cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
adversary owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4168474078178406
desired expected reward: 12.971165657043457



buy possibilites: [-1] 
expected returns: [[15.717612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  6. 11.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [10.  8.  3.  0.  8.] 
adversary cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
adversary owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -0.40486329793930054
desired expected reward: 11.591744422912598






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [10.  8.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  8.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.  8.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  8. 25.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  8. 29.  0.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3 14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0
 29  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.  8.] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  0.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.  8.] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  0.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25.  8.] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.495173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  1.  0. 15.] 
adversary cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0.] 
adversary owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46932902932167053
desired expected reward: 15.248283386230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[13.276203]
 [13.782778]
 [13.739046]
 [13.445699]
 [14.674004]
 [14.559185]
 [13.839382]
 [14.167428]
 [14.345958]
 [14.677568]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  6.] 
adversary cards in hand: [ 3.  3.  1.  0. 15.] 
adversary cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0.] 
adversary owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.43600621819496155
desired expected reward: 14.05916690826416



buy possibilites: [-1] 
expected returns: [[11.852682]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  3.  1.  0. 15.] 
adversary cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0.] 
adversary owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0  0] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -3  0  0 32  0] 
sum of rewards: 24 

action type: buy - action 15.0
Learning step: 0.41407445073127747
desired expected reward: 14.760032653808594






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0. 15.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  0  1  0  8 29 16  0  0 29
  0  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 8.  0. 15.  3.  6.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29 16  0  0 29  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 8.  0. 15.  3.  6.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29 16  0  0 29  0
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6. 10.  5.] 
adversary cards in hand: [ 8.  0. 15.  3.  6.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 0.  8.  1.  8.  6.  0.  0. 29. 14.  8.  4. 29.  0. 10. 25.  8.  0.  8.
 29.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29 16  0  0 29  0
  0  0  0 22] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0. 15.  3.  6.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 8.  0. 15.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[11.893369]
 [11.426959]
 [11.561757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  3.  6.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  3.  0. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29 16  0  0 29  0
  0  0  0 22] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3829345405101776
desired expected reward: 11.469747543334961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.447707]
 [11.849073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  3.  6.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  3.  0. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29 16  0  0 29  0
  0  0  0 22] -> size -> 28 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3882715404033661
desired expected reward: 11.505097389221191



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 16. 14.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14 25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29 16  0  0 29  0
  0  0  0 22] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.  8.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.  8.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.  8.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.  8.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[11.067521]
 [10.557382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.  8.  0. 15.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [29.  6. 25. 10.  0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.39140585064888
desired expected reward: 11.45766830444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 9.669941]
 [10.172995]
 [10.129567]
 [11.063956]
 [10.557383]
 [11.067522]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [ 3. 11.  8.  0. 16.  0.  6.  6.  0.  8.  8.  6.  6.  0. 23.  3.  0.  6.
  0.  3.  6. 11. 15.  0.  0.  3.  0.  0.  8.  0. 15.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [29.  6. 25. 10.  0.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3710578978061676
desired expected reward: 10.696463584899902



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [29.  6. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 25. 10.  0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10.  0. 14.  0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10.  0. 14.  0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 26. 30. 25. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10.  0. 14.  0.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [8. 0. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[16.986856]
 [16.520449]
 [16.520449]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [15.  8.  8.  4.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30627554655075073
desired expected reward: 10.761245727539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.62672 ]
 [17.028088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [15.  8.  8.  4.  3.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4866965115070343
desired expected reward: 16.500160217285156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [15.  8.  8.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  4.  3.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [8. 0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.  4.  3.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [8. 0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.  4.  3.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [8. 0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [16.  0.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[17.100744]
 [15.868875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  3.  0.] 
cards in discard: [8. 0. 8. 6. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 29.  1.  8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.48645856976509094
desired expected reward: 16.541627883911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.733794]
 [16.196636]
 [17.13516 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  3.  0.] 
cards in discard: [8. 0. 8. 6. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 24. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 29.  1.  8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4896548092365265
desired expected reward: 16.611087799072266



buy possibilites: [-1] 
expected returns: [[19.433691]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  3.  0.] 
cards in discard: [8. 0. 8. 6. 3. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 29.  1.  8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3  0] -> size -> 29 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -4  0  0  8  0] 
sum of rewards: -1 

action type: buy - action 3.0
Learning step: -0.30418816208839417
desired expected reward: 15.892448425292969






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.  8.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  1  8  3  8  6  1  0  8 29  0  0 29  0  0  0
  0 22  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  1  0  8 29  0  0 29  0  0  0  0
 22  0  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  1  0  8 29  0  0 29  0  0  0  0
 22  0  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15  3] -> size -> 39 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [8. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[15.898478]
 [15.446954]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  6 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0
  6  0 23  0  0  0 15  8  0  0 11  0  0 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  1.  8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  1  0  8 29  0  0 29  0  0  0  0
 22  0  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5679731369018555
desired expected reward: 18.865718841552734



action possibilites: [-1] 
expected returns: [[13.946334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  1.  8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  1  0  8 29  0  0 29  0  0  0  0
 22  0  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 13
Learning step: 0.13100866973400116
desired expected reward: 15.645271301269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.7346525]
 [14.103342 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  1.  8.] 
adversary cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  1  0  8 29  0  0 29  0  0  0  0
 22  0  3  0] -> size -> 28 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1739465594291687
desired expected reward: 14.120280265808105






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.  8.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  1  0  8 29  0  0 29  0  0  0  0
 22  0  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 11.  6.  8.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 11.  6.  8.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 23. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 11.  6.  8.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 0.  8.  3.  0.  3. 25. 29.  6. 10.  0. 14.  0.  0. 15.  8.  8.  4.  3.
  8.  0.  0. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 22. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 11.  6.  8.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
adversary victory points: -3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[15.673247]
 [15.677324]
 [15.221724]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  8.  0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 22. 28.  8.  0.  6.  6.  0.  9.  7.  8.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  8.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.40977543592453003
desired expected reward: 13.693565368652344



action possibilites: [-1] 
expected returns: [[15.9461355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 22. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  8.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 30 

action type: gain_card_n - action 6
Learning step: 0.6493300199508667
desired expected reward: 14.586141586303711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[14.612035 ]
 [15.0676365]
 [15.985008 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 22. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  8.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.13304553925991058
desired expected reward: 16.079181671142578



buy possibilites: [-1] 
expected returns: [[18.28328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  3.  8.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 21 

action type: buy - action 3.0
Learning step: 0.36994534730911255
desired expected reward: 15.437581062316895






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  8.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  3. 22.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 37 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  3. 29. 15.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 37 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8.  3. 29. 15.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.] 
adversary owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 37 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6.  6.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[15.646646]
 [15.326908]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0
  0  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [0. 8. 8. 4. 8.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5355514883995056
desired expected reward: 17.74772834777832



action possibilites: [-1] 
expected returns: [[13.822978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [0. 8. 8. 4. 8.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.1353340446949005
desired expected reward: 15.462242126464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[12.532343]
 [13.031425]
 [12.987944]
 [12.697722]
 [13.909393]
 [13.794439]
 [13.086496]
 [13.41031 ]
 [13.585578]
 [13.905316]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [0. 8. 8. 4. 8.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1761908084154129
desired expected reward: 13.999168395996094



buy possibilites: [-1] 
expected returns: [[15.637279]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 3. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [0. 8. 8. 4. 8.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -2.  0.  0.  0.  0.] 
sum of rewards: 13.0 

action type: buy - action 0.0
Learning step: 0.17822112143039703
desired expected reward: 12.710563659667969






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 4. 8.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 23. 15.  6.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 4. 8.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 23. 15.  6.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 4. 8.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 23. 15.  6.  0.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
adversary victory points: -2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 23. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 15.] 
expected returns: [[10.13123 ]
 [ 9.062924]
 [ 9.813726]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23. 15.  6.  0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5166206955909729
desired expected reward: 15.120657920837402



action possibilites: [-1. 15.] 
expected returns: [[11.661572]
 [11.341834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6.  0.  0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.2992158830165863
desired expected reward: 9.362140655517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[10.21204 ]
 [10.711122]
 [10.667641]
 [11.589089]
 [11.090006]
 [11.585013]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  0.  0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0] -> size -> 37 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  6.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.21668680012226105
desired expected reward: 11.878259658813477



buy possibilites: [ 0. -1.] 
expected returns: [[11.552306]
 [12.914659]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6.  0.  0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [25.  3.  0. 10.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  9  0] 
sum of rewards: 21 

action type: buy - action 11.0
Learning step: 0.41307714581489563
desired expected reward: 11.97323989868164






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [25.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 10.  0.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 10.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 25. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0. 14.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 10.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14. 25.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14. 25.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 26. 30. 21. 28.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14. 25.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
adversary victory points: -2
player victory points: 9 





Player: 0 
cards in hand: [ 0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[17.420223]
 [17.428701]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  7.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -3
     0 -1800    88     0] 
sum of rewards: -1720 

action type: discard_down_to_3_cards - action 1
Learning step: -52.011985778808594
desired expected reward: -32.180179595947266



action possibilites: [-1] 
expected returns: [[16.395727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  6.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 6
Learning step: 0.5112776160240173
desired expected reward: 16.207191467285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[15.033376]
 [15.487332]
 [16.395727]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  0.  8.  6.  3.  3. 16.  0.  6.  3.  0.  8. 14.  3. 11.  0.  6.  8.
  0.  0. 15.  6.  6.  0. 11. 23.  6. 15.  6.  0.  0.  0. 10. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  6.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12392526119947433
desired expected reward: 16.5196533203125






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  6.  9.  6.  9.  5.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
adversary victory points: -2
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  6.  9.  6.  9.  5.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
adversary victory points: -2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  7.  6.  9.  6.  9.  5.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
adversary victory points: -2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [22.  3.  3.  8.  3. 29. 15.  0.  0.  0.  8.  8.  4.  8.  4. 10. 14. 25.
  3.  0.  0.  0. 29.  0.  6. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
adversary victory points: -2
player victory points: 9 





Player: 0 
cards in hand: [16.  3.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[18.487677]
 [17.288939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [29.  0.  4.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29] -> size -> 31 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4527859091758728
desired expected reward: 15.942941665649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.155043]
 [18.517397]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [29.  0.  4.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29] -> size -> 31 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5159195065498352
desired expected reward: 17.971757888793945



buy possibilites: [-1] 
expected returns: [[14.820964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  0.  3.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [29.  0.  4.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29] -> size -> 31 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: -0.6590311527252197
desired expected reward: 16.49601173400879






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [29.  0.  4.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  4.  8.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [ 0. 16.  3.  6.  0.  3.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14  0] -> size -> 40 
adversary victory points: -2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  4.  8.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [ 0. 16.  3.  6.  0.  3.] 
adversary owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14  0] -> size -> 40 
adversary victory points: -2
player victory points: 9 


Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 0 
Gold: 0 
Estate: 4 
Duchy: 1 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 3 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 3 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [ 0. 16.  3.  6.  0.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  0  8  0  8  6  8  3  6 16  6  6  6  6  3  0  6  0 23  0  0
  0 15  8  0  0 11  0  0 15  3 14  3  0 11 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 21. 27.  8.  0.  6.  5.  0.  9.  6.  6.  9.  6.  9.  5.] 
adversary cards in hand: [29.  0.  4.  8.  8.] 
adversary cards in discard: [0.] 
adversary owned cards: [25 15 10  8  3  8 14 29  4  8  3  8  6  0  8 29  0  0 29  0  0  0  0 22
  0  3  0  3  0  4 29  0] -> size -> 32 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.594629287719727
desired expected reward: -0.7736654281616211



