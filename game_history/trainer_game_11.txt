 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.3223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   3  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 528 

action type: buy - action -1.0
Learning step: 13.733423233032227
desired expected reward: 267.06494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[316.66525]
 [317.1249 ]
 [317.0424 ]
 [316.66525]
 [320.23856]
 [318.6822 ]
 [318.69815]
 [331.10437]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.53447437286377
desired expected reward: 323.6556396484375



buy possibilites: [-1] 
expected returns: [[325.73953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -7.72710657119751
desired expected reward: 309.3977966308594






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[343.0546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.646058082580566
desired expected reward: 317.0934753417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[335.48154]
 [335.95847]
 [335.87296]
 [335.48154]
 [337.37555]
 [339.19083]
 [337.57504]
 [343.58643]
 [338.81577]
 [337.5918 ]
 [340.4148 ]
 [350.5949 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.638921737670898
desired expected reward: 334.40191650390625



buy possibilites: [-1] 
expected returns: [[299.33365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 29.0
Learning step: -8.944315910339355
desired expected reward: 334.64215087890625






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[279.75757]
 [273.5781 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.77546501159668
desired expected reward: 290.5581970214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[265.97375]
 [266.34155]
 [266.27567]
 [265.97375]
 [269.14124]
 [267.6866 ]
 [267.70053]
 [280.25717]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.133076667785645
desired expected reward: 274.1433410644531



buy possibilites: [-1] 
expected returns: [[308.31598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -5.579969882965088
desired expected reward: 260.7616271972656






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 8.  0.  0.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [ 1.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 8.  0.  0.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 1. 0.] 
adversary cards in discard: [ 1.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.0059]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [ 1.  0. 29.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.093485832214355
desired expected reward: 299.2225036621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[273.27567]
 [273.77866]
 [273.68878]
 [273.27567]
 [275.26328]
 [277.166  ]
 [275.4701 ]
 [281.77573]
 [276.76935]
 [275.48624]
 [278.44907]
 [288.98785]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 0.] 
cards in discard: [ 1.  0. 29.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.103371620178223
desired expected reward: 277.332763671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.8605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 3.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.605319976806641
desired expected reward: 281.38250732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[290.27155]
 [290.71463]
 [290.6359 ]
 [290.27155]
 [292.02176]
 [293.69885]
 [292.20428]
 [297.7583 ]
 [293.3489 ]
 [292.21896]
 [294.82886]
 [304.3929 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 3.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.89337158203125
desired expected reward: 299.7320251464844



buy possibilites: [-1] 
expected returns: [[289.6759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 3. 3. 3.] 
adversary cards in discard: [10.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -6.723735332489014
desired expected reward: 288.1051330566406






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 3.] 
cards in discard: [10.  0.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 3.] 
cards in discard: [10.  0.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 3.] 
cards in discard: [10.  0.  8.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[332.9307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.6104044914245605
desired expected reward: 282.06549072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[313.87003]
 [314.42795]
 [314.32913]
 [313.87003]
 [316.07852]
 [318.19296]
 [316.30746]
 [323.3148 ]
 [317.7521 ]
 [316.32648]
 [319.61862]
 [331.33582]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.012389183044434
desired expected reward: 322.1383361816406



buy possibilites: [-1] 
expected returns: [[311.0635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 10.0
Learning step: -9.0090970993042
desired expected reward: 307.3174133300781






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  8 10  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[263.7439 ]
 [258.71265]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.249794006347656
desired expected reward: 300.813720703125



action possibilites: [-1.] 
expected returns: [[297.01468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 29.0
Learning step: -5.885009288787842
desired expected reward: 253.47177124023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[279.37802]
 [279.83185]
 [279.37802]
 [279.75174]
 [279.51202]
 [279.37802]
 [281.18558]
 [282.91693]
 [281.37125]
 [286.14365]
 [287.3885 ]
 [282.55524]
 [283.96408]
 [281.38715]
 [282.3695 ]
 [284.16174]
 [294.38846]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.054936408996582
desired expected reward: 288.9597473144531






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [ 0. 10.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  1.] 
adversary cards in discard: [29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [ 0. 10.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  1.] 
adversary cards in discard: [29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [ 0. 10.  8.  3.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  1.] 
adversary cards in discard: [29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 15.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[306.3329 ]
 [294.74875]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  1.] 
cards in discard: [29.  0.  0.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.57833194732666
desired expected reward: 285.81011962890625



action possibilites: [-1] 
expected returns: [[327.64938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [29.  0.  0.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 15.0
Learning step: -6.878733158111572
desired expected reward: 286.1381530761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[314.7976 ]
 [315.26575]
 [314.7976 ]
 [315.18173]
 [314.93607]
 [314.7976 ]
 [316.66406]
 [318.4468 ]
 [316.8566 ]
 [321.78302]
 [323.07605]
 [318.07877]
 [319.51895]
 [316.8722 ]
 [317.8862 ]
 [319.7251 ]
 [330.3454 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [29.  0.  0.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -8.785979270935059
desired expected reward: 318.8634033203125



buy possibilites: [-1] 
expected returns: [[324.30142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [29.  0.  0.  1.  0.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 10.0 

action type: buy - action 8.0
Learning step: -8.046048164367676
desired expected reward: 308.810546875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[299.70578]
 [287.91147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.174490928649902
desired expected reward: 314.1269226074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[284.9315 ]
 [285.34244]
 [285.2687 ]
 [284.9315 ]
 [288.21512]
 [286.7299 ]
 [286.74283]
 [298.5791 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8. 10. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.107414245605469
desired expected reward: 291.1343994140625



buy possibilites: [-1] 
expected returns: [[261.37485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -24.515640258789062
desired expected reward: 260.41583251953125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  3.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [1. 8. 0. 0. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [1. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[307.40042]
 [295.88544]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 3.] 
cards in discard: [ 6.  0. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29  1 15 10  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.4358367919921875
desired expected reward: 253.9390106201172



action possibilites: [-1] 
expected returns: [[273.6038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 6.  0. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 9
Learning step: -9.237868309020996
desired expected reward: 284.6412048339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[261.12747]
 [261.50848]
 [261.12747]
 [263.15268]
 [275.58728]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6.  0. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  3.  3.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  0. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -8.39477252960205
desired expected reward: 265.2090148925781






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.  3.] 
cards in discard: [ 1.  0.  0.  3.  0.  0. 29.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  3. 15.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  3.  3.] 
cards in discard: [ 1.  0.  0.  3.  0.  0. 29.  0.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 29.  3. 15.  0.] 
adversary cards in discard: [ 6.  0. 10.  3.  0.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 29.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[245.30255]
 [236.64659]
 [232.65445]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3. 15.  0.] 
cards in discard: [ 6.  0. 10.  3.  0.  0.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -10.107306480407715
desired expected reward: 265.47998046875



action possibilites: [-1. 15. 10.] 
expected returns: [[281.39526]
 [272.95105]
 [270.57172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 29.0
Learning step: -6.163600444793701
desired expected reward: 230.06771850585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[266.92517]
 [267.33054]
 [267.25824]
 [266.92517]
 [268.51672]
 [270.04468]
 [268.68558]
 [273.7412 ]
 [269.72754]
 [268.69644]
 [271.07574]
 [279.51938]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 15.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.667953491210938
desired expected reward: 272.727294921875



buy possibilites: [-1] 
expected returns: [[249.47885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 15.  0. 10.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -9.932985305786133
desired expected reward: 256.9921875






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [ 0. 29.  1.  3. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [ 0. 29.  1.  3. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[234.09299]
 [222.84087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [ 0. 29.  1.  3. 15.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -9.04023265838623
desired expected reward: 240.43861389160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.39171]
 [218.73578]
 [218.39171]
 [220.2191 ]
 [231.4712 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [ 0. 29.  1.  3. 15.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.337698936462402
desired expected reward: 224.68301391601562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[298.04968]
 [291.96805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.63015079498291
desired expected reward: 224.84107971191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[279.2876 ]
 [279.71524]
 [279.63904]
 [279.41464]
 [279.2876 ]
 [280.9676 ]
 [282.57953]
 [281.1453 ]
 [285.39264]
 [286.4805 ]
 [282.2449 ]
 [283.48996]
 [281.15683]
 [282.06726]
 [283.6676 ]
 [292.5649 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -10.208243370056152
desired expected reward: 287.67987060546875



buy possibilites: [-1] 
expected returns: [[230.38344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -29.5 

action type: buy - action 11.0
Learning step: -10.42034912109375
desired expected reward: 272.1591796875






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 8. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 8. 0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 15. 10.] 
adversary cards in discard: [11.  0.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 15 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 8. 0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 15. 10.] 
adversary cards in discard: [11.  0.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 15 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 8. 0. 3. 0. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 15. 10.] 
adversary cards in discard: [11.  0.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 15 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[235.93452]
 [223.78908]
 [226.4778 ]
 [223.80373]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15. 10.] 
cards in discard: [11.  0.  0. 29.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -8.581940650939941
desired expected reward: 221.80149841308594



action possibilites: [-1] 
expected returns: [[261.90872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.] 
cards in discard: [11.  0.  0. 29.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action 15.0
Learning step: -6.613193035125732
desired expected reward: 219.5095977783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[252.12021]
 [252.49667]
 [252.42899]
 [252.12021]
 [253.5984 ]
 [255.01653]
 [253.7554 ]
 [258.4495 ]
 [254.72253]
 [253.76506]
 [255.97404]
 [264.18585]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [11.  0.  0. 29.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -8.531851768493652
desired expected reward: 253.3768768310547



buy possibilites: [-1] 
expected returns: [[248.82233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [11.  0.  0. 29.  0.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 8 

action type: buy - action 29.0
Learning step: -6.923970699310303
desired expected reward: 251.52549743652344






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29] -> size -> 15 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  1. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  9.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29] -> size -> 15 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  1. 10.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29] -> size -> 15 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 6. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[207.76085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0. 29.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -9.983195304870605
desired expected reward: 238.83912658691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.44664]
 [198.76631]
 [198.7092 ]
 [198.44664]
 [200.92653]
 [199.84709]
 [199.85681]
 [208.46407]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0. 29.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.016456604003906
desired expected reward: 199.00228881835938



buy possibilites: [-1] 
expected returns: [[234.59315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 3. 3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0. 29.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -74.0 

action type: buy - action 0.0
Learning step: -8.343986511230469
desired expected reward: 190.1026611328125






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [11.  0.  0. 29.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [0. 0. 6. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [11.  0.  0. 29.  1. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [0. 0. 6. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [11.  0.  0. 29.  1. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 10.] 
adversary cards in discard: [0. 0. 6. 1. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0] -> size -> 16 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[279.72986]
 [269.9038 ]
 [273.736  ]
 [268.50842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 10.] 
cards in discard: [0. 0. 6. 1. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -7.831966400146484
desired expected reward: 226.7611846923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[265.29605]
 [265.63956]
 [265.29605]
 [267.11966]
 [278.35483]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 10.] 
cards in discard: [0. 0. 6. 1. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -9.973642349243164
desired expected reward: 266.86968994140625



buy possibilites: [-1] 
expected returns: [[229.23944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29. 10.] 
cards in discard: [0. 0. 6. 1. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 3.0
Learning step: -8.5393648147583
desired expected reward: 240.40567016601562






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  3  0  8  1 29  3 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0.  0. 29.  1. 10.  0.  3.  8.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  1. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [15.  0.  1. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.] 
expected returns: [[252.67505]
 [242.53406]
 [245.74815]
 [239.66833]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1. 29.  8.] 
cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1 29  1 15 10  8  6  0 11 29  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -6.088512420654297
desired expected reward: 223.1509246826172



action possibilites: [-1] 
expected returns: [[192.0196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.] 
cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 7
Learning step: -6.602328777313232
desired expected reward: 228.8530731201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[182.12334]
 [182.3875 ]
 [182.12334]
 [183.55096]
 [192.32399]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.] 
cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 27. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -4.575593948364258
desired expected reward: 187.4440155029297



buy possibilites: [-1] 
expected returns: [[194.11346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.] 
cards in discard: [ 0.  0.  6.  1.  3.  3.  3.  0.  0. 11. 29. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 36 

action type: buy - action 3.0
Learning step: -2.9518210887908936
desired expected reward: 179.43565368652344






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[167.03062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0. 11. 10.  8.] 
adversary cards in discard: [22.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -5.5608978271484375
desired expected reward: 188.5525665283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[155.5297 ]
 [155.94351]
 [155.86525]
 [155.5297 ]
 [158.812  ]
 [157.3717 ]
 [157.37708]
 [169.51065]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0. 11. 10.  8.] 
adversary cards in discard: [22.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -4.326557159423828
desired expected reward: 162.10791015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 10.  8.] 
cards in discard: [22.  0.  0.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [3. 0. 3. 6. 1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  8.] 
cards in discard: [22.  0.  0.  0.  1.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9.  9.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [3. 0. 3. 6. 1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  8.] 
cards in discard: [22.  0.  0.  0.  1.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  9.  9.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  3.  0. 11.  0.] 
adversary cards in discard: [3. 0. 3. 6. 1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[216.22119]
 [205.7084 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  0.] 
cards in discard: [3. 0. 3. 6. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9.  9.  8.  7. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -3.3512418270111084
desired expected reward: 166.159423828125



action possibilites: [-1] 
expected returns: [[254.15677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [3. 0. 3. 6. 1. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9.  9.  8.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 32 

action type: gain_card_n - action 6
Learning step: -2.7114098072052
desired expected reward: 197.8873291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[241.66193]
 [242.04861]
 [241.66193]
 [243.74255]
 [256.53192]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [3. 0. 3. 6. 1. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 26. 30.  8.  9.  9.  8.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -5.757302761077881
desired expected reward: 248.3994598388672



buy possibilites: [-1] 
expected returns: [[301.15182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [3. 0. 3. 6. 1. 8. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  8.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -283.0 

action type: buy - action 6.0
Learning step: -19.457181930541992
desired expected reward: 222.20474243164062






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  8.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 10.  1.] 
adversary cards in discard: [ 3.  0.  3.  6.  1.  8.  6. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  8.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 10.  1.] 
adversary cards in discard: [ 3.  0.  3.  6.  1.  8.  6. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [22.  0.  0.  0.  1.  0. 16. 11.  8.  0. 10.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 10.  1.] 
adversary cards in discard: [ 3.  0.  3.  6.  1.  8.  6. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[218.69315]
 [210.98615]
 [210.98615]
 [204.38962]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 10.  1.] 
cards in discard: [ 3.  0.  3.  6.  1.  8.  6. 11.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -10.469042778015137
desired expected reward: 290.6827697753906



action possibilites: [-1. 29. 10.  8.] 
expected returns: [[171.77898]
 [165.86713]
 [160.77737]
 [160.77353]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  1.  8.] 
cards in discard: [ 3.  0.  3.  6.  1.  8.  6. 11.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 29.0
Learning step: -5.885870933532715
desired expected reward: 203.4212188720703



action possibilites: [-1. 29.  8.] 
expected returns: [[170.0524 ]
 [165.16725]
 [161.00806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  0  1] 
sum of rewards: 38 

action type: take_action - action 10.0
Learning step: -2.2901551723480225
desired expected reward: 158.48721313476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[160.4206 ]
 [160.74966]
 [160.68648]
 [160.51923]
 [160.4206 ]
 [161.72855]
 [162.98007]
 [161.87057]
 [165.17924]
 [166.02977]
 [162.72522]
 [163.68855]
 [161.8747 ]
 [162.58319]
 [163.8306 ]
 [170.7648 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  6. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: -2.9635658264160156
desired expected reward: 167.08883666992188



buy possibilites: [-1] 
expected returns: [[147.50398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  8.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 39.0 

action type: buy - action 8.0
Learning step: -2.82468843460083
desired expected reward: 159.04586791992188






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 6. 1.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 6. 1.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 6. 1.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 3. 3. 6. 1.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[191.04964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 1.] 
cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0.  8. 22.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -3.2784759998321533
desired expected reward: 144.2255096435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[184.00195]
 [184.27097]
 [184.2192 ]
 [184.00195]
 [186.08463]
 [185.1811 ]
 [185.18407]
 [192.40771]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 1.] 
cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0.  8. 22.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -5.388853549957275
desired expected reward: 183.35440063476562



buy possibilites: [-1] 
expected returns: [[197.6559]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 1.] 
cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 25. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  1.  0.  8. 22.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 17 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 10.0 

action type: buy - action 3.0
Learning step: -4.263702869415283
desired expected reward: 179.95550537109375






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [11.  1.  0.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  8. 22.] 
cards in discard: [29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6.  8.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 22.] 
cards in discard: [29.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6.  8.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 22.] 
cards in discard: [29.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 24. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6.  8.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 22.] 
cards in discard: [29.  8.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [11.  6.  8.  3.  3.] 
adversary cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  6.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[180.6278 ]
 [171.14899]
 [169.87946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8.  3.  3.] 
cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [16.  1.  0. 11.  0.] 
adversary cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.564502239227295
desired expected reward: 191.09140014648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[169.41411]
 [169.41411]
 [181.78412]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.  3.  3.] 
cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [16.  1.  0. 11.  0.] 
adversary cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -5.658833980560303
desired expected reward: 174.11776733398438



buy possibilites: [-1] 
expected returns: [[155.6319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.  3.  3.] 
cards in discard: [ 8. 29. 10.  0. 29.  1.  8.  0.  3.  0.  3.  3.  6.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [16.  1.  0. 11.  0.] 
adversary cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action 0.0
Learning step: -7.068986415863037
desired expected reward: 162.34510803222656






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [16.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0. 11.  0.] 
cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0. 11.  0.] 
cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[213.82346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22. 16.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -3.604278326034546
desired expected reward: 152.02761840820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[199.6356 ]
 [200.04529]
 [199.96661]
 [199.6356 ]
 [202.79622]
 [201.42526]
 [201.4289 ]
 [212.54756]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  5. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22. 16.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.635173320770264
desired expected reward: 205.6900177001953



buy possibilites: [-1] 
expected returns: [[174.31743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22. 16.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 8.0
Learning step: -6.649121284484863
desired expected reward: 194.77613830566406






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [29.  8.  3.  3. 11.  1.  0.  8. 22. 16.  1.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0. 29.  6.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0. 29.  6.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0. 29.  6.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  0. 29.  6.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  3.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[187.81966]
 [181.13141]
 [181.13141]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  6.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  1. 29. 11.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.2537055015563965
desired expected reward: 169.063720703125



action possibilites: [-1. 29.] 
expected returns: [[161.90305]
 [155.46448]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  6.  3.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  1. 29. 11.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 29.0
Learning step: -4.904458522796631
desired expected reward: 172.7907257080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.24681]
 [148.60907]
 [148.24681]
 [150.2177 ]
 [162.31349]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  6.  3.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  8.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  1. 29. 11.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -4.252572059631348
desired expected reward: 157.6504669189453



buy possibilites: [-1] 
expected returns: [[169.62881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  6.  3.] 
cards in discard: [8. 0. 0. 3. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8.  0.  1. 29. 11.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -303.0 

action type: buy - action 6.0
Learning step: -18.745695114135742
desired expected reward: 129.50112915039062






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  1. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 29. 11.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 1. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 11. 16.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3 11  0  0 22 16 11  3  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  7.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 1. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  6.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 1. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 23. 30.  8.  6.  9.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 1. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [8. 1. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [8. 1. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[164.63292]
 [154.13516]
 [154.13516]
 [154.13516]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 8. 8.] 
cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  8  6  0 11 29  0  3  3  8  6  8  3  0  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 22.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -5.597566604614258
desired expected reward: 164.03125



action possibilites: [-1] 
expected returns: [[126.84052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 22.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 4
Learning step: -3.8666770458221436
desired expected reward: 137.5450897216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[119.80181 ]
 [120.14228 ]
 [120.07731 ]
 [119.80181 ]
 [122.43843 ]
 [121.295685]
 [121.299576]
 [130.43803 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  4. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 22.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -3.222745180130005
desired expected reward: 123.6177749633789



buy possibilites: [-1] 
expected returns: [[136.92142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 22.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: 9.0 

action type: buy - action 8.0
Learning step: -2.5340518951416016
desired expected reward: 118.76162719726562






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 8. 22.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  1.  3.  0.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.  8.  8.  1.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3.  0.  0. 11.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.  8.  8.  1.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3.  0.  0. 11.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.  8.  8.  1.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3.  0.  0. 11.] 
cards in discard: [ 0. 10.  3.  0.  3.  0.  3.  6. 16. 29. 16.  8.  0.  1. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [10.  3.  1. 11.  6.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.  8.  8.  1.  0.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  1. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[251.57877]
 [239.21646]
 [240.75117]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 11.  6.] 
cards in discard: [ 8.  0.  0.  3.  3.  0.  6. 29.  3.  0. 29.  6.  3.  8.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  8.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.9856613874435425
desired expected reward: 134.93576049804688



action possibilites: [-1. 11.] 
expected returns: [[154.56137]
 [146.58026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  6.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  8.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 10.0
Learning step: -8.210687637329102
desired expected reward: 231.00576782226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.31978]
 [147.59694]
 [147.31978]
 [148.81012]
 [157.93251]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  6.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  8.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.982598066329956
desired expected reward: 150.57876586914062






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  3  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  7.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  8.  6.  0. 29.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  8.  6.  0. 29.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  8.  6.  0. 29.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.] 
adversary owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[170.75136]
 [160.7894 ]
 [165.44571]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  0. 29.] 
cards in discard: [10.  3.  1. 11.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16. 10.  0. 15.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.] 
adversary owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -4.36552095413208
desired expected reward: 153.5669708251953



action possibilites: [-1.  8.  8.] 
expected returns: [[208.76794]
 [197.50104]
 [197.50104]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 8.] 
cards in discard: [10.  3.  1. 11.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1 29  1 10  6  0 11 29  0  3  3  6  8  3  0  8  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16. 10.  0. 15.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.] 
adversary owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 29.0
Learning step: -2.733356475830078
desired expected reward: 159.9620361328125



action possibilites: [-1] 
expected returns: [[201.9272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  3.  1. 11.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16. 10.  0. 15.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.] 
adversary owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: trash_cards_n_from_hand - action 11
Learning step: -2.935516357421875
desired expected reward: 194.64205932617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[190.01398]
 [190.36235]
 [190.01398]
 [191.88504]
 [204.36488]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  3.  1. 11.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  3. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16. 10.  0. 15.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.] 
adversary owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -3.312480926513672
desired expected reward: 198.61471557617188



buy possibilites: [-1] 
expected returns: [[132.20203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  3.  1. 11.  6.  6.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  2. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16. 10.  0. 15.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.] 
adversary owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 56 

action type: buy - action 8.0
Learning step: -3.8197083473205566
desired expected reward: 188.06536865234375






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [16. 10.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0. 15.  0.] 
cards in discard: [11. 16.  1.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  2. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
adversary owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.] 
cards in discard: [11. 16.  1.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  2. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
adversary owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0.] 
cards in discard: [11. 16.  1.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  2. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
adversary owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  0.] 
cards in discard: [11. 16.  1.  8.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
adversary owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[130.45334]
 [121.16996]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1 29  1 10  0 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [6. 1. 3. 0. 0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -3.382488250732422
desired expected reward: 128.8195343017578



action possibilites: [-1] 
expected returns: [[122.63162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [6. 1. 3. 0. 0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.3534436225891113
desired expected reward: 116.04307556152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.5129  ]
 [113.51398 ]
 [124.472534]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [6. 1. 3. 0. 0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -2.6228294372558594
desired expected reward: 120.0087890625



buy possibilites: [-1] 
expected returns: [[65.05958]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [6. 1. 3. 0. 0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -294 

action type: buy - action 6.0
Learning step: -18.9118595123291
desired expected reward: 94.60211944580078






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 0. 0.] 
cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 29.  3.  1.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.  6.  8.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 0. 0.] 
cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0.  3. 29.  3.  1.] 
adversary cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.  6.  8.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[92.91292 ]
 [87.655716]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  1.] 
cards in discard: [10.  3.  1. 11.  6.  6.  8. 29.  8.  0.  6.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  8. 29. 22.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -1.9279407262802124
desired expected reward: 63.13163757324219



action possibilites: [-1.] 
expected returns: [[113.221634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  8. 29. 22.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 7 

action type: take_action - action 29.0
Learning step: -1.4586095809936523
desired expected reward: 85.66331481933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.671196]
 [102.06716 ]
 [101.997246]
 [101.79415 ]
 [101.672386]
 [103.21548 ]
 [104.69857 ]
 [103.38436 ]
 [107.278496]
 [108.35664 ]
 [104.39714 ]
 [105.53397 ]
 [103.39286 ]
 [104.228264]
 [105.702866]
 [114.32298 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  8. 29. 22.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -2.977492332458496
desired expected reward: 110.244140625



buy possibilites: [-1] 
expected returns: [[116.34121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  8. 29. 22.  0.] 
adversary cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
adversary owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -3.665882110595703
desired expected reward: 98.00531005859375






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11.  8. 29. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29. 22.  0.] 
cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8 10  0  8  1 29  3  0  0 22 16 11  3  3  0  6 16 15 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.] 
cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  0  8  1 29  3  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.] 
cards in discard: [11. 16.  1.  8.  0.  8. 15. 16. 10.  0.  6.  1.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  0  8  1 29  3  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 8.  6.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[130.76921]
 [124.02812]
 [127.18315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 29.  1.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 10.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  0  8  1 29  3  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -3.685778856277466
desired expected reward: 112.65543365478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.92698 ]
 [123.135704]
 [122.927734]
 [124.0311  ]
 [130.7722  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3. 29.  1.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 10.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  0  8  1 29  3  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -4.314696788787842
desired expected reward: 124.49114990234375



buy possibilites: [-1] 
expected returns: [[106.31456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3. 29.  1.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 10.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  0  8  1 29  3  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 3.0
Learning step: -3.5147080421447754
desired expected reward: 119.62100219726562






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  0  8  1 29  3  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  6. 10.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  6. 10.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 22. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  6. 10.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11.  6. 10.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [11.  6. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[129.14427 ]
 [120.19818 ]
 [118.960846]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10.  3.  6.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  5.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  3. 11.  0. 15.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -2.22407603263855
desired expected reward: 104.09048461914062



action possibilites: [-1] 
expected returns: [[118.38858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  6.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  4.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  3. 11.  0. 15.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    1    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -284 

action type: gain_card_n - action 3
Learning step: -17.327482223510742
desired expected reward: 98.49702453613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.688934]
 [108.68988 ]
 [119.109764]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  6.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  4.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  3. 11.  0. 15.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -2.5743653774261475
desired expected reward: 115.81421661376953



buy possibilites: [-1] 
expected returns: [[128.38762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  6.] 
cards in discard: [ 0. 29.  0.  3.  3.  1.  0.  3.  8.  6.  3. 29.  1.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  3. 11.  0. 15.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   1   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action 0.0
Learning step: -3.245725393295288
desired expected reward: 105.44320678710938






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  0. 15.] 
cards in discard: [0. 8. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.] 
cards in discard: [0. 8. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.] 
cards in discard: [0. 8. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1. 10.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.] 
cards in discard: [ 0.  8.  8.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [0. 0. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[113.55042]
 [105.3006 ]
 [105.3006 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  8  6  8  8  6  0  3  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.] 
adversary owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0 25] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -4.202443599700928
desired expected reward: 124.18517303466797



action possibilites: [-1] 
expected returns: [[136.7282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.] 
adversary owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0 25] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.997724175453186
desired expected reward: 96.48444366455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[131.16193]
 [131.39229]
 [131.16248]
 [132.37987]
 [139.78607]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [16.  0.  0.  0.  8.] 
adversary cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.] 
adversary owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0 25] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -3.019577741622925
desired expected reward: 133.7086181640625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  8.] 
cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29  0  0 16 11  3  3  0  6 16 15 11  8  0 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  4.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  1.  3.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  1.  3.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  6.  1.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  1.  3.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  6.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  1.  3.] 
adversary cards in discard: [8. 0. 0. 6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 3. 29.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[78.265366]
 [73.64509 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  1.  3.] 
cards in discard: [8. 0. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  6.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 6.  1. 29. 11. 16.] 
adversary cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.  8. 16.  0.  0.  8.] 
adversary owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -5.012208938598633
desired expected reward: 134.77386474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[69.5409 ]
 [69.86598]
 [69.80849]
 [69.54152]
 [72.02846]
 [70.95195]
 [79.62587]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  1.  3.] 
cards in discard: [8. 0. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  6.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 6.  1. 29. 11. 16.] 
adversary cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.  8. 16.  0.  0.  8.] 
adversary owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -1.8903945684432983
desired expected reward: 74.6410140991211



buy possibilites: [-1] 
expected returns: [[99.86959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  1.  3.] 
cards in discard: [ 8.  0.  0.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 6.  1. 29. 11. 16.] 
adversary cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.  8. 16.  0.  0.  8.] 
adversary owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 24 

action type: buy - action 11.0
Learning step: -0.15435753762722015
desired expected reward: 71.87410736083984






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  1. 29. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 29. 11. 16.] 
cards in discard: [ 0.  8.  8.  3. 25. 15.  1.  3. 11.  6.  8. 16.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 16.  3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 22. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  3.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 21. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.] 
cards in discard: [6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 21. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  3.] 
cards in discard: [6. 3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 10.  0.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 3.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[87.66247]
 [76.61356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 10.  0.] 
cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15.  6.  8.  8.] 
adversary cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.] 
adversary owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -3.8468024730682373
desired expected reward: 96.02278900146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[76.27462]
 [76.27541]
 [88.99497]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 10.  0.] 
cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15.  6.  8.  8.] 
adversary cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.] 
adversary owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.2045419216156006
desired expected reward: 83.6404800415039



buy possibilites: [-1] 
expected returns: [[118.855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 10.  0.] 
cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 15.  6.  8.  8.] 
adversary cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.] 
adversary owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -44.0 

action type: buy - action 0.0
Learning step: -3.3394935131073
desired expected reward: 72.93512725830078






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  8.  8.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29  0 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6. 11.  8. 29.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6. 11.  8. 29.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 20. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6. 11.  8. 29.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 19. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 3.  6. 11.  8. 29.] 
adversary cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  6. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[39.96442 ]
 [35.28533 ]
 [34.651894]
 [37.096863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  8. 29.] 
cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 16.  1.  8.  0.] 
adversary cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.] 
adversary owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -6.305980682373047
desired expected reward: 112.54902648925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.7001  ]
 [33.70047 ]
 [39.888756]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  8. 29.] 
cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  3.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 16.  1.  8.  0.] 
adversary cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.] 
adversary owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -2.380842924118042
desired expected reward: 37.583587646484375



buy possibilites: [-1] 
expected returns: [[52.972023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  8. 29.] 
cards in discard: [ 8.  0.  0.  6. 11.  3. 29.  0.  1.  3.  0.  3.  6.  3. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 16.  1.  8.  0.] 
adversary cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.] 
adversary owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action 6.0
Learning step: -17.243154525756836
desired expected reward: 16.457326889038086






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  8.  0.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 16 11  3  3  0  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11. 10.  8.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11. 10.  8.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11. 10.  8.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [ 6.  3.  3. 29. 11.  1. 16.  3.  3. 15.  6.  8.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [11. 10.  8.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6] -> size -> 24 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  8.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[51.69971 ]
 [47.360847]
 [46.75013 ]
 [46.74523 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  6.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  3.  8. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -3.326958417892456
desired expected reward: 49.64506530761719



action possibilites: [-1] 
expected returns: [[70.90361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  1.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 1.  3.  8. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: gain_card_n - action 9
Learning step: -0.6735397577285767
desired expected reward: 45.703880310058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[65.82054]
 [65.98411]
 [65.82093]
 [72.19619]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  1.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 1.  3.  8. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -2.762829542160034
desired expected reward: 68.14077758789062






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  8. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 25. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 30.  8.  2.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 11.  8.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 19. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 11.  8.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 19. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 11.  8.  6.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6] -> size -> 26 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[53.521255]
 [46.876873]
 [49.479584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 15.] 
adversary cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0  3] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -356 

action type: buy - action -1.0
Learning step: -20.306589126586914
desired expected reward: 51.88960266113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[32.884365]
 [33.16029 ]
 [33.111477]
 [32.884365]
 [35.049152]
 [34.1154  ]
 [41.632576]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 18. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 15.] 
adversary cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0  3] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -4.337009906768799
desired expected reward: 42.441829681396484



buy possibilites: [-1] 
expected returns: [[103.64562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 15.] 
adversary cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0  3] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -43.0 

action type: buy - action 3.0
Learning step: -1.4735472202301025
desired expected reward: 31.637929916381836






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  3. 15.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8  0 25  6  8  3  3  3  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8 25  6  8  3  3  3  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8 25  6  8  3  3  3  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [6. 6. 8. 3. 0.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[79.6451 ]
 [71.00166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 3. 0.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 16.  6.  0.  3.] 
adversary cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.  0. 15.  8.  3.  3.] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -5.724192142486572
desired expected reward: 97.92143249511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.520134]
 [68.520134]
 [78.207565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 3. 0.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 16.  6.  0.  3.] 
adversary cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.  0. 15.  8.  3.  3.] 
adversary owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.5980024337768555
desired expected reward: 75.04710388183594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  6.  0.  3.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.  0. 15.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  3  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  7. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 1.  3. 29.  0.  6.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.  0. 15.  8.  3.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 1.  3. 29.  0.  6.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [ 3. 25.  1.  3.  8. 11.  8.  6.  0. 15.  8.  3.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 1.  3. 29.  0.  6.] 
adversary cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 1.  3. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[69.99849 ]
 [67.114204]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  0.  6.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 3. 29.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -4.113418102264404
desired expected reward: 74.0941390991211



action possibilites: [-1.] 
expected returns: [[96.463295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 3. 29.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 2
Learning step: -1.7632640600204468
desired expected reward: 61.910499572753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[83.75812 ]
 [83.97356 ]
 [83.934425]
 [83.75812 ]
 [84.59884 ]
 [85.40847 ]
 [87.361145]
 [85.243835]
 [84.69813 ]
 [85.954185]
 [90.42738 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 17. 30.  8.  1.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 3. 29.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.636679172515869
desired expected reward: 92.82661437988281



buy possibilites: [-1] 
expected returns: [[73.04308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3.] 
cards in discard: [15. 11. 10.  8.  6.  1.  6.  3.  0.  0. 11. 29.  0.  6.  6.  8.  3.  0.
  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [ 3. 29.  3. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -18.844436645507812
desired expected reward: 64.91368103027344






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 11.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [15.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  8.] 
cards in discard: [3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6. 10. 10.  7.  9.  7.] 
adversary cards in hand: [15.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [ 3.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [ 3.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  5.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [ 3.  3. 15. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [15.  3.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[23.867867]
 [21.17777 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  3.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  6.  0. 16. 11.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -5.448735237121582
desired expected reward: 67.59434509277344



action possibilites: [-1] 
expected returns: [[51.75964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  6.  0. 16. 11.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 15.0
Learning step: -1.1778528690338135
desired expected reward: 19.67104148864746





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[43.663143]
 [52.667027]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  6.  0. 16. 11.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15 11] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -2.7903995513916016
desired expected reward: 48.96923828125






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 16. 11.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  0  3  0 29 15 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  6.  6.  6. 29.] 
adversary cards in discard: [15.  3.  6.  3.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  6.  6.  6. 29.] 
adversary cards in discard: [15.  3.  6.  3.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  6.  6.  6. 29.] 
adversary cards in discard: [15.  3.  6.  3.  3.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 8.  6.  6.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[59.2475 ]
 [51.10254]
 [54.91224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  6.  6. 29.] 
cards in discard: [15.  3.  6.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29.  3.  3.  8.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -3.6998291015625
desired expected reward: 48.967201232910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.743874]
 [57.26469 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  6.  6. 29.] 
cards in discard: [15.  3.  6.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29.  3.  3.  8.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.] 
adversary owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -4.0246100425720215
desired expected reward: 54.3878059387207



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [29.  3.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  8.  8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  3  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29. 10.  0.  6.  3.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29. 10.  0.  6.  3.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29. 10.  0.  6.  3.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29. 10.  0.  6.  3.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [29. 10.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 1.1898377 ]
 [ 0.40220398]
 [-0.08298169]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  6.  3.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  6. 15.  1.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -4.649800777435303
desired expected reward: 52.61488723754883



action possibilites: [-1. 10.] 
expected returns: [[16.469034]
 [12.539825]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  6. 15.  1.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: discard_n_cards - action 4
Learning step: -0.4524875581264496
desired expected reward: -0.7547074556350708



action possibilites: [-1.] 
expected returns: [[48.9287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  6. 15.  1.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   2] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: 0.7739044427871704
desired expected reward: 13.313730239868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[40.56554 ]
 [40.71894 ]
 [40.690147]
 [41.147476]
 [41.720795]
 [43.522305]
 [41.601032]
 [41.215893]
 [42.117344]
 [46.631485]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  4.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  6. 15.  1.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1.0
Learning step: -1.2873021364212036
desired expected reward: 47.641395568847656



buy possibilites: [-1] 
expected returns: [[34.417343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  6. 15.  1.  8.] 
adversary cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 8.5 

action type: buy - action 11.0
Learning step: -0.8866495490074158
desired expected reward: 40.834144592285156






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 15.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 15.  1.  8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 17. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 8.] 
cards in discard: [ 3.  3. 15. 11. 29. 11.  1.  8.  0. 16.  6.  0. 11.  0.  8. 29.  3.  8.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[39.59022 ]
 [33.562267]
 [34.31741 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  6.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -3.2032392024993896
desired expected reward: 31.21410369873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[30.165663]
 [30.362236]
 [30.326645]
 [31.660604]
 [31.017405]
 [36.689438]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  6.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.5508201122283936
desired expected reward: 36.03940200805664



buy possibilites: [-1] 
expected returns: [[29.96408]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 8.  6.  8.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0
  3] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -76.0 

action type: buy - action 0.0
Learning step: -4.634091377258301
desired expected reward: 25.531566619873047






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  8.  8. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  6.  0.  3. 11.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  6.  0.  3. 11.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  6.  0.  3. 11.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 25.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1.  6.  0.  3. 11.] 
adversary cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 1.  6.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[50.809834]
 [48.18946 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  3. 11.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [11. 29.  0.  3.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -2.6804261207580566
desired expected reward: 27.283655166625977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[48.113224]
 [48.22565 ]
 [48.205635]
 [48.987827]
 [48.613346]
 [51.608204]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  3. 11.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 16. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [11. 29.  0.  3.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -3.7307541370391846
desired expected reward: 47.07908248901367



buy possibilites: [-1] 
expected returns: [[47.04875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  3. 11.] 
cards in discard: [15.  3.  6.  3.  3.  8.  6.  6.  6. 29.  3.  3. 11. 29. 10.  0.  6.  1.
  0.  8. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [11. 29.  0.  3.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0] -> size -> 25 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -33.0 

action type: buy - action 3.0
Learning step: -3.0016849040985107
desired expected reward: 45.20395278930664






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [11. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  3.  0.] 
cards in discard: [ 0.  8.  6.  8. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29.  0.  3. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3] -> size -> 31 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  3.  0.] 
cards in discard: [ 0.  8.  6.  8. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 15. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29.  0.  3. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3] -> size -> 31 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  3.  0.] 
cards in discard: [ 0.  8.  6.  8. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [29.  0.  3. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3] -> size -> 31 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [29.  0.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[11.274374]
 [ 9.661163]
 [ 8.638454]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  1.  8.  1. 16.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -4.376283168792725
desired expected reward: 42.67247009277344



action possibilites: [-1. 11.] 
expected returns: [[40.06726 ]
 [35.382782]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.] 
cards in discard: [0. 6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  1.  8.  1. 16.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: -0.7873460650444031
desired expected reward: 7.080137252807617



action possibilites: [-1] 
expected returns: [[16.35043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [0. 6. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  1.  8.  1. 16.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: gain_card_n - action 0
Learning step: -3.0760467052459717
desired expected reward: 30.802581787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.407194]
 [16.579557]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [0. 6. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 0.  1.  8.  1. 16.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -0.7349941730499268
desired expected reward: 15.615435600280762






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  8.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  1. 16.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3.  0.  6.  8.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  1. 16.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 26. 30. 14. 30.  8.  0.  8.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3.  0.  6.  8.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8.  1. 16.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [15.  3.  0.  6.  8.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.] 
adversary owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3  0] -> size -> 32 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [15.  3.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[-0.3035972]
 [-0.3035972]
 [-0.3035972]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  6.  8.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1 29  1 10 11 29  0  3  3  6  3  0  6  8  8  6  0  3  6  0 11  0  6
 15  6  3  6 11  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3. 11. 29. 11.  6.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.970374584197998
desired expected reward: 11.300495147705078



action possibilites: [-1] 
expected returns: [[-0.3035972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3. 11. 29. 11.  6.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 13
Learning step: -1.241651177406311
desired expected reward: -1.5452483892440796





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.3035972]
 [-0.3035972]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 26. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3. 11. 29. 11.  6.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.241651177406311
desired expected reward: -1.5452483892440796






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 29. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 11.  6.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  1.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  6.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  1.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  6.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  1.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  6.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  0. 11.  1.  3.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[42.943275]
 [39.268932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  1.  3.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  3. 15. 15.  3.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.
  0. 11.  3. 29. 11.  6.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.3042736053466797
desired expected reward: -1.6078708171844482





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[36.458263]
 [36.613983]
 [36.586292]
 [37.671646]
 [37.148537]
 [41.445213]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  1.  3.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 3.  3. 15. 15.  3.] 
adversary cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.
  0. 11.  3. 29. 11.  6.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.5382707118988037
desired expected reward: 39.40501022338867



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 15.  3.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.
  0. 11.  3. 29. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 15.  3.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.
  0. 11.  3. 29. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 15.  3.] 
cards in discard: [ 0.  8.  6.  8. 25.  3. 11. 29.  0.  3.  0. 16.  0.  1.  8.  1. 16.  1.
  0. 11.  3. 29. 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[125.004166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [16.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.5096673965454102
desired expected reward: 39.93555450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[116.66141]
 [124.00045]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [16.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -5.781458854675293
desired expected reward: 119.22270965576172



buy possibilites: [-1] 
expected returns: [[67.25821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [16.  8.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -8.0697603225708
desired expected reward: 108.59163665771484






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [16.  8.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 10.  0.  6.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 10.  0.  6.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [ 1. 10.  0.  6.  6.] 
adversary cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 1. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[91.159836]
 [84.65758 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  6.  6.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [16. 11.  8.  8. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -3.6249496936798096
desired expected reward: 63.63325881958008



action possibilites: [-1.] 
expected returns: [[116.48027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [16. 11.  8.  8. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -24 

action type: take_action - action 10.0
Learning step: -2.812072515487671
desired expected reward: 81.84549713134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.89771 ]
 [100.14966 ]
 [100.102486]
 [100.88643 ]
 [101.84314 ]
 [104.12846 ]
 [101.65328 ]
 [101.01169 ]
 [102.484726]
 [107.73382 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  6.] 
adversary cards in hand: [16. 11.  8.  8. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.761561870574951
desired expected reward: 111.71871185302734



buy possibilites: [-1] 
expected returns: [[64.567154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [ 0.  6.  0. 29. 11.  3.  6.  8. 15.  3.  0. 11.  1.  3.  0.  3.  3.  0.
  6.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  5.] 
adversary cards in hand: [16. 11.  8.  8. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 7 

action type: buy - action 15.0
Learning step: -3.3214752674102783
desired expected reward: 99.16325378417969






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [16. 11.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  8.  8. 29.] 
cards in discard: [ 0. 16.  8.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  5.] 
adversary cards in hand: [ 6.  3. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  8.  8. 29.] 
cards in discard: [ 0. 16.  8.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  5.] 
adversary cards in hand: [ 6.  3. 11.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[30.012262]
 [27.036694]
 [26.618786]
 [28.19813 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  8. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  5.] 
adversary cards in hand: [11.  0.  6.  3. 15.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -4.842810153961182
desired expected reward: 59.724342346191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.523314]
 [30.480274]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  8. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  5.] 
adversary cards in hand: [11.  0.  6.  3. 15.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.1032283306121826
desired expected reward: 26.90903663635254



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [11.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  3. 15.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  5.] 
adversary cards in hand: [11.  8.  1.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 15.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  4.] 
adversary cards in hand: [11.  8.  1.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 15.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  4.] 
adversary cards in hand: [11.  8.  1.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3. 15.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  4.] 
adversary cards in hand: [11.  8.  1.  0.  3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [11.  8.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[8.54223  ]
 [7.2148485]
 [7.0227766]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  1.  0.  3.] 
cards in discard: [ 6.  3. 11.  8. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  4.] 
adversary cards in hand: [ 1. 25.  1.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -3.6002414226531982
desired expected reward: 26.88003158569336



action possibilites: [-1] 
expected returns: [[17.562956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  3.] 
adversary cards in hand: [ 1. 25.  1.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -9 

action type: gain_card_n - action 8
Learning step: -0.4321688115596771
desired expected reward: 7.114537239074707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[13.109131]
 [13.247494]
 [13.221544]
 [14.150697]
 [13.702394]
 [17.262844]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  7.  9.  3.] 
adversary cards in hand: [ 1. 25.  1.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.80085027217865
desired expected reward: 15.762105941772461



buy possibilites: [-1] 
expected returns: [[16.871649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  3.] 
adversary cards in hand: [ 1. 25.  1.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -7 

action type: buy - action 10.0
Learning step: -0.6555075645446777
desired expected reward: 13.046884536743164






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 1. 25.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.  0.  3.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  3.] 
adversary cards in hand: [ 6.  3. 15.  0. 10.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 3. 3. 1.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  3.] 
adversary cards in hand: [ 6.  3. 15.  0. 10.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3. 3. 1.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  3.] 
adversary cards in hand: [ 6.  3. 15.  0. 10.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 3. 3. 1.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 6.  3. 15.  0. 10.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 6.  3. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[29.133371]
 [27.726059]
 [27.327879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15.  0. 10.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  3.  0. 15. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15. 25.  1.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.458878755569458
desired expected reward: 14.41277027130127





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.57593 ]
 [28.751255]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.  0. 10.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  3.  0. 15. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15. 25.  1.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.08088755607605
desired expected reward: 26.052488327026367



buy possibilites: [-1] 
expected returns: [[32.902233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15.  0. 10.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  3.  0. 15. 29.] 
adversary cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15. 25.  1.  1.  0.  3.  3.  1.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -4.338496685028076
desired expected reward: 22.237430572509766






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 15. 29.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15. 25.  1.  1.  0.  3.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  6. 10. 10.  6.  9.  2.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 29.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15. 25.  1.  1.  0.  3.  3.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  5. 10. 10.  6.  9.  2.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15. 29.] 
cards in discard: [ 0. 16.  8.  3.  0.  0. 16. 11.  8.  8. 29. 15.  0. 11.  0.  6.  3. 15.
 15. 25.  1.  1.  0.  3.  3.  1. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  5. 10. 10.  6.  9.  2.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0] -> size -> 34 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[48.848316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  5. 10. 10.  6.  9.  2.] 
adversary cards in hand: [15.  1.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.796024799346924
desired expected reward: 30.10620880126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[42.61796 ]
 [42.7594  ]
 [42.733543]
 [43.171864]
 [43.707687]
 [44.987156]
 [43.59883 ]
 [43.24056 ]
 [44.065968]
 [46.99939 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  5. 10. 10.  6.  9.  2.] 
adversary cards in hand: [15.  1.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -3.6972885131835938
desired expected reward: 45.15102767944336



buy possibilites: [-1] 
expected returns: [[21.551872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [15.  1.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -13 

action type: buy - action 29.0
Learning step: -2.4144411087036133
desired expected reward: 42.572723388671875






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [15.  1.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 14. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  3.  6.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29] -> size -> 35 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [11.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[50.708874]
 [45.758793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [16. 29. 11.  1.  8.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.734708309173584
desired expected reward: 18.817163467407227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[42.448925]
 [42.653065]
 [42.615498]
 [44.021072]
 [43.34686 ]
 [49.08985 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [16. 29. 11.  1.  8.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.279197692871094
desired expected reward: 46.4296760559082



buy possibilites: [-1] 
expected returns: [[37.091053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [16. 29. 11.  1.  8.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -5.587897777557373
desired expected reward: 36.86102294921875






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [16. 29. 11.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 11.  1.  8.] 
cards in discard: [ 3. 15.  1.  0.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 6. 29. 15.  6.  3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.  0. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 11.  1.  8.] 
cards in discard: [ 3. 15.  1.  0.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 6. 29. 15.  6.  3.] 
adversary cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.  0. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 29. 15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[46.56926]
 [43.52374]
 [42.14252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 15.  6.  3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.  0. 11.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [29. 25.  3.  8.  0.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -3.6051137447357178
desired expected reward: 33.485939025878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[40.09548 ]
 [46.674435]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 15.  6.  3.] 
cards in discard: [ 6.  3. 11.  8. 29. 15. 10. 11.  8.  1.  0.  3.  0.  6.  3. 15.  0. 10.
 29.  3.  0.  1.  0.  3.  0. 11.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [29. 25.  3.  8.  0.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.092169284820557
desired expected reward: 42.47710037231445



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [29. 25.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  8.  0.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3.  8.  0.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.665936]
 [17.850582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 3.  3.  0. 15. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -4.658865451812744
desired expected reward: 42.01558303833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[17.229464]
 [17.279612]
 [19.30007 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 3.  3.  0. 15. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -3.326982259750366
desired expected reward: 16.36804962158203



buy possibilites: [-1] 
expected returns: [[35.176186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 3.  3.  0. 15. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -87.0 

action type: buy - action 0.0
Learning step: -4.420009136199951
desired expected reward: 12.809455871582031






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15. 15.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3  0 29 15 11  0  0  3
  0  3 16  1  0  0  0 15  0 15 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  3. 10.  6.  3.] 
adversary cards in discard: [0. 0. 8. 6. 0. 6.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0] -> size -> 37 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  3. 10.  6.  3.] 
adversary cards in discard: [0. 0. 8. 6. 0. 6.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0] -> size -> 37 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [11.  3. 10.  6.  3.] 
adversary cards in discard: [0. 0. 8. 6. 0. 6.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0] -> size -> 37 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [11.  3. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[22.775583]
 [17.209997]
 [16.425047]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  6.  3.] 
cards in discard: [0. 0. 8. 6. 0. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  6.  9.  2.] 
adversary cards in hand: [ 0. 11. 16.  8. 29.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -4.073493957519531
desired expected reward: 31.102691650390625



action possibilites: [-1] 
expected returns: [[81.99481]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  3.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 0. 11. 16.  8. 29.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0  -3   0   0   9   0] 
sum of rewards: -29 

action type: gain_card_n - action 7
Learning step: -0.41211292147636414
desired expected reward: 15.727807998657227





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[71.91634]
 [80.50042]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  3.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 0. 11. 16.  8. 29.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -4.121830940246582
desired expected reward: 77.87297821044922



buy possibilites: [-1] 
expected returns: [[47.386284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  3.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 0. 11. 16.  8. 29.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20 -30   0   0   0  -4   0   0   0   0] 
sum of rewards: -69 

action type: buy - action 0.0
Learning step: -5.979625701904297
desired expected reward: 65.93672180175781






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 16.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  8. 29.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0] -> size -> 39 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 16.  8. 29.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0] -> size -> 39 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.696682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 1. 11.  6.  0.  0.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -4.451138973236084
desired expected reward: 42.93514633178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.377941]
 [22.564281]
 [29.448412]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 1. 11.  6.  0.  0.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -3.6625754833221436
desired expected reward: 26.034107208251953



buy possibilites: [-1] 
expected returns: [[56.642143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 1. 11.  6.  0.  0.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -90.0 

action type: buy - action 0.0
Learning step: -4.344448089599609
desired expected reward: 18.033485412597656






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6.  0.  0.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  7.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  6.  3. 11. 29.] 
adversary cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  6.  3. 11. 29.] 
adversary cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  6.  3. 11. 29.] 
adversary cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0.] 
cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  6.  3. 11. 29.] 
adversary cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.] 
adversary owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3.  6.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[80.990105]
 [73.89835 ]
 [76.67998 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 11. 29.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  0.  3.  0. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -3.833636522293091
desired expected reward: 52.80850601196289



action possibilites: [-1. 11.] 
expected returns: [[35.74688 ]
 [29.517939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  0.  3.  0. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_n_cards - action 4
Learning step: -4.587718963623047
desired expected reward: 67.04312133789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[29.239346]
 [29.418917]
 [37.364143]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  0.  3.  0. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.800675868988037
desired expected reward: 32.94622039794922



Player 1 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 2 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 0 
Workshop: 3 
Chapel: 5 
Witch: 0 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 11.  0.] 
cards in discard: [ 0.  0.  8.  6.  0.  6. 10.  0. 11.  3. 10.  6.  3.  0.  0.  0.  6.  3.
  3.  3.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1 29  1 10 11 29  3  3  3  0  6  8  8  6  0  3  6  0 11  0  6 15  6  3
  6 11  0  3  0  0 15 15 10  0 29  0  0 10  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 25. 30. 13. 30.  8.  0.  6.  3.  0.  9.  4. 10. 10.  5.  9.  2.] 
adversary cards in hand: [ 3.  0.  3.  0. 15.] 
adversary cards in discard: [ 3. 15.  1.  0.  3.  6. 16. 29. 11.  1.  8. 29. 25.  3.  8.  0. 15.  3.
  3. 15.  0. 11. 16.  8. 29. 16.  0. 11.  1.  6.  0.  0.] 
adversary owned cards: [ 1  8  1 29 11  6 16 15 11  8 25  6  8  3  3  3  3 29 15 11  0  0  3  0
  3 16  1  0  0  0 15  0 15 29  3 16  0] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -50    0    0   20  -30    0    0    0   -6    0    0
    0    0] 
sum of rewards: -571 

action type: buy - action 0.0
Learning step: -30.0119686126709
desired expected reward: -0.7726020812988281



