 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.92535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
None 
sum of rewards: None 

action type: None - action None
Learning step: None
desired expected reward: None





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[337.2672 ]
 [337.54254]
 [337.84793]
 [337.824  ]
 [337.51324]
 [338.1556 ]
 [337.5749 ]
 [338.34766]
 [338.1317 ]
 [337.88025]
 [338.407  ]
 [339.53723]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.42209529876709
desired expected reward: 329.4949035644531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.12265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.879714965820312
desired expected reward: 329.65753173828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[339.70255]
 [339.97784]
 [340.28333]
 [340.25937]
 [340.59094]
 [340.01022]
 [340.31558]
 [341.97256]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.026723861694336
desired expected reward: 332.06866455078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.6955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.808116912841797
desired expected reward: 332.1644592285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[348.35162]
 [348.62692]
 [348.93237]
 [348.90845]
 [349.24002]
 [348.6593 ]
 [348.9647 ]
 [350.62164]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.261818885803223
desired expected reward: 340.4275817871094



buy possibilites: [-1] 
expected returns: [[354.9913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -25.608118057250977
desired expected reward: 323.3003234863281






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[363.2824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.658358573913574
desired expected reward: 344.33294677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[364.6035 ]
 [364.87888]
 [365.18423]
 [365.1603 ]
 [364.84955]
 [365.49194]
 [364.91116]
 [365.68402]
 [365.46796]
 [365.21658]
 [365.74338]
 [366.8736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [6. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -11.224970817565918
desired expected reward: 355.0508728027344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[377.09125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -10.94223690032959
desired expected reward: 355.9313049316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[377.61252]
 [377.88782]
 [378.1932 ]
 [378.16928]
 [378.5009 ]
 [377.9202 ]
 [378.22552]
 [379.8825 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -11.622179985046387
desired expected reward: 368.4418029785156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[377.37973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -11.586246490478516
desired expected reward: 368.2962646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[377.8708 ]
 [378.14618]
 [378.45157]
 [378.42764]
 [378.75925]
 [378.1785 ]
 [378.48392]
 [380.14087]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -11.63067626953125
desired expected reward: 368.7195129394531



buy possibilites: [-1] 
expected returns: [[383.75848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 6. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -26.98681640625
desired expected reward: 351.44085693359375






Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[376.47992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 16.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -12.349888801574707
desired expected reward: 371.4085998535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[377.70264]
 [377.9779 ]
 [378.28336]
 [378.2594 ]
 [377.94867]
 [378.591  ]
 [378.01025]
 [378.78308]
 [378.5671 ]
 [378.31567]
 [378.84244]
 [379.97266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 16.] 
adversary cards in discard: [ 0.  3.  3. 11.  3.  0.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -12.139862060546875
desired expected reward: 367.3283996582031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 16.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  8.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 16  8  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  8.  0.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  8.  0.  0.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  3.  3. 11.  3.  0.  8.  0.  0.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[382.57605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -12.023791313171387
desired expected reward: 367.9488525390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[377.54346]
 [378.0921 ]
 [379.78412]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -12.229948997497559
desired expected reward: 369.00140380859375



buy possibilites: [-1] 
expected returns: [[384.3537]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 3.] 
cards in discard: [0. 0. 0. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -27.50664710998535
desired expected reward: 350.58544921875






Player: 1 
cards in hand: [3. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 6 6] -> size -> 13 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[373.45856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [3. 0. 8. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -12.998236656188965
desired expected reward: 371.35546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[374.69763]
 [374.9688 ]
 [375.2702 ]
 [375.24628]
 [374.93982]
 [375.5741 ]
 [375.0008 ]
 [375.76364]
 [375.55023]
 [375.3022 ]
 [375.8221 ]
 [376.93832]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 6 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [3. 0. 8. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -12.605517387390137
desired expected reward: 363.81439208984375



buy possibilites: [-1] 
expected returns: [[391.3626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [3. 0. 8. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -13 

action type: buy - action 14.0
Learning step: -10.621851921081543
desired expected reward: 364.9283447265625






Player: 1 
cards in hand: [ 0.  0.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  3.] 
cards in discard: [3. 0. 8. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  7.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [3. 0. 8. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  6.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [3. 0. 8. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  6.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [3. 0. 8. 8. 0. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  6.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[399.77762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  6.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -12.256729125976562
desired expected reward: 379.10589599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[399.78152]
 [400.35406]
 [400.33014]
 [400.08466]
 [402.02216]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  6.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -12.8565034866333
desired expected reward: 389.8724670410156



buy possibilites: [-1] 
expected returns: [[406.60663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [14.  0.  0.  3.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  5.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -28.16786003112793
desired expected reward: 372.16229248046875






Player: 1 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  5.  9.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  5.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 29. 30.  8.  5.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3.  0.  8.  8.  0.  6.  0. 16.  0.  3.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  5.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[411.5575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  5.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -13.30368709564209
desired expected reward: 393.3029479980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[410.83646]
 [411.3851 ]
 [413.07715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  5.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -13.745165824890137
desired expected reward: 400.77239990234375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  5.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.] 
cards in discard: [16. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[429.2426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 6. 6. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [16. 10. 11.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -13.229666709899902
desired expected reward: 399.84747314453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[429.90897]
 [430.1801 ]
 [430.4815 ]
 [430.45758]
 [430.78537]
 [430.21213]
 [430.51352]
 [432.1496 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 6. 6. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [16. 10. 11.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10] -> size -> 22 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -14.202078819274902
desired expected reward: 417.98419189453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [6. 6. 6. 3. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [6. 6. 6. 3. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  0. 14.] 
adversary cards in discard: [6. 6. 6. 3. 0. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[439.13055]
 [437.74246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 14.] 
cards in discard: [6. 6. 6. 3. 0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -13.968478202819824
desired expected reward: 418.1811218261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[439.62207]
 [439.89322]
 [440.1946 ]
 [440.1707 ]
 [440.49854]
 [439.92514]
 [440.2266 ]
 [441.86267]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 14.] 
cards in discard: [6. 6. 6. 3. 0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -14.476799011230469
desired expected reward: 427.57476806640625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[423.53296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  6. 16.  0.] 
adversary cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.  0.  8.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -14.797378540039062
desired expected reward: 427.06536865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[423.46234]
 [424.03488]
 [424.011  ]
 [423.76553]
 [425.703  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  6. 16.  0.] 
adversary cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.  0.  8.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -14.061144828796387
desired expected reward: 412.4170227050781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 16.  0.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.  0.  8.  3.  0.  3.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.  0.  8.  3.  0.  3.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6.] 
cards in discard: [16. 10. 11.  0. 16.  0.  0.  1.  0.  0.  0.  0.  0.  0.  8.  3.  0.  3.
  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[396.9406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -13.254920959472656
desired expected reward: 385.6634521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[397.52914]
 [397.7823 ]
 [398.06503]
 [398.0407 ]
 [398.35135]
 [397.81207]
 [398.09482]
 [399.6367 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -13.303361892700195
desired expected reward: 386.2965087890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 16.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  5.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.] 
cards in discard: [6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6.  6. 14.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0. 6. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[412.527 ]
 [411.2173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 14.  0.] 
cards in discard: [6. 3. 0. 3. 0. 6. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -12.464282035827637
desired expected reward: 387.17236328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[412.3323 ]
 [412.8682 ]
 [412.8438 ]
 [412.6152 ]
 [414.43982]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 14.  0.] 
cards in discard: [6. 3. 0. 3. 0. 6. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0] -> size -> 26 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -13.210436820983887
desired expected reward: 401.2032470703125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[409.93982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0. 16.  0.  8.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -13.238426208496094
desired expected reward: 401.2013854980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[409.85928]
 [410.39514]
 [410.3708 ]
 [410.14218]
 [411.96683]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0. 16.  0.  8.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -13.175541877746582
desired expected reward: 399.4273681640625



buy possibilites: [-1] 
expected returns: [[418.71222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0. 16.  0.  8.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -28 

action type: buy - action 8.0
Learning step: -12.48608684539795
desired expected reward: 397.6561279296875






Player: 1 
cards in hand: [10.  0. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  0.  8.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 14.  6.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  8.  0.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 14.  6.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8.  0.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 14.  6.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8.  0.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 14.  6.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[436.77173]
 [435.46207]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14.  6.] 
cards in discard: [8. 3. 6. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3. 10. 10.  0. 16.  0.
  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -12.867036819458008
desired expected reward: 405.8451843261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[436.56882]
 [437.10474]
 [437.08038]
 [436.85175]
 [438.67648]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 14.  6.] 
cards in discard: [8. 3. 6. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3. 10. 10.  0. 16.  0.
  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -13.889609336853027
desired expected reward: 425.01397705078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3. 10. 10.  0. 16.  0.
  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  0.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3. 10. 10.  0. 16.  0.
  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  0.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6.  0. 11.  3.  0. 16.  0. 15.  0.  0.  1.  0.  3. 10. 10.  0. 16.  0.
  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  0.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[436.03046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  0.  0.  6. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -13.906829833984375
desired expected reward: 424.7695617675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[436.54007]
 [436.79327]
 [437.076  ]
 [437.05164]
 [437.36227]
 [436.823  ]
 [437.10574]
 [438.64767]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  0.  0.  6. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -13.783377647399902
desired expected reward: 422.97174072265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 16.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0
  6  0 15 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0  6
  0 15 10  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0  6
  0 15 10  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 29. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [1. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0  6
  0 15 10  0  1  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[413.7739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0  6
  0 15 10  0  1  3] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -14.363306999206543
desired expected reward: 424.2843322753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[414.6989 ]
 [414.952  ]
 [415.23477]
 [415.21042]
 [414.92453]
 [415.52106]
 [414.98175]
 [415.69962]
 [415.49677]
 [415.26453]
 [415.75327]
 [416.80643]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0  6
  0 15 10  0  1  3] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -13.256753921508789
desired expected reward: 403.1466064453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16 10  1  0  0  6
  0 15 10  0  1  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14.  0.  0.  3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[414.01556]
 [412.7059 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  0.  3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  6.  0. 16.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -13.277865409851074
desired expected reward: 403.5285949707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[413.90607]
 [414.44193]
 [414.4176 ]
 [414.18893]
 [416.0136 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  0.  3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 28. 30.  8.  4.  7.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  6.  0. 16.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -13.27481746673584
desired expected reward: 403.1346740722656



buy possibilites: [-1] 
expected returns: [[402.45483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  0.  3.] 
cards in discard: [0. 0. 3. 0. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  6.  0. 16.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0] -> size -> 28 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -28 

action type: buy - action 8.0
Learning step: -12.552592277526855
desired expected reward: 401.6363830566406






Player: 1 
cards in hand: [ 1.  6.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 16.  0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  8.  6. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8  8] -> size -> 17 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 16.  0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  8.  6. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8  8] -> size -> 17 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 16.  0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 6. 0. 8.] 
adversary cards in discard: [ 0.  0.  3.  0.  0.  8.  6. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8  8] -> size -> 17 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[411.4822]
 [409.7516]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 8.] 
cards in discard: [ 0.  0.  3.  0.  0.  8.  6. 14.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  6  6 14  6  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 16.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -12.662873268127441
desired expected reward: 389.7919616699219



action possibilites: [-1] 
expected returns: [[399.70355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  0.  3.  0.  0.  8.  6. 14.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 16.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 7
Learning step: -11.185112953186035
desired expected reward: 398.38372802734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[398.2741 ]
 [398.75497]
 [400.27106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  0.  3.  0.  0.  8.  6. 14.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3. 16.  0.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -10.691160202026367
desired expected reward: 389.01239013671875






Player: 1 
cards in hand: [10.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 16.  0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 16.  0.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 14.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[394.39514]
 [393.151  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0. 10.  0.  3.
 16.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.789650917053223
desired expected reward: 388.4814147949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[393.73526]
 [394.21613]
 [395.73224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  3.] 
adversary cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0. 10.  0.  3.
 16.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.653258323669434
desired expected reward: 385.24981689453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  3.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0. 10.  0.  3.
 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0. 10.  0.  3.
 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3.] 
cards in discard: [ 1.  3. 16.  0.  0.  8.  0.  8.  0.  0.  1.  6.  0. 16.  0. 10.  0.  3.
 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[400.71387]
 [398.98328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [ 0. 14.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.428630828857422
desired expected reward: 384.3035888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[400.5016 ]
 [401.007  ]
 [400.98245]
 [400.76794]
 [402.49854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [ 0. 14.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.806361198425293
desired expected reward: 391.1672668457031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[391.2702]
 [389.5396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10] -> size -> 31 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.973784446716309
desired expected reward: 390.5247497558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[391.78494]
 [392.023  ]
 [392.29034]
 [392.26578]
 [392.56235]
 [392.0513 ]
 [392.31866]
 [393.7819 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10] -> size -> 31 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.543364524841309
desired expected reward: 382.23748779296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[407.51117]
 [405.78058]
 [406.2671 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  0.  0.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  8.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10 10] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.190253257751465
desired expected reward: 382.59161376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[407.27444]
 [407.77994]
 [407.75537]
 [407.54083]
 [409.27142]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  0.  0.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  8.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10 10] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.969887733459473
desired expected reward: 397.32208251953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  8.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10
  0  1  3  0  0  0 10 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 28. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0
  1  3  0  0  0 10 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 27. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0
  1  3  0  0  0 10 10  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 27. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0
  1  3  0  0  0 10 10  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 30. 27. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[400.46558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 27. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  1. 16.  0.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.] 
adversary owned cards: [ 0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0
  1  3  0  0  0 10 10  3  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -12.596931457519531
desired expected reward: 396.67449951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[399.79257]
 [400.27344]
 [401.78952]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 27. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  1. 16.  0.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.] 
adversary owned cards: [ 0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0
  1  3  0  0  0 10 10  3  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -12.319904327392578
desired expected reward: 390.641845703125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  1. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 16.  0.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0
  1  3  0  0  0 10 10  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 27. 30.  8.  4.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 14.  8.] 
adversary cards in discard: [3. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1
  3  0  0  0 10 10  3  0  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 14.  8.] 
adversary cards in discard: [3. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1
  3  0  0  0 10 10  3  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 14.  8.] 
adversary cards in discard: [3. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1
  3  0  0  0 10 10  3  0  6  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 14.  8.] 
adversary cards in discard: [3. 6. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
expected returns: [[419.5424 ]
 [417.8118 ]
 [418.29828]
 [417.8118 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 14.  8.] 
cards in discard: [3. 6. 6. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1
  3  0  0  0 10 10  3  0  6  1] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.332324028015137
desired expected reward: 390.4571533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[419.31992]
 [419.82535]
 [419.80075]
 [419.58633]
 [421.31686]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 14.  8.] 
cards in discard: [3. 6. 6. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 6.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.] 
adversary owned cards: [ 3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1
  3  0  0  0 10 10  3  0  6  1] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -12.27712631225586
desired expected reward: 408.5800476074219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1
  3  0  0  0 10 10  3  0  6  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[368.7946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 16.  6.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -11.54527473449707
desired expected reward: 382.3642272949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[369.27872]
 [369.49704]
 [369.7451 ]
 [369.72137]
 [369.99844]
 [369.524  ]
 [369.772  ]
 [371.1319 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 16.  6.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -10.418930053710938
desired expected reward: 360.70111083984375



buy possibilites: [-1] 
expected returns: [[371.51727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  1. 16.  6.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.  8.  0.  3.  6.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 14 

action type: buy - action 1.0
Learning step: -9.415712356567383
desired expected reward: 360.081298828125






Player: 1 
cards in hand: [ 0.  1. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.  6.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.  8.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  0. 14.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.  6.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.  8.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  0. 14.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.  6.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15. 10.  0. 10.  0.  3.  0.  3.  0. 16.  0.  0.  8.
  6.  1. 16. 11.  1.  0.  0.  8.  0.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  0. 14.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[381.79288]
 [380.18497]
 [380.6357 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  0. 14.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  6.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -10.180830955505371
desired expected reward: 361.3364562988281



action possibilites: [-1] 
expected returns: [[382.142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  6.  0.] 
adversary cards in discard: [6. 1.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 14.0
Learning step: -9.665152549743652
desired expected reward: 371.6017761230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[381.94568]
 [382.1639 ]
 [382.41202]
 [382.38828]
 [382.13956]
 [382.66534]
 [382.19086]
 [382.822  ]
 [382.64163]
 [382.43896]
 [382.86807]
 [383.79883]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  6.  0.] 
adversary cards in discard: [6. 1.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -9.684617042541504
desired expected reward: 372.4573669433594






Player: 1 
cards in hand: [10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [6. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [6. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [6. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[378.7087 ]
 [377.10077]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 14  6  8  8  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 6.  1. 10.  6.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -10.834994316101074
desired expected reward: 372.9638366699219



action possibilites: [-1] 
expected returns: [[371.14545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 6.  1. 10.  6.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 7
Learning step: -9.77202320098877
desired expected reward: 368.6838684082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[369.25708]
 [369.69974]
 [371.11026]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 6.  1. 10.  6.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -9.4185152053833
desired expected reward: 361.7269287109375






Player: 1 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 6.  1. 10.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3
  0  0  0 10 10  3  0  6  1  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  1.  8.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  1. 10.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  1.  8.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  1. 10.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 26. 30. 27. 30.  8.  3.  7.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  1.  8.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  1. 10.  6.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 27. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  1.  8.  0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[386.80817]
 [385.651  ]
 [385.20023]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  8.  0.] 
cards in discard: [8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  1.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -10.01452922821045
desired expected reward: 361.0957336425781



action possibilites: [-1] 
expected returns: [[389.7111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 27. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 14.0
Learning step: -9.819181442260742
desired expected reward: 377.9344177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[389.11224]
 [389.33054]
 [389.35217]
 [389.57858]
 [389.30682]
 [389.55487]
 [389.30612]
 [389.83197]
 [389.3575 ]
 [389.78592]
 [389.98862]
 [389.80826]
 [389.98334]
 [389.6055 ]
 [389.75693]
 [390.03467]
 [390.96542]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [8. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 26. 30. 27. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -9.902033805847168
desired expected reward: 379.8090515136719



buy possibilites: [-1] 
expected returns: [[390.01007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 0.] 
cards in discard: [8. 6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 29.0 

action type: buy - action 3.0
Learning step: -9.253703117370605
desired expected reward: 380.32489013671875






Player: 1 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  6.  3. 14.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10. 10.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  6.  3. 14.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  6.  3. 14.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[405.80637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  6.  3. 14.  0.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -10.010164260864258
desired expected reward: 379.9999084472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[406.00702]
 [406.2253 ]
 [406.4734 ]
 [406.44974]
 [406.72678]
 [406.2523 ]
 [406.50034]
 [407.86026]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  6.  3. 14.  0.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -10.798407554626465
desired expected reward: 395.4389343261719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0. 10.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.  8.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.  8.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.  8.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[377.91013]
 [376.4198 ]
 [376.83676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -10.115180969238281
desired expected reward: 369.8575744628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[377.34537]
 [377.75195]
 [379.0605 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8] -> size -> 37 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -10.114364624023438
desired expected reward: 369.54217529296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 8. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 1. 3.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 1. 3.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 26. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 1. 3.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 25. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 3.] 
adversary cards in discard: [ 8.  0.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [6. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[380.9914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 3.] 
cards in discard: [ 8.  0.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [16.  0. 10. 16.  0.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -10.51758861541748
desired expected reward: 368.54290771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[381.747  ]
 [381.9464 ]
 [382.17615]
 [382.1536 ]
 [381.92377]
 [382.41132]
 [381.9718 ]
 [382.556  ]
 [382.38876]
 [382.20154]
 [382.59857]
 [383.46213]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 3.] 
cards in discard: [ 8.  0.  3. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 25. 30.  8.  3.  6.  9.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [16.  0. 10. 16.  0.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -10.612893104553223
desired expected reward: 370.9620666503906



buy possibilites: [-1] 
expected returns: [[389.8167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 3.] 
cards in discard: [ 8.  0.  3. 14.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 25. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [16.  0. 10. 16.  0.] 
adversary cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.] 
adversary owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8  3] -> size -> 38 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -1.0 

action type: buy - action 8.0
Learning step: -10.377715110778809
desired expected reward: 371.5940856933594






Player: 1 
cards in hand: [16.  0. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10. 16.  0.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0
  0  0 10 10  3  0  6  1  0  0 16 29  8  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 25. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 24. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 6.  1. 10.  6.  0. 16. 15.  0.  0.  0. 11.  0. 29.  0.  0.  1.  8. 10.
 16.  0.  3.  0.  8.  3.  0.  3.  8.  1.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [14.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [14.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[377.72437]
 [376.651  ]
 [376.23404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3] -> size -> 39 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -12.125219345092773
desired expected reward: 377.6914978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[377.66702]
 [378.0962 ]
 [378.07364]
 [377.89185]
 [379.38214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 23. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3] -> size -> 39 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -11.569051742553711
desired expected reward: 367.2945861816406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 1. 0.] 
adversary cards in discard: [14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 23. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 1. 0.] 
adversary cards in discard: [14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 1. 0.] 
adversary cards in discard: [14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [8. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[385.18713]
 [383.6968 ]
 [383.6968 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 1. 0.] 
cards in discard: [14.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 14  6  8  8  1  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 1. 6. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -11.962647438049316
desired expected reward: 367.41949462890625



action possibilites: [-1] 
expected returns: [[377.62485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [14.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 1. 6. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: trash_cards_n_from_hand - action 11
Learning step: -11.264808654785156
desired expected reward: 370.9625549316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[377.32434]
 [377.7309 ]
 [379.03943]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 1. 6. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -11.013252258300781
desired expected reward: 366.6116027832031



buy possibilites: [-1] 
expected returns: [[375.4397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14.  3.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 1. 6. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 6.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -12.56882381439209
desired expected reward: 364.7555236816406






Player: 1 
cards in hand: [1. 1. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6. 3. 0.] 
cards in discard: [3. 0. 3. 0. 0. 6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 6. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[380.17657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6.  9.  9.] 
adversary cards in hand: [10. 16. 11.  1.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22] -> size -> 41 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -11.842378616333008
desired expected reward: 363.5973205566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[379.5785 ]
 [379.9851 ]
 [381.29364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6.  9.  9.] 
adversary cards in hand: [10. 16. 11.  1.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22] -> size -> 41 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -12.14708423614502
desired expected reward: 369.16876220703125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 16. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 11.  1.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 16. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  1.  0. 10.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  1.  0. 10.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  6.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  1.  0. 10.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[383.30713]
 [381.81683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [3. 0. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 16.  8. 15.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 42 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -12.097959518432617
desired expected reward: 369.1956787109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[383.563  ]
 [383.7624 ]
 [383.99216]
 [383.9696 ]
 [383.7398 ]
 [384.22733]
 [383.78778]
 [384.37198]
 [384.20477]
 [384.01752]
 [384.4146 ]
 [385.27817]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [3. 0. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 16.  8. 15.  0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 42 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -12.158642768859863
desired expected reward: 371.14849853515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 16.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8. 15.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 15 10  0  1  3  0  0
  0 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0
 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0
 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 8.  3.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[368.02805]
 [366.60898]
 [366.60898]
 [367.00592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 29. 16.  8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0
 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 41 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -11.7610502243042
desired expected reward: 356.35650634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[367.46268]
 [367.84818]
 [369.09433]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  8. 29. 16.  8.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0.] 
adversary owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0
 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 41 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -11.810349464416504
desired expected reward: 357.2911376953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 29. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 16.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 16.  8.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0
 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  8.  6.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 11  8  8  0  0  6  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0
 10 10  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 8.  3.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[363.97873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 8.  3.  0.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 39 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -12.402880668640137
desired expected reward: 356.69146728515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[363.8355 ]
 [364.2427 ]
 [364.22092]
 [364.04807]
 [365.4671 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 8.  3.  0.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 39 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -12.164687156677246
desired expected reward: 352.3614196777344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 22. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[350.87695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -13.000264167785645
desired expected reward: 352.46685791015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[351.27832]
 [351.46667]
 [351.68558]
 [351.66373]
 [351.90967]
 [351.49088]
 [351.70975]
 [352.90994]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  9.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -12.328219413757324
desired expected reward: 339.8092346191406



buy possibilites: [-1] 
expected returns: [[360.8982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -35 

action type: buy - action 11.0
Learning step: -11.225272178649902
desired expected reward: 340.6843566894531






Player: 1 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [11.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [11.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  4. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [11.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  6. 22.  1.  1.  6.  3.  0. 10. 10. 16. 11.  1.  0.
 10.  8.  3. 16.  0. 29.  8.  0. 16.  3.  0.  0.  0.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [11.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[368.03668]
 [366.61765]
 [366.61765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 3.] 
cards in discard: [11.  3.  0.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8] -> size -> 41 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -12.423844337463379
desired expected reward: 348.4743347167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[366.80743]
 [367.1929 ]
 [368.43912]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8. 3.] 
cards in discard: [11.  3.  0.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8] -> size -> 41 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -12.7718505859375
desired expected reward: 355.26483154296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3. 10.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [25.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[380.46286]
 [379.46262]
 [379.44077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 16. 10.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25] -> size -> 42 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -12.501981735229492
desired expected reward: 355.9371032714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[380.36786]
 [380.77515]
 [380.7533 ]
 [380.58044]
 [381.99948]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  3.  3. 16. 10.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.] 
adversary owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25] -> size -> 42 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -13.126245498657227
desired expected reward: 368.0705871582031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16. 10.] 
cards in discard: [25.  0.  0.  1.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [ 3. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [25.  0.  0.  1.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11  8  0  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10
  3  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  3.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [ 3. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [ 3. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [ 3. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 8. 6. 3. 8.] 
adversary cards in discard: [ 3. 11.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[387.5625 ]
 [386.14346]
 [386.14346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 8.] 
cards in discard: [ 3. 11.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3.] 
adversary owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0] -> size -> 43 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -13.039580345153809
desired expected reward: 368.9599304199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[386.3993 ]
 [386.78476]
 [388.03098]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 8.] 
cards in discard: [ 3. 11.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3.] 
adversary owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0] -> size -> 43 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -13.307327270507812
desired expected reward: 374.25518798828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  9.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[382.20712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [ 3. 16.  8.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.] 
adversary owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 44 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -13.44345760345459
desired expected reward: 374.5875244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[381.91083]
 [382.31805]
 [382.2963 ]
 [382.12344]
 [383.54248]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 21. 30.  8.  3.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [ 3. 16.  8.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.] 
adversary owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 44 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -13.160780906677246
desired expected reward: 369.4211120605469



buy possibilites: [-1] 
expected returns: [[357.5386]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [ 3. 16.  8.  8.  0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.] 
adversary owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -364.0 

action type: buy - action 6.0
Learning step: -28.615005493164062
desired expected reward: 353.6812744140625






Player: 1 
cards in hand: [ 3. 16.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  8.  0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  8  0  0 16  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3
  0  6  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[341.39313]
 [340.47437]
 [340.0895 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [6. 3. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [22.  3.  0.  0. 29.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0] -> size -> 43 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -13.403227806091309
desired expected reward: 344.1353759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[341.37134]
 [341.54187]
 [341.743  ]
 [341.72247]
 [341.94946]
 [341.56454]
 [341.76575]
 [342.86823]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [6. 3. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [22.  3.  0.  0. 29.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0] -> size -> 43 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -12.565980911254883
desired expected reward: 328.8271789550781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [22.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0. 29.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [ 0.  6.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 16.  0.  3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22. 10.  8.] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [ 0.  6.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29. 16.  0.  3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22. 10.  8.] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  5.  8.  9.] 
adversary cards in hand: [ 0.  6.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29. 16.  0.  3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22. 10.  8.] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  6.  6.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[361.60223]
 [360.29852]
 [360.6629 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  8. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  3. 10.  0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -12.210920333862305
desired expected reward: 330.6573181152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[360.71533]
 [361.06647]
 [362.21222]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  8. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  3. 10.  0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -13.148653984069824
desired expected reward: 348.63818359375



buy possibilites: [-1] 
expected returns: [[361.83945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  8. 14.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  3. 10.  0.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -94.0 

action type: buy - action 0.0
Learning step: -14.594378471374512
desired expected reward: 346.1209411621094






Player: 1 
cards in hand: [ 1.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10.  0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  6.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.  0.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 0.  0.  6.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
adversary victory points: 1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[345.15527]
 [343.85162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 0.  0.  6.  6.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11.  0.  6. 10.  3.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.  1.  0.
  3. 10.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -13.53270435333252
desired expected reward: 348.3067321777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[344.5749 ]
 [344.94656]
 [344.9261 ]
 [344.76816]
 [346.07175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 0.  0.  6.  6.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11.  0.  6. 10.  3.] 
adversary cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.  1.  0.
  3. 10.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -12.681612968444824
desired expected reward: 332.4736633300781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10.  3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.  1.  0.
  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 10.  3.] 
cards in discard: [25.  0.  0.  1.  6.  0.  8.  0. 10. 16.  3.  3.  3. 22.  0.  3.  0.  1.
  0.  0.  8.  3.  0. 10. 22. 10.  8.  3.  0.  0. 29. 16.  0.  3.  1.  0.
  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
adversary victory points: 1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[354.81396]
 [353.5103 ]
 [353.8952 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -12.527917861938477
desired expected reward: 333.5438537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[354.25452]
 [354.6262 ]
 [354.60562]
 [354.44772]
 [355.7514 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  2.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -12.946757316589355
desired expected reward: 341.86724853515625



buy possibilites: [-1] 
expected returns: [[361.19107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  3. 10.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -56 

action type: buy - action 8.0
Learning step: -12.395588874816895
desired expected reward: 342.0521545410156






Player: 1 
cards in hand: [ 3.  3. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8] -> size -> 16 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  8.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8] -> size -> 16 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  1.  0.] 
cards in discard: [11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 3. 0. 8.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8] -> size -> 16 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[336.7469 ]
 [335.44324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [ 8.  8.  0. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22.  0.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10 11] -> size -> 45 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -13.689475059509277
desired expected reward: 347.5015869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[336.0231 ]
 [336.39478]
 [336.37427]
 [336.21634]
 [337.52002]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [ 8.  8.  0. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 21. 30.  8.  2.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22.  0.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10 11] -> size -> 45 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -12.453608512878418
desired expected reward: 324.29327392578125



buy possibilites: [-1] 
expected returns: [[336.73956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [ 8.  8.  0. 11.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0.  0. 22.  0.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10 11] -> size -> 45 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -375.0 

action type: buy - action 6.0
Learning step: -27.9920711517334
desired expected reward: 308.3822021484375






Player: 1 
cards in hand: [ 8.  0.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 22.  0.] 
cards in discard: [11.  3.  3. 10.  1.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6
  1  0  0 16 29  8  3  3  3  3 22 10  3  8 25  8  0 22  0 10 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.  6.  6.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11.  3.  3. 10.  1.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.  6.  6.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  3.  3. 10.  1.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.  6.  6.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  0.  6.  0.] 
adversary cards in discard: [ 8.  8.  0. 11.  0.  3.  6.  6.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [14.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[325.87305]
 [324.93375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  6.  0.] 
cards in discard: [ 8.  8.  0. 11.  0.  3.  6.  6.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [16.  0. 10.  0.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -13.25968074798584
desired expected reward: 323.4798889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[325.38455]
 [325.75623]
 [325.7357 ]
 [325.57773]
 [326.8814 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  6.  0.] 
cards in discard: [ 8.  8.  0. 11.  0.  3.  6.  6.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [16.  0. 10.  0.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -12.699285507202148
desired expected reward: 313.1737976074219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11. 14.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 21. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11. 14.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11. 14.  3.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11. 14.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
expected returns: [[362.3833 ]
 [361.46454]
 [361.44397]
 [361.07962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.] 
adversary owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -12.448600769042969
desired expected reward: 314.43280029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[328.78827]
 [329.10214]
 [330.13864]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  3.  6.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.] 
adversary owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -13.3185453414917
desired expected reward: 316.45062255859375



buy possibilites: [-1] 
expected returns: [[324.476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  3.  6.  8.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  0. 29.  8.  0.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.] 
adversary owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -115 

action type: buy - action 0.0
Learning step: -14.888702392578125
desired expected reward: 313.8995666503906






Player: 1 
cards in hand: [ 8.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  8.  0.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1
  0  0 16 29  8  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 11. 14.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 11. 14.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 11. 14.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [ 0. 11. 14.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[313.35046]
 [312.17236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 3. 0.] 
cards in discard: [ 0. 11. 14.  3.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [10.  6.  0. 16.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -13.429491996765137
desired expected reward: 311.0465087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[312.41516]
 [312.729  ]
 [313.7655 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 3. 0.] 
cards in discard: [ 0. 11. 14.  3.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [10.  6.  0. 16.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -12.866007804870605
desired expected reward: 300.4844665527344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  6.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 16.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 0. 11. 14.  3.  6.  8.  3.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0. 16.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 0. 11. 14.  3.  6.  8.  3.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[292.2251 ]
 [291.04703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [ 0. 11. 14.  3.  6.  8.  3.  8.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -13.369287490844727
desired expected reward: 300.3962097167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[292.25513]
 [292.40643]
 [292.58826]
 [292.569  ]
 [292.77536]
 [292.4274 ]
 [292.6092 ]
 [293.6055 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [ 0. 11. 14.  3.  6.  8.  3.  8.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -12.264941215515137
desired expected reward: 279.96014404296875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[299.3864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [22.  6.  1. 10.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0] -> size -> 43 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -12.194079399108887
desired expected reward: 281.411376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[299.5276 ]
 [299.67892]
 [299.86075]
 [299.84143]
 [299.6599 ]
 [300.0478 ]
 [299.69983]
 [300.16013]
 [300.02856]
 [299.88165]
 [300.1947 ]
 [300.87796]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [22.  6.  1. 10.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0] -> size -> 43 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -12.459089279174805
desired expected reward: 286.9273376464844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [22.  6.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  1. 10.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  8.  3.  8. 14.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  1. 10.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  8.  3.  8. 14.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  1. 10.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  8.  3.  8. 14.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  3.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[304.8398 ]
 [303.6617 ]
 [303.6617 ]
 [303.99042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  8. 14.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0. 22.  6.  1. 10.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0] -> size -> 44 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -12.443270683288574
desired expected reward: 288.4346923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[303.86646]
 [304.18033]
 [305.2168 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3.  8. 14.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  1.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0. 22.  6.  1. 10.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0] -> size -> 44 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -12.632820129394531
desired expected reward: 292.2070007324219



buy possibilites: [-1] 
expected returns: [[308.1308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3.  8. 14.] 
cards in discard: [3. 0. 0. 0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0. 22.  6.  1. 10.  3.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -396 

action type: buy - action 6.0
Learning step: -28.076074600219727
desired expected reward: 276.104248046875






Player: 1 
cards in hand: [11.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0. 22.  6.  1. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  6.  3.  8.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0. 22.  6.  1. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  6.  3.  8.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [11.  3.  3. 10.  1.  0.  0.  8.  0.  0.  3. 16.  0. 10.  0.  3.  0.  8.
 10.  6.  0. 16.  3.  0.  0. 25.  0.  0.  3.  0. 22.  6.  1. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  6.  3.  8.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[285.41293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  6.  3.  8.  3.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0] -> size -> 45 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -13.784749031066895
desired expected reward: 294.3460388183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[285.35455]
 [285.50586]
 [285.6877 ]
 [285.8748 ]
 [285.5268 ]
 [285.70862]
 [286.7049 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  6.  3.  8.  3.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0] -> size -> 45 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -12.629470825195312
desired expected reward: 272.783447265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  0.  6.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  0.  6.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 10.] 
cards in discard: [0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0.  0.  6.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[309.4022 ]
 [308.22412]
 [308.57208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -12.180602073669434
desired expected reward: 274.5242919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[308.79453]
 [309.12766]
 [308.96677]
 [310.1449 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 20. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -13.300992012023926
desired expected reward: 296.1011657714844



buy possibilites: [-1] 
expected returns: [[292.18872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  8. 11.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -77 

action type: buy - action 3.0
Learning step: -12.253700256347656
desired expected reward: 296.8739929199219






Player: 1 
cards in hand: [ 3.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 6.  0. 14.  8.  3.] 
adversary cards in discard: [ 3.  0.  0.  6.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 6.  0. 14.  8.  3.] 
adversary cards in discard: [ 3.  0.  0.  6.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[285.20605]
 [284.41858]
 [284.11487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  8.  3.] 
cards in discard: [ 3.  0.  0.  6.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -12.448760032653809
desired expected reward: 279.7399597167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[284.28162]
 [285.5307 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  8.  3.] 
cards in discard: [ 3.  0.  0.  6.  8. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [8. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -12.092302322387695
desired expected reward: 273.1136779785156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 16  1  0  0  6  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0
 16  3  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  6.  8. 11.  6.  0. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  6.  8. 11.  6.  0. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 26. 30. 19. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  6.  8. 11.  6.  0. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 3.  0.  0.  6.  8. 11.  6.  0. 14.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[269.0839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 3.  0.  0.  6.  8. 11.  6.  0. 14.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3] -> size -> 45 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -12.972147941589355
desired expected reward: 272.5585632324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[268.99677]
 [269.1349 ]
 [269.3031 ]
 [269.4769 ]
 [269.1547 ]
 [269.32288]
 [270.24585]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 3.  0.  0.  6.  8. 11.  6.  0. 14.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1.  0.  0. 10.  3.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3] -> size -> 45 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -12.132631301879883
desired expected reward: 256.9512634277344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  6.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [14.  3.  6.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [14.  3.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[288.6601 ]
 [287.87262]
 [287.5689 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 22.  0.  3.  3.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -11.773900985717773
desired expected reward: 258.4719543457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[287.846 ]
 [289.0951]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 22.  0.  3.  3.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16] -> size -> 46 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -12.684809684753418
desired expected reward: 275.97528076171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 22.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  3.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [14.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3.  0. 10.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [14.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3.  0. 10.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 26. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [14.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3.  0. 10.  3.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [14.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[285.44598]
 [284.35486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [14.  3.  6.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 16.  6. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1] -> size -> 47 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -12.787848472595215
desired expected reward: 276.3072509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[285.26672]
 [285.40488]
 [285.57306]
 [285.74686]
 [285.42465]
 [285.59283]
 [286.5158 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [14.  3.  6.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 0. 16.  6. 10.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1] -> size -> 47 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -12.584665298461914
desired expected reward: 272.8613586425781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6. 10.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6. 10.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 18. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6. 10.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[272.2428 ]
 [271.15164]
 [271.47388]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 14  6  8  3  8  0 11  6  0  8  6  0  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1. 10.  3. 16.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3] -> size -> 48 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -13.456725120544434
desired expected reward: 273.05908203125



action possibilites: [-1] 
expected returns: [[285.80215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1. 10.  3. 16.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3] -> size -> 48 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 11
Learning step: -11.3574857711792
desired expected reward: 259.4031982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[285.63687]
 [286.88596]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [ 1. 10.  3. 16.  0.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3] -> size -> 48 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -12.0916166305542
desired expected reward: 273.7105407714844






Player: 1 
cards in hand: [ 1. 10.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3. 16.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3. 16.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  1.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3. 16.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [3. 6. 3. 0. 6.] 
adversary cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[274.45056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [25.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -13.419161796569824
desired expected reward: 273.4668273925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[273.66443]
 [274.9135 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [25.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -12.793417930603027
desired expected reward: 261.6571350097656



buy possibilites: [-1] 
expected returns: [[266.87543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 6.] 
cards in discard: [14.  3.  6.  0.  8.  6.  0.  0.  8.  0.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [25.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -135.0 

action type: buy - action 0.0
Learning step: -14.4285249710083
desired expected reward: 259.23590087890625






Player: 1 
cards in hand: [25.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  8. 11.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  3.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  3.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 17. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  3.  0.] 
cards in discard: [ 0.  1.  0.  0.  3. 10.  3.  3.  0.  0. 11.  3.  8.  0.  0. 16.  1.  0.
  0. 10.  3.  1. 22.  0.  0.  3.  3.  0. 10.  3.  3.  0. 16.  6. 10.  0.
  8.  1. 10.  3. 16.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
adversary victory points: 0
player victory points: 11 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[275.9804 ]
 [274.88928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8  3] -> size -> 50 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -12.889841079711914
desired expected reward: 253.98558044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[252.43098]
 [252.55394]
 [252.70657]
 [252.86467]
 [252.72476]
 [253.56279]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  4.  8.  9.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8  3] -> size -> 50 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -12.682406425476074
desired expected reward: 239.9130859375



buy possibilites: [-1] 
expected returns: [[258.76343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8  3] -> size -> 50 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -97 

action type: buy - action 10.0
Learning step: -11.6640625
desired expected reward: 241.06072998046875






Player: 1 
cards in hand: [0. 1. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 16  1  0  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3
  3  3  3 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3
  8  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  0. 14.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  0. 14.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  0. 14.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 45 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  3.  0.  0. 14.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 10 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[262.6039 ]
 [261.88846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  0. 14.] 
cards in discard: [10.  8.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [10. 10.  0.  3.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 48 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -12.28327465057373
desired expected reward: 246.4801483154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[262.13254]
 [262.4081 ]
 [263.2643 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  0. 14.] 
cards in discard: [10.  8.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [10. 10.  0.  3.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 48 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -12.463584899902344
desired expected reward: 250.14031982421875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  8.] 
cards in discard: [0. 8. 0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 16  0  0 10  0  1  3  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3
 10  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [8. 8. 6. 0. 6.] 
adversary cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [8. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[260.02185]
 [259.03125]
 [259.03125]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 6.] 
cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 14  6  8  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.] 
adversary owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -12.069537162780762
desired expected reward: 251.1947784423828



action possibilites: [-1] 
expected returns: [[261.3095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.] 
adversary owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: trash_cards_n_from_hand - action 11
Learning step: -10.254054069519043
desired expected reward: 248.41629028320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[261.17343]
 [262.30524]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  8.  3.  0.  0.  0.  6.  3.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.] 
adversary owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -10.36944580078125
desired expected reward: 250.9400634765625






Player: 1 
cards in hand: [ 0. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[256.18964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  1.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.  0. 11.  0.  3.  3.] 
adversary owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -11.550994873046875
desired expected reward: 250.75424194335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[255.66353]
 [255.9391 ]
 [256.79532]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 3.  3.  1.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.  0. 11.  0.  3.  3.] 
adversary owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -11.238423347473145
desired expected reward: 244.9512176513672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0. 11.] 
cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.  0. 11.  0.  3.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  9. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  8.] 
adversary cards in discard: [0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.  0. 11.  0.  3.  3. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0
 14] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  8.] 
adversary cards in discard: [0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0.] 
cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.  0. 11.  0.  3.  3. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0
 14] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  8.] 
adversary cards in discard: [0. 0. 3. 6. 3.] 
adversary owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 9 


Player 1 won the game! 



Player 0 bought cards:
Copper: 4 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  0. 14.  3.  8.] 
cards in discard: [0. 0. 3. 6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 14  3  8  0  6  0  8  6  0  6  3  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 25. 30. 16. 30.  8.  0.  5.  7.  0.  9.  9.  8. 10.  3.  8.  9.] 
adversary cards in hand: [3. 3. 1. 0.] 
adversary cards in discard: [ 0.  8.  0.  0. 10.  8. 10.  0.  0.  0. 11.  0.  3.  3. 14.  0.] 
adversary owned cards: [11 16  0  0 10  0  1  0  0  0 10 10  3  0  6  1  0  0 16  3  3  3  3 10
  3  8 25  8  0 22  0 10 11  0  3  0  0  0  0  0  3 16  1  3  8  3  0  0
 14  0] -> size -> 50 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -80    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -584 

action type: buy - action -1.0
Learning step: -42.039764404296875
desired expected reward: 214.75555419921875



