 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.072239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
None 
sum of rewards: None 

action type: None - action None
Learning step: None
desired expected reward: None





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.170881]
 [25.18542 ]
 [25.197788]
 [25.19725 ]
 [25.213503]
 [25.186592]
 [25.198961]
 [25.278118]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6438451409339905
desired expected reward: 24.644128799438477



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.159628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6419242024421692
desired expected reward: 24.636198043823242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.31064 ]
 [25.325184]
 [25.337553]
 [25.337017]
 [25.324446]
 [25.353268]
 [25.326359]
 [25.368706]
 [25.35273 ]
 [25.338726]
 [25.367271]
 [25.417887]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6449089646339417
desired expected reward: 24.728370666503906



buy possibilites: [-1] 
expected returns: [[26.145124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5010742545127869
desired expected reward: 24.85219383239746






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.93378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6598185896873474
desired expected reward: 25.485305786132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.026499]
 [26.041037]
 [26.053406]
 [26.05287 ]
 [26.069122]
 [26.042212]
 [26.05458 ]
 [26.133738]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6606079339981079
desired expected reward: 25.4855899810791



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.734966]
 [26.67035 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6513174772262573
desired expected reward: 25.482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.844893]
 [26.85943 ]
 [26.8718  ]
 [26.871262]
 [26.887514]
 [26.860605]
 [26.872974]
 [26.952131]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.676103413105011
desired expected reward: 26.273048400878906



buy possibilites: [-1] 
expected returns: [[26.800354]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 3. 0. 0. 3. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.13437914848327637
desired expected reward: 26.72504997253418






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.914238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.66915363073349
desired expected reward: 26.131200790405273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.102283]
 [27.116823]
 [27.129196]
 [27.116285]
 [27.128654]
 [27.116087]
 [27.144907]
 [27.117998]
 [27.146343]
 [27.160345]
 [27.14437 ]
 [27.157   ]
 [27.13037 ]
 [27.142462]
 [27.158909]
 [27.209526]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6787706017494202
desired expected reward: 26.45046043395996



buy possibilites: [-1] 
expected returns: [[27.33879]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 0.  8. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8] -> size -> 16 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 4.0
Learning step: 0.8235686421394348
desired expected reward: 27.939855575561523






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 0.  8. 11.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [4. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 0.  8. 11.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [4. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 0.  8. 11.  0.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [4. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4] -> size -> 13 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[28.25229 ]
 [28.187672]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [4. 3. 0. 0. 1. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6714844703674316
desired expected reward: 26.667306900024414



action possibilites: [-1] 
expected returns: [[28.68101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [4. 3. 0. 0. 1. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.020022811368107796
desired expected reward: 28.390949249267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.6096  ]
 [28.624142]
 [28.636509]
 [28.635973]
 [28.652227]
 [28.625317]
 [28.637686]
 [28.716843]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [4. 3. 0. 0. 1. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.10952968150377274
desired expected reward: 28.57147979736328



buy possibilites: [-1] 
expected returns: [[30.944538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [4. 3. 0. 0. 1. 0. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.07125463336706161
desired expected reward: 30.134489059448242






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.197697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.758856475353241
desired expected reward: 30.18568229675293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.358852]
 [30.37396 ]
 [30.386827]
 [30.386356]
 [30.37316 ]
 [30.403114]
 [30.375149]
 [30.419199]
 [30.40265 ]
 [30.38801 ]
 [30.417755]
 [30.470205]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7434830069541931
desired expected reward: 29.683156967163086



buy possibilites: [-1] 
expected returns: [[30.608078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8] -> size -> 17 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.740205764770508
desired expected reward: 20.64615249633789






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [11.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 3. 8. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 3. 8. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 3. 8. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [3. 1. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[31.322834]
 [31.227774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 8. 3.] 
cards in discard: [6. 0. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.  0.  0. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7373126149177551
desired expected reward: 29.870765686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.373655]
 [31.401623]
 [31.401157]
 [31.389944]
 [31.485   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 8. 3.] 
cards in discard: [6. 0. 0. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 8. 10.  8.  0.  0.  0.  0. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7666892409324646
desired expected reward: 30.788448333740234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.  0. 11.  0. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  4.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0. 3. 1. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.  0. 11.  0. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  4.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0. 3. 1. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 8. 10.  8.  0.  0.  0.  0. 11.  0. 11.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  4.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0. 3. 1. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[32.62788 ]
 [32.560795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  4.] 
cards in discard: [6. 0. 0. 0. 3. 0. 3. 1. 3. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7498214840888977
desired expected reward: 30.735183715820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.748676]
 [32.763783]
 [32.776646]
 [32.77618 ]
 [32.792942]
 [32.76497 ]
 [32.777836]
 [32.860027]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  4.] 
cards in discard: [6. 0. 0. 0. 3. 0. 3. 1. 3. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7913637161254883
desired expected reward: 32.066768646240234



buy possibilites: [-1] 
expected returns: [[32.654118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  4.] 
cards in discard: [6. 0. 0. 0. 3. 0. 3. 1. 3. 8. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  1.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.2500452697277069
desired expected reward: 32.513736724853516






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [14.  1.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 4. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 4. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 4. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  3.] 
cards in discard: [14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 4. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.526432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 4. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3. 10.] 
adversary cards in discard: [14. 14.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14] -> size -> 20 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 7
Learning step: -0.791851282119751
desired expected reward: 32.06966781616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.587223]
 [32.615192]
 [32.614723]
 [32.60351 ]
 [32.69857 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 4. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  7. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3. 10.] 
adversary cards in discard: [14. 14.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14] -> size -> 20 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7901334762573242
desired expected reward: 31.97122573852539



buy possibilites: [-1] 
expected returns: [[33.41987]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 4. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3. 10.] 
adversary cards in discard: [14. 14.  1.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14] -> size -> 20 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.5371967554092407
desired expected reward: 32.066314697265625






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3. 10.] 
cards in discard: [14. 14.  1.  0. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  3.] 
cards in discard: [14. 14.  1.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [14. 14.  1.  0. 11.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [14. 14.  1.  0. 11.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [14. 14.  1.  0. 11.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [8. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.1294  ]
 [34.034336]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 4. 11.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [14. 14.  1.  0. 11.  3.  3.  0. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7922189831733704
desired expected reward: 32.62765121459961



action possibilites: [-1] 
expected returns: [[33.606323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 4. 11.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [14. 14.  1.  0. 11.  3.  3.  0. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.2166866660118103
desired expected reward: 33.96610641479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.54164]
 [33.56836]
 [33.65013]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 4. 11.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [14. 14.  1.  0. 11.  3.  3.  0. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.20539604127407074
desired expected reward: 33.40092849731445






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [14. 14.  1.  0. 11.  3.  3.  0. 10. 11.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 6. 0. 1.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [14. 14.  1.  0. 11.  3.  3.  0. 10. 11.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 6. 0. 1.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [14. 14.  1.  0. 11.  3.  3.  0. 10. 11.  3.  0.  3.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 6. 0. 1.] 
adversary cards in discard: [ 4. 11.  8.  0.  3.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [1. 3. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.751316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 0. 1.] 
cards in discard: [ 4. 11.  8.  0.  3.  0.  8.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0 15] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7927735447883606
desired expected reward: 32.857357025146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.970215]
 [34.985012]
 [34.9975  ]
 [34.984447]
 [34.996937]
 [34.984154]
 [35.013412]
 [34.986126]
 [35.014862]
 [35.02909 ]
 [35.012848]
 [35.025673]
 [34.998615]
 [35.01088 ]
 [35.027645]
 [35.078705]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 1.] 
cards in discard: [ 4. 11.  8.  0.  3.  0.  8.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0 15] -> size -> 23 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8300747275352478
desired expected reward: 34.09662628173828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  3  1 10  0  8 11  8  0 14 14  3  0 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.769873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [15. 14. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8663659691810608
desired expected reward: 34.21234130859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.934517]
 [31.949312]
 [31.961802]
 [31.961237]
 [31.948458]
 [31.977715]
 [31.950428]
 [31.993391]
 [31.977146]
 [31.962917]
 [31.991943]
 [32.043007]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [15. 14. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7741398811340332
desired expected reward: 31.22541046142578



buy possibilites: [-1] 
expected returns: [[33.284416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [15. 14. 14.  8.  0.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.19972801208496094
desired expected reward: 32.191673278808594






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [15. 14. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14. 14.  8.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 0. 3. 1.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8 15] -> size -> 18 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  8.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8 15] -> size -> 18 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  8.  0.] 
cards in discard: [8. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8 15] -> size -> 18 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  8.  0.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8 15] -> size -> 18 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.163494]
 [34.07091 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  4  3  8  6  1  8 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3] -> size -> 22 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.8529568910598755
desired expected reward: 34.60043716430664



action possibilites: [-1] 
expected returns: [[33.77172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.2221709042787552
desired expected reward: 34.00362777709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.707035]
 [33.733757]
 [33.815525]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3] -> size -> 22 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.2086213231086731
desired expected reward: 33.5630989074707






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 6. 3. 4. 1.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 6. 3. 4. 1.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 26. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 6. 3. 4. 1.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [8. 6. 3. 4. 1.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [8. 6. 3. 4. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.869446]
 [34.776867]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 4. 1.] 
cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  1  4  3  8  6  1  8 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7970731258392334
desired expected reward: 33.01845169067383



action possibilites: [-1] 
expected returns: [[34.033413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 1.] 
cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.237812802195549
desired expected reward: 34.600975036621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[34.020535]
 [34.04782 ]
 [34.047253]
 [34.036446]
 [34.12903 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1.] 
cards in discard: [15.  0.  0.  3.  0.  0.  3.  1.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.21325922012329102
desired expected reward: 33.820152282714844






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6. 10. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 14. 15. 14.  8.  0.  1.  3. 11.  3.  0. 11.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 1.  0.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[33.87483]
 [33.80953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8160810470581055
desired expected reward: 33.31294250488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.875084]
 [33.889713]
 [33.887283]
 [33.901913]
 [33.889038]
 [33.901237]
 [33.888763]
 [33.917603]
 [33.890774]
 [33.919083]
 [33.933037]
 [33.916927]
 [33.929543]
 [33.90297 ]
 [33.914917]
 [33.93155 ]
 [33.981632]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 26. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8089509010314941
desired expected reward: 33.02960968017578



buy possibilites: [-1] 
expected returns: [[33.77265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 11.  0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.6770786046981812
desired expected reward: 33.2126350402832






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [0. 4. 3. 0. 8.] 
adversary cards in discard: [ 1.  1.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15  1] -> size -> 16 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [0. 4. 3. 0. 8.] 
adversary cards in discard: [ 1.  1.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15  1] -> size -> 16 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [0. 4. 3. 0. 8.] 
adversary cards in discard: [ 1.  1.  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15  1] -> size -> 16 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [0. 4. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[34.18052]
 [34.08966]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 3. 0. 8.] 
cards in discard: [ 1.  1.  0.  1. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  1  4  3  8  1  8 15  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8023970723152161
desired expected reward: 32.970252990722656



action possibilites: [-1] 
expected returns: [[33.66475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0.] 
cards in discard: [ 1.  1.  0.  1. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.22422705590724945
desired expected reward: 34.03266906738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.595234]
 [33.621387]
 [33.701782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0.] 
cards in discard: [ 1.  1.  0.  1. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.2065972089767456
desired expected reward: 33.458152770996094






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [8. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 15.] 
adversary cards in discard: [ 1.  1.  0.  1. 11.  0.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [8. 3. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  9. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 15.] 
adversary cards in discard: [ 1.  1.  0.  1. 11.  0.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 8.  3.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  0.  3.  0. 15.] 
adversary cards in discard: [ 1.  1.  0.  1. 11.  0.  8.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 8.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[36.144676]
 [36.053818]
 [36.094597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 15.] 
cards in discard: [ 1.  1.  0.  1. 11.  0.  8.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  1. 14.] 
adversary cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7797253727912903
desired expected reward: 32.92205810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.201576]
 [36.2284  ]
 [36.227726]
 [36.217262]
 [36.30812 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 15.] 
cards in discard: [ 1.  1.  0.  1. 11.  0.  8.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 25. 29.  8.  9. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  1. 14.] 
adversary cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8600017428398132
desired expected reward: 35.494544982910156



buy possibilites: [-1] 
expected returns: [[36.834152]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 15.] 
cards in discard: [ 1.  1.  0.  1. 11.  0.  8.  4.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0.  3. 14.  1. 14.] 
adversary cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.850072860717773
desired expected reward: 26.377653121948242






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  1. 14.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [4. 1. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 14.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [4. 0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 14.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8. 10.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [4. 0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 14.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [4. 0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.709003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [4. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 25.  8.  0.] 
adversary cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29. 14.  0.  3.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 0
Learning step: -0.8973708152770996
desired expected reward: 36.58965301513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.914337]
 [35.928967]
 [35.941166]
 [35.92829 ]
 [35.94049 ]
 [35.928013]
 [35.956852]
 [35.930027]
 [35.958332]
 [35.97229 ]
 [35.95618 ]
 [35.968796]
 [35.942226]
 [35.95417 ]
 [35.970806]
 [36.020885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [4. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 11. 25.  8.  0.] 
adversary cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29. 14.  0.  3.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8501979112625122
desired expected reward: 35.0774040222168



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  8.  0.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29. 14.  0.  3.  1. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  8. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 11.  3.] 
adversary cards in discard: [4. 0. 1. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6] -> size -> 15 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0. 11.  0.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29. 14.  0.  3.  1. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 29.  8.  7. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 11.  3.] 
adversary cards in discard: [4. 0. 1. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0. 11.  0.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29. 14.  0.  3.  1. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 25. 29.  8.  7. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 11.  3.] 
adversary cards in discard: [4. 0. 1. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6] -> size -> 16 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  0. 11.  0.] 
cards in discard: [ 8.  3.  3. 25.  1.  0.  0.  0.  3. 29. 14.  0.  3.  1. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 11.  3.] 
adversary cards in discard: [4. 0. 1. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6] -> size -> 16 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 8.  6.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[37.865997]
 [37.775143]
 [37.801968]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 11.  3.] 
cards in discard: [4. 0. 1. 1. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  6.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  1.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29  3] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: -9.831280708312988
desired expected reward: 26.189605712890625



action possibilites: [-1] 
expected returns: [[38.783016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 3.] 
cards in discard: [4. 0. 1. 1. 0. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  1.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29  3] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: -0.16243399679660797
desired expected reward: 37.826087951660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.6658  ]
 [38.691948]
 [38.772346]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 3.] 
cards in discard: [4. 0. 1. 1. 0. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  1.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29  3] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.30690425634384155
desired expected reward: 38.476112365722656






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [14.  1.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25
 29  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  8.] 
adversary cards in discard: [ 4.  0.  1.  1.  0.  6.  8. 11.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  8.] 
adversary cards in discard: [ 4.  0.  1.  1.  0.  6.  8. 11.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 24. 29.  8.  7. 10.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  8.] 
adversary cards in discard: [ 4.  0.  1.  1.  0.  6.  8. 11.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.] 
cards in discard: [16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 1.  0. 15.  0.  8.] 
adversary cards in discard: [ 4.  0.  1.  1.  0.  6.  8. 11.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 1.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[39.08132]
 [39.03212]
 [38.99205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  8.] 
cards in discard: [ 4.  0.  1.  1.  0.  6.  8. 11.  8.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8869262933731079
desired expected reward: 37.36909484863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.242176]
 [39.256626]
 [39.268547]
 [39.26778 ]
 [39.25561 ]
 [39.28403 ]
 [39.25766 ]
 [39.299255]
 [39.283268]
 [39.269573]
 [39.29772 ]
 [39.346928]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  8.] 
cards in discard: [ 4.  0.  1.  1.  0.  6.  8. 11.  8.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9121324419975281
desired expected reward: 38.24424743652344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [16. 15. 14.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [16. 15. 14.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [6. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [16. 15. 14.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  7.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [6. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [16. 15. 14.  1.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [6. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.240593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [6. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 29. 11.  3.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 2
Learning step: -0.9585076570510864
desired expected reward: 39.10073471069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[37.40808 ]
 [37.42254 ]
 [37.434452]
 [37.43369 ]
 [37.42152 ]
 [37.44994 ]
 [37.42357 ]
 [37.465164]
 [37.449177]
 [37.435482]
 [37.46363 ]
 [37.51284 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [6. 1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 8. 29. 11.  3.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11] -> size -> 27 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8803262710571289
desired expected reward: 36.573917388916016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8. 29. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 11.  3.  0.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  8.] 
adversary cards in hand: [ 6. 15.  8. 11.  8.] 
adversary cards in discard: [6. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6. 15.  8. 11.  8.] 
adversary cards in discard: [6. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.  0.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6. 15.  8. 11.  8.] 
adversary cards in discard: [6. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.  0.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 6. 15.  8. 11.  8.] 
adversary cards in discard: [6. 1. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 15.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.  8.] 
expected returns: [[40.170044]
 [40.120842]
 [40.080772]
 [40.107147]
 [40.080772]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  8. 11.  8.] 
cards in discard: [6. 1. 0. 0. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  9. 10.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.852510392665863
desired expected reward: 36.66032791137695



action possibilites: [-1] 
expected returns: [[41.122814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  8.  8.] 
cards in discard: [ 6.  1.  0.  0.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: -0.05553554370999336
desired expected reward: 40.18863296508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.016148]
 [41.041756]
 [41.120907]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  8.  8.] 
cards in discard: [ 6.  1.  0.  0.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.3524298369884491
desired expected reward: 40.7703857421875



buy possibilites: [-1] 
expected returns: [[41.131535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  8.  8.] 
cards in discard: [ 6.  1.  0.  0.  1. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [ 3. 11.  1. 25.  0.] 
adversary cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.3486032783985138
desired expected reward: 40.667545318603516






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1. 25.  0.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 8. 4. 0.] 
adversary cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0] -> size -> 19 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  0.  8. 25.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 8. 4. 0.] 
adversary cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  0.  8. 25.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 8. 4. 0.] 
adversary cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  0.  8. 25.] 
cards in discard: [16. 15. 14.  1.  3. 11. 14.  0.  3.  0.  0. 15.  0. 11.  8. 29.  3.  0.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 8. 4. 0.] 
adversary cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [1. 0. 8. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[40.884872]
 [40.7956  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 4. 0.] 
cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.955029487609863
desired expected reward: 31.17650604248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.96949 ]
 [40.98395 ]
 [40.995865]
 [40.9951  ]
 [40.982937]
 [41.011353]
 [40.984985]
 [41.026573]
 [41.01059 ]
 [40.99689 ]
 [41.025047]
 [41.07425 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 4. 0.] 
cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  8. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9458502531051636
desired expected reward: 39.939022064208984



buy possibilites: [-1] 
expected returns: [[41.447853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 4. 0.] 
cards in discard: [ 6.  1.  0.  0.  1. 10.  0. 11.  6. 15.  8.  8.  6. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: 0.014884757809340954
desired expected reward: 41.025474548339844






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  6.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14] -> size -> 21 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  5.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  6.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14] -> size -> 21 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  6.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14] -> size -> 21 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [11.  6.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[40.758553]
 [40.695656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  3. 25.  0. 11.] 
adversary cards in discard: [8. 8. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9643657803535461
desired expected reward: 40.48348617553711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.855   ]
 [40.869457]
 [40.88137 ]
 [40.880608]
 [40.89686 ]
 [40.87049 ]
 [40.882397]
 [40.959755]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  6.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  3. 25.  0. 11.] 
adversary cards in discard: [8. 8. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9472025632858276
desired expected reward: 39.94175720214844



buy possibilites: [-1] 
expected returns: [[41.406963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  1.  0.  3.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  3. 25.  0. 11.] 
adversary cards in discard: [8. 8. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.4003264605998993
desired expected reward: 40.49653625488281






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [14.  3. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 25.  0. 11.] 
cards in discard: [8. 8. 0. 3. 3. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  6. 15.  8.  6.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 22 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 25.  0.] 
cards in discard: [8. 8. 0. 3. 3. 0. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  6. 15.  8.  6.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 22 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 25.  0.] 
cards in discard: [8. 8. 0. 3. 3. 0. 1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  6. 15.  8.  6.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 22 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[42.034622]
 [41.986256]
 [41.94674 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  8.  6.] 
cards in discard: [11. 11.  6.  1.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [15. 29.  3.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9512268304824829
desired expected reward: 40.45573806762695



action possibilites: [-1] 
expected returns: [[42.65347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6.] 
cards in discard: [11. 11.  6.  1.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [15. 29.  3.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.36172622442245483
desired expected reward: 41.62453079223633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.59998 ]
 [42.614315]
 [42.625988]
 [42.625156]
 [42.641396]
 [42.615387]
 [42.62706 ]
 [42.703274]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [11. 11.  6.  1.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 24. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [15. 29.  3.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.38182199001312256
desired expected reward: 42.27164840698242



buy possibilites: [-1] 
expected returns: [[42.871426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [15. 29.  3.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.31862959265708923
desired expected reward: 42.30735778808594






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [15. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.  0.  3.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 8. 1. 4.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3] -> size -> 22 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  3.  0.  3.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 8. 1. 4.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3] -> size -> 22 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 1. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[42.238865]
 [42.150978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 4.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  0.  1.  0. 16.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9930038452148438
desired expected reward: 41.878421783447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[42.323303]
 [42.337643]
 [42.349316]
 [42.34848 ]
 [42.336533]
 [42.364727]
 [42.338715]
 [42.379776]
 [42.363895]
 [42.350388]
 [42.378227]
 [42.426598]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 4.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  5.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  0.  1.  0. 16.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9722616076469421
desired expected reward: 41.266597747802734



buy possibilites: [-1] 
expected returns: [[42.12395]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 4.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  4.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  0.  1.  0. 16.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.8436402082443237
desired expected reward: 41.52108383178711






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1.  0. 16.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  4.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  1. 14.  0.  0.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1.  0. 16.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  4.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  1. 14.  0.  0.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1.  0. 16.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  3.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  1. 14.  0.  0.] 
adversary cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 8.  1. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[38.167583]
 [38.0797  ]
 [38.104877]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14.  0.  0.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  3.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11. 11.  0. 15.  1.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.013380527496338
desired expected reward: 41.11056900024414



action possibilites: [-1] 
expected returns: [[38.38232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  3.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  0.  1.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.2901321053504944
desired expected reward: 37.81475067138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[38.523544]
 [38.537876]
 [38.535213]
 [38.54955 ]
 [38.53704 ]
 [38.548717]
 [38.536766]
 [38.564957]
 [38.538944]
 [38.566505]
 [38.58001 ]
 [38.564125]
 [38.57628 ]
 [38.550617]
 [38.561943]
 [38.57846 ]
 [38.62683 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  3.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  0.  1.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.2964702844619751
desired expected reward: 38.08584976196289



buy possibilites: [-1] 
expected returns: [[39.33142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [11. 11.  6.  1.  0.  3.  3. 15.  6.  8.  6. 11.  0.  0.  8.  1.  4. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  0.  1.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: -0.1589687317609787
desired expected reward: 38.40598678588867






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  8.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  4.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  8.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  8.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 6.  8.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[43.565723]
 [43.477837]
 [43.50385 ]
 [43.489513]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  6  8 10  0  6 14 11  3 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  0.  1. 25.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8727557063102722
desired expected reward: 38.45866394042969



action possibilites: [-1] 
expected returns: [[42.983505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  0.  1. 25.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.4003153443336487
desired expected reward: 42.98775863647461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.086582]
 [43.11176 ]
 [43.189877]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  0.  1. 25.  3.] 
adversary cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.3865193724632263
desired expected reward: 42.59698486328125






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [14.  0.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1. 25.  3.] 
cards in discard: [ 8.  8.  0.  3.  3.  0.  1. 11. 14.  3. 25.  0. 15. 29.  3.  0.  3. 11.
  8.  0.  1.  0. 16. 11. 15.  8. 11.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  6.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [4. 1. 6. 0. 8.] 
adversary cards in discard: [ 8.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.  3.  3.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [4. 1. 6. 0. 8.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.  3.  3.  1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 23. 30. 23. 29.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [4. 1. 6. 0. 8.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.  3.  3.  1.] 
cards in discard: [4.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [4. 1. 6. 0. 8.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 3
player victory points: 9 





Player: 0 
cards in hand: [4. 1. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[42.823124]
 [42.73524 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 1. 6. 0. 8.] 
cards in discard: [ 8.  0. 11. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  0. 25.  0.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4] -> size -> 35 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: -9.996421813964844
desired expected reward: 33.19345474243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.783283]
 [42.797398]
 [42.80882 ]
 [42.807915]
 [42.82403 ]
 [42.798492]
 [42.809917]
 [42.88411 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 6. 0. 8.] 
cards in discard: [ 8.  0. 11. 10.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [14.  0. 25.  0.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4] -> size -> 35 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9820535182952881
desired expected reward: 41.742942810058594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [14.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 25.  0.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 1. 11.  3.  0. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  8.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [11.  3. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[41.747677]
 [41.687595]
 [41.687595]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 23. 28.  8.  5.  9.  2.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 5
Learning step: -1.0000053644180298
desired expected reward: 41.93397903442383



action possibilites: [-1] 
expected returns: [[41.026802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 28.  8.  5.  9.  2.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: -0.3686237335205078
desired expected reward: 41.27821350097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.96953]
 [40.99416]
 [41.07036]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 23. 28.  8.  5.  9.  2.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 3.  0.  0. 11.  3.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25] -> size -> 36 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.35006096959114075
desired expected reward: 40.67674255371094






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 28.  8.  5.  9.  2.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 14. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 23. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 14. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 23. 30. 23. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 14. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25 11  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 14. 11.] 
adversary cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [ 6.  1.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[38.617462]
 [38.556477]
 [38.55738 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 14. 11.] 
cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0. 11.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  3.  8. 15.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25 11  3] -> size -> 38 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9769665598869324
desired expected reward: 40.0933952331543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[38.666985]
 [38.681107]
 [38.692528]
 [38.691628]
 [38.707745]
 [38.6822  ]
 [38.693626]
 [38.767826]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 14. 11.] 
cards in discard: [ 8.  0. 11. 10.  6.  4.  1.  6.  0.  8.  1.  0.  0. 11.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  3.  8. 15.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25 11  3] -> size -> 38 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9020485877990723
desired expected reward: 37.71541213989258



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 15.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  3  1  0  8 11  8  0 14 14  3  0 15  3  1  3 25 25 29
  3 16 11 15  0  1  8  1 11  8  4 25 11  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [10.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [10.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [10.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [10.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 9 





Player: 0 
cards in hand: [10.  0.  3.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[44.436188]
 [44.361984]
 [44.350567]
 [44.389317]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  4  3  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [29.  8.  1.  1. 16.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3  0] -> size -> 37 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8468887805938721
desired expected reward: 37.92093276977539



action possibilites: [-1] 
expected returns: [[44.502956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [29.  8.  1.  1. 16.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3  0] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: -0.4105059802532196
desired expected reward: 43.84906005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.54243 ]
 [44.567066]
 [44.643265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [29.  8.  1.  1. 16.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0.] 
adversary owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3  0] -> size -> 37 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.4168300926685333
desired expected reward: 44.086124420166016






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [29.  8.  1.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  1.  1. 16.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 4. 14. 11. 11.  3.] 
adversary cards in discard: [ 8. 10. 15.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  1. 16.  3.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 11  3  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16
 11 15  0  1  8  1 11  8  4 25 11  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  8. 10.  7.] 
adversary cards in hand: [ 4. 14. 11. 11.  3.] 
adversary cards in discard: [ 8. 10. 15.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 1.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 4. 14. 11. 11.  3.] 
adversary cards in discard: [ 8. 10. 15.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 1.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  3.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 4. 14. 11. 11.  3.] 
adversary cards in discard: [ 8. 10. 15.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 1.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 4. 14. 11. 11.  3.] 
adversary cards in discard: [ 8. 10. 15.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 4. 14. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 11.] 
expected returns: [[45.6638  ]
 [45.602814]
 [45.60372 ]
 [45.60372 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14. 11. 11.  3.] 
cards in discard: [ 8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11. 11. 11.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1.] 
adversary owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.010208249092102
desired expected reward: 43.633052825927734



action possibilites: [-1] 
expected returns: [[45.93476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 11. 11.  3.] 
cards in discard: [ 8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.4357694387435913
desired expected reward: 45.16704559326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[45.87877 ]
 [45.90431 ]
 [45.903404]
 [45.89399 ]
 [45.979603]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 11. 11.  3.] 
cards in discard: [ 8. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 11.  0.] 
adversary cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.4458247423171997
desired expected reward: 45.48893737792969






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11
 15  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  0. 11.  1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  0. 11.  1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  0. 11.  1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 4. 25. 14.  0.  1.  3.  3.  1. 25. 14.  0. 25.  0.  0. 11.  3. 11.  3.
  0.  0.  3.  0.  8. 15.  0. 10.  8. 29. 16.  8.  1.  1. 11. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [11.  1.  0. 11.  1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [11.  1.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[43.910233]
 [43.85015 ]
 [43.85015 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 11.  1.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  4.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.0686672925949097
desired expected reward: 44.91093826293945



action possibilites: [-1] 
expected returns: [[43.424885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  1.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  4.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: -0.1366695761680603
desired expected reward: 43.61769485473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.612785]
 [43.62671 ]
 [43.637955]
 [43.62576 ]
 [43.637012]
 [43.625275]
 [43.652977]
 [43.627808]
 [43.654213]
 [43.667183]
 [43.652035]
 [43.663418]
 [43.63906 ]
 [43.649498]
 [43.66595 ]
 [43.711464]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  1.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 22. 30. 22. 28.  8.  5.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  4.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.39431920647621155
desired expected reward: 43.03056716918945



buy possibilites: [-1] 
expected returns: [[43.620872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  1.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  4.  0. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.401091575622559
desired expected reward: 34.23591995239258






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  4.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  0. 11. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15
  0  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  7. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4. 11.] 
cards in discard: [10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[41.746246]
 [41.66259 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [10. 15.  3.  4. 11.] 
adversary owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0206420421600342
desired expected reward: 42.6002311706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.802616]
 [41.81653 ]
 [41.82778 ]
 [41.826836]
 [41.842804]
 [41.81763 ]
 [41.828888]
 [41.901287]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  1.  3.  0.  3.] 
adversary cards in discard: [10. 15.  3.  4. 11.] 
adversary owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9629970788955688
desired expected reward: 40.78324890136719



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [10.  1.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [10. 15.  3.  4. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 1.] 
cards in discard: [10. 15.  3.  4. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 1.] 
cards in discard: [10. 15.  3.  4. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  2.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 1.] 
cards in discard: [10. 15.  3.  4. 11.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [6. 8. 0. 6. 1.] 
adversary cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
adversary owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [6. 8. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[38.831932]
 [38.748276]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 1.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  4  8  1  8 15  1  6  8 10  0  6 14 11  3 11 11  6  0  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 11.  0.  8. 16.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 39 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9996546506881714
desired expected reward: 40.901634216308594



action possibilites: [-1] 
expected returns: [[41.833393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 11.  0.  8. 16.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 39 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: -0.2701892852783203
desired expected reward: 38.3778076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.922028]
 [41.946255]
 [42.020702]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8. 10. 15. 14.  4. 11. 11.  3.  1.  6. 11.  1.  0. 11.  1.  0.  0.  6.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 1. 11.  0.  8. 16.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 39 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.3642691671848297
desired expected reward: 41.46912384033203






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  8. 16.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  1  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 16 11 15  0
  1  8  1 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 0. 11.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 0. 11.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[42.778877]
 [42.72039 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  8.  0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9616885781288147
desired expected reward: 41.059017181396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[42.878048]
 [42.891956]
 [42.903214]
 [42.90227 ]
 [42.890533]
 [42.918236]
 [42.893066]
 [42.93244 ]
 [42.917294]
 [42.90432 ]
 [42.93121 ]
 [42.976727]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 30. 22. 28.  8.  4.  9.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  8.  0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9826575517654419
desired expected reward: 41.79621505737305



buy possibilites: [-1] 
expected returns: [[44.649696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  1.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  8.  0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: -0.007894019596278667
desired expected reward: 42.88263702392578






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  8.  0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  8  0 14 14  3  0 15  3  1  3 25 25 29  3 11 15  0  1  8  1
 11  8  4 25 11  3  0 10  8  0 10  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  1. 14. 11.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  1. 14. 11.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  1. 14. 11.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 6.  0.  1. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[43.448486]
 [43.38906 ]
 [43.39    ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 14. 11.] 
cards in discard: [16.  0. 11.  6.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  8.  3. 11.  0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0336118936538696
desired expected reward: 43.616085052490234



action possibilites: [-1] 
expected returns: [[43.609364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 11.] 
cards in discard: [16.  0. 11.  6.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.3937733471393585
desired expected reward: 42.99528503417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.675938]
 [43.68985 ]
 [43.7011  ]
 [43.688915]
 [43.70016 ]
 [43.688423]
 [43.716125]
 [43.690956]
 [43.71736 ]
 [43.730335]
 [43.715187]
 [43.726566]
 [43.70221 ]
 [43.71265 ]
 [43.729095]
 [43.774612]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 11.] 
cards in discard: [16.  0. 11.  6.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  1.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.3991904556751251
desired expected reward: 43.210174560546875



buy possibilites: [-1] 
expected returns: [[43.403847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 11.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.3425987958908081
desired expected reward: 43.268707275390625






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  8.  1. 11.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  8.  1. 11.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  8.  1. 11.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.] 
adversary owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16
  8] -> size -> 25 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [10.  0.  8.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[42.490997]
 [42.42032 ]
 [42.40933 ]
 [42.434013]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  1. 11.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  4  8  1  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14. 25.  8. 11. 11.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0063995122909546
desired expected reward: 42.39744567871094



action possibilites: [-1] 
expected returns: [[43.415276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14. 25.  8. 11. 11.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: -0.36349397897720337
desired expected reward: 41.94831848144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.50288]
 [43.52658]
 [43.59931]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14. 25.  8. 11. 11.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0] -> size -> 36 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.3951391279697418
desired expected reward: 43.020137786865234






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [14. 25.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.  8. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25.  8. 11. 11.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 11.  8.  4.  0.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.  8. 11. 11.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 11.  8.  4.  0.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 25.  8. 11. 11.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6. 11.  8.  4.  0.] 
adversary cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 6. 11.  8.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[41.68332 ]
 [41.62634 ]
 [41.601654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8.  4.  0.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 14.  0.  1.  3.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0. 14. 25.  8. 11. 11.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.0206927061080933
desired expected reward: 42.57862091064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.62882 ]
 [41.65252 ]
 [41.725254]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8.  4.  0.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 14.  0.  1.  3.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0. 14. 25.  8. 11. 11.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.9628580212593079
desired expected reward: 40.720462799072266



buy possibilites: [-1] 
expected returns: [[41.288536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8.  4.  0.] 
cards in discard: [16.  0. 11.  6.  0.  1.  8. 14.  6.  0.  1. 11.  8. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15. 14.  0.  1.  3.] 
adversary cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0. 14. 25.  8. 11. 11.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.9653348922729492
desired expected reward: 40.663482666015625






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [15. 14.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.  1.  3.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0. 14. 25.  8. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  0.  1.  3.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0. 14. 25.  8. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  1.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  0.  1.  3.] 
cards in discard: [10. 15.  3.  4. 11.  8. 10.  1.  3.  0.  3.  1.  0.  8.  0.  8.  0.  0.
  8. 11.  0.  0.  3.  0.  0. 14. 25.  8. 11. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  0.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 6.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[42.50927 ]
 [42.4276  ]
 [42.464996]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  3. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  0.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9426614046096802
desired expected reward: 40.34587478637695



action possibilites: [-1] 
expected returns: [[43.56675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  0.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.3664990961551666
desired expected reward: 42.0984992980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[43.515728]
 [43.529423]
 [43.540413]
 [43.539433]
 [43.54148 ]
 [43.61216 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  0.  0.  7.  9.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.39962688088417053
desired expected reward: 43.16712188720703



buy possibilites: [-1] 
expected returns: [[43.459843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.14008380472660065
desired expected reward: 43.68156814575195






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [10. 11.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 28.  8.  4.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 16.  0.  0.] 
adversary cards in discard: [10. 15.  6.  8.  3.] 
adversary owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10] -> size -> 24 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 28.  8.  3.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 16.  0.  0.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.] 
adversary owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 22. 28.  8.  3.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 16.  0.  0.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.] 
adversary owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 29.  1.  0.] 
cards in discard: [1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 21. 30. 22. 28.  8.  3.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  4. 16.  0.  0.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.] 
adversary owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10
  6] -> size -> 25 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  4. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[43.182304]
 [43.098064]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 16.  0.  0.] 
cards in discard: [10. 15.  6.  8.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  3.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [4. 1. 0. 8. 8.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -10.000734329223633
desired expected reward: 33.4591064453125



action possibilites: [-1] 
expected returns: [[43.147816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  2.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [4. 1. 0. 8. 8.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 2
Learning step: -9.41299819946289
desired expected reward: 34.615447998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[43.28551 ]
 [43.309597]
 [43.308594]
 [43.379314]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 21. 30. 22. 28.  8.  2.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [4. 1. 0. 8. 8.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.389443576335907
desired expected reward: 42.75837326049805



buy possibilites: [-1] 
expected returns: [[43.38936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [4. 1. 0. 8. 8.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.393669128417969
desired expected reward: 33.91492462158203






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [4. 1. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 1. 0. 8. 8.] 
cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0. 11.  8.  8.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.] 
adversary owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 0. 8. 8.] 
cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  5. 10.  7.] 
adversary cards in hand: [ 6.  0. 11.  8.  8.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.] 
adversary owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 0. 8. 8.] 
cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [ 6.  0. 11.  8.  8.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.] 
adversary owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 6.  0. 11.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[42.070705]
 [42.015472]
 [41.99139 ]
 [41.99139 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  8.  8.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4  8  8 15  1  8 10  0  6 14 11  3 11 11  6  0  1  6 16  8  0 10  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [25.  1.  3.  3.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0. 10.  4.  1.  0.  8.  8.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1 10] -> size -> 40 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.0103874206542969
desired expected reward: 42.378971099853516



action possibilites: [-1] 
expected returns: [[43.214912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4  8  8 15  1  8 10  0 14  3 11 11  6  0  1  6 16  8  0 10  6  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [25.  1.  3.  3.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0. 10.  4.  1.  0.  8.  8.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1 10] -> size -> 40 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 13
Learning step: -0.35690921545028687
desired expected reward: 41.665283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.25323 ]
 [43.27631 ]
 [43.347027]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4  8  8 15  1  8 10  0 14  3 11 11  6  0  1  6 16  8  0 10  6  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [25.  1.  3.  3.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0. 10.  4.  1.  0.  8.  8.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1 10] -> size -> 40 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.39176422357559204
desired expected reward: 42.82314682006836






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [25.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3.  3.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0. 10.  4.  1.  0.  8.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  1.  8.  0.  0.  7.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [11. 11.  1.  6.  0.] 
adversary cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.  8.  8.] 
adversary owned cards: [ 4  8  8 15  1  8 10  0 14  3 11 11  6  0  1  6 16  8  0 10  6  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 8 


Player 1 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 3 
Gold: 0 
Estate: 1 
Duchy: 1 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 4 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 11.  1.  6.  0.] 
cards in discard: [10. 15.  6.  8.  3.  6.  6.  6. 16.  4.  0.  0.  8.  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 4  8  8 15  1  8 10  0 14  3 11 11  6  0  1  6 16  8  0 10  6  6  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 22. 28.  8.  0.  8.  0.  0.  7.  9.  7. 10.  4. 10.  7.] 
adversary cards in hand: [1. 3. 3. 0. 8. 8.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 29.  1.  0. 10.  4.  1.  0.  8.  8.] 
adversary owned cards: [ 0  0 11  8  0 14 14  3  0 15  3  1  3 25 29  3 11 15  0  1  8  1 11  8
  4 25 11  3  0 10  8  0 10  8  0  0  0 11  1 10] -> size -> 40 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -805 

action type: buy - action -1.0
Learning step: -25.450410842895508
desired expected reward: 17.896615982055664



