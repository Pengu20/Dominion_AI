 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.11182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
None 
sum of rewards: None 

action type: None - action None
Learning step: None
desired expected reward: None





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[340.28268]
 [340.57523]
 [340.90106]
 [340.8634 ]
 [340.58633]
 [341.1886 ]
 [340.57013]
 [341.4212 ]
 [341.15088]
 [340.896  ]
 [341.4434 ]
 [342.6412 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-16.005342]
desired expected reward: 326.14300537109375



buy possibilites: [-1] 
expected returns: [[343.42175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20.   0.   4.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -4.0 

action type: buy - action 3.0
Learning step: [-14.571772]
desired expected reward: 326.3293151855469






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[350.3914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: [-14.394683]
desired expected reward: 329.0270690917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[350.9438 ]
 [351.23633]
 [351.56223]
 [351.52454]
 [351.84964]
 [351.23123]
 [351.55713]
 [353.30225]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-20   0   4  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: [-15.405838]
desired expected reward: 338.02850341796875



buy possibilites: [-1] 
expected returns: [[356.96588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -20.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -317.0 

action type: buy - action 6.0
Learning step: [-46.093777]
desired expected reward: 305.4307556152344






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.71533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: [-16.40583]
desired expected reward: 340.56005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[359.96622]
 [360.25873]
 [360.58466]
 [360.5469 ]
 [360.2699 ]
 [360.8721 ]
 [360.25366]
 [361.10474]
 [360.8344 ]
 [360.5796 ]
 [361.12692]
 [362.3247 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-16.853485]
desired expected reward: 344.89697265625



buy possibilites: [-1] 
expected returns: [[359.47284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -12.5 

action type: buy - action 1.0
Learning step: [-16.418749]
desired expected reward: 343.8399658203125






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0. 10.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0. 10.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.  0. 10.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[364.43552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: [-16.29866]
desired expected reward: 343.1741943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[364.38593]
 [365.0043 ]
 [364.9666 ]
 [364.67334]
 [366.7444 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-17.149462]
desired expected reward: 350.33880615234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[364.1029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [0. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1.0
Learning step: [-17.086395]
desired expected reward: 349.6579895019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[363.93192]
 [364.55038]
 [364.51266]
 [364.21945]
 [366.29044]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10. 10.] 
adversary cards in discard: [0. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-17.176588]
desired expected reward: 349.97540283203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [0. 1. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [0. 1. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10. 10.] 
cards in discard: [0. 1. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[366.737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 6. 0.] 
cards in discard: [3. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1.0
Learning step: [-16.824224]
desired expected reward: 349.4662170410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[367.8988 ]
 [368.19138]
 [368.51724]
 [368.47955]
 [368.20248]
 [368.80472]
 [368.18628]
 [369.03735]
 [368.767  ]
 [368.51218]
 [369.05957]
 [370.2573 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 0.] 
cards in discard: [3. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 6 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-17.147797]
desired expected reward: 352.64190673828125



buy possibilites: [-1] 
expected returns: [[388.04883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 6. 0.] 
cards in discard: [ 3.  3.  0.  3.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 15 

action type: buy - action 16.0
Learning step: [-12.7743]
desired expected reward: 355.42822265625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[371.43588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: [-18.754599]
desired expected reward: 369.2942199707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[363.59583]
 [363.87997]
 [364.1971 ]
 [364.15894]
 [363.89087]
 [364.4779 ]
 [363.87503]
 [364.70493]
 [364.4397 ]
 [364.19214]
 [364.7254 ]
 [365.89532]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-20   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: [-16.47057]
desired expected reward: 348.9984436035156



buy possibilites: [-1] 
expected returns: [[368.95016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  8.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -20.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -328.0 

action type: buy - action 6.0
Learning step: [-47.28813]
desired expected reward: 316.87078857421875






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  8.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  8.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6] -> size -> 15 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6] -> size -> 15 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[374.97]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-20   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: buy - action -1
Learning step: [-16.225508]
desired expected reward: 352.72467041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[375.3978 ]
 [375.682  ]
 [375.9991 ]
 [375.96094]
 [376.2799 ]
 [375.67703]
 [375.99417]
 [377.69733]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-20   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1.0
Learning step: [-17.130522]
desired expected reward: 360.83544921875



buy possibilites: [-1] 
expected returns: [[387.0988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 6.  3.  0.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-20   0   2   0   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 0 

action type: buy - action 10.0
Learning step: [-14.579508]
desired expected reward: 361.4146728515625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  7.  9. 10. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6 10] -> size -> 16 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0. 16.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[391.99503]
 [389.99057]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6  1 16  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1
Learning step: [-15.97419]
desired expected reward: 371.1246032714844



action possibilites: [-1] 
expected returns: [[422.5248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: 37 

action type: gain_card_n - action 13
Learning step: [-10.430652]
desired expected reward: 382.66680908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[420.791  ]
 [421.35403]
 [423.09048]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: take_action - action -1
Learning step: [-15.84227]
desired expected reward: 406.68255615234375



buy possibilites: [-1] 
expected returns: [[420.23502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [22.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  1.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20.   0.   2.  10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: [-15.753095]
desired expected reward: 405.0378723144531






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  1.] 
cards in discard: [ 6. 10.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  1.] 
cards in discard: [ 6. 10.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  6.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  1.] 
cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [22.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[426.40988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [22.  0. 16.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.  0.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6] -> size -> 18 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-16.403843]
desired expected reward: 403.8311767578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[426.9949 ]
 [427.27908]
 [427.59622]
 [427.55798]
 [427.8769 ]
 [427.2741 ]
 [427.59122]
 [429.2944 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [22.  0. 16.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.  0.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6] -> size -> 18 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: take_action - action -1.0
Learning step: [-17.328287]
desired expected reward: 412.07171630859375



buy possibilites: [-1] 
expected returns: [[426.67856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [22.  0. 16.  0.  3.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [6. 0. 3. 1. 0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.  0.  3.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6] -> size -> 18 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 20 

action type: buy - action 1.0
Learning step: [-15.391532]
desired expected reward: 411.8875427246094






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.  0.  3.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.  0.  3.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1. 0.] 
cards in discard: [ 6. 10.  3.  0.  0.  0.  0.  6.  0.  3.  0. 10.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[435.0545]
 [433.3513]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-16.474426]
desired expected reward: 410.2041320800781



action possibilites: [-1.] 
expected returns: [[411.32153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action 10.0
Learning step: [-15.214133]
desired expected reward: 420.818603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[408.80392]
 [409.07166]
 [409.37164]
 [409.33365]
 [409.63757]
 [409.06586]
 [409.3658 ]
 [410.9881 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 30.  8.  5.  9. 10. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1.0
Learning step: [-12.753842]
desired expected reward: 398.56768798828125



buy possibilites: [-1] 
expected returns: [[422.58585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [22.  0. 16.  0.  3.  3.  1.  0.  3.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 40 

action type: buy - action 11.0
Learning step: [-10.149177]
desired expected reward: 399.4884033203125






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1.  1. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 11.  0. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
expected returns: [[398.60065]
 [397.25018]
 [397.22916]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-16.455317]
desired expected reward: 406.1305236816406



action possibilites: [-1] 
expected returns: [[401.09717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 24 

action type: take_action - action 22.0
Learning step: [-12.091184]
desired expected reward: 387.84173583984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[400.71298]
 [400.9808 ]
 [401.28076]
 [400.9428 ]
 [401.24274]
 [400.9919 ]
 [401.54672]
 [400.975  ]
 [401.52966]
 [401.76343]
 [401.50873]
 [401.79745]
 [401.27493]
 [401.52567]
 [401.7805 ]
 [402.8972 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9. 10.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1
Learning step: [-12.295786]
desired expected reward: 388.8013916015625



buy possibilites: [-1] 
expected returns: [[415.70782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.  0.  0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 6. 0. 0.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20.   0.   2.  20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 30.0 

action type: buy - action 15.0
Learning step: [-10.627566]
desired expected reward: 391.1529541015625






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [10.  1.  1.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15] -> size -> 20 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [10.  1.  1.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15] -> size -> 20 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 0.] 
cards in discard: [10.  1.  1.  3.  3.  0. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15] -> size -> 20 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 1.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[436.0696]
 [434.4474]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0. 23.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-13.4342985]
desired expected reward: 402.2735290527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[437.21585]
 [437.4837 ]
 [437.7836 ]
 [437.7456 ]
 [437.4948 ]
 [438.04953]
 [437.47787]
 [438.26633]
 [438.0116 ]
 [437.77783]
 [438.28336]
 [439.40002]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0. 23.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: take_action - action -1.0
Learning step: [-15.666885]
desired expected reward: 422.8221435546875



buy possibilites: [-1] 
expected returns: [[436.7702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [10.  1.  1.  3.  3.  0. 23.  0.  1.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20.    0.    2.   20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 6.5 

action type: buy - action 1.0
Learning step: [-15.273749]
desired expected reward: 422.20989990234375






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  1.  1.  3.  3.  0. 23.  0.  1.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 16.] 
adversary cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  1.  1.  3.  3.  0. 23.  0.  1.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 29. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 16.] 
adversary cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [10.  1.  1.  3.  3.  0. 23.  0.  1.  6.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 16.] 
adversary cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15  1] -> size -> 21 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[452.39667]
 [450.49142]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 16.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  6 16  6 10 22  0  1 11 15  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  5.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1
Learning step: [-15.661676]
desired expected reward: 421.1085205078125



action possibilites: [-1] 
expected returns: [[453.4896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  4.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -20    0    0  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -310 

action type: gain_card_n - action 3
Learning step: [-46.669064]
desired expected reward: 398.8492431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[453.75397]
 [454.28375]
 [455.9381 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  4.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-20   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1
Learning step: [-17.313435]
desired expected reward: 436.1761474609375



buy possibilites: [-1] 
expected returns: [[458.7555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [15. 22.  0. 11.  0.  0.  3.  0.  0.  1.  1.  3.  0.  0. 10.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -20.    0.   -1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -321.0 

action type: buy - action 6.0
Learning step: [-48.233685]
desired expected reward: 406.0500183105469






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [1. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[414.66547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 23.  0.  3.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-20   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: [-23.371344]
desired expected reward: 435.3841552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[378.3585 ]
 [378.6004 ]
 [378.8741 ]
 [378.8376 ]
 [379.1182 ]
 [378.59518]
 [378.86884]
 [380.35895]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 23.  0.  3.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-20   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: [-15.5354185]
desired expected reward: 364.804931640625



buy possibilites: [-1] 
expected returns: [[377.03534]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 6.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 6. 23.  0.  3.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-20.   0.  -1. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: [-15.566772]
desired expected reward: 362.7917175292969






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 6. 23.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.  0.  3.  1.] 
cards in discard: [ 0. 10.  0.  0.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [0. 1. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23.  0.  3.  1.] 
cards in discard: [ 0. 10.  0.  0.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [0. 1. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[376.69696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [0. 1. 0. 3. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-20   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: [-15.18143]
desired expected reward: 361.8539123535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[377.70035]
 [377.9422 ]
 [378.21588]
 [378.17932]
 [377.95306]
 [378.46005]
 [377.93704]
 [378.6595 ]
 [378.42352]
 [378.21066]
 [378.6729 ]
 [379.70074]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [0. 1. 0. 3. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  9. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-20   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: [-15.240839]
desired expected reward: 363.1636047363281



buy possibilites: [-1] 
expected returns: [[389.83835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-20.    0.   -1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -36.5 

action type: buy - action 11.0
Learning step: [-14.171308]
desired expected reward: 364.28875732421875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15. 16.  0.  0.  6.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11] -> size -> 24 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 28. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15. 16.  0.  0.  6.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11] -> size -> 24 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 27. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [15. 16.  0.  0.  6.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11] -> size -> 24 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [15. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[407.75522]
 [406.7274 ]
 [406.00748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  0.  0.  6.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 27. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-20   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: [-15.366168]
desired expected reward: 374.47216796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[406.92957]
 [407.4452 ]
 [407.40866]
 [407.16638]
 [408.93008]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  0.  0.  6.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 24. 30. 27. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-20   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: [-17.08187]
desired expected reward: 390.6733093261719



buy possibilites: [-1] 
expected returns: [[410.34036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  0.  0.  6.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  1.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-20   0   0 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -32 

action type: buy - action 3.0
Learning step: [-15.120758]
desired expected reward: 392.3244323730469






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  1.] 
cards in discard: [ 0. 10.  0.  0.  6.  0.  6.  6. 23.  0.  3.  1.  3.  3.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 10. 22.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 10. 22.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 24. 30. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 10. 22.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 6.] 
cards in discard: [2.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 11.  0. 10. 22.] 
adversary cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 3. 11.  0. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 22.] 
expected returns: [[413.52652]
 [412.28586]
 [412.03647]
 [412.26538]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10. 22.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-20   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: buy - action -1
Learning step: [-16.02562]
desired expected reward: 394.31475830078125



action possibilites: [-1] 
expected returns: [[408.5733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.  1.  6.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-20   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -18 

action type: take_action - action 22.0
Learning step: [-14.290695]
desired expected reward: 397.9747314453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[408.66757]
 [408.90945]
 [409.1831 ]
 [409.14664]
 [409.42734]
 [408.9043 ]
 [409.17792]
 [410.668  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.  1.  6.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 29. 26. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-20   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1
Learning step: [-13.962839]
desired expected reward: 394.6104736328125



buy possibilites: [-1] 
expected returns: [[412.00558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.  1.  6.] 
cards in discard: [ 0.  1.  0.  3.  3.  6. 11.  0.  0.  0.  6.  0.  3. 15. 16.  0.  0.  6.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 29. 25. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20.   0.   1. -10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -7.0 

action type: buy - action 3.0
Learning step: [-12.734012]
desired expected reward: 396.4491271972656






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 25. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 29. 25. 30.  8.  3.  9.  8. 10. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 29. 25. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  6.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 1.  6.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[401.2393 ]
 [400.21152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 29. 25. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 23.  0.  6.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: buy - action -1
Learning step: [-15.721875]
desired expected reward: 396.2837219238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[401.64883]
 [401.89072]
 [402.16437]
 [402.12787]
 [402.4085 ]
 [401.88556]
 [402.15918]
 [403.64926]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 29. 25. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 23.  0.  6.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1.0
Learning step: [-14.771311]
desired expected reward: 388.1755065917969



buy possibilites: [-1] 
expected returns: [[400.5895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  3. 15.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 24. 29. 25. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 23.  0.  6.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20.   0.   1. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -29.0 

action type: buy - action 0.0
Learning step: [-14.867197]
desired expected reward: 386.7816162109375






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  6.  3.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 25. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0. 16.  3.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  6.  3.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 29. 25. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0. 16.  3.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  0.  6.  3.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0. 16.  3.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[416.38547]
 [415.14474]
 [414.63773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  3.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.  3.  0. 23.  0.  6.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-14.662421]
desired expected reward: 385.9270935058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[388.71054]
 [389.19226]
 [389.15707]
 [388.93137]
 [390.59088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  3.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 3. 3. 6.] 
adversary cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.  3.  0. 23.  0.  6.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: [-13.481082]
desired expected reward: 376.08929443359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.  3.  0. 23.  0.  6.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [22.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 6.] 
cards in discard: [ 2. 10.  0.  0.  1.  1.  6.  8.  0.  0.  0. 10.  3.  3.  0. 23.  0.  6.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [22.  3.  3.  0.  6.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [22.  3.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[395.6589]
 [394.4705]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3.  0.  6.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  3.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1.0
Learning step: [-13.196536]
desired expected reward: 377.3943176269531



action possibilites: [-1] 
expected returns: [[386.03024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  6.  0. 11.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  3.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: LIBRARY: skip_action_card - action 1
Learning step: [-12.362842]
desired expected reward: 381.6409606933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[386.1847 ]
 [386.40988]
 [386.66635]
 [386.6312 ]
 [386.8965 ]
 [386.40546]
 [386.66187]
 [388.065  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6.  0. 11.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  3.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1
Learning step: [-11.404086]
desired expected reward: 374.62615966796875



buy possibilites: [-1] 
expected returns: [[386.95743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  6.  0. 11.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [23.  3.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -1 

action type: buy - action 1.0
Learning step: [-9.802594]
desired expected reward: 376.60736083984375






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [23.  3.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 10.  6.  6.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.  1. 22.  3.  3.  0.  6.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1] -> size -> 28 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3. 10.  6.  6.  0.] 
adversary cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.  1. 22.  3.  3.  0.  6.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1] -> size -> 28 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[387.07547]
 [385.6724 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  6.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.  1. 22.  3.  3.  0.  6.  0.
 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-13.597763]
desired expected reward: 373.35968017578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[385.71402]
 [386.1605 ]
 [387.5943 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  6.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.  1. 22.  3.  3.  0.  6.  0.
 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: [-13.571817]
desired expected reward: 373.503662109375



buy possibilites: [-1] 
expected returns: [[380.60498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  6.  0.] 
cards in discard: [ 0.  1.  6.  0.  3. 15. 11.  0. 16.  3.  0.  1. 22.  3.  3.  0.  6.  0.
 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [0. 3. 6. 1. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20.   0.   1. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -39.0 

action type: buy - action 0.0
Learning step: [-13.935226]
desired expected reward: 371.77874755859375






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [23.  3.  6.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [23.  3.  6.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 1. 0.] 
cards in discard: [23.  3.  6.  0.  1. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  8.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[378.8207 ]
 [377.65225]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  7.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-13.3945465]
desired expected reward: 367.21044921875



action possibilites: [-1] 
expected returns: [[388.4404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -10 

action type: gain_card_n - action 9
Learning step: [-9.617042]
desired expected reward: 368.362548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[389.35532]
 [389.58054]
 [389.83698]
 [389.54535]
 [389.8018 ]
 [389.59134]
 [390.06717]
 [389.57608]
 [390.05618]
 [390.25558]
 [390.03195]
 [390.28183]
 [389.83252]
 [390.04724]
 [390.26663]
 [391.2356 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 23. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1
Learning step: [-11.330942]
desired expected reward: 377.1094665527344



buy possibilites: [-1] 
expected returns: [[388.74313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [10.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -14.5 

action type: buy - action 1.0
Learning step: [-11.222922]
desired expected reward: 378.3576354980469






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  0. 16.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[383.70993]
 [382.0657 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  3.  0.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-14.077164]
desired expected reward: 374.66595458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[382.78043]
 [383.26212]
 [383.22687]
 [383.00122]
 [384.66074]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  3.  0.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: [-13.496063]
desired expected reward: 370.2138671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 15.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 2.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 15.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 2.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 22. 29. 24. 30.  8.  3.  9.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 15.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 2.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 11. 15.  3.  0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[362.9733 ]
 [361.85037]
 [362.0414 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  3.  0.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11
  3  3  0  1  0 10  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0. 16.
 10.  0.  3.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1.0
Learning step: [-12.291568]
desired expected reward: 355.5443420410156



action possibilites: [-1] 
expected returns: [[366.69098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0. 16.
 10.  0.  3.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action 15.0
Learning step: [-9.250876]
desired expected reward: 352.79052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[365.37582]
 [365.59024]
 [365.83615]
 [365.80215]
 [366.05725]
 [365.58633]
 [365.83224]
 [367.1802 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0. 16.
 10.  0.  3.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1
Learning step: [-9.677225]
desired expected reward: 357.0137634277344



buy possibilites: [-1] 
expected returns: [[374.81375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 10.] 
adversary cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0. 16.
 10.  0.  3.  3.  0.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -1 

action type: buy - action 10.0
Learning step: [-7.2748656]
desired expected reward: 358.5574035644531






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 10.] 
cards in discard: [23.  3.  6.  0.  1. 15.  0.  3.  6.  1.  0.  0.  0.  6.  8.  0.  0. 16.
 10.  0.  3.  3.  0.  2.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2
  8  3 15  0 16] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  8.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  7.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [6. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[366.4443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  7.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-12.627319]
desired expected reward: 362.1864318847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[367.12357]
 [367.33792]
 [367.58386]
 [367.3039 ]
 [367.54987]
 [367.34897]
 [367.805  ]
 [367.33405]
 [367.79514]
 [367.9862 ]
 [367.771  ]
 [368.01096]
 [367.57996]
 [367.78592]
 [367.99606]
 [368.92792]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  7.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: [-11.600574]
desired expected reward: 354.8437194824219



buy possibilites: [-1] 
expected returns: [[376.84756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -34.5 

action type: buy - action 11.0
Learning step: [-10.737445]
desired expected reward: 357.0675354003906






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [11. 10. 15.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  1  0  1  6  6  6  1 23  3  0  3  2  8
  3 15  0 16 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 22.  3.  6.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [11. 10. 15.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 22.  3.  6.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11. 10. 15.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  3.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 22.  3.  6.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 22.  3.  6.] 
adversary cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 22.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[374.7052 ]
 [373.56323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 22.  3.  6.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [1. 6. 2. 1. 3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-12.091575]
desired expected reward: 364.7559814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[373.35873]
 [373.78506]
 [375.16312]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 22.  3.  6.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [1. 6. 2. 1. 3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: [-11.83754]
desired expected reward: 362.86767578125



buy possibilites: [-1] 
expected returns: [[373.3737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 22.  3.  6.] 
cards in discard: [10.  1. 11.  0.  0.  1.  0.  6.  0. 16.  3.  0. 10. 15.  3. 11.  3. 11.
  6.  0.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [1. 6. 2. 1. 3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20.   0.   1. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -39.0 

action type: buy - action 0.0
Learning step: [-11.920715]
desired expected reward: 361.43804931640625






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [1. 6. 2. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 2. 1. 3.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 2. 1. 3.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 2. 1. 3.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 7 
card supply: [21. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0. 10.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 10.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[389.87433]
 [388.5264 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  1.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: [-10.441154]
desired expected reward: 362.9325256347656



action possibilites: [-1.] 
expected returns: [[389.6238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action 10.0
Learning step: [-9.99324]
desired expected reward: 378.53314208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[388.85193]
 [389.0663 ]
 [389.3123 ]
 [389.27826]
 [389.5334 ]
 [389.06244]
 [389.30838]
 [390.6563 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1.0
Learning step: [-10.02288]
desired expected reward: 379.6009216308594



buy possibilites: [-1] 
expected returns: [[383.23178]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 6.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6  0] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-20.   0.   1. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -19.0 

action type: buy - action 0.0
Learning step: [-10.558255]
desired expected reward: 378.2936706542969






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0
 16 11  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10. 10. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15. 22.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15. 22.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15. 22.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 15. 22.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  3. 15. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22.] 
expected returns: [[379.36697]
 [378.4351 ]
 [378.22498]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15. 22.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3
  3  0  1  0 10  1 10 11  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: buy - action -1
Learning step: [-11.371286]
desired expected reward: 371.8605041503906



action possibilites: [-1] 
expected returns: [[368.18732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 22.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action 15.0
Learning step: [-8.458796]
desired expected reward: 369.9762878417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[367.36783]
 [367.5711 ]
 [367.80536]
 [367.7722 ]
 [367.58188]
 [368.01608]
 [367.56686]
 [368.1893 ]
 [367.98294]
 [367.80118]
 [368.1978 ]
 [369.0879 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 22.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action -1
Learning step: [-7.3575015]
desired expected reward: 360.8298034667969



buy possibilites: [-1] 
expected returns: [[378.44873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 22.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 23 

action type: buy - action 15.0
Learning step: [-3.2390077]
desired expected reward: 364.95880126953125






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15] -> size -> 34 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15] -> size -> 34 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [11. 10. 15.  1.  3.  3.  6.  8.  6.  0.  1.  6.  2.  1.  3. 29.  0. 16.
  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15] -> size -> 34 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[366.34894]
 [365.2771 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: buy - action -1
Learning step: [-10.633347]
desired expected reward: 367.81536865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[365.9568 ]
 [366.16   ]
 [366.39426]
 [366.36108]
 [366.605  ]
 [366.15576]
 [366.39008]
 [367.67685]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 29. 24. 30.  8.  2.  8.  6.  9. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1.0
Learning step: [-9.301828]
desired expected reward: 357.047119140625



buy possibilites: [-1] 
expected returns: [[372.68884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 21. 29. 24. 30.  8.  2.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-20.   0.   1. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -27.0 

action type: buy - action 8.0
Learning step: [-8.676004]
desired expected reward: 357.47979736328125






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 23.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  2.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 10.  3.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 23.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 29. 24. 30.  8.  2.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 10.  3.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 23.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 10.  3.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 1. 10.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[368.3991]
 [367.1123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  6.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  3. 29. 10. 11.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-20   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: buy - action -1
Learning step: [-8.870349]
desired expected reward: 363.8184814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[368.094  ]
 [368.29718]
 [368.5314 ]
 [368.4983 ]
 [368.74216]
 [368.29297]
 [368.52722]
 [369.81403]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  6.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  3. 29. 10. 11.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-20   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1.0
Learning step: [-8.325538]
desired expected reward: 360.0735778808594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 10. 11.] 
cards in discard: [ 6.  0.  0.  0.  3. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  1.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 11.  2.] 
cards in discard: [ 6.  0.  0.  0.  3. 23.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  6.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  1.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  2.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  1.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  2.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 16. 11.  1.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 16. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[372.06836]
 [370.5623 ]
 [370.99652]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 11.  1.  1.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3
  0  1  0 10  1 10 11  0  0 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 24. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-20   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: buy - action -1.0
Learning step: [-8.285828]
desired expected reward: 361.5281982421875



action possibilites: [-1] 
expected returns: [[371.95984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 16 

action type: gain_card_n - action 1
Learning step: [-4.616797]
desired expected reward: 364.2113342285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[373.28064]
 [373.48386]
 [373.71817]
 [373.68494]
 [373.4947 ]
 [373.9289 ]
 [373.47968]
 [374.10205]
 [373.89566]
 [373.71396]
 [374.11066]
 [375.0007 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 21. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: take_action - action -1
Learning step: [-5.055359]
desired expected reward: 366.90447998046875



buy possibilites: [-1] 
expected returns: [[372.8606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 21. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 1.  0. 16.  0.  3.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20.   0.   2.  10.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: [-5.5355196]
desired expected reward: 367.7451477050781






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  0.  3.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.  0.  3.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 21. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.  0.  3.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[366.19507]
 [365.1232 ]
 [364.90826]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -8 

action type: buy - action -1
Learning step: [-7.9539275]
desired expected reward: 364.90667724609375



action possibilites: [-1. 11.] 
expected returns: [[366.02496]
 [364.9531 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 13 

action type: take_action - action 10.0
Learning step: [-5.0501494]
desired expected reward: 359.8581237792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[363.86038]
 [364.06357]
 [364.29785]
 [364.26465]
 [364.50858]
 [364.0594 ]
 [364.29364]
 [365.58044]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20   0   2  10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 12 

action type: take_action - action -1.0
Learning step: [-5.299268]
desired expected reward: 360.7257080078125



buy possibilites: [-1] 
expected returns: [[353.89978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [ 0. 10.  3.  0.  1.  6.  6. 15. 15.  0.  3. 22.  8.  0. 11.  0.  3.  0.
  1. 10.  3.  0.  6.  3.  0. 16. 11.  1.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-20.   0.   2.  10.   0.   0.  20.   0.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: 10.0 

action type: buy - action 0.0
Learning step: [-4.2848206]
desired expected reward: 348.12249755859375






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3. 11. 22.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 20. 29. 23. 30.  8.  1.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3. 11. 22.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 20. 29. 23. 30.  8.  0.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3. 11. 22.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 22.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
expected returns: [[365.97607]
 [364.94043]
 [364.92212]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 22.  3.  6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 23. 30.  8.  0.  8.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1.  3.  6. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-3.9966004]
desired expected reward: 349.9031677246094



action possibilites: [-1] 
expected returns: [[374.2693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  3.  6.] 
cards in discard: [16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 23. 30.  8.  0.  7.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1.  3.  6. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0  -3   0   0  16   0] 
sum of rewards: 35 

action type: gain_card_n - action 3
Learning step: [-1.2582978]
desired expected reward: 364.35430908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[373.03278]
 [374.69473]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  3.  6.] 
cards in discard: [16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 20. 29. 23. 30.  8.  0.  7.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1.  3.  6. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1
Learning step: [-3.3851013]
desired expected reward: 370.8841857910156



buy possibilites: [-1] 
expected returns: [[371.31256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  3.  6.] 
cards in discard: [16.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1.  3.  6. 10.] 
adversary cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0  -4   0   0   0   0] 
sum of rewards: 18 

action type: buy - action 0.0
Learning step: [-3.7631257]
desired expected reward: 369.2696533203125






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  6. 10.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [15. 10.  0.  0.  1.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  6. 10.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  8. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [15. 10.  0.  0.  1.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 39 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  6. 10.] 
cards in discard: [ 6.  0.  0.  0.  3. 23. 11. 10. 11.  3.  3. 29.  2.  1.  1.  0. 16.  0.
  3.  6.  6.  6.  0.  0. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [15. 10.  0.  0.  1.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 39 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [15. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[363.59802]
 [362.73785]
 [362.35425]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.  1.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-5.8076386]
desired expected reward: 365.5049133300781



action possibilites: [-1. 15. 15.] 
expected returns: [[369.55322]
 [368.69308]
 [368.69308]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  1. 15.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0
  1  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action 10.0
Learning step: [-2.3988922]
desired expected reward: 359.9553527832031



action possibilites: [-1. 15.] 
expected returns: [[382.04556]
 [381.18542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 3 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 42 

action type: take_action - action 15.0
Learning step: [-0.02327881]
desired expected reward: 368.6697692871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[381.68484]
 [381.8807 ]
 [381.89923]
 [382.10733]
 [381.848  ]
 [381.89072]
 [382.31125]
 [381.87634]
 [382.3027 ]
 [382.47818]
 [382.27853]
 [382.50104]
 [382.10303]
 [382.29285]
 [382.4867 ]
 [383.3468 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7. 10.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 42 

action type: take_action - action -1.0
Learning step: [-1.2383636]
desired expected reward: 380.80718994140625



buy possibilites: [-1] 
expected returns: [[392.6357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 15.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 8. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20.    0.    2.   20.    0.    0.   40.    0.    0.    0.    0.   -4.
   0.    0.   12.5   0. ] 
sum of rewards: 50.5 

action type: buy - action 25.0
Learning step: [0.3252289]
desired expected reward: 382.6279296875






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 8. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  1  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16
 11  6  0 29  0  1  6 11  1  6  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25] -> size -> 39 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25] -> size -> 39 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[391.00574]
 [389.97015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [16.  0. 11. 29.  3.] 
adversary cards in discard: [8. 1.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-5.6426787]
desired expected reward: 386.9930419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[390.22137]
 [390.6439 ]
 [390.41287]
 [391.88336]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  7.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [16.  0. 11. 29.  3.] 
adversary cards in discard: [8. 1.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: take_action - action -1.0
Learning step: [-5.4011292]
desired expected reward: 385.6046142578125



buy possibilites: [-1] 
expected returns: [[396.9639]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [16.  0. 11. 29.  3.] 
adversary cards in discard: [8. 1.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0  -5   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: [-4.599167]
desired expected reward: 385.813720703125






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [16.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11. 29.  3.] 
cards in discard: [8. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11. 29.  3.] 
cards in discard: [8. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[387.66937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  3. 10.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-6.405182]
desired expected reward: 390.5587158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[387.18124]
 [387.377  ]
 [387.6037 ]
 [387.8076 ]
 [387.37274]
 [387.5994 ]
 [388.8432 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  3. 10.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: take_action - action -1.0
Learning step: [-5.362619]
desired expected reward: 382.3067626953125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 10.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  0.  8.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  3. 10.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  6.  0.  8.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[380.5269 ]
 [379.29233]
 [379.0671 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  8.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  0.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1.0
Learning step: [-5.842273]
desired expected reward: 380.77203369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[379.68988]
 [380.11005]
 [379.8804 ]
 [381.34018]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  8.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0. 10.  0.  6.  0.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: take_action - action -1.0
Learning step: [-5.153714]
desired expected reward: 375.3731689453125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.  0.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 16.  3. 11.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.  0.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  6.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 16.  3. 11.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.  0.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  5.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 16.  3. 11.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  1. 16.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[386.02115]
 [384.57538]
 [384.9938 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.  3. 11.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  5.  5.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  6.  1. 15.  8.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1.0
Learning step: [-4.7360625]
desired expected reward: 376.6041259765625



action possibilites: [-1] 
expected returns: [[387.1649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.  3.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  5.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  6.  1. 15.  8.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0  -6   0   0   9   0] 
sum of rewards: 25 

action type: gain_card_n - action 4
Learning step: [-2.7680938]
desired expected reward: 381.7647705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[385.51462]
 [385.7096 ]
 [385.93478]
 [386.1375 ]
 [385.7051 ]
 [385.9303 ]
 [387.16486]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 16.  3.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  5.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 3.  6.  1. 15.  8.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1
Learning step: [-3.3312957]
desired expected reward: 383.8335876464844






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  1. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 15.  8.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  5.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 10.  1.  3.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11. 11.  0.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 15.  8.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  5.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 10.  1.  3.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11. 11.  0.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 15.  8.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [ 0.  1. 10.  1.  3.] 
adversary cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11. 11.  0.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  1. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[374.35394]
 [373.11935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  1.  3.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11. 11.  0.  1. 16.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [23. 11.  3.  2.  0.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1.0
Learning step: [-6.301758]
desired expected reward: 380.8631286621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[372.70367]
 [372.89865]
 [373.12384]
 [372.86563]
 [372.90814]
 [373.32657]
 [372.89413]
 [373.3181 ]
 [373.49237]
 [373.29364]
 [373.51486]
 [373.11935]
 [373.30762]
 [373.5009 ]
 [374.3539 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  1.  3.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11. 11.  0.  1. 16.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  9.  5.  9.  7.] 
adversary cards in hand: [23. 11.  3.  2.  0.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: take_action - action -1.0
Learning step: [-5.0206604]
desired expected reward: 369.333251953125



buy possibilites: [-1] 
expected returns: [[380.92398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  1.  3.] 
cards in discard: [16.  0. 11.  3. 22.  3.  6. 25. 10. 15.  0.  1. 15.  8. 11.  6.  3.  0.
  0.  0.  0.  3.  0.  6.  0. 10.  6.  0.  8. 11. 11.  0.  1. 16.  3. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  8.  5.  9.  7.] 
adversary cards in hand: [23. 11.  3.  2.  0.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0  -7   0   0  50   0] 
sum of rewards: 45 

action type: buy - action 23.0
Learning step: [-0.08911438]
desired expected reward: 373.4257507324219






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [23. 11.  3.  2.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 11.  3.  2.  0.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  8.  5.  9.  7.] 
adversary cards in hand: [15. 16. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23] -> size -> 42 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 11.  3.  2.  0.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  8.  5.  9.  7.] 
adversary cards in hand: [15. 16. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23] -> size -> 42 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 16. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 10. 11.] 
expected returns: [[398.04004]
 [397.18692]
 [396.5942 ]
 [396.80542]
 [397.01263]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9. 10.  8.  5.  9.  7.] 
adversary cards in hand: [0. 1. 1. 3. 6.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8. 23. 11.  3.  2.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 2 

action type: buy - action -1
Learning step: [-3.9729493]
desired expected reward: 376.9510192871094



action possibilites: [-1] 
expected returns: [[405.41605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16. 10.  0.] 
cards in discard: [14.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [0. 1. 1. 3. 6.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8. 23. 11.  3.  2.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0  -8   0   0  16   0] 
sum of rewards: 30 

action type: gain_card_n - action 7
Learning step: [-2.1595795]
desired expected reward: 394.8245849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[404.65677]
 [406.30707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16. 10.  0.] 
cards in discard: [14.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [0. 1. 1. 3. 6.] 
adversary cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8. 23. 11.  3.  2.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-20   0   2  20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1
Learning step: [-3.7258728]
desired expected reward: 401.690185546875






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 1. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 3. 6.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8. 23. 11.  3.  2.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 3. 6.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8. 23. 11.  3.  2.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 20. 29. 23. 30.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 3. 6.] 
cards in discard: [ 8.  1. 16.  0. 11. 29.  3.  0.  6.  6.  3. 10.  8.  0. 10.  0.  6.  0.
  8.  3.  6.  1. 15.  8. 23. 11.  3.  2.  0.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[388.85995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [14. 11. 15. 16. 10.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [4. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-20   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: buy - action -1.0
Learning step: [-10.179474]
desired expected reward: 396.12762451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[389.90625]
 [390.10126]
 [390.11917]
 [390.32645]
 [390.06827]
 [390.11075]
 [390.5292 ]
 [390.0967 ]
 [390.52072]
 [390.69504]
 [390.49622]
 [390.7174 ]
 [390.322  ]
 [390.51016]
 [390.70346]
 [391.55652]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [14. 11. 15. 16. 10.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 20. 29. 23. 29.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [4. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-20   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1.0
Learning step: [-8.202167]
desired expected reward: 380.65777587890625



buy possibilites: [-1] 
expected returns: [[388.06952]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [4. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-20.    0.    5.   20.    0.    0.    0.    0.    0.    0.    0.   -9.
   0.    0.   12.5   0. ] 
sum of rewards: 8.5 

action type: buy - action 4.0
Learning step: [-4.5982666]
desired expected reward: 385.4700012207031






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [4. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [22.  6.  3.  6.  8.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4] -> size -> 44 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 6. 6. 8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [22.  6.  3.  6.  8.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4] -> size -> 44 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [22.  6.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
expected returns: [[391.29022]
 [390.2654 ]
 [389.86035]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  3.  6.  8.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  6 16  6 10 22  0  1 11 15  1  6  6  0 11  3  3  0  1
  0 10  1 10 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [ 8. 23. 11.  0.  3.] 
adversary cards in discard: [4. 0. 6. 6. 8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-20   0   5  20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: [-4.422403]
desired expected reward: 383.6471252441406



action possibilites: [-1] 
expected returns: [[380.26752]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [ 8. 23. 11.  0.  3.] 
adversary cards in discard: [4. 0. 6. 6. 8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: trash_cards_n_from_hand - action 12
Learning step: [-2.1147277]
desired expected reward: 387.1451110839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[379.95618]
 [381.5727 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [ 8. 23. 11.  0.  3.] 
adversary cards in discard: [4. 0. 6. 6. 8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: [-1.0957031]
desired expected reward: 379.17181396484375



buy possibilites: [-1] 
expected returns: [[371.7944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [ 8. 23. 11.  0.  3.] 
adversary cards in discard: [4. 0. 6. 6. 8.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0  -6   0   0   0   0] 
sum of rewards: 30 

action type: buy - action 0.0
Learning step: [-2.641983]
desired expected reward: 377.314208984375






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8. 23. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 11.  0.  3.] 
cards in discard: [4. 0. 6. 6. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [11. 10.  6.  0.  8.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0] -> size -> 41 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 23. 11.  0.  3.] 
cards in discard: [4. 0. 6. 6. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [11. 10.  6.  0.  8.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0] -> size -> 41 
adversary victory points: 6
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[375.60986]
 [374.60486]
 [374.40112]
 [374.18005]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6.  0.  8.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 28.  8.  0.  7.  4.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [10.  6. 16.  1.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: [-3.044632]
desired expected reward: 368.749755859375



action possibilites: [-1] 
expected returns: [[380.18378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  8.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [10.  6. 16.  1.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0  -7   0   0   9   0] 
sum of rewards: 38 

action type: gain_card_n - action 4
Learning step: [-0.7644928]
desired expected reward: 373.3868408203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[379.3858]
 [381.0023]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [10.  6. 16.  1.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: [-1.4906616]
desired expected reward: 378.693115234375



buy possibilites: [-1] 
expected returns: [[377.65625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [10.  6. 16.  1.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  30.   0.   0.  20.   0.   0.   0.   0.  -8.   0.   0.
   0.   0.] 
sum of rewards: 28.0 

action type: buy - action 0.0
Learning step: [-2.420102]
desired expected reward: 376.9656982421875






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10.  6. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 16.  1.  0.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [3. 0. 1. 1. 6.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0] -> size -> 43 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 16.  1.  0.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  5.  9.  7.] 
adversary cards in hand: [3. 0. 1. 1. 6.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0] -> size -> 43 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 16.  1.  0.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [3. 0. 1. 1. 6.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0] -> size -> 43 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 1. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[364.54285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 1. 6.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10. 11.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4 10] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: [-4.6182375]
desired expected reward: 373.03802490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[364.97525]
 [365.1665 ]
 [365.38757]
 [365.13318]
 [365.1754 ]
 [365.58673]
 [365.16187]
 [365.5783 ]
 [365.74875]
 [365.55347]
 [365.77072]
 [365.383  ]
 [365.56696]
 [365.75717]
 [366.59174]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 6.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 20. 29. 23. 28.  8.  0.  7.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10. 11.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4 10] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: [-3.1109772]
desired expected reward: 361.431884765625



buy possibilites: [-1] 
expected returns: [[375.74475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 1. 6.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 3.  0.  8. 10. 11.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4 10] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  30.   0.   0.   0.   0.   0.   0.   0.  -9.   0.   0.
   8.   0.] 
sum of rewards: 15.0 

action type: buy - action 16.0
Learning step: [-2.4908082]
desired expected reward: 362.6846008300781






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10. 11.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [15.  1. 11. 23.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11.  3.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0
 29  0  1  6 11  1  6  8  8  8  4 10] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [15.  1. 11. 23.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [15.  1. 11. 23.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [15.  1. 11. 23.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [15.  1. 11. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 23.] 
expected returns: [[383.01843]
 [382.1839 ]
 [382.01346]
 [382.1974 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 11. 23.  0.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: [-2.8433473]
desired expected reward: 372.9013977050781



action possibilites: [-1. 15. 11.] 
expected returns: [[373.4526 ]
 [372.61807]
 [372.4476 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 11.  0.  3.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10
 11  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action 23.0
Learning step: [-2.3217409]
desired expected reward: 379.87567138671875



action possibilites: [-1] 
expected returns: [[376.79663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: take_action - action 15.0
Learning step: [1.1416992]
desired expected reward: 373.7597351074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[375.1827 ]
 [375.3746 ]
 [375.39172]
 [375.59592]
 [375.34106]
 [375.3826 ]
 [375.79498]
 [375.3695 ]
 [375.78586]
 [375.95648]
 [375.76138]
 [375.9787 ]
 [375.5908 ]
 [375.7745 ]
 [375.96555]
 [376.79663]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16] -> size -> 43 
action values: 0 
buys: 2 
player value: 6 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  9.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 56 

action type: take_action - action -1
Learning step: [0.72384036]
desired expected reward: 377.5204772949219



buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[382.49905]
 [382.91223]
 [382.68585]
 [384.11298]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  40   0   0   0   0  -9   0   0  16   0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: [2.0252075]
desired expected reward: 377.9816589355469



buy possibilites: [-1] 
expected returns: [[384.41333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  30.   0.   0.  40.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: 46.0 

action type: buy - action 0.0
Learning step: [-0.39184266]
desired expected reward: 382.107177734375






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[380.12244]
 [378.91663]
 [379.1208 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 15.  2.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: [-4.0688753]
desired expected reward: 380.3444519042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[378.50854]
 [378.92175]
 [378.6953 ]
 [380.12244]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 15.  2.] 
adversary cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0. 29.  1.  0.  0.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: [-3.6397858]
desired expected reward: 376.482666015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  6. 15.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 15.  2.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0. 29.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3. 10.  0.
 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 15.  2.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0. 29.  1.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  9.  7.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3. 10.  0.
 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 15.  2.] 
cards in discard: [ 4.  0.  6.  6.  8.  8. 23. 11.  0.  3. 10. 10.  6. 16.  1.  0. 10.  8.
  3. 11.  3.  0. 29.  1.  0.  0.  3. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3. 10.  0.
 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [25.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[373.23126]
 [372.22046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  3.  0.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3. 10.  0.
 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [8. 0. 8. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1.0
Learning step: [-4.2253633]
desired expected reward: 375.8970642089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[371.61734]
 [372.03055]
 [371.80414]
 [373.23126]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  3.  0.] 
cards in discard: [14. 11. 15. 16. 10.  0.  4.  0.  0.  1.  0.  0.  0.  8. 11.  0. 11. 10.
  6.  0.  8. 16.  3.  0.  1.  1.  6. 29.  0. 23. 15.  1. 11.  3. 10.  0.
 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [8. 0. 8. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22] -> size -> 36 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: [-3.5362458]
desired expected reward: 369.69500732421875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [11. 10.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 6. 1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [11. 10.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 6. 1.] 
cards in discard: [0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [11. 10.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 16.] 
expected returns: [[398.7419 ]
 [397.74033]
 [397.53613]
 [397.31485]
 [397.32794]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 11 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11
  0  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  4.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 6.  4.  3. 10.  6.] 
adversary cards in discard: [0. 8. 0. 8. 6. 1.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1.0
Learning step: [-0.98287356]
desired expected reward: 372.2483825683594



action possibilites: [-1] 
expected returns: [[396.94507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 6.  4.  3. 10.  6.] 
adversary cards in discard: [0. 8. 0. 8. 6. 1.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0 -10   0   0   4   0] 
sum of rewards: 30 

action type: gain_card_n - action 6
Learning step: [-1.8487275]
desired expected reward: 389.6360778808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[397.10553]
 [398.71945]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 6.  4.  3. 10.  6.] 
adversary cards in discard: [0. 8. 0. 8. 6. 1.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: [-1.6402406]
desired expected reward: 395.3048400878906






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 6.  4.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  4.  3. 10.  6.] 
cards in discard: [0. 8. 0. 8. 6. 1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [11. 15. 15.  0.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  4.  3. 10.  6.] 
cards in discard: [0. 8. 0. 8. 6. 1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [11. 15. 15.  0.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 15. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15.] 
expected returns: [[399.39453]
 [398.39288]
 [398.5635 ]
 [398.5635 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 15.  0.  0.] 
cards in discard: [ 8. 16. 10.  0.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 1.  0.  3.  6. 22.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1.0
Learning step: [-3.6510742]
desired expected reward: 395.0683898925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[398.59717]
 [399.01038]
 [398.784  ]
 [400.21106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 15.  0.  0.] 
cards in discard: [ 8. 16. 10.  0.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 1.  0.  3.  6. 22.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: [-3.6363983]
desired expected reward: 395.75811767578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  6. 22.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [25.  1.  1.  4. 11.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6. 0. 2. 8.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [25.  1.  1.  4. 11.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0. 2. 8.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 7 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  3.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [25.  1.  1.  4. 11.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6. 0. 2. 8.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [25.  1.  1.  4. 11.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [25.  1.  1.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[407.07593]
 [406.06512]
 [406.07425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.  4. 11.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11] -> size -> 38 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1.0
Learning step: [-2.8818328]
desired expected reward: 397.32928466796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[407.15604]
 [407.34793]
 [407.5692 ]
 [407.35593]
 [407.76828]
 [407.34283]
 [407.92978]
 [407.73474]
 [407.56412]
 [407.93887]
 [408.76993]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  4. 11.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  3.  9.  8.  9.  8.  4.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11] -> size -> 38 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: [-3.4097137]
desired expected reward: 403.66619873046875



buy possibilites: [-1] 
expected returns: [[409.725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  4. 11.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  3.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11] -> size -> 38 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20.    0.    6.   30.    0.    0.    0.    0.    0.    0.    0.  -11.
   0.    0.    4.5   0. ] 
sum of rewards: 9.5 

action type: buy - action 10.0
Learning step: [-3.6434693]
desired expected reward: 400.93719482421875






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  3.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10] -> size -> 46 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  3.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10] -> size -> 46 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  2.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [11. 10.  0.  1.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10] -> size -> 46 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[396.67072]
 [395.6878 ]
 [395.48602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  1.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  2.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 6. 10. 16.  1.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: [-4.847168]
desired expected reward: 404.8778381347656



action possibilites: [-1] 
expected returns: [[399.4013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  1.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 6. 10. 16.  1.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0 -12   0   0   4   0] 
sum of rewards: 28 

action type: gain_card_n - action 5
Learning step: [-1.8403015]
desired expected reward: 393.1734924316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[399.87936]
 [400.0688 ]
 [400.28696]
 [400.07565]
 [400.4833 ]
 [400.06345]
 [400.64224]
 [400.45   ]
 [400.28156]
 [400.65173]
 [401.46625]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  1.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 6. 10. 16.  1.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: [-1.2841462]
desired expected reward: 398.1171569824219



buy possibilites: [-1] 
expected returns: [[402.68045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 6. 10. 16.  1.  8.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20.   0.   6.  30.   0.   0.  20.   0.   0.   0.   0. -13.   0.   0.
   2.   0.] 
sum of rewards: 25.0 

action type: buy - action 8.0
Learning step: [-2.2297943]
desired expected reward: 397.8336181640625






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 6. 10. 16.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 16.  1.  8.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [14.  0.  3. 29.  6.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 16.  1.  8.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [14.  0.  3. 29.  6.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10. 16.  1.  8.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [14.  0.  3. 29.  6.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [14.  0.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[412.14316]
 [411.12695]
 [411.31915]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 29.  6.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 1. 11.  0.  3. 23.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: [-2.598117]
desired expected reward: 400.08233642578125



action possibilites: [-1.] 
expected returns: [[400.16223]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 1. 11.  0.  3. 23.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: discard_n_cards - action 2
Learning step: [-2.3946717]
desired expected reward: 408.367431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[398.57532]
 [398.98297]
 [400.16223]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 20. 29. 23. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 1. 11.  0.  3. 23.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-20   0   6  30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: [-1.3346833]
desired expected reward: 398.8275451660156



buy possibilites: [-1] 
expected returns: [[398.21024]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [ 1. 11.  0.  3. 23.] 
adversary cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-20   0   7  40   0   0  20   0   0   0   0 -14   0   0   8   0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: [-0.970874]
desired expected reward: 398.0120849609375






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  3. 23.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3] -> size -> 49 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  3. 23.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  3.  8.  7.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3] -> size -> 49 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  3. 23.] 
cards in discard: [ 0.  8.  0.  8.  6.  1.  6.  4.  3. 10.  6. 11. 22.  1.  0.  3.  6.  0.
  2.  8.  8.  0.  0. 29.  3.  3.  0.  6. 10. 16.  1.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3] -> size -> 49 
adversary victory points: 7
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[386.3263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10.  1. 10. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-20   0   7  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: [-3.3191133]
desired expected reward: 394.89111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[384.73944]
 [384.92886]
 [385.147  ]
 [385.34335]
 [385.14154]
 [386.3263 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  2.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10.  1. 10. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-20   0   7  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: [-2.130719]
desired expected reward: 384.1955871582031



buy possibilites: [-1] 
expected returns: [[389.27448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10.  1. 10. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-20   0   7  40   0   0   0   0   0   0   0 -15   0   0  18   0] 
sum of rewards: 30 

action type: buy - action 11.0
Learning step: [-1.5019257]
desired expected reward: 383.8414306640625






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10.  1. 10. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10. 11. 15.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [16. 16.  0.  3.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3 11] -> size -> 50 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 11. 15.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [16. 16.  0.  3.  0.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3 11] -> size -> 50 
adversary victory points: 7
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[368.38153]
 [366.99097]
 [366.99097]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0.  3.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0
  0 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8
  3 11] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 22. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10. 23.  1.  2. 10.] 
adversary cards in discard: [10.  1. 10. 11. 15.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[-20   0   7  40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: [-4.1896973]
desired expected reward: 385.08477783203125



action possibilites: [-1] 
expected returns: [[374.5207]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10. 23.  1.  2. 10.] 
adversary cards in discard: [10.  1. 10. 11. 15.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  20   0   0   0   0 -15   0   0   4   0] 
sum of rewards: 47 

action type: gain_card_n - action 1
Learning step: [-0.23175049]
desired expected reward: 376.6998291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[372.9553 ]
 [374.52075]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10. 23.  1.  2. 10.] 
adversary cards in discard: [10.  1. 10. 11. 15.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: [1.1093384]
desired expected reward: 375.6300354003906



buy possibilites: [-1] 
expected returns: [[369.54236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [10. 23.  1.  2. 10.] 
adversary cards in discard: [10.  1. 10. 11. 15.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20.   0.   8.  50.   0.   0.  20.   0.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: 42.0 

action type: buy - action 0.0
Learning step: [-0.6009796]
desired expected reward: 372.3543395996094






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [10. 23.  1.  2. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  1.  2. 10.] 
cards in discard: [10.  1. 10. 11. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [ 8. 23.  0. 10.  1.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1. 23. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  2. 10.  3.] 
cards in discard: [10.  1. 10. 11. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [ 8. 23.  0. 10.  1.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 2 
buys: 1 
player value: 1 
card supply: [10. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [ 8. 23.  0. 10.  1.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10] -> size -> 41 
action values: 0 
buys: 2 
player value: 7 
card supply: [10. 20. 29. 21. 28.  8.  0.  6.  1.  0.  9.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [ 8. 23.  0. 10.  1.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
adversary victory points: 8
player victory points: 3 


buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 20. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [ 8. 23.  0. 10.  1.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 10.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 20. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [ 8. 23.  0. 10.  1.] 
adversary cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 8. 23.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 10.] 
expected returns: [[373.5434 ]
 [372.15942]
 [372.75345]
 [372.37488]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0. 10.  1.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [11. 29.  0.  8. 22.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: [-0.5122742]
desired expected reward: 369.03009033203125



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[367.02307]
 [365.6391 ]
 [365.85455]
 [366.05432]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  1. 11.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0] -> size -> 51 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 9. 20. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [11. 29.  0.  8. 22.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 58 

action type: take_action - action 23.0
Learning step: [0.6121063]
desired expected reward: 373.36553955078125



action possibilites: [-1] 
expected returns: [[364.53125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  1.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [11. 29.  0.  8. 22.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  40   0   0   0   0 -17   0   0   9   0] 
sum of rewards: 70 

action type: gain_card_n - action 1
Learning step: [2.1424103]
desired expected reward: 368.63763427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[362.96582]
 [363.1531 ]
 [363.36856]
 [363.15927]
 [363.56244]
 [363.71973]
 [363.52957]
 [363.36273]
 [363.72928]
 [364.53122]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  1.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1] -> size -> 52 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 9. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  7.] 
adversary cards in hand: [11. 29.  0.  8. 22.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 78 

action type: take_action - action -1
Learning step: [3.1388092]
desired expected reward: 367.6700439453125



buy possibilites: [ 0. -1.] 
expected returns: [[365.90018]
 [367.46558]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  1.] 
cards in discard: [ 8. 16. 10.  0.  8. 11. 15. 15.  0.  0. 10. 25.  1.  1.  4. 11.  8.  8.
 11. 10.  0.  1.  0. 14.  6.  3. 29.  0.  3.  3. 11.  3.  0.  0.  0.  6.
  3.  0. 16. 16.  3.  0.  1. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [11. 29.  0.  8. 22.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
adversary owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  40   0   0   0   0 -18   0   0  16   0] 
sum of rewards: 76 

action type: buy - action 15.0
Learning step: [3.2179506]
desired expected reward: 366.947265625






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [11. 29.  0.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  8. 22.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16 11  6  0 29
  0  1  6 11  1  6  8  8  8  4 10 22  0 11  8  0 10 25  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [10. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[390.64832]
 [389.4798 ]
 [389.67953]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: [1.4504395]
desired expected reward: 368.916015625



action possibilites: [-1. 11. 15.] 
expected returns: [[393.17953]
 [392.21075]
 [392.37762]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0
 15  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3
 11  3  0  1 15] -> size -> 53 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 58 

action type: take_action - action 10.0
Learning step: [1.5894531]
desired expected reward: 391.0692443847656



action possibilites: [-1. 11.] 
expected returns: [[403.6192]
 [402.6504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15] -> size -> 52 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 8. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 78 

action type: take_action - action 15.0
Learning step: [3.831839]
desired expected reward: 396.20947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[402.49957]
 [402.68686]
 [402.90234]
 [402.69302]
 [403.09625]
 [403.25348]
 [403.0634 ]
 [402.8965 ]
 [403.2631 ]
 [404.065  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 19. 29. 21. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-20   0   8  50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 78 

action type: take_action - action -1.0
Learning step: [2.7466888]
desired expected reward: 406.36590576171875



buy possibilites: [-1] 
expected returns: [[401.6671]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [3.] 
cards in deck: 47 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-20.   0.   9.  60.   0.   0.  40.   0.   0.   0.   0. -18.   0.   0.
   2.   0.] 
sum of rewards: 73.0 

action type: buy - action 3.0
Learning step: [2.1662812]
desired expected reward: 405.0686340332031






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [0. 0. 4. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 3. 6.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [3. 0. 6. 3. 4.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
adversary victory points: 9
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3. 6.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [3. 0. 6. 3. 4.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
adversary victory points: 9
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 6. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[392.8246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 4.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [16.  8.  3.  6.  8.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-20   0   9  60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: [-0.85299075]
desired expected reward: 400.8141174316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[392.59332]
 [394.15448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 4.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [16.  8.  3.  6.  8.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6.] 
adversary owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-20   0   9  60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: [-0.02575684]
desired expected reward: 393.7498779296875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [16.  8.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  6.  8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1
  6 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  2.  8.  6.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
adversary victory points: 9
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
adversary victory points: 9
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
adversary victory points: 9
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 0.  8. 25. 10.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
adversary victory points: 9
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[390.64447]
 [389.26483]
 [389.66974]
 [389.48026]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25. 10.  0.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 29. 20. 28.  8.  0.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0] -> size -> 42 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[-20   0   9  70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 59 

action type: buy - action -1.0
Learning step: [0.6782746]
desired expected reward: 394.832763671875



action possibilites: [-1] 
expected returns: [[396.01483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0. 23.  8.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6] -> size -> 43 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[-20   0   9  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 79 

action type: take_action - action 25.0
Learning step: [3.878763]
desired expected reward: 393.5484313964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[394.87   ]
 [395.27325]
 [396.43115]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0. 23.  8.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6] -> size -> 43 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[-20   0   9  70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 79 

action type: take_action - action -1
Learning step: [3.2842011]
desired expected reward: 399.2990417480469



buy possibilites: [-1] 
expected returns: [[396.81836]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0. 23.  8.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6] -> size -> 43 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[-20.   0.   9.  70.   0.   0.  20.   0.   0.   0.   0. -19.   0.   0.
   0.   0.] 
sum of rewards: 60.0 

action type: buy - action 0.0
Learning step: [1.3918488]
desired expected reward: 396.2618713378906






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 0. 29.  0.  8. 15.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0] -> size -> 54 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 0. 29.  0.  8. 15.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0] -> size -> 54 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3.  0.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 0. 29.  0.  8. 15.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0] -> size -> 54 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15.] 
expected returns: [[408.9751 ]
 [408.16742]
 [407.59546]
 [408.17804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8. 15.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [6. 1. 0. 6. 8.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.  8. 11.  3.  3.  0.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0] -> size -> 44 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 69 

action type: buy - action -1
Learning step: [3.2382843]
desired expected reward: 400.056640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[407.41394]
 [407.8172 ]
 [408.9751 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8. 15.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [6. 1. 0. 6. 8.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.  8. 11.  3.  3.  0.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0] -> size -> 44 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 69 

action type: take_action - action -1.0
Learning step: [2.0226104]
desired expected reward: 410.9977111816406



buy possibilites: [-1] 
expected returns: [[406.6056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8. 15.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [6. 1. 0. 6. 8.] 
adversary cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.  8. 11.  3.  3.  0.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0] -> size -> 44 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20.   0.   9.  80.   0.   0.   0.   0.   0.   0.   0. -20.   0.   0.
   0.   0.] 
sum of rewards: 49.0 

action type: buy - action 0.0
Learning step: [0.0657898]
desired expected reward: 407.479736328125






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [6. 1. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 6. 8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.  8. 11.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10. 11.  0. 10.  1.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 6. 8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.  8. 11.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10. 11.  0. 10.  1.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 6. 8.] 
cards in discard: [10.  1. 10. 11. 15. 25.  0. 10. 23.  1.  2. 10.  3.  0.  0.  8. 29.  0.
  0.  4.  3.  6. 10.  0. 16.  8.  6.  8.  6.  0.  8. 11.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10. 11.  0. 10.  1.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [10. 11.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[401.6129 ]
 [400.44873]
 [400.64877]
 [400.44873]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  1.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 69 

action type: buy - action -1
Learning step: [1.5471954]
desired expected reward: 408.15277099609375



action possibilites: [-1. 11. 10.] 
expected returns: [[396.9616 ]
 [395.9975 ]
 [395.79745]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  1.  1.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 91 

action type: take_action - action 10.0
Learning step: [3.9408357]
desired expected reward: 404.3895568847656



action possibilites: [-1. 11. 15.] 
expected returns: [[398.311  ]
 [397.34686]
 [397.51392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  1. 15.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 109 

action type: take_action - action 10.0
Learning step: [6.37406]
desired expected reward: 402.1714782714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[396.74982]
 [396.9377 ]
 [397.15314]
 [396.9047 ]
 [396.94244]
 [397.3469 ]
 [397.33627]
 [397.50336]
 [397.3139 ]
 [397.52505]
 [397.14688]
 [397.32504]
 [397.51395]
 [398.31104]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  1. 15.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  8.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 109 

action type: take_action - action -1.0
Learning step: [6.1226993]
desired expected reward: 404.4337463378906



buy possibilites: [-1] 
expected returns: [[408.68677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  1. 15.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  7.  9.  8.  1.  8.  6.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20.   0.   9.  80.   0.   0.  40.   0.   0.   0.   0. -21.   0.   0.
   8.   0.] 
sum of rewards: 96.0 

action type: buy - action 29.0
Learning step: [5.674039]
desired expected reward: 403.1773986816406






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  7.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  1. 11.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  6.  1.  0.  8.  7.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
adversary victory points: 9
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [16.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  5.  1.  0.  8.  7.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [16.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  5.  1.  0.  8.  7.  9.  8.  1.  8.  6.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [16. 14.] 
cards in deck: 39 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [ 3. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [ 3. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[397.31927]
 [395.9508 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  3.  0.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [ 0.  3. 10.  3. 10.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 69 

action type: buy - action -1
Learning step: [0.91300356]
desired expected reward: 409.5997619628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[395.75812]
 [396.1614 ]
 [397.31927]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  3.  0.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 19. 29. 20. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [ 0.  3. 10.  3. 10.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[-20   0   9  80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 69 

action type: take_action - action -1.0
Learning step: [2.0497499]
desired expected reward: 399.3690490722656



buy possibilites: [-1] 
expected returns: [[392.62128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  3.  0.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [ 0.  3. 10.  3. 10.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0   0   0   0   0   0 -22   0   0   8   0] 
sum of rewards: 66 

action type: buy - action 3.0
Learning step: [1.3891662]
desired expected reward: 397.550537109375






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [ 8. 11.  6.  3.  3.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3] -> size -> 57 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [ 8. 11.  6.  3.  3.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3] -> size -> 57 
adversary victory points: 10
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[374.8025 ]
 [373.43335]
 [373.84735]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  3.  3.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  6.] 
adversary cards in hand: [15. 29.  8.  0.  4.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 80 

action type: buy - action -1
Learning step: [1.5069275]
desired expected reward: 394.1282043457031



action possibilites: [-1] 
expected returns: [[374.55682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 3.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [15. 29.  8.  0.  4.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0 -23   0   0  16   0] 
sum of rewards: 93 

action type: gain_card_n - action 8
Learning step: [4.692334]
desired expected reward: 378.1257019042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[373.00635]
 [374.55682]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 3.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [15. 29.  8.  0.  4.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 100 

action type: take_action - action -1
Learning step: [5.2799897]
desired expected reward: 379.8368225097656






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [15. 29.  8.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  8.  0.  4.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 0.  1.  0. 11.  1.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15] -> size -> 58 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  4. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 0.  1.  0. 11.  1.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15] -> size -> 58 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  4. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 0.  1.  0. 11.  1.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15] -> size -> 58 
adversary victory points: 10
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[365.8241]
 [364.8689]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.  1.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  1.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  1.  0. 23.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 80 

action type: buy - action -1.0
Learning step: [2.5736542]
desired expected reward: 377.1304931640625



action possibilites: [-1] 
expected returns: [[364.08725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  1.  0. 23.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0 -24   0   0   9   0] 
sum of rewards: 85 

action type: gain_card_n - action 4
Learning step: [3.918918]
desired expected reward: 368.3471984863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[362.5368 ]
 [362.72418]
 [362.73956]
 [362.93887]
 [362.6914 ]
 [362.72784]
 [363.12033]
 [363.28687]
 [363.09924]
 [363.30835]
 [362.93277]
 [363.10904]
 [363.29858]
 [364.08722]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  8.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  1.  0. 23.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 100 

action type: take_action - action -1
Learning step: [5.4530215]
desired expected reward: 369.540283203125



buy possibilites: [-1] 
expected returns: [[373.8108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11 25] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  1.  0. 23.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
adversary owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20.    0.   10.   90.    0.    0.   20.    0.    0.    0.    0.  -25.
   0.    0.   12.5   0. ] 
sum of rewards: 87.5 

action type: buy - action 25.0
Learning step: [5.259369]
desired expected reward: 368.3797302246094






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 23.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  0  1  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6
 11  1  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  0. 16.  1. 16.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25. 11.  0.  1.  0.  1.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11 25] -> size -> 60 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  0. 16.  1. 16.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25. 11.  0.  1.  0.  1.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11 25] -> size -> 60 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 8.  0. 16.  1. 16.] 
adversary cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25. 11.  0.  1.  0.  1.] 
adversary owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11 25] -> size -> 60 
adversary victory points: 10
player victory points: 1 





Player: 0 
cards in hand: [ 8.  0. 16.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
expected returns: [[381.61996]
 [380.2508 ]
 [380.26056]
 [380.26056]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  1. 16.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25. 11.  0.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16 10  0  1 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15
  8  3  0  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11
  3  0  1 15  3  0  0 29  3 15 11 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [25.  6.  0.  6.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 80 

action type: buy - action -1
Learning step: [4.0760164]
desired expected reward: 377.8868103027344



action possibilites: [-1] 
expected returns: [[376.43842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25. 11.  0.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [25.  6.  0.  6.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 100 

action type: trash_cards_n_from_hand - action 10
Learning step: [5.0393586]
desired expected reward: 385.50482177734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[374.88797]
 [376.43842]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 3. 10. 15. 11.  3.  0.  3.  0.  6.  3.  4.  0. 25.  0.  8. 10.  0. 23.
  8.  0.  0. 29.  0.  8. 15. 29. 10. 10. 11.  0.  1.  1. 15.  3.  3. 16.
  0.  3.  0. 15. 11.  8.  6.  3.  3. 11. 25. 11.  0.  1.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25] -> size -> 57 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [25.  6.  0.  6.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 100 

action type: take_action - action -1
Learning step: [5.4420624]
desired expected reward: 381.8804931640625






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [25.  6.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  0.  6.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [10.  0. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25] -> size -> 57 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  0.  6.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [10.  0. 11.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25] -> size -> 57 
adversary victory points: 10
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 11.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 14.] 
expected returns: [[420.6391 ]
 [419.48456]
 [419.6839 ]
 [419.6511 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0. 14.] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16.  6.  6.  8.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 80 

action type: buy - action -1.0
Learning step: [7.357877]
desired expected reward: 383.7962951660156



action possibilites: [-1. 11. 14.] 
expected returns: [[417.3277 ]
 [416.37247]
 [416.33972]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25] -> size -> 57 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16.  6.  6.  8.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 100 

action type: take_action - action 10.0
Learning step: [4.849878]
desired expected reward: 424.3344421386719



action possibilites: [-1. 14.] 
expected returns: [[415.16342]
 [414.1715 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [0.] 
cards in deck: 51 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16.  6.  6.  8.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  40   0   0   0   0 -23   0   0   0   0] 
sum of rewards: 97 

action type: gain_card_n - action 0
Learning step: [3.8717194]
desired expected reward: 424.20855712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[414.42914]
 [414.83603]
 [415.99045]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [0.] 
cards in deck: 51 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0] -> size -> 58 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 19. 29. 19. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16.  6.  6.  8.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[-20   0  10  90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 120 

action type: take_action - action -1.0
Learning step: [6.763742]
desired expected reward: 421.9271545410156



buy possibilites: [-1] 
expected returns: [[405.12997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.] 
cards in discard: [0. 3.] 
cards in deck: 51 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 18. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16.  6.  6.  8.  0.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[-20   0  11 100   0   0  40   0   0   0   0 -24   0   0   8   0] 
sum of rewards: 115 

action type: buy - action 3.0
Learning step: [5.2527466]
desired expected reward: 420.0887451171875






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [16.  6.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  6.  8.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 18. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3] -> size -> 59 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  6.  8.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 19. 29. 18. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3] -> size -> 59 
adversary victory points: 11
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  6.  8.  0.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 19. 29. 18. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3] -> size -> 59 
adversary victory points: 11
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[396.24323]
 [394.86664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 6.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 18. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 1.  2. 11.  6. 10.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0] -> size -> 46 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[-20   0  11 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 91 

action type: buy - action -1
Learning step: [3.2069702]
desired expected reward: 408.3369445800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[394.26514]
 [394.672  ]
 [395.8264 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 6.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 19. 29. 18. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 1.  2. 11.  6. 10.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0] -> size -> 46 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[-20   0  11 100   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 91 

action type: take_action - action -1.0
Learning step: [4.0556946]
desired expected reward: 400.29888916015625



buy possibilites: [-1] 
expected returns: [[395.90073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 6.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [ 1.  2. 11.  6. 10.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0] -> size -> 46 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[-20   0  12 110   0   0   0   0   0   0   0 -25   0   0   8   0] 
sum of rewards: 85 

action type: buy - action 3.0
Learning step: [3.640036]
desired expected reward: 398.31207275390625






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [ 1.  2. 11.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  2. 11.  6. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16. 16.  3.  6.  1.] 
adversary cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6.] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3  3] -> size -> 60 
adversary victory points: 12
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 11.  6. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  7.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16. 16.  3.  6.  1.] 
adversary cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6.] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3  3] -> size -> 60 
adversary victory points: 12
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  2. 11.  6. 10.] 
cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  6.  8.  8.  1.  8.  5.] 
adversary cards in hand: [16. 16.  3.  6.  1.] 
adversary cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6.] 
adversary owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3  3] -> size -> 60 
adversary victory points: 12
player victory points: 1 





Player: 0 
cards in hand: [16. 16.  3.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[388.83072]
 [387.46225]
 [387.46225]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3.  6.  1.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 15  1  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0
  0 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1
 15  3  0  0 29  3 15 11 25  0  3  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  6.  8.  8.  1.  8.  5.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0. 29.  1.  2.
 11.  6. 10.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0 29] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[-20   0  12 110   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 102 

action type: buy - action -1
Learning step: [4.58927]
desired expected reward: 400.489990234375



action possibilites: [-1] 
expected returns: [[399.4431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6. 15.] 
cards in deck: 41 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 10 15  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0  0
 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1 15
  3  0  0 29  3 15 11 25  0  3  3 15] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  6.  8.  8.  1.  8.  4.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0. 29.  1.  2.
 11.  6. 10.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0 29] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[-20   0  12 110   0   0  20   0   0   0   0 -25   0   0  16   0] 
sum of rewards: 113 

action type: gain_card_n - action 11
Learning step: [5.7943206]
desired expected reward: 409.4083557128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[397.88187]
 [399.44315]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6. 15.] 
cards in deck: 41 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 10 15  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0  0
 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1 15
  3  0  0 29  3 15 11 25  0  3  3 15] -> size -> 60 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  6.  8.  8.  1.  8.  4.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0. 29.  1.  2.
 11.  6. 10.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0 29] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[-20   0  12 110   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 122 

action type: take_action - action -1
Learning step: [7.1114135]
desired expected reward: 406.5545349121094



Player 0 won the game! 



Player 0 bought cards:
Copper: 16 
Silver: 5 
Gold: 0 
Estate: 8 
Duchy: 1 
Province: 0 
Curse: 3 

Remodel: 2 
Workshop: 4 
Chapel: 3 
Witch: 2 
Poacher: 2 
Militia: 0 
Market: 1 
Village: 3 
Library: 0 
Moneylender: 3 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [16.  3.  6.] 
cards in discard: [ 0.  3. 10. 11.  0.  0. 14.  3.  3.  3.  0.  0.  8.  6. 15.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 10 15  6  6  0 11  3  3  0  1  0 10  1 10 11  0  0 15  8  3  0  0
 16  0 25  8 11 23 14  4  0 11  0 16 29  0  8 10  8  8  3 11  3  0  1 15
  3  0  0 29  3 15 11 25  0  3  3 15  0] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 29. 17. 28.  8. -1.  5.  0.  0.  7.  6.  8.  8.  1.  8.  4.] 
adversary cards in hand: [0. 3. 0. 8. 1.] 
adversary cards in discard: [16. 14. 10. 11.  0.  0.  6.  1.  0.  3. 10.  3. 10.  8. 29. 15.  0.  4.
 10.  8. 23.  0. 25.  6.  0.  6.  0.  0. 16.  6.  6.  8.  0. 29.  1.  2.
 11.  6. 10.] 
adversary owned cards: [ 3 10 10  6  6  1 23  3  0  3  2  8  3 15  0 16  6  0 29  0  1  6 11  1
  6  8  8  8  4 10  0 11  8  0 10 25  0  0 10  0  6  0  0 16 14  0 29] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -20 1000   12  110    0    0   20    0    0    0    0  -26    0    0
    0    0] 
sum of rewards: 1096 

action type: buy - action 0.0
Learning step: [69.81182]
desired expected reward: 467.6936950683594



