 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.549057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     390       0       0      20       0       0
       0       0    -180       0       0      27       0] 
sum of rewards: 3000252 

action type: buy - action 11.0
Learning step: 299983.09375
desired expected reward: 300404.4375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 35.606575]
 [ 70.8284  ]
 [ 53.739773]
 [ 12.063696]
 [ 65.944855]
 [ 68.40662 ]
 [ 49.748566]
 [118.16743 ]
 [ 24.22185 ]
 [ 35.04076 ]
 [ 56.328964]
 [ 32.869152]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.967350006103516



buy possibilites: [-1] 
expected returns: [[12.593837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 118.16743469238281






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  3.  0.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.999799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.593836784362793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.488563  ]
 [41.5314    ]
 [28.100033  ]
 [-0.43972707]
 [40.260693  ]
 [25.113964  ]
 [15.670075  ]
 [15.106719  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.638772010803223



buy possibilites: [-1] 
expected returns: [[24.992107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 41.53139877319336






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[14.696021]
 [59.118355]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.992107391357422



action possibilites: [-1.] 
expected returns: [[34.02209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.7945671081543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 43.073257]
 [ 79.82967 ]
 [ 60.490574]
 [ 33.431496]
 [ 20.295317]
 [ 76.22565 ]
 [ 75.722565]
 [ 57.308945]
 [132.1284  ]
 [118.44504 ]
 [ 29.170643]
 [ 82.82772 ]
 [ 39.39619 ]
 [ 45.797073]
 [ 63.34179 ]
 [ 34.1939  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.022090911865234



buy possibilites: [-1] 
expected returns: [[12.896745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 132.12841796875






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [8. 3. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [8. 3. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[38.913887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.896744728088379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 44.954063]
 [ 84.70438 ]
 [ 65.19757 ]
 [ 18.090254]
 [ 80.08449 ]
 [ 81.75643 ]
 [ 61.154716]
 [123.41198 ]
 [ 31.276077]
 [ 42.958332]
 [ 68.39206 ]
 [ 38.38559 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.237937927246094



buy possibilites: [-1] 
expected returns: [[5.7869425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 123.4119644165039






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 2.6382782]
 [26.71513  ]
 [33.642002 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9. 10.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.786942481994629



action possibilites: [-1] 
expected returns: [[9.855947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.6357536315918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 9.911269  ]
 [23.583242  ]
 [17.239676  ]
 [ 0.63911843]
 [20.917114  ]
 [23.748295  ]
 [15.372756  ]
 [38.703644  ]
 [ 5.9194727 ]
 [10.465336  ]
 [18.213266  ]
 [10.998226  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  1. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.85594654083252



buy possibilites: [-1] 
expected returns: [[19.695404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  1. 29.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 38.70364761352539






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 16.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 16.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 16.  0.  0.  0.  6. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.37554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 25. 29.  0.  3.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  6.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.695404052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 50.13278 ]
 [ 80.07807 ]
 [ 62.38703 ]
 [ 29.201473]
 [ 77.83831 ]
 [ 74.96138 ]
 [ 60.18525 ]
 [116.3068  ]
 [ 38.906677]
 [ 46.71737 ]
 [ 64.87121 ]
 [ 40.61381 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 25. 29.  0.  3.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  6.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.117103576660156



buy possibilites: [-1] 
expected returns: [[55.152237]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 25. 29.  0.  3.  0.  1. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  6.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 116.30680084228516






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [16.  6.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[68.35504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [16.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.15223693847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 73.85871 ]
 [103.79263 ]
 [ 88.253685]
 [ 55.94697 ]
 [100.204384]
 [100.62597 ]
 [ 85.29458 ]
 [140.22166 ]
 [ 63.76008 ]
 [ 71.74208 ]
 [ 90.6677  ]
 [ 67.917984]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [16.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.39615631103516



buy possibilites: [-1] 
expected returns: [[57.01723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [16.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 140.2216796875






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [16.  6.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29. 29.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [16.  6.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1. 29.  0. 29. 29.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[22.445105]
 [51.084854]
 [51.084854]
 [51.084854]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29. 29.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.01723098754883



action possibilites: [-1. 29. 29.] 
expected returns: [[32.0385 ]
 [58.86367]
 [58.86367]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 29.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 49.720436096191406



action possibilites: [-1. 29.] 
expected returns: [[ 81.88219]
 [130.14331]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  3.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.86368179321289



action possibilites: [-1. 29.] 
expected returns: [[43.342968]
 [99.905525]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 29.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.14332580566406



action possibilites: [-1. 25.] 
expected returns: [[ 88.19341]
 [158.75764]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 25.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 99.90550994873047



action possibilites: [-1] 
expected returns: [[207.6365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.75762939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[216.67586]
 [243.16878]
 [203.74655]
 [230.05035]
 [208.90628]
 [234.42926]
 [195.36623]
 [240.30537]
 [240.91988]
 [227.4715 ]
 [285.1259 ]
 [274.7645 ]
 [205.82852]
 [245.31453]
 [214.35309]
 [218.57477]
 [232.18033]
 [209.79156]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 9 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  9.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 207.63650512695312



buy possibilites: [-1] 
expected returns: [[186.30782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.   30.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 285.12591552734375






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [16.  6.  0.  3.  3.  0.  0.  0. 29.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  3.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 61.252724]
 [108.029045]
 [108.029045]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  1. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  6.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 186.3078155517578



action possibilites: [-1. 29. 29.] 
expected returns: [[ 38.887966]
 [101.82757 ]
 [101.82757 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  6.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.66808319091797



action possibilites: [-1. 29.] 
expected returns: [[ 66.730156]
 [129.80412 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  6.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.82756805419922



action possibilites: [-1.] 
expected returns: [[130.60172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  6.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 129.8041229248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[152.9103 ]
 [187.7644 ]
 [136.11456]
 [169.83452]
 [143.25305]
 [125.22465]
 [184.56813]
 [183.90564]
 [166.72198]
 [233.64432]
 [222.53874]
 [138.87134]
 [190.5377 ]
 [149.12093]
 [155.63132]
 [172.69156]
 [142.21877]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  8.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  6.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 130.60171508789062



buy possibilites: [-1] 
expected returns: [[112.80707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  6.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 177.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 233.64431762695312






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  6.] 
cards in discard: [29.  0.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  6.] 
cards in discard: [29.  0.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  6.] 
cards in discard: [29.  0.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[133.43202]
 [203.10779]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.  0.  0.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.80706787109375



action possibilites: [-1] 
expected returns: [[154.29561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 25.  0.] 
cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.  0.  0.  0.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 196.60931396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[166.39796]
 [193.03706]
 [180.20381]
 [142.74252]
 [190.778  ]
 [190.24384]
 [177.99251]
 [217.90533]
 [155.25375]
 [165.09894]
 [182.24657]
 [159.8922 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.  0.] 
cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.  0.  0.  0.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.2956085205078



buy possibilites: [-1] 
expected returns: [[138.32701]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.  0.] 
cards in discard: [25. 29. 29. 29.  3.  3.  1.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  6.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  3.  0.  0.  0.  0. 29.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 217.9053192138672






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  6.  0.] 
cards in discard: [29.  0.  0.  0.  3.  3.  0.  0.  0.  0. 29.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  6.  0.] 
cards in discard: [29.  0.  0.  0.  3.  3.  0.  0.  0.  0. 29.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[33.290283]
 [71.29487 ]
 [71.29487 ]
 [71.29487 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.32701110839844



action possibilites: [-1. 29. 29.] 
expected returns: [[52.768967]
 [97.22138 ]
 [97.22138 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 67.3807601928711



action possibilites: [-1. 29.] 
expected returns: [[ 81.992424]
 [163.74026 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.22137451171875



action possibilites: [-1. 25.] 
expected returns: [[121.18274]
 [199.09946]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  7.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 163.740234375



action possibilites: [-1] 
expected returns: [[74.26334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  6.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 199.0994415283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 81.5477  ]
 [113.41086 ]
 [ 70.240654]
 [ 98.191185]
 [ 73.528755]
 [ 62.474632]
 [108.87767 ]
 [112.12697 ]
 [ 94.50316 ]
 [157.17061 ]
 [145.4115  ]
 [ 71.99341 ]
 [115.12813 ]
 [ 80.171394]
 [ 83.17488 ]
 [100.75362 ]
 [ 77.58453 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 29. 30. 30. 30.  8.  6.  9. 10.  9.  7.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.26334381103516



buy possibilites: [-1] 
expected returns: [[85.7242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 29.  0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  6.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6  6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 157.1706085205078






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 16.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29  6 29  6  0  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  6.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [6. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  5.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [6. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  5.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29. 29.  0.  0.] 
adversary cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [25. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 75.3527 ]
 [117.82244]
 [111.27652]
 [111.27652]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  0.  0.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  5.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.72419738769531



action possibilites: [-1] 
expected returns: [[34.059544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  0.  3.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  4.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 115.50979614257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.608875]
 [48.35033 ]
 [40.418713]
 [18.108427]
 [50.04874 ]
 [38.091393]
 [31.224209]
 [31.177261]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0.  0.  3.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  4.  9. 10.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.05954360961914



buy possibilites: [-1] 
expected returns: [[67.28064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0.  0.  3.] 
cards in discard: [25. 29. 29. 29. 25.  0.  0.  0.  3. 29.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  4.  9.  9.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.048744201660156






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  4.  9.  9.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  4.  9.  9.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8.  4.  9.  9.  9.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  4.  9.  9.  9.  6.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0. 29. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 76.963104]
 [127.385506]
 [135.59062 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  1.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  4.  9.  9.  9.  6.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14] -> size -> 21 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.2806396484375



action possibilites: [-1] 
expected returns: [[87.1139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.7884063720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 81.06034 ]
 [102.536865]
 [ 94.01365 ]
 [ 64.68139 ]
 [ 97.162445]
 [104.72848 ]
 [ 90.39266 ]
 [125.63009 ]
 [ 74.07272 ]
 [ 82.32516 ]
 [ 95.637215]
 [ 83.154045]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  2.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.11389923095703



buy possibilites: [-1] 
expected returns: [[67.99951]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  3. 25.  0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 125.6301040649414






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.  3.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 6.  6. 16.  6.  0.  0.  6. 14. 29.  0.  0.  0.  3.  0.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 98.535255]
 [124.75832 ]
 [124.75832 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  0.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.99951171875



action possibilites: [-1. 29.] 
expected returns: [[109.23078]
 [154.1931 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 125.28319549560547



action possibilites: [-1. 29.] 
expected returns: [[ 79.73293]
 [125.35578]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 154.1930694580078



action possibilites: [-1. 11.] 
expected returns: [[ 91.04762 ]
 [117.457726]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 125.35579681396484



action possibilites: [-1] 
expected returns: [[164.89165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.64295959472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[165.95842]
 [195.74643]
 [155.97139]
 [182.43498]
 [158.28851]
 [147.62346]
 [191.99933]
 [195.70007]
 [178.53806]
 [233.48166]
 [222.3583 ]
 [157.6872 ]
 [197.36641]
 [166.83688]
 [167.47588]
 [184.63634]
 [167.94678]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  6.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 164.8916473388672



buy possibilites: [-1] 
expected returns: [[196.70161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 317.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 233.48158264160156






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10. 25. 29. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  3.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10. 25. 29. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 3.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  3.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10. 25. 29. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [29.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 77.620766]
 [130.42227 ]
 [130.42227 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10. 25. 29. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  3.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 196.7016143798828



action possibilites: [-1. 29. 25.] 
expected returns: [[ 99.33546]
 [144.94997]
 [150.54448]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 25.] 
cards in discard: [29. 25.  0. 29.  1.  3. 25.  0. 10. 25. 29. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  3.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3] -> size -> 24 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.42222595214844



action possibilites: [-1] 
expected returns: [[91.526955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  2.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.54444885253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.14008 ]
 [102.47064 ]
 [ 94.29058 ]
 [ 76.91137 ]
 [ 70.36053 ]
 [ 98.79942 ]
 [103.13178 ]
 [ 91.598785]
 [132.8185  ]
 [123.19962 ]
 [ 76.87475 ]
 [102.96158 ]
 [ 83.79356 ]
 [ 83.58719 ]
 [ 95.76093 ]
 [ 83.79988 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 29. 30.  8.  2.  9.  9.  9.  5.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.5269546508789



buy possibilites: [-1] 
expected returns: [[55.07566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  1. 25.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  2.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 435 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 132.8184814453125






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [3. 6. 0. 0. 6. 3. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  2.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 25. 25.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [3. 6. 0. 0. 6. 3. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  2.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 25. 25.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [3. 6. 0. 0. 6. 3. 6. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  2.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 25. 25.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [25.  0.  3. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[ 72.15963]
 [124.71052]
 [124.71052]
 [124.71052]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 25. 25.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  2.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  6.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3. 6. 3. 0. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.075660705566406



action possibilites: [-1] 
expected returns: [[111.210106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 25. 10.  3.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  6.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3. 6. 3. 0. 3. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.71051788330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[106.90398]
 [ 78.89779]
 [115.07207]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 25. 10.  3.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  6.] 
adversary cards in discard: [3. 6. 0. 0. 6. 3. 6. 3. 0. 3. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6] -> size -> 27 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.2101058959961






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [29.  0.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  6.] 
cards in discard: [3. 6. 0. 0. 6. 3. 6. 3. 0. 3. 6. 0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  6.  0.] 
cards in discard: [3. 6. 0. 0. 6. 3. 6. 3. 0. 3. 6. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  6.  0.] 
cards in discard: [3. 6. 0. 0. 6. 3. 6. 3. 0. 3. 6. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  6.  0.] 
cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 29.  0.] 
adversary cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[188.8979 ]
 [224.70418]
 [249.146  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  0.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6. 14. 16.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 115.07207489013672



action possibilites: [-1. 11.] 
expected returns: [[214.47519]
 [250.94066]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  6. 14. 16.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 249.14598083496094



action possibilites: [-1] 
expected returns: [[287.88077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 14. 16.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 266.0302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[292.62915]
 [314.53415]
 [306.24048]
 [284.7921 ]
 [274.73926]
 [309.62552]
 [316.55118]
 [302.93985]
 [340.23923]
 [331.97482]
 [285.1673 ]
 [314.57098]
 [293.87738]
 [292.9274 ]
 [307.884  ]
 [296.55237]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  4.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 14. 16.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 287.8807678222656



buy possibilites: [-1] 
expected returns: [[301.28998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 29. 25.  3. 29.  0.  0.  1. 25. 25.  0.  3. 25. 25. 10.  3. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 14. 16.  6.] 
adversary cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 465 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 340.2392272949219






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 14. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14. 16.  6.] 
cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3
  6  3  6 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6.] 
cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.] 
cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.] 
cards in discard: [ 3.  6.  0.  0.  6.  3.  6.  3.  0.  3.  6.  0.  0.  6. 14. 29.  0.  0.
 29.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 0. 29. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[37.430275]
 [97.10205 ]
 [97.10205 ]
 [97.10205 ]
 [97.10205 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 301.28997802734375



action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[149.55917]
 [167.98354]
 [167.98354]
 [167.98354]
 [167.98354]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 95.18594360351562



action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[181.19226]
 [201.96489]
 [201.96489]
 [201.96489]
 [201.96489]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 167.98355102539062



action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[190.6816 ]
 [217.39952]
 [217.39952]
 [217.39952]
 [217.39952]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 201.9648895263672



action possibilites: [-1. 29. 29. 29. 11.] 
expected returns: [[291.2968 ]
 [325.69995]
 [325.69995]
 [325.69995]
 [311.52252]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 217.39952087402344



action possibilites: [-1. 29. 29. 11.] 
expected returns: [[327.9511 ]
 [359.62375]
 [359.62375]
 [344.06287]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 5 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 325.6999206542969



action possibilites: [-1. 29. 11. 25.] 
expected returns: [[336.77863]
 [380.0414 ]
 [358.7884 ]
 [388.42682]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 6 
card supply: [26. 29. 30. 28. 30.  8.  1.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0] -> size -> 29 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 359.62371826171875



action possibilites: [-1] 
expected returns: [[334.90054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 6 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 388.4268493652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[345.0827 ]
 [365.26483]
 [335.69113]
 [355.50867]
 [338.62598]
 [358.29828]
 [362.5182 ]
 [363.5716 ]
 [353.62665]
 [391.2094 ]
 [384.2777 ]
 [337.26843]
 [366.3423 ]
 [343.75735]
 [346.1601 ]
 [357.1035 ]
 [340.1666 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  3.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 334.9005432128906



buy possibilites: [-1] 
expected returns: [[208.71924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.  0. 25.  3.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.  140.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 377.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 391.2094421386719






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 15.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0. 25.  0. 10.] 
adversary cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25] -> size -> 29 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  3. 15.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0. 25.  0. 10.] 
adversary cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25] -> size -> 29 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
expected returns: [[273.351  ]
 [266.62244]
 [351.61908]
 [266.62244]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.  0. 10.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 14.  0.  6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 208.71923828125



action possibilites: [-1] 
expected returns: [[275.95624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  3.  3.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 14.  0.  6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 351.6190490722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[262.5803 ]
 [290.23438]
 [282.53445]
 [280.80252]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.  3.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 14.  0.  6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 275.95623779296875



buy possibilites: [-1] 
expected returns: [[329.89197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.  3.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 14.  0.  6.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 290.23443603515625






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [16.  0. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 14.  0.  6.] 
cards in discard: [ 6.  3.  0.  6.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 25. 25.] 
adversary cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  6.] 
cards in discard: [ 6.  3.  0.  6.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25. 25.] 
adversary cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  6.] 
cards in discard: [ 6.  3.  0.  6.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25. 25.] 
adversary cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [ 1. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 69.35339]
 [143.36041]
 [143.36041]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 200.26339721679688



action possibilites: [-1] 
expected returns: [[82.89486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 25.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 143.36041259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[84.691795]
 [96.94657 ]
 [94.12331 ]
 [85.03063 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25. 25.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.89485931396484



buy possibilites: [-1] 
expected returns: [[145.05997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25. 25.] 
cards in discard: [25. 29. 29. 29. 29. 29. 29. 25.  0. 29. 11.  0. 25.  3.  3. 25. 10.  0.
  0. 10.  3.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 96.94658660888672






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [29.  6.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  0.  3.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 0.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[142.94104]
 [192.08504]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 145.05996704101562



action possibilites: [-1] 
expected returns: [[197.45503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 192.0850372314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[187.24321]
 [197.30112]
 [193.03021]
 [194.39304]
 [199.24927]
 [191.41472]
 [212.90785]
 [186.8736 ]
 [189.6006 ]
 [193.72891]
 [197.30836]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  1.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.4550323486328



buy possibilites: [-1] 
expected returns: [[152.42165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0. 25.] 
cards in discard: [29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 212.90780639648438






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [29.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  0.  0.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 29. 29. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 29. 29. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 29. 29. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3. 29. 29. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [25.  3. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 25.] 
expected returns: [[173.63562]
 [224.528  ]
 [216.4386 ]
 [216.4386 ]
 [224.528  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29. 29. 25.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 152.42164611816406



action possibilites: [-1] 
expected returns: [[135.99281]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 25. 25. 29.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 224.5279998779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[140.76244]
 [135.90108]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29. 25. 25. 29.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.99281311035156



buy possibilites: [-1] 
expected returns: [[169.94402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29. 25. 25. 29.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3. 14.  6.  3.] 
adversary cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 140.76246643066406






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6.  3. 14.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.  6.  3.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0. 29.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0] -> size -> 33 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 14.  6.  3.] 
cards in discard: [ 6.  3.  0.  6.  3. 15. 14. 16.  0.  0.  6.  3.  1. 29.  6.  0.  0.  6.
  0.  0.  0. 29.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0] -> size -> 33 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  3.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[238.4391 ]
 [282.52136]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 29.  0.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.9440155029297



action possibilites: [-1.] 
expected returns: [[240.07503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 259.3734436035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[246.69748]
 [270.22156]
 [259.37335]
 [268.28464]
 [256.84723]
 [245.15492]
 [241.71158]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 240.0750274658203



buy possibilites: [-1] 
expected returns: [[272.2525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 270.2215881347656






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25. 10. 29.  0. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25. 10. 29.  0. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25. 10. 29.  0. 25.] 
adversary cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [25. 10. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29. 25.] 
expected returns: [[ 92.38486]
 [154.25726]
 [ 91.47212]
 [143.38087]
 [154.25726]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29.  0. 25.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1. 29.  3.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 272.25250244140625



action possibilites: [-1] 
expected returns: [[162.52594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 25.  3. 10.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1. 29.  3.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.2572784423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[156.04282]
 [159.77502]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 25.  3. 10.] 
cards in discard: [29. 25.  0.  3.  0.  0.  0. 25.  0. 25.  3. 29. 29. 25. 25. 29.  0.  0.
  1. 29.  3.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 162.52593994140625






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [1. 0. 0. 6. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29. 25. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [1. 0. 0. 6. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29. 25. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29. 25. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [29. 29. 25. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 29. 11.] 
expected returns: [[227.61609]
 [271.09857]
 [271.09857]
 [279.43048]
 [271.09857]
 [252.15282]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 29. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 6.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 159.77500915527344



action possibilites: [-1] 
expected returns: [[138.0979]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 11. 25.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 6.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 279.43048095703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[142.87843]
 [140.40297]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 11. 25.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 6.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.097900390625



buy possibilites: [-1] 
expected returns: [[77.25524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 11. 25.  0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 6.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 270.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 285.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 142.87843322753906






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [3. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 6.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 6.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 6.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [25.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [25.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[267.84393]
 [335.1387 ]
 [264.35675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10.  0.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  3.  1.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.25524139404297



action possibilites: [-1] 
expected returns: [[169.9762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 25.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  3.  1.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 335.1387023925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[160.46674]
 [182.43651]
 [176.30954]
 [175.07458]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 25.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 26. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  3.  1.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 169.9761962890625



buy possibilites: [-1] 
expected returns: [[338.49176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3. 25.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  3.  1.] 
adversary cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 182.4364776611328






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 15.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  3.  1.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29. 10.  0.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  3.  1.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29. 10.  0.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  3.  1.] 
cards in discard: [1. 0. 0. 6. 0. 6. 0. 6. 6. 3. 0. 0. 0. 3. 6. 0. 3. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 29. 10.  0.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [ 1. 29. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[152.92851]
 [204.02162]
 [149.61372]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10.  0.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16. 14. 29. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 338.49176025390625



action possibilites: [-1. 10.] 
expected returns: [[189.09465]
 [184.61592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16. 14. 29. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 174.76638793945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[176.37341]
 [214.01785]
 [198.8249 ]
 [206.50429]
 [215.96744]
 [193.426  ]
 [164.89948]
 [179.06268]
 [201.6082 ]
 [184.28049]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  9.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16. 14. 29. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 189.09461975097656



buy possibilites: [-1] 
expected returns: [[245.7419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16. 14. 29. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   20.    0.    0.    0.    0.  -20.
   0.    0.   13.5   0. ] 
sum of rewards: 278.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 215.9674530029297






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [16. 14. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 29. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14. 29. 29.  0.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25.  0. 25.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 29.  0.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 29.  0.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 29.  0.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [ 0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[237.61856]
 [302.8512 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1. 14. 16. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1] -> size -> 37 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  270    0    0    0    0    0    0    0  -20    0    0
 1492    0] 
sum of rewards: 1737 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 76.4766845703125



action possibilites: [-1] 
expected returns: [[209.11641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1. 14. 16. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1] -> size -> 37 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 302.8512268066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[201.24336]
 [211.14967]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 6. 0. 3.] 
adversary cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1. 14. 16. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1] -> size -> 37 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 209.1164093017578






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1. 14. 16. 29. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1. 14. 16. 29. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 24. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 3.] 
cards in discard: [ 1.  0.  0.  6.  0.  6.  0.  6.  6.  3.  0.  0.  0.  3.  6.  0.  3.  6.
  3.  0.  6. 15.  3.  1.  1. 14. 16. 29. 29.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [29.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[117.61282]
 [170.77702]
 [170.77702]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 29.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 211.1497344970703



action possibilites: [-1. 29.] 
expected returns: [[135.47646]
 [168.17097]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 145.27456665039062



action possibilites: [-1.] 
expected returns: [[144.7664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.  0. 29.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 149.34393310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[132.06142]
 [163.78499]
 [155.18828]
 [170.89758]
 [148.92166]
 [137.59703]
 [144.76643]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.  0. 29.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  8.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 144.7664031982422



buy possibilites: [-1] 
expected returns: [[101.689156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 25. 29. 29. 29. 11. 25.  0.  3. 25.  0. 10.  0.  3. 25.  3.  0. 25.
 11. 29.  1. 10.  0.  1. 25. 25.  0.  3. 29.  3.  0. 29.  3. 25. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 299 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 170.8975067138672






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 25. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 25. 11.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
adversary victory points: 6
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[313.77487]
 [399.87418]
 [351.1178 ]
 [386.02902]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.68915557861328



action possibilites: [-1] 
expected returns: [[306.503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29. 11. 25.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 399.87420654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[303.42007]
 [307.95828]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29. 11. 25.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 306.50299072265625






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0.  0.] 
cards in discard: [ 1.  0.  3.  0. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  6  0  6  6  6  6 14  6 15  3  6
  3  6 14  0  0  6  1  0  1  0  0  3  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 25.  3.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 25.  3.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 25.  3.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 25.  3.  0.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [29.  3. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[241.17642]
 [276.00665]
 [290.86267]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25.  3.  0.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 307.958251953125



action possibilites: [-1] 
expected returns: [[317.30792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  0. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 290.8626708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[315.17346]
 [328.8213 ]
 [325.27222]
 [327.9251 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  0. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 23. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 317.30792236328125



buy possibilites: [-1] 
expected returns: [[210.73407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  0. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 14.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 231 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 328.8212890625






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  0.  0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 25. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 7 
card supply: [19. 25. 30. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29. 25. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[153.4005 ]
 [193.27113]
 [203.83614]
 [193.27113]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 29.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 98.83055114746094



action possibilites: [-1] 
expected returns: [[226.51807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 29.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 203.8361358642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[212.29585]
 [226.11946]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 10.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 29.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 226.51806640625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  6.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  3. 29.  0.  1.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [29.  3. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[144.8069 ]
 [192.15309]
 [192.15309]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  1.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 226.11944580078125



action possibilites: [-1. 29.] 
expected returns: [[143.44258]
 [187.25046]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 181.66766357421875



action possibilites: [-1.] 
expected returns: [[236.79927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 160.56764221191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[244.42696]
 [266.0365 ]
 [261.0905 ]
 [237.35246]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3] -> size -> 39 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 25. 29. 22. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 236.7992706298828



buy possibilites: [-1] 
expected returns: [[158.31848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 6. 3. 0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 266.0364990234375






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [25. 25.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[42.773495]
 [84.449615]
 [84.449615]
 [73.395355]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0. 29.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  6.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 158.3184814453125



action possibilites: [-1] 
expected returns: [[108.75291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.  0.  1.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  6.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.44960021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 91.98489 ]
 [119.747604]
 [111.17798 ]
 [ 82.07728 ]
 [112.40472 ]
 [125.47875 ]
 [105.713646]
 [154.26219 ]
 [ 85.74376 ]
 [118.561295]
 [ 98.86061 ]
 [ 91.263756]
 [113.066376]
 [108.75291 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29.  0.  1.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  2.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  6.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.7529067993164



buy possibilites: [-1] 
expected returns: [[48.136124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29.  0.  1.] 
cards in discard: [25.  3. 11.  0. 29. 11. 25.  3. 25. 29.  3.  3.  0.  0. 29.  0. 10. 25.
 29. 29.  0. 10.  1.  3.  0. 25.  3. 29. 29.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  6.  0.  6.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -60   0   0 250   0] 
sum of rewards: 475 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 154.26217651367188






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [15.  3.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  0.  6.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1. 25.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  0.  6.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1. 25.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  0.  6.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1. 25.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
adversary victory points: 8
player victory points: -1 





Player: 0 
cards in hand: [ 3.  1. 25.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[151.69254]
 [196.47215]
 [171.12172]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  3. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  6. 29.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.13612365722656



action possibilites: [-1] 
expected returns: [[241.32793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  6. 29.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 196.47218322753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[250.68971]
 [267.52795]
 [264.39404]
 [243.32034]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 29. 21. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  6. 29.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 241.3279266357422



buy possibilites: [-1] 
expected returns: [[150.72847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 11. 29. 29.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  6. 29.  0.] 
adversary cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 267.5278625488281






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 29.  0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3. 10. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 29.  0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3. 10. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 29.  0.] 
cards in discard: [ 1.  0.  3.  0. 14.  0.  0. 16.  3.  0.  0.  2. 14.  1.  0.  0.  0.  6.
  3. 15. 29.  1.  0.  0.  0.  0.  6.  6.  3.  0.  0. 15.  3.  6.  0.  6.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3. 10. 11. 11.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [25.  3. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 11.] 
expected returns: [[128.10765]
 [177.34367]
 [119.5045 ]
 [145.935  ]
 [145.935  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 10. 11. 11.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 1. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0] -> size -> 44 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.7284698486328



action possibilites: [-1] 
expected returns: [[278.79337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11.  0.  3.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 1. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0] -> size -> 44 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 177.3436279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[271.72644]
 [278.8705 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 11.  0.  3.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [3. 0. 1. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0] -> size -> 44 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 278.7933654785156






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 6.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 6.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  7.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 6.] 
cards in discard: [11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 25.  0.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
adversary victory points: 9
player victory points: -1 





Player: 0 
cards in hand: [ 0. 25.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[186.15321]
 [231.29274]
 [231.29274]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 25.  0.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 278.87054443359375



action possibilites: [-1] 
expected returns: [[303.84705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0.  3. 25.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 231.29270935058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[282.65173]
 [305.64478]
 [299.14243]
 [305.51468]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  3. 25.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 29. 20. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 303.8470458984375



buy possibilites: [-1] 
expected returns: [[147.25636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  3. 25.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 281 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 305.64471435546875






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0. 29.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0. 29.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0. 29.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
adversary victory points: 10
player victory points: -1 





Player: 0 
cards in hand: [10.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[135.82904]
 [126.79545]
 [204.31114]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 29.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.25636291503906



action possibilites: [-1. 10.] 
expected returns: [[312.91333]
 [314.56894]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 163.74461364746094



action possibilites: [-1. 25.] 
expected returns: [[254.13484]
 [362.3147 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 2 
buys: 0 
player value: 1 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 314.56903076171875



action possibilites: [-1. 29.] 
expected returns: [[220.78853]
 [259.6761 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 362.3147277832031



action possibilites: [-1.] 
expected returns: [[298.25964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10. 25. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 235.7318878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[282.66312]
 [326.0696 ]
 [312.5658 ]
 [313.49973]
 [334.2839 ]
 [304.38126]
 [271.4613 ]
 [290.87747]
 [315.48395]
 [298.2596 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10. 25. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  6.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 298.2596435546875



buy possibilites: [-1] 
expected returns: [[352.4737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10. 25. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3. 15. 29.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5.    0.    0.  330.    0.    0.   80.    0.    0.    0.    0.  -90.
   0.    0.   13.5   0. ] 
sum of rewards: 328.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 334.283935546875






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [15.  3. 15. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15. 29.  0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3
  6 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29. 25.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29. 25.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 29.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29. 25.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 29.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29. 25.] 
adversary cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
adversary victory points: 10
player victory points: -1 





Player: 0 
cards in hand: [ 0. 25.  1. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 74.90688]
 [136.75221]
 [119.34269]
 [136.75221]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 29. 25.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 352.47369384765625



action possibilites: [-1] 
expected returns: [[66.957054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 25. 25. 29.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.75225830078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[64.99252]
 [72.15557]
 [69.63923]
 [74.13204]
 [68.0283 ]
 [65.67496]
 [66.95706]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 25. 25. 29.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  5.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.9570541381836



buy possibilites: [-1] 
expected returns: [[96.74862]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 25. 25. 29.] 
cards in discard: [ 3. 25.  3.  1.  3. 11. 29. 29. 25.  3. 10. 11. 11.  0.  3.  3. 25.  0.
  3. 25.  0.  3. 25.  0. 29.  3.  0. 11. 29. 10. 25. 29.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: 299 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 74.13202667236328






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
adversary victory points: 10
player victory points: -1 





Player: 0 
cards in hand: [ 3.  1.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[275.77994]
 [335.65924]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.74861907958984



action possibilites: [-1.] 
expected returns: [[264.97937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [0. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 307.8933410644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[256.5671 ]
 [285.15497]
 [275.13065]
 [289.55484]
 [270.03876]
 [260.2695 ]
 [264.6854 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [0. 3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  4.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 264.9793701171875



buy possibilites: [-1] 
expected returns: [[346.45328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 0.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -110    0    0
   54    0] 
sum of rewards: 289 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 289.5548095703125






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29. 11.  1. 29. 25.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  9.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29. 11.  1. 29. 25.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29. 11.  1. 29. 25.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
adversary victory points: 10
player victory points: -1 





Player: 0 
cards in hand: [29. 11.  1. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 25.] 
expected returns: [[253.75575]
 [283.76608]
 [270.9444 ]
 [283.76608]
 [288.9073 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  1. 29. 25.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 346.4532775878906



action possibilites: [-1] 
expected returns: [[158.28923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  1. 29.  3. 10.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 288.9072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[145.02498]
 [171.0415 ]
 [164.16942]
 [156.8152 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  1. 29.  3. 10.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 19. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.2892303466797



buy possibilites: [-1] 
expected returns: [[199.66264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  1. 29.  3. 10.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 18. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -120    0    0
   16    0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 171.04151916503906






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [6. 1. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 6.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 18. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  0.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3] -> size -> 47 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 6.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 29. 18. 30.  8.  0.  9.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  0.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3] -> size -> 47 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 6.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 18. 30.  8.  0.  8.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  0.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3] -> size -> 47 
adversary victory points: 11
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[325.02557]
 [382.16937]
 [354.4391 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  0.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 18. 30.  8.  0.  8.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29. 14.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 199.6626434326172



action possibilites: [-1. 11.] 
expected returns: [[243.36523]
 [267.50217]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 18. 30.  8.  0.  8.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29. 14.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 351.88201904296875



action possibilites: [-1] 
expected returns: [[313.92795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 18. 30.  8.  0.  8.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29. 14.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 292 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 260.1916198730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[294.6399 ]
 [323.663  ]
 [317.20377]
 [333.22992]
 [310.32803]
 [303.8688 ]
 [316.10205]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 29. 18. 30.  8.  0.  8.  3.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29. 14.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 313.9279479980469



buy possibilites: [-1] 
expected returns: [[320.76288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  8.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1. 29. 14.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -140    0    0
   54    0] 
sum of rewards: 309 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 333.22991943359375






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 14.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  8.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0. 25. 11. 29.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 14.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 18. 30.  8.  0.  8.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0. 25. 11. 29.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 14.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0. 25. 11. 29.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 





Player: 0 
cards in hand: [29.  0. 25. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11. 29.] 
expected returns: [[ 95.465065]
 [122.04616 ]
 [136.70856 ]
 [108.33607 ]
 [122.04616 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 11. 29.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 2. 0. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.
  0.  0.  1. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16] -> size -> 50 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 320.76287841796875



action possibilites: [-1] 
expected returns: [[240.26836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 29.  3.  3.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 2. 0. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.
  0.  0.  1. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16] -> size -> 50 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.70860290527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[218.21028]
 [240.26834]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11. 29.  3.  3.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 6. 2. 0. 0.] 
adversary cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.
  0.  0.  1. 29. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16] -> size -> 50 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 240.2683563232422






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 6. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 2. 0. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.
  0.  0.  1. 29. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3. 25. 25. 25.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 2. 0. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.
  0.  0.  1. 29. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  2.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3. 25. 25. 25.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 2. 0. 0.] 
cards in discard: [11.  3.  0.  1.  3.  6.  1.  6.  0.  0.  3.  0.  0. 15.  3. 15. 29.  0.
  3. 14.  6.  0.  0.  8.  0.  3.  0.  6.  0. 16.  6.  1.  0.  0.  6. 16.
  0.  0.  1. 29. 14. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [11.  3. 25. 25. 25.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 





Player: 0 
cards in hand: [11.  3. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 25.] 
expected returns: [[147.69829]
 [161.2173 ]
 [182.80028]
 [182.80028]
 [182.80028]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25. 25. 25.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 240.2683563232422



action possibilites: [-1] 
expected returns: [[182.61343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25. 25.  0. 29.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 182.8002471923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[168.12163]
 [182.61346]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 25. 25.  0. 29.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.61343383789062






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25. 25. 25.  0.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25. 25. 25.  0.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 25. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 25.] 
expected returns: [[111.16436]
 [145.09995]
 [145.09995]
 [145.09995]
 [145.09995]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 25.  0.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  6. 29.] 
adversary cards in discard: [ 0. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 182.61343383789062



action possibilites: [-1] 
expected returns: [[213.7015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  0.  3.  3.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  6. 29.] 
adversary cards in discard: [ 0. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.0999298095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[184.40842]
 [213.7015 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 25.  0.  3.  3.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  6. 29.] 
adversary cards in discard: [ 0. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 213.70150756835938






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  6. 29.] 
cards in discard: [ 0. 16.  0.  3.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  0.  3.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29. 25. 25. 25. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  6. 29.] 
cards in discard: [ 0. 16.  0.  3.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  0.  3.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29. 25. 25. 25. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  6. 29.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 11. 29.  0.  3.] 
adversary cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29. 25. 25. 25. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
adversary victory points: 11
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[132.62183]
 [164.32114]
 [193.01654]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0.  3.] 
cards in discard: [ 0.  3. 11. 29.  1.  3.  3.  3. 25. 29. 11.  1. 29.  3. 10.  0. 10.  1.
 11. 29. 11.  0.  0. 25. 29.  0. 11. 29.  3.  3. 25. 11.  3. 25. 25.  0.
 29. 25. 25. 25. 25.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  6.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 213.70150756835938



action possibilites: [-1. 11. 25.] 
expected returns: [[255.37987]
 [277.02872]
 [307.5379 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25.] 
cards in discard: [0. 0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  6.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 160.68617248535156



action possibilites: [-1] 
expected returns: [[211.6125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.] 
cards in discard: [0. 0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  6.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 307.53790283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[206.23572]
 [219.8618 ]
 [216.26093]
 [212.51581]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  0.] 
cards in discard: [0. 0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 29. 18. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  6.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
adversary victory points: -1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 211.6125030517578



buy possibilites: [-1] 
expected returns: [[200.83385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  0.] 
cards in discard: [0. 0. 3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  6.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   40    0    0    0    0 -150    0    0
   16    0] 
sum of rewards: 291 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 219.86178588867188






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [15. 29.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.  6.  0.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6
 14  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8
 16 16 11 14] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
adversary victory points: 12
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  7. 10.  8. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14.] 
cards in deck: 36 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
adversary victory points: 12
player victory points: -1 





Player: 0 
cards in hand: [11. 25. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 29. 29.] 
expected returns: [[239.16942]
 [266.64432]
 [302.40857]
 [302.40857]
 [289.72427]
 [289.72427]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25. 29. 29.] 
cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14. 15. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14] -> size -> 52 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 200.83384704589844



action possibilites: [-1] 
expected returns: [[269.33624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29. 29. 11.  0.] 
cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14. 15. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14] -> size -> 52 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 302.40863037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[248.47647]
 [270.03812]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25. 29. 29. 11.  0.] 
cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14. 15. 29.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14] -> size -> 52 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 269.33624267578125






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 14.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14. 15. 29.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [29. 29. 10. 25. 29.] 
adversary cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0. 25. 11. 25. 29. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 14.] 
cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14. 15. 29.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  1.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [29. 29. 10. 25. 29.] 
adversary cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0. 25. 11. 25. 29. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
adversary victory points: 12
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 2 
Silver: 2 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 0 
Witch: 9 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 29. 10. 25. 29.] 
cards in discard: [ 0.  0.  3. 29. 25. 11.  3. 11.  0. 25. 11. 25. 29. 29. 11.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 25 29 29 29 29 25 25 29 25 11 29 10
 25 25 10 25 25  3  3 29  0  1  0  3 11 11  3  3 25  3  3 11 11 11  3  1
 11  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 17. 30.  8.  0.  7.  0.  8.  1.  0.  6. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3.  1.  0. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  6. 14.  0.  0.  1.  6. 29. 14. 15. 29.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 16 29 29  0  6  6  6  6 14  6 15  3  6  3  6 14
  0  0  6  1  0  1  0  0  3  1  3  0  0  2 15  0  0  0 11  1  0  0  8 16
 16 11 14 14 11] -> size -> 53 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[     -5 3000000       0     390       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000385 

action type: buy - action -1.0
Learning step: 300011.5
desired expected reward: 300281.53125



