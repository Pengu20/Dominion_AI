 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.774134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[   -5  -500     0     0     0     0     0     0     0     0     0    -8
     0 -1800    36     0] 
sum of rewards: -2277 

action type: discard_down_to_3_cards - action 8
Learning step: -68.861083984375
desired expected reward: -50.49138259887695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.972275]
 [22.858747]
 [22.585854]
 [21.017723]
 [24.186361]
 [23.572786]
 [23.299889]
 [24.057775]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6319855451583862
desired expected reward: 23.551546096801758



buy possibilites: [-1] 
expected returns: [[24.377161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.07963068038225174
desired expected reward: 24.106733322143555






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.792925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6079747676849365
desired expected reward: 23.76918601989746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.535406]
 [25.42188 ]
 [25.148985]
 [23.58085 ]
 [24.95932 ]
 [26.749495]
 [26.135916]
 [26.763762]
 [25.180475]
 [25.86302 ]
 [26.06695 ]
 [26.620905]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6598489284515381
desired expected reward: 25.372539520263672



buy possibilites: [-1] 
expected returns: [[25.805367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6151058673858643
desired expected reward: 23.92030143737793






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.1524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6466443538665771
desired expected reward: 25.158721923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.355358]
 [25.241833]
 [24.968935]
 [23.400806]
 [24.779272]
 [26.569445]
 [25.955868]
 [26.583715]
 [25.000427]
 [25.682974]
 [25.886902]
 [26.440859]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6736724972724915
desired expected reward: 25.756486892700195



buy possibilites: [-1] 
expected returns: [[25.273663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.5068814754486084
desired expected reward: 24.73495101928711






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3. 10.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.015446]
 [25.144032]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.643349289894104
desired expected reward: 24.630313873291016



action possibilites: [-1] 
expected returns: [[26.318714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.22788424789905548
desired expected reward: 25.843290328979492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.70421 ]
 [25.590685]
 [25.31779 ]
 [23.749657]
 [26.9183  ]
 [26.304724]
 [26.031826]
 [26.789711]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06735580414533615
desired expected reward: 26.251358032226562



buy possibilites: [-1] 
expected returns: [[25.666416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.451948344707489
desired expected reward: 27.370248794555664






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[25.20886 ]
 [25.337448]
 [24.45097 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6547142863273621
desired expected reward: 25.011701583862305



action possibilites: [-1] 
expected returns: [[24.78529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.4517606198787689
desired expected reward: 25.361671447753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.120785]
 [23.719837]
 [22.181799]
 [24.695824]
 [25.157484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.04101676866412163
desired expected reward: 24.744272232055664






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.386961]
 [23.524355]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [14. 11.  0. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6570760607719421
desired expected reward: 24.50040626525879



action possibilites: [-1] 
expected returns: [[26.712284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [14. 11.  0. 10.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.2832964360713959
desired expected reward: 24.189382553100586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.739702]
 [25.610073]
 [25.338758]
 [23.80072 ]
 [26.9138  ]
 [26.314743]
 [26.043425]
 [26.776403]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [14. 11.  0. 10.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07903507351875305
desired expected reward: 26.633249282836914



buy possibilites: [-1] 
expected returns: [[27.678707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [14. 11.  0. 10.  0.  3. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.47321251034736633
desired expected reward: 27.387008666992188






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.130093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7468554973602295
desired expected reward: 26.931852340698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.599014]
 [21.459366]
 [21.19118 ]
 [19.933142]
 [19.670832]
 [21.009443]
 [22.749426]
 [22.15592 ]
 [23.435965]
 [22.762352]
 [21.221863]
 [20.935734]
 [21.887732]
 [20.075386]
 [22.082209]
 [22.612255]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5874581336975098
desired expected reward: 21.651180267333984



buy possibilites: [-1] 
expected returns: [[25.38572]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [14. 11.  0. 10.  0.  3. 10. 11. 11.  0.  0.  3.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 15.0
Learning step: -0.3059162497520447
desired expected reward: 21.776294708251953






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 10.  3.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 10.  3.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15] -> size -> 19 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.525349]
 [24.662743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.651725709438324
desired expected reward: 24.733993530273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.865746]
 [23.736115]
 [23.464798]
 [22.192133]
 [21.92676 ]
 [23.280966]
 [25.039839]
 [24.440784]
 [25.72638 ]
 [25.052765]
 [23.495853]
 [23.206408]
 [24.169466]
 [22.336035]
 [24.366226]
 [24.902445]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7. 10. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6363117694854736
desired expected reward: 24.028474807739258



buy possibilites: [-1] 
expected returns: [[25.376677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5567684173583984
desired expected reward: 23.884016036987305






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [10. 10.  3.  0.  0.  0.  3.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  9. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [15.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[24.06736]
 [23.53114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 10.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6597399711608887
desired expected reward: 24.716936111450195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.36062 ]
 [22.959677]
 [21.421637]
 [23.935661]
 [24.397318]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 10.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6306180953979492
desired expected reward: 23.5419921875



buy possibilites: [-1] 
expected returns: [[22.561298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 10.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.3618966042995453
desired expected reward: 22.5977783203125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 10.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0. 10. 10. 11.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0. 10. 10. 11.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [14.  0. 10. 10. 11.] 
adversary cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3] -> size -> 21 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [14.  0. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10. 11.] 
expected returns: [[22.533264]
 [21.12667 ]
 [21.80029 ]
 [21.80029 ]
 [22.670658]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10. 10. 11.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5935813784599304
desired expected reward: 21.967716217041016



action possibilites: [-1. 14. 10. 11.] 
expected returns: [[23.304968]
 [21.918104]
 [22.592154]
 [23.458147]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10. 11.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.04308631643652916
desired expected reward: 21.63808250427246



action possibilites: [-1. 14. 10.] 
expected returns: [[29.61897 ]
 [28.232107]
 [28.906155]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 4
Learning step: 1.216533899307251
desired expected reward: 21.836069107055664



action possibilites: [-1] 
expected returns: [[34.835552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 14.0
Learning step: 1.168810248374939
desired expected reward: 29.40091323852539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.04439 ]
 [33.910385]
 [33.637608]
 [32.10894 ]
 [33.45503 ]
 [35.207108]
 [34.613888]
 [35.216473]
 [33.667065]
 [34.341114]
 [34.533062]
 [35.05393 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  9. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0.9650403261184692
desired expected reward: 35.800594329833984



buy possibilites: [-1] 
expected returns: [[34.61151]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 8.  0.  1.  0. 11.  0.  3. 15.  0.  3.  3.  0. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 3.] 
adversary cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 60.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 57.0 

action type: buy - action 8.0
Learning step: 1.0350041389465332
desired expected reward: 35.648895263671875






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 16.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [14. 10.  0.  0.  0.  0.  0. 10.  3.  0.  0. 10.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 16.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 16.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 11.] 
expected returns: [[27.379974]
 [26.667158]
 [25.781069]
 [27.533152]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9044219851493835
desired expected reward: 33.707088470458984



action possibilites: [-1] 
expected returns: [[30.698526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.20633308589458466
desired expected reward: 28.073047637939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.708128]
 [27.77268 ]
 [30.71767 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1622929573059082
desired expected reward: 30.53623390197754






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  1.  0.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  1.  0.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  4. 10.  9.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8. 10.  4. 10.  9.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [23.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[27.678738]
 [26.965925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 76  0] 
sum of rewards: 71 

action type: discard_down_to_3_cards - action 9
Learning step: 1.6588410139083862
desired expected reward: 26.990633010864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.930246]
 [26.796242]
 [26.52347 ]
 [24.994802]
 [28.092968]
 [27.499748]
 [27.226976]
 [27.939789]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6989321708679199
desired expected reward: 27.090463638305664



buy possibilites: [-1] 
expected returns: [[25.36643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  3.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.16046178340911865
desired expected reward: 27.06651496887207






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  3.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  8. 11.  8.  3.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  8. 11.  8.  3.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  8. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  8. 11.  8.  3.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  7. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [14.  8. 11.  8.  3.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [14.  8. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.  8.] 
expected returns: [[24.324247]
 [22.98987 ]
 [23.900888]
 [24.471678]
 [23.900888]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 11.  8.  3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  7. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6582104563713074
desired expected reward: 24.708219528198242



action possibilites: [-1] 
expected returns: [[26.71872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  7. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.04234680160880089
desired expected reward: 23.078384399414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.956   ]
 [25.541689]
 [24.030222]
 [26.520395]
 [26.933178]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  7. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07999299466609955
desired expected reward: 26.63872718811035



buy possibilites: [-1] 
expected returns: [[26.533316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  6. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.1729879081249237
desired expected reward: 26.693382263183594






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  6. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8] -> size -> 26 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  6. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8] -> size -> 26 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  7.  6. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8] -> size -> 26 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [23. 10. 14.  0.  0.  0.  0.  8. 10.  3.  0.  3.  3.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  6.  6. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8] -> size -> 26 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.619192]
 [23.7921  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  6.  6. 10. 10.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6969085931777954
desired expected reward: 25.836406707763672



action possibilites: [-1] 
expected returns: [[26.1901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  6.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.27295273542404175
desired expected reward: 24.341062545776367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.543343]
 [25.405043]
 [25.129036]
 [23.610426]
 [26.693434]
 [26.10774 ]
 [25.83173 ]
 [26.520523]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  6.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06561338156461716
desired expected reward: 26.124486923217773



buy possibilites: [-1] 
expected returns: [[25.329004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11. 10. 16.  3.  0.  3. 15. 10. 10.  1.  0.  8. 14.  8. 11.  8.  3.
 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.4551514983177185
desired expected reward: 27.148584365844727






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[30.336662]
 [29.64787 ]
 [29.64787 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  3.  0.  0. 10.] 
adversary cards in discard: [ 1. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5939803719520569
desired expected reward: 24.735023498535156



action possibilites: [-1. 10.] 
expected returns: [[31.581415]
 [30.892622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  3.  0.  0. 10.] 
adversary cards in discard: [ 1. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.11418691277503967
desired expected reward: 29.649106979370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.178652]
 [31.040352]
 [30.764343]
 [29.245728]
 [30.58397 ]
 [32.328743]
 [31.74305 ]
 [32.335617]
 [30.792587]
 [31.467037]
 [31.654291]
 [32.155834]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  3.  0.  0. 10.] 
adversary cards in discard: [ 1. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.16753451526165009
desired expected reward: 31.413881301879883






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [23.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0. 10.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0. 10.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0.  0.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
action values: 3 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1] -> size -> 22 
action values: 0 
buys: 2 
player value: 5 
card supply: [26. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 


buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8. 16.  3. 11. 14.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 8. 16.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11. 14.] 
expected returns: [[26.326809]
 [25.914026]
 [24.754946]
 [26.499718]
 [24.963566]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3. 11. 14.] 
cards in discard: [10. 10.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10. 10. 10. 23.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8431527018547058
desired expected reward: 31.31267738342285



action possibilites: [-1] 
expected returns: [[31.430712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3. 14.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10. 10. 10. 23.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.17765767872333527
desired expected reward: 24.25648307800293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.523125]
 [28.590204]
 [31.500307]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3. 14.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10. 10. 10. 23.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10] -> size -> 24 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.17585249245166779
desired expected reward: 31.254859924316406






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10. 10. 10. 23.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [11. 15.  0.  1.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3] -> size -> 29 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10. 10. 10. 23.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [11. 15.  0.  1.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3] -> size -> 29 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [ 1. 11.  0.  0.  0. 10.  0. 10. 10. 10. 23.  3.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [11. 15.  0.  1.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3] -> size -> 29 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [11. 15.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[25.696896]
 [25.865278]
 [25.20859 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  1.  3.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.82573401927948
desired expected reward: 30.67457389831543



action possibilites: [-1] 
expected returns: [[24.564287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  3.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.18858414888381958
desired expected reward: 26.49994468688965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[22.751839]
 [23.61386 ]
 [23.332623]
 [21.81603 ]
 [24.901392]
 [24.32061 ]
 [24.706163]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  3.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  5.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.036104679107666016
desired expected reward: 24.528182983398438



buy possibilites: [-1] 
expected returns: [[25.314795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  3.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  4.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.5087635517120361
desired expected reward: 25.410158157348633






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  4.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  3. 10.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  4.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  4.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[23.452206]
 [22.785418]
 [22.785418]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0] 
sum of rewards: 93 

action type: discard_down_to_3_cards - action 3
Learning step: 2.281511068344116
desired expected reward: 27.314939498901367



action possibilites: [-1. 10.  8.] 
expected returns: [[23.51303 ]
 [22.84624 ]
 [23.127478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.010377731174230576
desired expected reward: 22.795795440673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.490057]
 [20.553478]
 [23.444384]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.022791538387537003
desired expected reward: 23.490238189697266






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [11. 14.  1.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [11. 14.  1.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3. 10. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[25.687532]
 [25.30198 ]
 [25.882763]
 [25.882763]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 11.  0.  0.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3. 10. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  9.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 11.  0.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5831920504570007
desired expected reward: 22.861186981201172



action possibilites: [-1] 
expected returns: [[26.454672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3. 10. 10.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 11.  0.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.5161563754081726
desired expected reward: 23.570079803466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.566904]
 [25.125677]
 [23.66583 ]
 [26.076187]
 [26.447088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0.  0.] 
cards in discard: [10. 10.  0.  0.  0.  0.  3. 11.  8. 16.  3. 14. 10. 11. 11. 15.  0.  1.
  3.  3.  3. 10. 10.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10. 11.  0.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07662002742290497
desired expected reward: 26.3780517578125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  6. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  5. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  5. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0. 16. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
expected returns: [[30.597528]
 [29.045416]
 [29.93074 ]
 [29.93074 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  1. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  1 10 11 14 10 11 15  8  3 16  8 10
 10  8 10 11  3 10 11 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10. 10.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6281984448432922
desired expected reward: 25.81888771057129



action possibilites: [-1] 
expected returns: [[31.026987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.3447451889514923
desired expected reward: 30.712682723999023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.384998]
 [28.44842 ]
 [31.339323]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.16531339287757874
desired expected reward: 30.86167335510254



buy possibilites: [-1] 
expected returns: [[33.126225]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [29.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.07091571390628815
desired expected reward: 28.88711929321289






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[28.874191]
 [28.238876]
 [28.238876]
 [29.09457 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0. 11.] 
cards in discard: [29.  0. 16.  0. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.
  0.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.842350423336029
desired expected reward: 32.28387451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.059221]
 [27.631227]
 [26.126753]
 [28.619335]
 [28.970963]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0. 11.] 
cards in discard: [29.  0. 16.  0. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 23.  0.  0.  0.] 
adversary cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.
  0.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7228620648384094
desired expected reward: 28.15132713317871



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  0.  0.  0.] 
cards in discard: [11. 14.  1.  0.  0.  3.  3. 10.  0.  0.  3.  8.  8. 11. 10. 10.  0.  0.
  0.  3.  0. 10.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [14.  3. 11.  8. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [14.  3. 11.  8. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0] -> size -> 29 
action values: 0 
buys: 2 
player value: 6 
card supply: [22. 28. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [14.  3. 11.  8. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 


buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8. 10.  8.  3.  4. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [14.  3. 11.  8. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8. 10.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [14.  3. 11.  8. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [14.  3. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8. 11.] 
expected returns: [[24.957563]
 [23.642523]
 [25.177942]
 [24.605938]
 [25.177942]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  8. 11.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8. 10.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 14.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8] -> size -> 31 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7586711049079895
desired expected reward: 28.212289810180664



action possibilites: [-1] 
expected returns: [[21.490143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8. 11.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 14.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8] -> size -> 31 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -9.032341957092285
desired expected reward: 14.567267417907715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.643808]
 [18.729618]
 [21.531315]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8. 11.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 14.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8] -> size -> 31 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.01824474334716797
desired expected reward: 21.50838851928711






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 14.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3. 11.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [15. 10.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[26.97908 ]
 [26.519737]
 [26.343767]
 [27.199461]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  3. 11.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10.  3.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5140323042869568
desired expected reward: 21.017282485961914



action possibilites: [-1. 15. 11.] 
expected returns: [[28.423409]
 [27.964062]
 [28.643787]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3. 11.  0.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10
  8 10 11  3 10 11 16 29  0  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10.  3.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.042073458433151245
desired expected reward: 26.30169105529785



action possibilites: [-1. 11.] 
expected returns: [[24.73719]
 [24.95757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10.  3.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0.4722069203853607
desired expected reward: 28.43627166748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[22.974072]
 [23.829765]
 [23.546076]
 [22.041603]
 [23.368675]
 [25.106188]
 [24.534184]
 [25.104755]
 [23.57077 ]
 [24.426462]
 [24.885807]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  3.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10.  3.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5617402195930481
desired expected reward: 25.298931121826172



buy possibilites: [-1] 
expected returns: [[24.173588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 10.  3.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 39.5 

action type: buy - action 11.0
Learning step: 0.6856369376182556
desired expected reward: 25.791826248168945






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 10.  3.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 10.  3.  0.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11] -> size -> 34 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10. 10.  3.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8. 11. 10.  3.  0.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11] -> size -> 34 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[27.32579 ]
 [26.974163]
 [27.54617 ]
 [26.690475]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  3.  0.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5894338488578796
desired expected reward: 23.58415412902832



action possibilites: [-1.  8. 11.] 
expected returns: [[27.370941]
 [27.019314]
 [27.591318]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0.  3.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.06322402507066727
desired expected reward: 26.627248764038086



action possibilites: [-1.  8.] 
expected returns: [[22.01624 ]
 [21.712608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 9
Learning step: 0.923041045665741
desired expected reward: 28.79804801940918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.391869]
 [19.502655]
 [22.182283]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6099106669425964
desired expected reward: 22.626150131225586






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 10.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  8.] 
adversary cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[28.100924]
 [26.651619]
 [27.791042]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  8.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8
 10 11  3 10 11 16 29  0  6 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3  1] -> size -> 34 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5253344774246216
desired expected reward: 21.656946182250977



action possibilites: [-1] 
expected returns: [[25.498322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3  1] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.0790976732969284
desired expected reward: 25.366920471191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.790108]
 [22.893425]
 [25.595562]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3  1] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05881747975945473
desired expected reward: 25.439504623413086



buy possibilites: [-1] 
expected returns: [[26.370066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [29.  0. 16.  0. 10. 10. 10. 10.  0.  0. 11.  6. 11. 14.  3.  8. 11. 11.
 10. 15.  3. 11.  0. 15. 10. 11.  8.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3  1] -> size -> 34 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: 14.0 

action type: buy - action 0.0
Learning step: -0.016817551106214523
desired expected reward: 23.773290634155273






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [10. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8.  0.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  0  0 10 10 14 23  8 11  1  0 10
  0 11  8  8  0  1  8  3  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 3. 29. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 3. 29. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 1.  8. 23.  0.  0.  0.  0.  0.  3.  3. 11.  0.  0.  3. 14.  3.  8. 10.
 10.  3.  1. 10.  0.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 3. 29. 10.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3  0] -> size -> 36 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 3. 29. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.  8.] 
expected returns: [[26.684858]
 [26.918907]
 [26.09539 ]
 [26.374979]
 [26.374979]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  8.  8.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0 10 11 14 10 11 15  8  3 16  8 10 10  8 10
 11  3 10 11 16 29  0  6 11 15  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6620577573776245
desired expected reward: 25.7080078125



action possibilites: [-1] 
expected returns: [[23.222893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 11
Learning step: -0.11125659942626953
desired expected reward: 26.725311279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.68853 ]
 [20.78384 ]
 [23.562365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.012308578006923199
desired expected reward: 23.21058464050293






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10. 11. 10.  0.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0] -> size -> 33 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  2.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10. 11. 10.  0.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0] -> size -> 33 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  8.  0.] 
cards in discard: [11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [11. 10. 11. 10.  0.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0] -> size -> 33 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [11. 10. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[25.00177 ]
 [25.249584]
 [24.396336]
 [25.249584]
 [24.396336]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10.  0.] 
cards in discard: [ 8. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  8.] 
adversary cards in hand: [23.  0.  8.  8.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5950334668159485
desired expected reward: 22.967329025268555



action possibilites: [-1] 
expected returns: [[31.080488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [ 8. 29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [23.  0.  8.  8.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.4902428388595581
desired expected reward: 26.0269832611084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.350674]
 [28.418682]
 [31.227291]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [ 8. 29. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [23.  0.  8.  8.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.16764673590660095
desired expected reward: 30.912841796875



buy possibilites: [-1] 
expected returns: [[32.081646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [ 8. 29. 15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [23.  0.  8.  8.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.09083610028028488
desired expected reward: 29.259838104248047






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [23.  0.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8.  8.  3.] 
cards in discard: [11.  0.  0. 14.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [16. 11. 11.  0.  3.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  8.  8.  3.] 
cards in discard: [11.  0.  0. 14.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [16. 11. 11.  0.  3.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 11.] 
expected returns: [[22.232592]
 [20.823767]
 [22.49226 ]
 [22.49226 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11. 11.  0.  3.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  8. 11. 11. 10.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8803297877311707
desired expected reward: 31.201316833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.427513]
 [19.53252 ]
 [22.20382 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11. 11.  0.  3.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  8. 11. 11. 10.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5962909460067749
desired expected reward: 21.636301040649414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  8. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 11. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 11. 10.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 10 10 14 23  8 11  1  0 10  0 11
  8  8  0  1  8  3  3  1 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[25.253513]
 [25.523367]
 [24.672628]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  1.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  1.  0.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5512569546699524
desired expected reward: 21.652565002441406



action possibilites: [-1] 
expected returns: [[23.581413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  1.  0.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 23 

action type: gain_card_n - action 5
Learning step: 0.23017901182174683
desired expected reward: 23.811038970947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[21.828001]
 [22.646484]
 [22.367682]
 [20.933006]
 [23.324295]
 [23.604311]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  3. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  1.  0.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.019288044422864914
desired expected reward: 23.56212615966797



buy possibilites: [-1] 
expected returns: [[24.424606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [10.  3.  1.  0.  3.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -2.  0.  0.  2.  0.] 
sum of rewards: 15.0 

action type: buy - action 8.0
Learning step: 0.006729526445269585
desired expected reward: 23.331024169921875






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [10.  3.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0.  3.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14.  8.  0. 16.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14.  8.  0. 16.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 14.  8.  0. 16.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [15. 14.  8.  0. 16.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [15. 14.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8. 16.] 
expected returns: [[20.414227]
 [20.018969]
 [19.208626]
 [20.136541]
 [19.020323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  8.  0. 16.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6738865375518799
desired expected reward: 23.75071907043457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.66772 ]
 [17.78883 ]
 [20.422722]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  8.  0. 16.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5602771043777466
desired expected reward: 19.85394859313965



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  3. 10. 15.  6.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 3.  3. 10. 15.  6.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 10. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[22.741158]
 [22.18234 ]
 [22.34258 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 15.  6.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5265802145004272
desired expected reward: 19.896141052246094



action possibilites: [-1] 
expected returns: [[22.929462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  6.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.020481834188103676
desired expected reward: 22.36306381225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.1702 ]
 [20.27521]
 [22.94651]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  6.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.009398803114891052
desired expected reward: 22.920063018798828



buy possibilites: [-1] 
expected returns: [[23.194603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  6.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0  0  0] 
sum of rewards: 12 

action type: buy - action 0.0
Learning step: -0.03156263381242752
desired expected reward: 21.138635635375977






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.  0. 15.  3.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  9.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.  0. 15.  3.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [11.  0.  0. 14.  8.  0. 23.  0.  8.  8.  3.  0.  8. 15. 10.  3.  1.  0.
  3.  0.  3.  3.  0.  0.  1. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.  0. 15.  3.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.337364]
 [21.594875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.  0. 15.  3.  3. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15 29] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6201733946800232
desired expected reward: 22.574430465698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.575827]
 [20.111021]
 [18.688276]
 [21.059679]
 [21.337364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [ 8. 29. 15.  0. 11. 10. 11. 10.  0. 16. 11. 11.  0.  3. 11.  8. 11.  0.
  0. 10.  0. 15. 14.  8.  0. 16.  0. 15.  3.  3. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15 29] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5760152339935303
desired expected reward: 20.761348724365234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1
  8  3  3  1 11  0 15 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  2. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 10.] 
expected returns: [[27.177952]
 [26.597069]
 [26.886871]
 [27.447807]
 [26.597069]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 0. 11.  8. 10.  3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5061731338500977
desired expected reward: 20.831192016601562



action possibilites: [-1] 
expected returns: [[27.494751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 11.  8. 10.  3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 8
Learning step: 0.3010493516921997
desired expected reward: 26.889232635498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.722862]
 [24.797413]
 [27.530254]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 11.  8. 10.  3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09848751127719879
desired expected reward: 27.396263122558594



buy possibilites: [-1] 
expected returns: [[25.58597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [15.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 11.  8. 10.  3.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: 10.0 

action type: buy - action 0.0
Learning step: -0.20303311944007874
desired expected reward: 25.519826889038086






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 10.  3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0] -> size -> 40 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 10.  3.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0] -> size -> 40 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.774189]
 [25.22091 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 14.  3.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6492738723754883
desired expected reward: 24.936695098876953



action possibilites: [-1.] 
expected returns: [[27.585035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 14.  3.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.016984404996037483
desired expected reward: 25.20392417907715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.435595]
 [25.988659]
 [24.510145]
 [26.98189 ]
 [27.242989]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 24. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 14.  3.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1016732007265091
desired expected reward: 27.483362197875977



buy possibilites: [-1] 
expected returns: [[28.086555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 0. 14.  3.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: 0.025249099358916283
desired expected reward: 26.01390838623047






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  3.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [29. 11. 11.  0.  8.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  3.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 23. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [29. 11. 11.  0.  8.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  3.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [29. 11. 11.  0.  8.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3] -> size -> 41 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [29. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.  8.] 
expected returns: [[22.862688]
 [23.127481]
 [23.143633]
 [23.143633]
 [22.611519]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  0.  8.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  5.] 
adversary cards in hand: [ 1.  8.  0. 15.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7509815692901611
desired expected reward: 27.335573196411133



action possibilites: [-1] 
expected returns: [[21.688005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  8.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 1.  8.  0. 15.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0 16  0] 
sum of rewards: 24 

action type: gain_card_n - action 8
Learning step: 0.2693784534931183
desired expected reward: 22.880897521972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.005394]
 [19.11811 ]
 [21.744255]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  8.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 1.  8.  0. 15.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8  3] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.015452499501407146
desired expected reward: 21.703458786010742






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 15.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3
  3  1 11  0 15 29  8  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  3.  3. 11.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  3.  3. 11.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  3.  3. 11.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 14.  3.  3. 11.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 0. 14.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[20.205486]
 [18.982996]
 [20.494093]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  3. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [29.  8.  0.  1.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5921788811683655
desired expected reward: 21.15207862854004



action possibilites: [-1] 
expected returns: [[22.938652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.12136596441268921
desired expected reward: 19.10436248779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[21.156624]
 [21.992096]
 [21.703297]
 [20.253078]
 [22.68504 ]
 [22.943111]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  9.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.006952457129955292
desired expected reward: 22.931699752807617



buy possibilites: [-1] 
expected returns: [[21.630533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -8.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -9.167797088623047
desired expected reward: 11.085283279418945






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3
  1 11  0 15 29  8  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0. 11. 15.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 43 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0. 11. 15.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 43 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11. 16.  0. 11. 15.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 43 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [11. 16.  0. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 11. 15.] 
expected returns: [[19.458092]
 [19.753902]
 [18.107758]
 [19.753902]
 [19.099491]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0. 11. 15.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10
 11 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 23.  1.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5958619117736816
desired expected reward: 21.034671783447266



action possibilites: [-1] 
expected returns: [[25.197224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 23.  1.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.14158602058887482
desired expected reward: 19.241079330444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[23.44651 ]
 [24.27444 ]
 [23.98439 ]
 [22.537802]
 [24.963202]
 [25.197227]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  8.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 23.  1.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05083751678466797
desired expected reward: 25.146385192871094



buy possibilites: [-1] 
expected returns: [[22.038122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16. 11.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 23.  1.  3.  0.] 
adversary cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -8.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -9.234733581542969
desired expected reward: 13.30306625366211






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  1.  3.  0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11.  8.  0. 16.  0.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6] -> size -> 43 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11.  8.  0. 16.  0.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6] -> size -> 43 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0] -> size -> 30 
action values: 0 
buys: 2 
player value: 6 
card supply: [16. 26. 30. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11.  8.  0. 16.  0.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6] -> size -> 43 
adversary victory points: 3
player victory points: 6 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  0. 11.  8. 10.  3.  3.  0. 14.  3.  3.  0.  0.  8.  1.
 15.  0. 29.  1.  8.  2.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [11.  8.  0. 16.  0.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6] -> size -> 43 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11.  8.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
expected returns: [[19.66205 ]
 [19.95745 ]
 [19.436161]
 [18.323023]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 16.  0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  4.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6067377924919128
desired expected reward: 21.431385040283203



action possibilites: [-1] 
expected returns: [[23.524338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  3.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -9  0  0 16  0] 
sum of rewards: 22 

action type: gain_card_n - action 8
Learning step: 0.3239207863807678
desired expected reward: 19.760080337524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.82019 ]
 [22.343777]
 [20.935635]
 [23.296562]
 [23.52434 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.  0.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  3.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.018302535638213158
desired expected reward: 23.50603485107422






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  3.] 
adversary cards in hand: [ 6. 15. 15.  0. 10.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11. 15. 11.  8.  0. 16.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6 15] -> size -> 44 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  1. 10.  8.  8.  9.  0. 10.  3.] 
adversary cards in hand: [ 6. 15. 15.  0. 10.] 
adversary cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11. 15. 11.  8.  0. 16.
  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6 15] -> size -> 44 
adversary victory points: 3
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 2 

Remodel: 0 
Workshop: 6 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 15. 15.  0. 10.] 
cards in discard: [15.  0. 11.  0. 10.  8. 10.  3. 10.  3.  3.  3.  0.  0. 15. 11. 29. 11.
  0.  8.  6. 14.  0.  3.  3. 11.  6. 15. 11. 16. 11. 15. 11.  8.  0. 16.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11  0 11 14 10 11 15  3 16  8 10 10  8 10 11  3 10 11
 16 29  0  6 11 15  3  0 15  0 11  8  0 15  0  3 15  6  6 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 29. 22. 30.  8.  7.  8.  0.  0. 10.  8.  8.  9.  0. 10.  3.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  3  3  3  0  0  0 14 23  8  1  0 10  0  8  8  0  1  8  3  3  1 11
  0 15 29  8  3  0  2  8] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.855730056762695
desired expected reward: 7.668607711791992



