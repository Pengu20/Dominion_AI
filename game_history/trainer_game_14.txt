 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.21704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   6  20   0   0   0 -30   0   0   0 -16   0   0   0   0] 
sum of rewards: 475 

action type: buy - action 0.0
Learning step: 23.642227172851562
desired expected reward: 25.797679901123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[312.0329 ]
 [312.8371 ]
 [312.79956]
 [312.1759 ]
 [314.7865 ]
 [316.13065]
 [314.55566]
 [320.4801 ]
 [315.54578]
 [314.67633]
 [317.0001 ]
 [328.88675]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.426424980163574
desired expected reward: 322.45025634765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.43472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.677779197692871
desired expected reward: 320.208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[327.66608]
 [328.54282]
 [328.50433]
 [327.82083]
 [332.21167]
 [330.3927 ]
 [330.52213]
 [347.70944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.922636985778809
desired expected reward: 339.70220947265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 1.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[328.7715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.029683113098145
desired expected reward: 337.6797790527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[313.00552]
 [313.8742 ]
 [313.83588]
 [313.15906]
 [315.96152]
 [317.40567]
 [315.71048]
 [322.06888]
 [316.7696 ]
 [315.8392 ]
 [318.33606]
 [331.08655]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.361161231994629
desired expected reward: 322.00732421875



buy possibilites: [-1] 
expected returns: [[315.16965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -8.050477981567383
desired expected reward: 305.785400390625






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[334.99338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.257896423339844
desired expected reward: 306.9117431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[319.0526 ]
 [319.97635]
 [319.9314 ]
 [319.21646]
 [323.746  ]
 [321.9431 ]
 [322.07892]
 [338.35992]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.373475074768066
desired expected reward: 326.2081298828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  0.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.72824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -9.756755828857422
desired expected reward: 328.6031494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[300.78848]
 [301.68436]
 [301.64325]
 [300.9463 ]
 [305.31244]
 [303.57043]
 [303.70053]
 [319.37106]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.040682792663574
desired expected reward: 311.4588623046875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  1.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.505518913269043
desired expected reward: 310.86553955078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[314.6358 ]
 [315.63962]
 [315.59265]
 [314.8129 ]
 [319.71036]
 [317.75708]
 [317.90305]
 [335.49014]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.367197036743164
desired expected reward: 324.54547119140625



buy possibilites: [-1] 
expected returns: [[334.4966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [14.  3.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 17 

action type: buy - action 10.0
Learning step: -7.518979549407959
desired expected reward: 310.3840637207031






Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [14.  3.  0.  0. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [14.  3.  0.  0. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.5734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.60151481628418
desired expected reward: 324.8951110839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[297.29468]
 [298.17093]
 [298.1303 ]
 [297.44907]
 [301.7201 ]
 [300.0163 ]
 [300.14346]
 [315.49963]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.040459632873535
desired expected reward: 309.7735900878906



buy possibilites: [-1] 
expected returns: [[296.601]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 17 

action type: buy - action 1.0
Learning step: -7.16951322555542
desired expected reward: 291.00140380859375






Player: 1 
cards in hand: [ 1. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[300.30222]
 [286.15128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 11.  0.  3.] 
adversary cards in discard: [29.  1. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.20676326751709
desired expected reward: 288.3942565917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[286.34726]
 [287.1162 ]
 [286.48434]
 [288.855  ]
 [303.1199 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 11.  0.  3.] 
adversary cards in discard: [29.  1. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.351859092712402
desired expected reward: 291.4710998535156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  0.  3.] 
cards in discard: [29.  1. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 11.  0.  3.] 
cards in discard: [29.  1. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.77518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  1. 15.  0.  0.  0. 14.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.502273559570312
desired expected reward: 294.61761474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[278.76578]
 [279.546  ]
 [279.50732]
 [278.97885]
 [278.8985 ]
 [281.41925]
 [282.71072]
 [281.19333]
 [286.06976]
 [286.90802]
 [282.1423 ]
 [283.77487]
 [281.30402]
 [282.3682 ]
 [283.54898]
 [295.6632 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  1. 15.  0.  0.  0. 14.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.428244590759277
desired expected reward: 289.5149230957031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  1. 15.  0.  0.  0. 14.  3. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [1. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  1. 15.  0.  0.  0. 14.  3. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [1. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  1. 15.  0.  0.  0. 14.  3. 11.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 10.] 
adversary cards in discard: [1. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[303.20694]
 [288.93338]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 10.] 
cards in discard: [1. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.0977783203125
desired expected reward: 287.5654296875



action possibilites: [-1.] 
expected returns: [[324.9296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 10.0
Learning step: -6.106899261474609
desired expected reward: 282.2493896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[312.91672]
 [313.6516 ]
 [313.6139 ]
 [313.04218]
 [316.6475 ]
 [315.2149 ]
 [315.32007]
 [328.28183]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -8.035500526428223
desired expected reward: 316.89410400390625



buy possibilites: [-1] 
expected returns: [[357.60385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 3. 0. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [29. 11.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -8.149748802185059
desired expected reward: 304.7669372558594






Player: 1 
cards in hand: [29. 11.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  1.  0.] 
cards in discard: [11.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.10385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [11.  1. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -10.75458812713623
desired expected reward: 346.8492736816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[301.53418]
 [302.2698 ]
 [302.23517]
 [301.6596 ]
 [305.2648 ]
 [303.82858]
 [303.93527]
 [319.33197]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [11.  1. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.958065032958984
desired expected reward: 309.9577331542969



buy possibilites: [-1] 
expected returns: [[324.24344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 11.] 
adversary cards in discard: [11.  1. 11. 29.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 17 

action type: buy - action 10.0
Learning step: -7.0512871742248535
desired expected reward: 296.88397216796875






Player: 1 
cards in hand: [ 0.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10] -> size -> 15 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[345.39108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  0.] 
adversary cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -9.005451202392578
desired expected reward: 315.23797607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[327.1551 ]
 [328.12134]
 [328.0758 ]
 [327.31992]
 [330.4527 ]
 [332.05246]
 [330.16647]
 [337.26562]
 [331.34674]
 [330.30652]
 [333.09268]
 [347.29953]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  0.] 
adversary cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -10.131339073181152
desired expected reward: 334.6118469238281



buy possibilites: [-1] 
expected returns: [[317.21463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 15.  0.] 
adversary cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 21 

action type: buy - action 29.0
Learning step: -8.675952911376953
desired expected reward: 328.58966064453125






Player: 1 
cards in hand: [ 3.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  0.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  1. 11. 29.  0.  1.  0.  3. 11.  0.  0.  3.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[341.47403]
 [330.0043 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11. 11. 29. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.793991088867188
desired expected reward: 308.420654296875



action possibilites: [-1.] 
expected returns: [[314.9101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11. 11. 29. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 10 

action type: take_action - action 10.0
Learning step: -8.503918647766113
desired expected reward: 321.0765075683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[301.31696]
 [302.02353]
 [301.98264]
 [301.49854]
 [301.415  ]
 [303.74808]
 [304.9268 ]
 [303.53705]
 [308.03345]
 [308.8026 ]
 [304.4004 ]
 [305.907  ]
 [303.63116]
 [304.61142]
 [305.696  ]
 [316.24765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11. 11. 29. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.296975135803223
desired expected reward: 306.6131286621094






Player: 1 
cards in hand: [11. 11. 29. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 14.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 14.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 14.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[332.7808 ]
 [316.51495]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [10.  0.  0.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  1.  0.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -9.011353492736816
desired expected reward: 307.2362976074219



action possibilites: [-1.] 
expected returns: [[379.1352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  1.  0.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 10 

action type: take_action - action 10.0
Learning step: -6.678846836090088
desired expected reward: 307.5089416503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[366.49408]
 [367.22397]
 [367.1859 ]
 [366.6012 ]
 [370.20987]
 [368.7813 ]
 [368.88297]
 [381.8395 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  1.  0.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -10.040644645690918
desired expected reward: 369.09454345703125






Player: 1 
cards in hand: [16.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  1.  0.] 
cards in discard: [10. 11. 11. 29. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1.  0.] 
cards in discard: [10. 11. 11. 29. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  1.  0.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[314.73892]
 [308.2627 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -12.590835571289062
desired expected reward: 369.2486572265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[303.62686]
 [304.29395]
 [304.25653]
 [303.7245 ]
 [307.01398]
 [305.71432]
 [305.80444]
 [317.32968]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -9.26486873626709
desired expected reward: 305.5984191894531



buy possibilites: [-1] 
expected returns: [[264.7307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 15.  1.  0.  3.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 7 

action type: buy - action 10.0
Learning step: -8.983782768249512
desired expected reward: 296.8206787109375






Player: 1 
cards in hand: [ 3. 15.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[247.3781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  0. 29.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0. 15.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.263480186462402
desired expected reward: 256.46722412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.32747]
 [231.00253]
 [230.9656 ]
 [230.42628]
 [233.75534]
 [232.43877]
 [232.53073]
 [246.05835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.  0. 29.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  0.] 
adversary cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0. 15.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.4168701171875
desired expected reward: 238.05230712890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0. 15.  3.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  1.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0. 15.  3.  1.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  1.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0. 15.  3.  1.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7. 10. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  1.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [10. 11. 11. 29. 14.  0. 10. 16.  0.  3.  1.  0. 15.  3.  1.  3. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0.  0.  1.] 
adversary cards in discard: [10.  0. 29.  0.  3.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[220.4949 ]
 [208.84586]
 [208.84586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  1.] 
cards in discard: [10.  0. 29.  0.  3.  0.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -8.015755653381348
desired expected reward: 238.04258728027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[197.92787]
 [198.57579]
 [198.53825]
 [198.02402]
 [200.17783]
 [201.31783]
 [199.98828]
 [205.25444]
 [200.79295]
 [200.07994]
 [202.10013]
 [212.82732]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  1.] 
cards in discard: [10.  0. 29.  0.  3.  0.  3.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -6.806515693664551
desired expected reward: 211.7263641357422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[270.20822]
 [263.8698 ]
 [259.47824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [ 3. 10.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -5.172543525695801
desired expected reward: 207.65478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[258.03598]
 [258.12457]
 [270.7462 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [ 3. 10.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.050131797790527
desired expected reward: 262.0523376464844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 10.  0.] 
cards in discard: [ 3. 10.  3.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [29. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 29.] 
cards in discard: [ 3. 10.  3.  8. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [29. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  1.] 
cards in discard: [ 3. 10.  3.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [29. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  1.] 
cards in discard: [ 3. 10.  3.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [29. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  1.] 
cards in discard: [ 3. 10.  3.  8. 11. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [29. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[284.27023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [29. 10.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [16. 11.  0.  3.  0.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -7.719839572906494
desired expected reward: 263.0263366699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[272.24506]
 [272.86252]
 [272.8314 ]
 [272.4102 ]
 [272.33597]
 [274.3724 ]
 [275.40024]
 [274.1872 ]
 [278.10666]
 [278.7766 ]
 [274.9449 ]
 [276.2554 ]
 [274.2749 ]
 [275.13007]
 [276.07022]
 [285.2774 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [29. 10.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  9. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [16. 11.  0.  3.  0.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.383312225341797
desired expected reward: 274.6153564453125



buy possibilites: [-1] 
expected returns: [[211.79512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [29. 10.  0.  3.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [16. 11.  0.  3.  0.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15] -> size -> 24 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 8.0
Learning step: -9.308771133422852
desired expected reward: 264.8784484863281






Player: 1 
cards in hand: [16. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  3.  0.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10.  0.] 
adversary cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  8.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10.  0.] 
adversary cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8. 10.  8.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10.  0.] 
adversary cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 10.  0.] 
adversary cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[184.00966]
 [173.75807]
 [173.75807]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10.  0.] 
cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [14.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.099517822265625
desired expected reward: 204.6956024169922



action possibilites: [-1. 10.] 
expected returns: [[223.04698]
 [211.20634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [14.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 10 

action type: take_action - action 10.0
Learning step: -3.1691391468048096
desired expected reward: 169.36766052246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[208.65979]
 [209.35193]
 [209.30917]
 [208.74316]
 [212.18864]
 [210.83746]
 [210.92618]
 [223.2746 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  7.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [14.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -5.798044204711914
desired expected reward: 217.24893188476562



buy possibilites: [-1] 
expected returns: [[170.02986]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [29. 10.  0.  3.  3.  8.  3.  0.  0.  1.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [14.  3.  0.  1. 15.] 
adversary cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16  0] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 27 

action type: buy - action 11.0
Learning step: -5.433759689331055
desired expected reward: 206.75486755371094






Player: 1 
cards in hand: [14.  3.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  1. 15.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  1.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.] 
cards in discard: [ 3. 10.  3.  8. 11. 15. 10. 10.  0.  3.  0. 29.  1. 16.  0. 11. 16.  0.
  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[210.55667]
 [202.3545 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15. 16. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -4.389150142669678
desired expected reward: 165.64071655273438



action possibilites: [-1.] 
expected returns: [[245.09077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15. 16. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 10 

action type: take_action - action 29.0
Learning step: -4.029791831970215
desired expected reward: 196.8568878173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[231.36945]
 [232.20502]
 [232.15483]
 [231.58803]
 [231.47084]
 [234.26785]
 [235.66005]
 [234.01668]
 [239.36972]
 [240.28241]
 [235.04132]
 [236.82388]
 [234.12863]
 [235.29247]
 [236.57272]
 [248.85875]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15. 16. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -6.341823101043701
desired expected reward: 238.7489471435547



buy possibilites: [-1] 
expected returns: [[266.5709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  7.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15. 16. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 17.0 

action type: buy - action 16.0
Learning step: -4.865546703338623
desired expected reward: 229.4022979736328






Player: 1 
cards in hand: [ 3. 15. 16. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 16. 11. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  7.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10. 11.  1.  3.  0.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 16. 11.] 
cards in discard: [16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10. 11.  1.  3.  0.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 16. 11.] 
cards in discard: [16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10. 11.  1.  3.  0.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 16. 11.] 
cards in discard: [16.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10. 11.  1.  3.  0.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10. 11.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[169.16331]
 [159.66336]
 [160.63301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1.  3.  0.] 
cards in discard: [16. 29.  0.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  1.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -10.173075675964355
desired expected reward: 256.3978271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[157.89186]
 [158.41612]
 [158.38675]
 [157.95525]
 [160.57858]
 [159.54767]
 [159.61827]
 [169.04297]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1.  3.  0.] 
cards in discard: [16. 29.  0.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 29.  1.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -5.209297180175781
desired expected reward: 162.22384643554688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  1.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10. 10.  8.  3.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.  8.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10. 10.  8.  3.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 1.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10. 10.  8.  3.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 1.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10. 10.  8.  3.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 1.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10. 10.  8.  3.] 
adversary cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[127.80751]
 [119.92266]
 [119.92266]
 [119.86808]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  8.  3.] 
cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 14. 15. 14.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -6.187405586242676
desired expected reward: 162.8555450439453



action possibilites: [-1. 10.  8.] 
expected returns: [[105.182106]
 [ 96.95499 ]
 [ 96.898575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  3.  0.] 
cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 14. 15. 14.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 10 

action type: take_action - action 10.0
Learning step: -3.1861066818237305
desired expected reward: 116.7365493774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 97.04135]
 [ 97.09656]
 [106.79893]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  3.  0.] 
cards in discard: [16. 29.  0.  3.  0.  0.  0. 10. 11.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  3. 14. 15. 14.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -2.472806453704834
desired expected reward: 102.70930480957031






Player: 1 
cards in hand: [ 0.  3. 14. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 15. 14.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 14.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [29.  3.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 14.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [29.  3.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 14.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [29.  3.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[193.7061 ]
 [188.03918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 10. 10.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.  1. 14.  0.
  3. 15. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: discard_down_to_3_cards - action 2
Learning step: -0.8594074249267578
desired expected reward: 90.80789184570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[181.65263]
 [181.71742]
 [193.0218 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 10. 10.] 
adversary cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.  1. 14.  0.
  3. 15. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -5.847105026245117
desired expected reward: 185.4010467529297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.  1. 14.  0.
  3. 15. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.  1. 14.  0.
  3. 15. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [16.  0. 11.  3. 15. 16. 11. 15. 10. 29.  0.  0.  1.  8.  1.  1. 14.  0.
  3. 15. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[207.20088]
 [193.25381]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [ 0.  0. 29.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1  0] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -5.13386344909668
desired expected reward: 177.58067321777344



action possibilites: [-1] 
expected returns: [[215.40288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0.  0. 29.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1  0] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.949995040893555
desired expected reward: 188.98118591308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[205.76915]
 [206.31761]
 [205.82343]
 [207.64066]
 [218.3762 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  0. 29.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1  0] -> size -> 31 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -6.055263519287109
desired expected reward: 209.3476104736328






Player: 1 
cards in hand: [ 3.  0. 16.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16
  0 14 16  0 15  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  8.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 16.  0. 10.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16  0
 14 16  0 15  1  0 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 16.  0. 10.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16  0
 14 16  0 15  1  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  0. 16.  0. 10.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 10.] 
expected returns: [[207.77652]
 [198.42004]
 [198.508  ]
 [198.42004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  0. 10.] 
cards in discard: [ 0.  0. 29.  3.  0.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16. 16. 11.  0.  1.] 
adversary cards in discard: [29. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16  0
 14 16  0 15  1  0 29] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -6.958312511444092
desired expected reward: 211.4179229736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[196.99837]
 [197.47894]
 [197.046  ]
 [198.64064]
 [208.96606]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.  0. 10.] 
cards in discard: [ 0.  0. 29.  3.  0.  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16. 16. 11.  0.  1.] 
adversary cards in discard: [29. 16.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16  0
 14 16  0 15  1  0 29] -> size -> 31 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.286532878875732
desired expected reward: 199.59982299804688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 16. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 11.  0.  1.] 
cards in discard: [29. 16.  0.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 16 10 10 10  8 15 16  0
 14 16  0 15  1  0 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.] 
cards in discard: [29. 16.  0.  3. 11.  2.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 29. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.] 
cards in discard: [29. 16.  0.  3. 11.  2.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 29. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 29. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[150.5368 ]
 [145.03595]
 [145.595  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 11.] 
cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10.  1. 14. 15.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -7.697004795074463
desired expected reward: 201.26904296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[143.91058]
 [143.93861]
 [150.41805]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10. 11.] 
cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8. 10.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10.  1. 14. 15.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -4.786932945251465
desired expected reward: 145.74989318847656



buy possibilites: [-1] 
expected returns: [[119.484116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10. 11.] 
cards in discard: [ 0.  0. 29.  3.  0.  8.  1. 10.  0. 16.  0. 10.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 10.  1. 14. 15.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -20.658536911010742
desired expected reward: 123.28005981445312






Player: 1 
cards in hand: [ 3. 10.  1. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1. 14. 15.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  6.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1. 14.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  6.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 14.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  8. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  6.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 14.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [10.  6.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10.  6.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[163.4299]
 [154.1793]
 [155.1486]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3. 11.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 15.  0.  1.  0.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0  8] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -3.572455644607544
desired expected reward: 115.91165924072266



action possibilites: [-1. 11.] 
expected returns: [[217.7931 ]
 [205.03543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 15.  0.  1.  0.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0  8] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -2 

action type: take_action - action 10.0
Learning step: -2.83135986328125
desired expected reward: 148.49136352539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[205.57553]
 [205.64734]
 [222.36572]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  9.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 15.  0.  1.  0.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0  8] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.151238918304443
desired expected reward: 211.641845703125



buy possibilites: [-1] 
expected returns: [[198.20543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  3.  0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 15.  0.  1.  0.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0  8] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -21.52274513244629
desired expected reward: 184.1245880126953






Player: 1 
cards in hand: [ 8. 15.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  1.  0.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14
 16  0 15  1  0 29  2  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16.  8.  0. 10. 29.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16.  8.  0. 10. 29.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16.  8.  0. 10. 29.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16.  8.  0. 10. 29.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [16.  8.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10. 29.] 
expected returns: [[199.04675]
 [189.81189]
 [189.659  ]
 [189.72461]
 [193.54   ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  0. 10. 29.] 
cards in discard: [ 6. 10.  6.  3. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 14. 11. 10.  3.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.232566833496094
desired expected reward: 190.97286987304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[185.75392]
 [185.80136]
 [196.77869]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  0. 10. 29.] 
cards in discard: [ 6. 10.  6.  3. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 14. 11. 10.  3.] 
adversary cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0] -> size -> 32 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.228919982910156
desired expected reward: 190.39215087890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11. 10.  3.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 14. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  3. 10.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 14. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  3. 15.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 15.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0 29] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 11. 14.] 
owned cards: [ 0  0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0
 15  1  0 29  2  0  8  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 11. 14. 15.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 11. 14. 15.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  4. 10.  7.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 16.  0.  3. 11.  2.  0. 16. 11.  0.  1.  8. 15.  3. 10.  1. 14.  0.
  8. 15.  0. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 11. 14. 15.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 0.] 
adversary cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.94117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: discard_down_to_3_cards - action 2
Learning step: -4.687098026275635
desired expected reward: 88.77838897705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[69.12124 ]
 [69.54226 ]
 [69.51228 ]
 [69.14977 ]
 [70.593315]
 [71.30277 ]
 [70.470245]
 [73.671005]
 [70.98263 ]
 [70.52107 ]
 [71.764336]
 [78.22145 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6. 10.  6.  3. 11.  3.  0. 16.  8.  0. 10. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -3.758862257003784
desired expected reward: 71.18230438232422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  7. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.  0.  3.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[152.18176]
 [143.38771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 29. 15.  8.  0.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -2.2624878883361816
desired expected reward: 75.95897674560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[145.32024]
 [145.83221]
 [145.79625]
 [145.35632]
 [147.84088]
 [146.89035]
 [146.94601]
 [155.74493]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 29. 15.  8.  0.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -5.82321310043335
desired expected reward: 145.0242462158203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  8.  0.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 16. 11.] 
adversary cards in discard: [ 1.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  8.  0.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 16. 11.] 
adversary cards in discard: [ 1.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  8. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 11.] 
expected returns: [[143.55724]
 [128.92485]
 [129.13925]
 [130.35017]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 16. 11.] 
cards in discard: [ 1.  3.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0 10 29 10  8 11 16  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 29. 14. 10. 10.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.387738227844238
desired expected reward: 149.357177734375



action possibilites: [-1] 
expected returns: [[193.65413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 1.  3.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 29. 14. 10. 10.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 13
Learning step: -3.386188507080078
desired expected reward: 126.48193359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[177.91127]
 [177.94557]
 [190.50981]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 1.  3.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 29. 14. 10. 10.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -6.732452392578125
desired expected reward: 186.9216766357422






Player: 1 
cards in hand: [ 0. 29. 14. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 14. 10. 10.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  3.  0. 10.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 14. 10. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10. 10. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  3.  0. 10.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10. 10. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 27. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  3.  0. 10.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10. 10. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  3.  0. 10.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[183.22523]
 [175.38412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 1.  3.  0. 10.  3.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14. 11.  1.  0. 10.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -8.211323738098145
desired expected reward: 182.29849243164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[163.71179]
 [164.37825]
 [164.32982]
 [163.75705]
 [166.04367]
 [167.15884]
 [165.84396]
 [170.90567]
 [166.6539 ]
 [165.92378]
 [167.88893]
 [179.15103]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 1.  3.  0. 10.  3.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14. 11.  1.  0. 10.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.963545322418213
desired expected reward: 174.45721435546875



buy possibilites: [-1] 
expected returns: [[149.02782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 1.  3.  0. 10.  3.  8. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14. 11.  1.  0. 10.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -50.5 

action type: buy - action 1.0
Learning step: -7.390786647796631
desired expected reward: 156.98745727539062






Player: 1 
cards in hand: [14. 11.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  1.  0. 10.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 1.  6.  6. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0. 10.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 10. 10.] 
adversary cards in discard: [1. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0. 10.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  6. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 10. 10.] 
adversary cards in discard: [1. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0. 10.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 10. 10.] 
adversary cards in discard: [1. 6.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[208.28256]
 [197.17252]
 [197.17252]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.] 
cards in discard: [1. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1. 15. 15.  3.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3  8] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 4
Learning step: -2.024874448776245
desired expected reward: 74.93708038330078



action possibilites: [-1. 10.] 
expected returns: [[180.58487]
 [168.82945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.] 
cards in discard: [1. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1. 15. 15.  3.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3  8] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -34 

action type: take_action - action 10.0
Learning step: -7.48400354385376
desired expected reward: 188.2509002685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[169.66411]
 [169.70705]
 [183.51323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [1. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1. 15. 15.  3.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10.] 
adversary owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3  8] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -6.7449541091918945
desired expected reward: 173.83993530273438






Player: 1 
cards in hand: [ 0.  1. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15. 15.  3.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15
  1  0 29  2  0  8  0 29 10  8  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  3.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[168.21065]
 [158.64278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 1.  6. 10.  6. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  8.  2.  3.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
adversary owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8 15] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -8.190096855163574
desired expected reward: 175.32313537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[145.6973 ]
 [146.26672]
 [146.22481]
 [145.72636]
 [148.65121]
 [147.52293]
 [147.5902 ]
 [158.06085]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 1.  6. 10.  6. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  5. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  8.  2.  3.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
adversary owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8 15] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.467948913574219
desired expected reward: 155.99481201171875



buy possibilites: [-1] 
expected returns: [[97.250565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 1.  6. 10.  6. 10.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10. 11.  8.  2.  3.] 
adversary cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
adversary owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8 15] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -53.0 

action type: buy - action 8.0
Learning step: -7.838009834289551
desired expected reward: 139.6849365234375






Player: 1 
cards in hand: [10. 11.  8.  2.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  2.  3.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 10. 29.  0.  1.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  2.  3. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1
  0 29  2  0  8  0 29 10  8  3  8 15] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 10. 29.  0.  1.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  2. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 10. 29.  0.  1.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  2. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 29. 26. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 10. 29.  0.  1.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  2. 16.] 
cards in discard: [ 8. 11. 29.  0.  0.  3.  0. 29. 15.  8.  0.  3. 29.  0. 14. 10. 10. 16.
  8. 14. 11.  1.  0. 10. 15. 15.  1. 15.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 10. 29.  0.  1.] 
adversary cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[98.621445]
 [89.752754]
 [92.96852 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  0.  1.] 
cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 8. 29.  2. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.443302154541016
desired expected reward: 91.80726623535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.09672]
 [ 89.52606]
 [ 89.49012]
 [ 89.11856]
 [ 91.59842]
 [ 90.56631]
 [ 90.62536]
 [100.80088]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.  0.  1.] 
cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  4. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 8. 29.  2. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -5.510169506072998
desired expected reward: 93.11126708984375



buy possibilites: [-1] 
expected returns: [[147.05777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.  0.  1.] 
cards in discard: [ 1.  6. 10.  6. 10.  0.  8.  0.  0.  0. 11.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 8. 29.  2. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15  3] -> size -> 36 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -53.0 

action type: buy - action 8.0
Learning step: -3.8695151805877686
desired expected reward: 86.69678497314453






Player: 1 
cards in hand: [ 8. 29.  2. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  2. 10.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  3 15 14 29 11 11  1  3 10 10 10  8 15 16  0 14 16  0 15  1  0
 29  2  0  8  0 29 10  8  3  8 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 10.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 10.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 1. 10.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[156.1416 ]
 [143.81813]
 [143.74779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10. 16. 14. 10.  0.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.238502025604248
desired expected reward: 140.81927490234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[142.42407]
 [142.95506]
 [142.45346]
 [144.47565]
 [156.82645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10. 16. 14. 10.  0.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.49630880355835
desired expected reward: 146.740478515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 16. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 14. 10.  0.] 
cards in discard: [ 8. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 16. 14. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14. 10.  0. 29.] 
cards in discard: [ 8. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 16. 14. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  0. 29.  3.] 
cards in discard: [ 8. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0 11  3 15 14 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0
  8  0 29 10  8  3  8 15  3] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 8. 29. 22.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10. 16.] 
owned cards: [ 0 11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8
  0 29 10  8  3  8 15  3 22] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 8. 29. 22.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10. 16.] 
owned cards: [ 0 11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8
  0 29 10  8  3  8 15  3 22] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  6. 11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[150.72896]
 [141.61273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [ 1. 10.  3.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 1.  0.  1. 15.  0.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3.] 
adversary owned cards: [ 0 11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8
  0 29 10  8  3  8 15  3 22] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -6.781978130340576
desired expected reward: 150.04446411132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[137.43037]
 [137.9398 ]
 [137.90295]
 [137.45639]
 [140.07635]
 [139.06564]
 [139.12622]
 [149.04306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  0.] 
cards in discard: [ 1. 10.  3.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [ 1.  0.  1. 15.  0.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3.] 
adversary owned cards: [ 0 11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8
  0 29 10  8  3  8 15  3 22] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.448228359222412
desired expected reward: 142.67628479003906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 15.  0.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8
  0 29 10  8  3  8 15  3 22] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [6. 1. 0. 0. 8.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [6. 1. 0. 0. 8.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22] -> size -> 32 
action values: 0 
buys: 1 
player value: 8 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  8. 10.  3.  9.  6.] 
adversary cards in hand: [6. 1. 0. 0. 8.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  3.  9.  6.] 
adversary cards in hand: [6. 1. 0. 0. 8.] 
adversary cards in discard: [ 1. 10.  3.  3.  8.  0.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [6. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[174.79599]
 [169.28018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 8.] 
cards in discard: [ 1. 10.  3.  3.  8.  0.  6. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3.  3. 14. 15.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -5.7975921630859375
desired expected reward: 143.24546813964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[163.52586]
 [163.72441]
 [163.70549]
 [163.53593]
 [164.22878]
 [164.56622]
 [164.17316]
 [165.85812]
 [164.41689]
 [164.19418]
 [164.78891]
 [169.07971]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 8.] 
cards in discard: [ 1. 10.  3.  3.  8.  0.  6. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  3.  3. 14. 15.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14] -> size -> 33 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -7.23104190826416
desired expected reward: 167.56494140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14. 15.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 0.  8. 10. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 29. 10.] 
adversary cards in discard: [ 0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  3.  9.  6.] 
adversary cards in hand: [ 8. 29. 10.] 
adversary cards in discard: [ 0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 29. 10.] 
adversary cards in discard: [ 0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[100.23033 ]
 [ 94.115   ]
 [ 96.55681 ]
 [ 94.141754]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10.] 
cards in discard: [ 0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 29. 15.  8. 11.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_down_to_3_cards - action 0
Learning step: -1.4796251058578491
desired expected reward: 26.91551971435547



action possibilites: [-1.  8. 29.] 
expected returns: [[83.695  ]
 [76.78636]
 [79.61722]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.] 
cards in discard: [ 0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 29. 15.  8. 11.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -24 

action type: take_action - action 10.0
Learning step: -4.007950782775879
desired expected reward: 89.06094360351562



action possibilites: [-1.  8.] 
expected returns: [[126.62815]
 [115.74591]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 19 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 29. 15.  8. 11.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: -1.4376567602157593
desired expected reward: 78.17955017089844



action possibilites: [-1.] 
expected returns: [[40.829254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 29. 15.  8. 11.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.326308488845825
desired expected reward: 96.5730209350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.047005]
 [31.055645]
 [41.567635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 29.  8.] 
owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 29. 15.  8. 11.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.42825624346733093
desired expected reward: 40.400997161865234






Player: 1 
cards in hand: [ 0. 29. 15.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  8. 11.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16  0 14 16  0 15  1  0 29  0  8  0
 29 10  8  3  8 15  3 22 14 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1. 11.  6. 10.  8.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1. 11.  6. 10.  8.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 11.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1. 11.  6. 10.  8.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 11.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 1. 11.  6. 10.  8.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[138.12466]
 [130.25482]
 [129.36807]
 [129.31586]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6. 10.  8.] 
cards in discard: [ 0. 10. 10. 29.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -1.291290283203125
desired expected reward: 40.276344299316406



action possibilites: [-1. 11.  8.  8.] 
expected returns: [[122.06374 ]
 [113.78894 ]
 [112.827255]
 [112.827255]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  6.  8.  8.] 
cards in discard: [ 0. 10. 10. 29.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 25. 30.  8.  8.  6.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -5.028815746307373
desired expected reward: 124.1014633178711



action possibilites: [-1.  8.  8.] 
expected returns: [[104.486565]
 [ 98.60613 ]
 [ 98.60613 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 8. 8.] 
cards in discard: [ 0. 10. 10. 29.  8.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  3  3 10  1  0 10 29 10  8 11  6  6  1  8  8 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 25. 30.  8.  8.  5.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: gain_card_n - action 4
Learning step: -2.709123373031616
desired expected reward: 108.68636322021484



action possibilites: [-1] 
expected returns: [[60.92936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0. 10. 10. 29.  8.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 25. 30.  8.  8.  5.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: -2.7173595428466797
desired expected reward: 94.04804229736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.965614]
 [50.9758  ]
 [60.735947]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 10. 10. 29.  8.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 25. 29. 25. 30.  8.  8.  5.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.9968277215957642
desired expected reward: 59.932533264160156



buy possibilites: [-1] 
expected returns: [[48.07337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 25. 30.  8.  8.  5.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  0.  8. 11.  8.] 
adversary cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action 0.0
Learning step: -2.216630220413208
desired expected reward: 48.748992919921875






Player: 1 
cards in hand: [10.  0.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 11.  8.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 25. 30.  8.  8.  5.  6.  3. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 0. 6. 0. 1.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0. 10. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 25. 30.  8.  8.  5.  6.  2. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 0. 6. 0. 1.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0. 10. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 29. 25. 30.  8.  8.  5.  6.  2. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 0. 6. 0. 1.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0. 10. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  8.] 
cards in discard: [ 8. 29. 22. 10. 10. 16.  0. 29.  3. 14. 15.  1.  1.  0. 10. 14.  0.  3.
  3. 15.  0. 15. 29.  8. 11.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 25. 30.  8.  8.  5.  6.  2. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [3. 0. 6. 0. 1.] 
adversary cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0. 10. 11.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.372696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 1.] 
cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0. 10. 11.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 30.  8.  8.  5.  6.  2. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8.  3. 15. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0  8  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.800283193588257
desired expected reward: 45.27309036254883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[74.86074]
 [75.25238]
 [75.22081]
 [74.87272]
 [76.23306]
 [76.89246]
 [76.11824]
 [79.10861]
 [76.58874]
 [76.16084]
 [77.32035]
 [83.36535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 1.] 
cards in discard: [ 0. 10. 10. 29.  8.  3. 16.  0. 10. 11.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 25. 30.  8.  8.  5.  6.  2. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8.  3. 15. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0  8  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.560062408447266
desired expected reward: 77.81263732910156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3. 15. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15. 16. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29
 10  8  3  8 15  3 22 14 10  0  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 30.  8.  8.  5.  6.  2. 10.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.] 
cards in discard: [25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 25. 30.  8.  8.  5.  6.  2.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 15.] 
cards in discard: [25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 29. 25. 30.  8.  8.  5.  6.  2.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 15.] 
cards in discard: [25.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  2.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  3.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[92.440926]
 [85.2264  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  2.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [8. 0. 8. 1. 0.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -4.3994669914245605
desired expected reward: 78.96586608886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.02984 ]
 [85.379395]
 [85.04147 ]
 [86.24614 ]
 [93.65087 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  2.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [8. 0. 8. 1. 0.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.780206203460693
desired expected reward: 86.61381530761719



buy possibilites: [-1] 
expected returns: [[109.1668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  6.  0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [8. 0. 8. 1. 0.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -37 

action type: buy - action 8.0
Learning step: -3.706054449081421
desired expected reward: 82.54009246826172






Player: 1 
cards in hand: [8. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 1. 0.] 
cards in discard: [25.  0. 16.  8.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10  8 15 16 14 16  0 15  1  0 29  0  8  0 29 10
  8  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8. 16.  0.  6.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [25.  0. 16.  8.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8. 16.  0.  6.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [25.  0. 16.  8.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 29. 25. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8. 16.  0.  6.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8. 16.  0.  6.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10.  8. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 16.] 
expected returns: [[113.473755]
 [107.349236]
 [107.31411 ]
 [107.41059 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 16.  0.  6.] 
cards in discard: [ 8. 10.  3.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 10.  3.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.702329158782959
desired expected reward: 103.46446990966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.349724]
 [103.35797 ]
 [110.52776 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 16.  0.  6.] 
cards in discard: [ 8. 10.  3.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 3.  0.  1. 10.  3.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -5.920360565185547
desired expected reward: 106.24113464355469



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10.  3.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  8. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  3. 22.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  8. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  3. 15. 29.  0.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 22.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  8. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  3. 15.  0.  3.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 22. 29.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  8. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  3. 15.  0.  3.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 22. 29.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 25. 29. 24. 30.  8.  8.  5.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  8. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1.  3. 15.  0.  3.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 22. 29.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  0.  8. 11.  3.] 
adversary cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [29.  0.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[56.474773]
 [54.871265]
 [53.877434]
 [54.12022 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 11.  3.] 
cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  8. 10. 11. 14.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -7.022552013397217
desired expected reward: 103.50521087646484



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[36.118717]
 [30.257116]
 [30.866718]
 [30.292513]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3. 10.] 
cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  8. 10. 11. 14.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: -3.72442364692688
desired expected reward: 51.14684295654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.238552]
 [29.517645]
 [29.246162]
 [30.232664]
 [36.09977 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3. 10.] 
cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  8. 10. 11. 14.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -2.797480344772339
desired expected reward: 33.321250915527344



buy possibilites: [-1] 
expected returns: [[100.07441]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3. 10.] 
cards in discard: [ 8. 10.  3.  0.  6.  0. 10.  8. 16.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [29.  8. 10. 11. 14.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -2.460254430770874
desired expected reward: 26.77831268310547






Player: 1 
cards in hand: [29.  8. 10. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 11. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10. 11. 14.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.  8. 10. 11. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11. 14. 10.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.  8. 11. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 14. 10.  0.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
action values: 2 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.  8. 11. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 14.  0. 16.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
action values: 3 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 14.  0. 16.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 14.  0. 16.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8. 10.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[53.002842]
 [47.0863  ]
 [47.120495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8. 14. 29. 15.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.  0. 29. 10. 10.  8. 11. 14.  0. 16.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.601583957672119
desired expected reward: 93.47282409667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.37326 ]
 [44.676323]
 [44.65219 ]
 [44.38088 ]
 [45.449272]
 [45.978825]
 [45.35834 ]
 [47.754887]
 [45.735565]
 [45.393097]
 [46.321297]
 [51.215195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8. 14. 29. 15.] 
adversary cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.  0. 29. 10. 10.  8. 11. 14.  0. 16.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.302016735076904
desired expected reward: 48.700828552246094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8. 14. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14. 29. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 14. 29. 15.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.  0. 29. 10. 10.  8. 11. 14.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 8.  0. 10.  6.  3.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 15.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.  0. 29. 10. 10.  8. 11. 14.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 10.  6.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 29. 15.] 
cards in discard: [25.  0. 16.  8.  3. 15.  3.  8.  0.  1.  0. 16. 10. 22. 29.  3.  0.  1.
  3. 15.  0.  3.  0. 29. 10. 10.  8. 11. 14.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 10.  6.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[107.49145]
 [101.81545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.] 
cards in discard: [ 8. 10.  0.  0.  1.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_down_to_3_cards - action 5
Learning step: -0.9671218991279602
desired expected reward: 11.163022994995117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 99.32649 ]
 [ 99.332954]
 [105.87839 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.] 
cards in discard: [ 8. 10.  0.  0.  1.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [10.  8.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -5.787185192108154
desired expected reward: 101.70426177978516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  6.] 
adversary cards in hand: [11.  6. 16.  0.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 15.] 
cards in discard: [15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  6. 16.  0.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 15.] 
cards in discard: [15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  6. 16.  0.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 15.] 
cards in discard: [15.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [11.  6. 16.  0.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [11.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[60.227463]
 [57.618515]
 [57.37925 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 16.  0.  0.] 
cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 16.  1. 25.  0.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -6.707499980926514
desired expected reward: 99.17089080810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[57.84724 ]
 [57.970898]
 [57.85069 ]
 [58.312572]
 [61.564636]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 16.  0.  0.] 
cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 16.  1. 25.  0.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.405519962310791
desired expected reward: 55.821937561035156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1. 25.  0.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16  0 15  1  0 29  0  8  0 29 10  8
  3  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  3.  0.  8. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6. 11.  6. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  3.  0.  8. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6. 11.  6. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [29.  3.  0.  8. 10.] 
adversary cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6. 11.  6. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[84.57297]
 [79.84345]
 [76.53162]
 [76.58259]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  8. 10.] 
cards in discard: [ 8. 10.  0.  0.  1.  8.  3.  0. 10.  6. 11.  6. 16.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [15. 29. 14.  0.  8.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -3.978691577911377
desired expected reward: 57.585941314697266



action possibilites: [-1.  8. 10.] 
expected returns: [[50.17926 ]
 [45.001606]
 [45.03076 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [15. 29. 14.  0.  8.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: -4.648520469665527
desired expected reward: 75.19493103027344



action possibilites: [-1.  8. 10.] 
expected returns: [[88.922386]
 [82.90736 ]
 [82.941536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  6. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [15. 29. 14.  0.  8.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -1.041886568069458
desired expected reward: 43.98887252807617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[81.329094]
 [81.616356]
 [81.33697 ]
 [82.33823 ]
 [88.35631 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  6. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [15. 29. 14.  0.  8.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.2632081508636475
desired expected reward: 85.65918731689453






Player: 1 
cards in hand: [15. 29. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 14.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 14.  0.  8.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [16.  8.  3.  1. 10.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 15. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.  8.  3.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 14 16 15  1  0 29  0  8  0 29 10  8  3
  8 15  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [16.  8.  3.  1. 10.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [16.  8.  3.  1. 10.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [16.  8.  3.  1. 10.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [16.  8.  3.  1. 10.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [16.  8.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
expected returns: [[49.737167]
 [45.663765]
 [45.601913]
 [45.623104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  1. 10.] 
cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 15. 22. 11. 16.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -5.809842109680176
desired expected reward: 77.13538360595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[44.45414 ]
 [44.64668 ]
 [44.458096]
 [45.13643 ]
 [49.2732  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  1. 10.] 
cards in discard: [29. 10.  3.  0.  8.  6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 29. 24. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 15. 22. 11. 16.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.166033744812012
desired expected reward: 45.57114028930664



buy possibilites: [-1] 
expected returns: [[54.138733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  1. 10.] 
cards in discard: [29. 10.  3.  0.  8.  6. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 23. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 15. 22. 11. 16.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -36 

action type: buy - action 3.0
Learning step: -2.8142127990722656
desired expected reward: 41.83246994018555






Player: 1 
cards in hand: [ 3. 15. 22. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 11. 16.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 22. 11. 16.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 23. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.  3. 16.  8.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3] -> size -> 21 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 16.  0.  3. 15.  3.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 23. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.  3. 16.  8.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 16.  0.  3. 15.  3.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 29. 23. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [29. 10.  3.  0.  8.  6. 10.  3. 16.  8.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3] -> size -> 21 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[34.131943]
 [25.895033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [29. 10.  3.  0.  8.  6. 10.  3. 16.  8.  3.  1. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 23. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0.  3. 10. 14. 16.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -4.181302070617676
desired expected reward: 49.95743179321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.563759]
 [23.979172]
 [23.943047]
 [23.571903]
 [25.747501]
 [24.907877]
 [24.950308]
 [34.082184]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [29. 10.  3.  0.  8.  6. 10.  3. 16.  8.  3.  1. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 29. 23. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0.  3. 10. 14. 16.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -3.2270073890686035
desired expected reward: 30.904943466186523



buy possibilites: [-1] 
expected returns: [[48.955666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [29. 10.  3.  0.  8.  6. 10.  3. 16.  8.  3.  1. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [ 0.  3. 10. 14. 16.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3.] 
adversary owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -31.0 

action type: buy - action 3.0
Learning step: -1.6456501483917236
desired expected reward: 22.29739761352539






Player: 1 
cards in hand: [ 0.  3. 10. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 14. 16.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15
  3 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  2.  9.  5.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 14.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  1.  9.  5.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 14.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  1.  9.  5.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[61.891685]
 [54.832253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  1.  9.  5.] 
adversary cards in hand: [ 0.  0.  8. 10.  1.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10. 16.  0. 10. 14.] 
adversary owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10] -> size -> 40 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -2.2415027618408203
desired expected reward: 46.71416473388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[50.300964]
 [50.66623 ]
 [50.636227]
 [50.307884]
 [52.291294]
 [51.51433 ]
 [51.55591 ]
 [59.155945]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  1.  9.  5.] 
adversary cards in hand: [ 0.  0.  8. 10.  1.] 
adversary cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10. 16.  0. 10. 14.] 
adversary owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10] -> size -> 40 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -2.986581563949585
desired expected reward: 58.905113220214844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  8. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  1.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10. 16.  0. 10. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  1.  9.  5.] 
adversary cards in hand: [11.  0. 10. 10. 10.] 
adversary cards in discard: [3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  1.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10. 16.  0. 10. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  7. 10.  1.  9.  5.] 
adversary cards in hand: [11.  0. 10. 10. 10.] 
adversary cards in discard: [3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  1.] 
cards in discard: [15.  0. 11. 10.  8.  0. 15.  0. 16.  1. 25.  0.  0. 29.  8. 15.  3. 22.
 15.  3. 11. 16.  0.  3. 15.  3. 10. 16.  0. 10. 14. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [11.  0. 10. 10. 10.] 
adversary cards in discard: [3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[94.65486]
 [91.40056]
 [91.03446]
 [91.03446]
 [91.03446]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10. 10.] 
cards in discard: [3. 0. 0. 8. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [ 8. 10.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -2.007082462310791
desired expected reward: 57.148868560791016



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[68.09096 ]
 [62.651054]
 [62.055515]
 [62.055515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10.  0.] 
cards in discard: [3. 0. 0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [ 8. 10.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -2 

action type: take_action - action 10.0
Learning step: -3.164675235748291
desired expected reward: 87.86978912353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.946556]
 [60.237034]
 [59.952847]
 [60.97046 ]
 [67.10299 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 10.  0.] 
cards in discard: [3. 0. 0. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [ 8. 10.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -2.1008644104003906
desired expected reward: 65.99008178710938






Player: 1 
cards in hand: [ 8. 10.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 29. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8. 10.  8. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8. 29. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [15 29 11 11  1  3 10 10 15 16 16 15  1 29  0  8  0 29 10  8  3  8 15  3
 22 14 10  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 41 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [3. 3. 3. 8. 6.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[83.21821]
 [71.89683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8. 6.] 
cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [11.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 29. 10.  8. 10.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0] -> size -> 39 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -2.690927267074585
desired expected reward: 64.41207885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[69.82748]
 [69.83953]
 [83.10798]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8. 6.] 
cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [11.  0.  0. 11.  1.] 
adversary cards in discard: [ 0. 29. 10.  8. 10.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0] -> size -> 39 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -3.531947374343872
desired expected reward: 79.68626403808594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  1.] 
cards in discard: [ 0. 29. 10.  8. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [ 6.  8. 16.  1.  0.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.  3.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  1.] 
cards in discard: [ 0. 29. 10.  8. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  6. 10.  1.  9.  5.] 
adversary cards in hand: [ 6.  8. 16.  1.  0.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.  3.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11.  1.] 
cards in discard: [ 0. 29. 10.  8. 10. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  9.  5.] 
adversary cards in hand: [ 6.  8. 16.  1.  0.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.  3.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[12.956962]
 [ 9.331073]
 [ 9.387551]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 16.  1.  0.] 
cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.  3.  3.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  1  8  8 16  0  8  0  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  9.  5.] 
adversary cards in hand: [15.  1. 22. 29.  0.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -5.038520812988281
desired expected reward: 78.06945037841797



action possibilites: [-1] 
expected returns: [[30.172989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.  3.  3.  3.  8.  6. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [15.  1. 22. 29.  0.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: 22 

action type: gain_card_n - action 13
Learning step: -1.9704421758651733
desired expected reward: 73.01624298095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.33704 ]
 [29.338242]
 [32.65092 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [ 3.  0.  0.  8.  0. 10. 11.  0. 10. 10.  0.  3.  3.  3.  8.  6. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [15.  1. 22. 29.  0.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -0.9467086791992188
desired expected reward: 29.226280212402344






Player: 1 
cards in hand: [15.  1. 22. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 29.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 22. 29.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 8.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 29.  0. 15.  0.  3.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 8.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 29.  0. 15.  0.  3.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 25. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 8.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 29.  0. 15.  0.  3.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [22.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 8.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[53.560963]
 [52.58093 ]
 [52.987587]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  6. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0 10 29 10 11  6  6  8  8 16  0  8  0  3  3 22] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 0. 25. 10. 15.  3.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -1.5827466249465942
desired expected reward: 31.068166732788086



action possibilites: [-1] 
expected returns: [[82.929665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 0. 25. 10. 15.  3.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 13
Learning step: -0.34767380356788635
desired expected reward: 51.92414855957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.97929]
 [74.98213]
 [82.78929]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 0. 25. 10. 15.  3.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -1.9372341632843018
desired expected reward: 80.992431640625






Player: 1 
cards in hand: [ 0. 25. 10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 15.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10. 15.  3.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 22. 30.  8.  8.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [10.  0. 10.  8. 10.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  3. 15.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [10.  0. 10.  8. 10.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  3. 15.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [10.  0. 10.  8. 10.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.  3. 15.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [10.  0. 10.  8. 10.] 
adversary cards in discard: [8. 3. 6.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 10.] 
expected returns: [[82.33858]
 [73.72705]
 [73.72705]
 [73.67936]
 [73.72705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8. 10.] 
cards in discard: [8. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 0. 16. 14.  3.  0.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -323 

action type: buy - action -1.0
Learning step: -18.50775909423828
desired expected reward: 64.28152465820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.4712 ]
 [72.47471]
 [82.75204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8. 10.] 
cards in discard: [8. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [ 0. 16. 14.  3.  0.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -3.4754478931427
desired expected reward: 78.86312866210938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 14.  3.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [22.  0. 16.  3.  3.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 14.  3.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [22.  0. 16.  3.  3.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 14.  3.  0.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [22.  0. 16.  3.  3.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [22.  0. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16.] 
expected returns: [[68.32241 ]
 [64.41772 ]
 [64.167145]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 16.  3.  3.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  1.  8.  5.] 
adversary cards in hand: [14.  3.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -3.7779643535614014
desired expected reward: 78.97408294677734



action possibilites: [-1] 
expected returns: [[40.324493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [14.  3.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -5 

action type: gain_card_n - action 9
Learning step: -1.7730015516281128
desired expected reward: 46.833045959472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.075787]
 [34.077694]
 [39.347637]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  3.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 29. 22. 30.  8.  7.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [14.  3.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -1.8670227527618408
desired expected reward: 38.45746994018555



buy possibilites: [-1] 
expected returns: [[90.3921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  3.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [14.  3.  8. 16. 10.] 
adversary cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -15.920062065124512
desired expected reward: 18.157630920410156






Player: 1 
cards in hand: [14.  3.  8. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8. 16. 10.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 16. 10.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 11.  0.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 16. 10.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 11.  0.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 16. 10.] 
cards in discard: [ 0. 29. 10.  8. 10. 14. 11.  0.  0. 11.  1.  1. 22. 15.  1. 29.  0. 15.
  0.  3.  0. 25.  0. 10. 15.  3. 15.  0.  0.  0. 16. 14.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 11.  0.] 
adversary cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.232019]
 [13.031906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [16. 10. 15. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_down_to_3_cards - action 0
Learning step: -1.9001057147979736
desired expected reward: -2.6169426441192627





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.905154]
 [12.968012]
 [12.905414]
 [13.127935]
 [14.42174 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 29. 22. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [16. 10. 15. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.6437132358551025
desired expected reward: 11.48266315460205



buy possibilites: [-1] 
expected returns: [[11.391357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 8.  3.  6. 10.  0. 10.  8. 10. 10.  6. 16. 22.  0.  3.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 21. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [16. 10. 15. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 3.0
Learning step: -1.6920950412750244
desired expected reward: 11.275914192199707






Player: 1 
cards in hand: [16. 10. 15. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 15. 16.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10. 15. 16.  8.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 21. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 10. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 16. 15. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15. 16.  8.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 21. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 10. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15. 16.  8.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0] -> size -> 44 
action values: 2 
buys: 1 
player value: 0 
card supply: [11. 24. 29. 21. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 10. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15. 16.  8.  3.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 21. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 10. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [10. 10. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 16.] 
expected returns: [[48.553818]
 [46.86575 ]
 [46.86575 ]
 [46.885754]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 16.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 21. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 15.  3.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -1.190069556236267
desired expected reward: 10.201288223266602



action possibilites: [-1] 
expected returns: [[35.368942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 15.  3.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 1 

action type: gain_card_n - action 1
Learning step: -1.7012380361557007
desired expected reward: 49.23954772949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.795319]
 [29.795856]
 [32.867626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 15.  3.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -1.1999772787094116
desired expected reward: 34.16896438598633






Player: 1 
cards in hand: [ 0.  0. 11. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 15.  3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10.  0.  3.  8.  8.] 
adversary cards in discard: [ 3. 16. 10. 10.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 15.  3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  1.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10.  0.  3.  8.  8.] 
adversary cards in discard: [ 3. 16. 10. 10.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 15.  3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10.  0.  3.  8.  8.] 
adversary cards in discard: [ 3. 16. 10. 10.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[15.613543]
 [14.688896]
 [14.684682]
 [14.684682]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8.  8.] 
cards in discard: [ 3. 16. 10. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  0. 14.  1.  0.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -2.4492268562316895
desired expected reward: 30.418399810791016



action possibilites: [-1.  8.  8.] 
expected returns: [[23.355976]
 [20.994476]
 [20.994476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 6.] 
cards in discard: [ 3. 16. 10. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  0. 14.  1.  0.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -0.37511786818504333
desired expected reward: 14.313774108886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.751472]
 [19.751602]
 [22.411827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 8. 6.] 
cards in discard: [ 3. 16. 10. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  0. 14.  1.  0.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -0.8317627310752869
desired expected reward: 22.52420997619629






Player: 1 
cards in hand: [15.  0. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 14.  1.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29  0 29 10  8  3  8 15  3 22 14 10
  0  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 24. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[3.409693 ]
 [3.5473173]
 [3.5640132]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  3.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10 11  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 15. 10. 10. 10.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -2.1909866333007812
desired expected reward: 20.220834732055664



action possibilites: [-1] 
expected returns: [[-0.71663666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 15. 10. 10. 10.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.38528379797935486
desired expected reward: 3.997905969619751





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.7166367]
 [-0.7166367]
 [-0.7166367]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 15. 10. 10. 10.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -0.13029249012470245
desired expected reward: -0.846929132938385



buy possibilites: [-1] 
expected returns: [[-0.71663666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0. 15. 10. 10. 10.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -1.630292534828186
desired expected reward: -2.3469290733337402






Player: 1 
cards in hand: [ 0. 15. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 10. 10.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 15. 10. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 10. 29.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  0
  8  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 46 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 4 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 29. 15. 10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 45 
action values: 2 
buys: 0 
player value: 4 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 29. 15. 10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 23. 29. 20. 30.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 29. 15. 10.] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 20. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3. 22.  0.  0.] 
adversary cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[16.38377 ]
 [15.881913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 22.  0.  0.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 20. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 14.  8. 10.  0.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 46 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -2.248112678527832
desired expected reward: -2.964749336242676





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.780233]
 [14.807614]
 [14.780281]
 [15.408475]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 22.  0.  0.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 20. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 14.  8. 10.  0.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 46 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -3.091804265975952
desired expected reward: 12.58263874053955



buy possibilites: [-1] 
expected returns: [[-0.71796703]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 22.  0.  0.] 
cards in discard: [ 3. 16. 10. 10.  6. 10.  0.  3.  8.  8.  6.  0.  8.  0.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 14.  8. 10.  0.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.] 
adversary owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -34 

action type: buy - action 3.0
Learning step: -2.4565351009368896
desired expected reward: 12.351082801818848






Player: 1 
cards in hand: [ 3. 14.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8. 10.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1  3 10 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8
  0 25  0  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3] -> size -> 23 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[42.631054]
 [36.837364]
 [36.869606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 1. 25.  0. 22.  1.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -0.6444949507713318
desired expected reward: -1.362462043762207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.33144 ]
 [36.331898]
 [43.06895 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 23. 29. 19. 29.  8.  6.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 1. 25.  0. 22.  1.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -2.8086698055267334
desired expected reward: 39.8223762512207



buy possibilites: [-1] 
expected returns: [[16.986153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  8. 10.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 1. 25.  0. 22.  1.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -343.0 

action type: buy - action 6.0
Learning step: -18.58440589904785
desired expected reward: 17.747488021850586






Player: 1 
cards in hand: [ 1. 25.  0. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 22.  1.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  1. 11. 16.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.  1. 11. 16.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  6.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.  1. 11. 16.  0.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  6. 10.  0.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [22.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[30.91603 ]
 [29.470968]
 [29.429918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6. 10.  0.  0.] 
cards in discard: [ 6.  3.  3.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 15. 29.  3.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -2.3137402534484863
desired expected reward: 14.672412872314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[30.03143]
 [30.05775]
 [30.03149]
 [32.1805 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6. 10.  0.  0.] 
cards in discard: [ 6.  3.  3.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 15. 29.  3.] 
adversary cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -2.9882402420043945
desired expected reward: 27.92778778076172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 29.  3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 16.  8. 10.  6.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 16.  8. 10.  6.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 10.  6.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  5.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 10.  6.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 10. 16. 15. 16.  8.  3.  8.  0.  0. 11. 15.  3.  1. 15. 14.  1.  0.
  0. 10.  4. 10. 29. 15. 10.  0.  8. 14. 29. 22.  8.  1. 25.  0.  1. 11.
 16.  0.  0. 15. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 10.  6.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[12.477433 ]
 [ 7.3032007]
 [ 7.32832  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.] 
cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  3. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: discard_down_to_3_cards - action 7
Learning step: -4.90032958984375
desired expected reward: 55.0136833190918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.347022 ]
 [ 6.34747  ]
 [12.4066725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.] 
cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  3. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -2.536245107650757
desired expected reward: 9.941191673278809



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  3. 29.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29.  8. 29.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.  8. 10.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.] 
cards in discard: [15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.  8. 10.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.] 
cards in discard: [15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.  8. 10.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.07759583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15. 11. 10. 10.  4.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -2.7720799446105957
desired expected reward: 9.63459587097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-0.71796703]
 [-0.71796703]
 [-0.71796703]
 [ 0.29885742]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 19. 29.  8.  5.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15. 11. 10. 10.  4.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -2.1472349166870117
desired expected reward: -2.2248306274414062



buy possibilites: [-1] 
expected returns: [[21.396631]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  8. 10. 22.  6. 10.  0.  0. 16.  8.  8. 10.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15. 11. 10. 10.  4.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -354.0 

action type: buy - action 6.0
Learning step: -17.18267822265625
desired expected reward: -17.900646209716797






Player: 1 
cards in hand: [15. 11. 10. 10.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10. 10.  4.] 
cards in discard: [15.  8. 29.  3. 29.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 15. 11. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10.  4. 16.] 
cards in discard: [15.  8. 29.  3. 29.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 10.  4. 16.] 
cards in discard: [15.  8. 29.  3. 29.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.877954]
 [20.427752]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -3.250310182571411
desired expected reward: 18.146320343017578



action possibilites: [-1.] 
expected returns: [[35.187283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action 10.0
Learning step: -1.929673433303833
desired expected reward: 18.49807357788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[32.474483]
 [32.649685]
 [32.474796]
 [36.895885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -2.662841558456421
desired expected reward: 32.52444076538086






Player: 1 
cards in hand: [1. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  0
  3 16  0 15  0  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 0. 6. 8. 6.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[22.61554 ]
 [18.746834]
 [18.746834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [10.  0.  0.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10.  0.  3. 15.  1.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0] -> size -> 43 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -3.6965320110321045
desired expected reward: 25.880878448486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.842876]
 [17.842876]
 [22.801716]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 8. 6.] 
cards in discard: [10.  0.  0.  3.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10.  0.  3. 15.  1.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0] -> size -> 43 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -3.3517205715179443
desired expected reward: 19.263830184936523



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  3. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 15.  1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3. 10. 16. 10.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3. 10. 16. 10.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 23. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3. 10. 16. 10.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 22. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3.  3. 10. 16. 10.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 10.] 
expected returns: [[5.2272453]
 [1.7454519]
 [1.7575881]
 [1.7454519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 16. 10.] 
cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 16.  0.  3.  0.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1] -> size -> 43 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -3.749284505844116
desired expected reward: 19.052438735961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.8129356]
 [1.8129356]
 [5.3457327]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 16. 10.] 
cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  4.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 16.  0.  3.  0.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1] -> size -> 43 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -2.86529278755188
desired expected reward: 2.3619563579559326



buy possibilites: [-1] 
expected returns: [[40.341125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 16. 10.] 
cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [10. 16.  0.  3.  0.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.] 
adversary owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1] -> size -> 43 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -365 

action type: buy - action 6.0
Learning step: -17.432971954345703
desired expected reward: -15.620036125183105






Player: 1 
cards in hand: [10. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0.  3.  0.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8.  3. 22. 10.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.  1.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11 11  1 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3
 16 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 19. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8.  3. 22. 10.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 18. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8.  3. 22. 10.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 22. 29. 18. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8.  3. 22. 10.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 29. 18. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8.  3. 22. 10.  3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 22. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 10.] 
expected returns: [[118.58841]
 [117.86041]
 [117.90788]
 [117.86823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 22. 10.  3.] 
cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 18. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 15. 22. 11.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -3.104287624359131
desired expected reward: 37.236839294433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.089195]
 [117.089195]
 [117.87831 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 22. 10.  3.] 
cards in discard: [10.  0.  0.  3.  3.  6.  8.  0.  6.  8.  6.  6.  3.  3. 10. 16. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 22. 29. 18. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0. 15. 22. 11.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0] -> size -> 44 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -7.032567024230957
desired expected reward: 111.55585479736328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 15. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 22. 11.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 18. 29.  8.  3.  4.  6.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 22.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 18. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 22.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 29. 18. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 22.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [8. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[59.642513]
 [57.29062 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  8. 29. 14. 14.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -8.814047813415527
desired expected reward: 109.06427764892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[55.848934]
 [55.96049 ]
 [55.848934]
 [58.607403]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  8. 29. 14. 14.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 46 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.934438705444336
desired expected reward: 53.70807647705078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 29. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 14. 14.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 14 10  8 25  3 16
 15  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 16.  3.  3.  6.] 
adversary cards in discard: [8. 6. 6. 0. 0.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 14.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 16.  3.  3.  6.] 
adversary cards in discard: [8. 6. 6. 0. 0.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 14.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 16.  3.  3.  6.] 
adversary cards in discard: [8. 6. 6. 0. 0.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[38.155006]
 [38.38496 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  3.  6.] 
cards in discard: [8. 6. 6. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15. 14.  8. 25. 29.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.  8.  0.
 29. 14.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -6.317890644073486
desired expected reward: 52.28951644897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[38.62998]
 [38.62998]
 [38.35331]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  3.  6.] 
cards in discard: [8. 6. 6. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15. 14.  8. 25. 29.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.  8.  0.
 29. 14.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.289523601531982
desired expected reward: 32.865482330322266



buy possibilites: [-1] 
expected returns: [[35.011463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  3.  6.] 
cards in discard: [8. 6. 6. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15. 14.  8. 25. 29.] 
adversary cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.  8.  0.
 29. 14.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 45 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -115 

action type: buy - action 0.0
Learning step: -6.893741130828857
desired expected reward: 31.736228942871094






Player: 1 
cards in hand: [15. 14.  8. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8. 25. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  8. 25. 29.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.  8.  0.
 29. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10 14  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  8.  3. 10. 10.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 29.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.  8.  0.
 29. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  8.  3. 10. 10.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 25. 29.] 
cards in discard: [15.  8. 29.  3. 29.  1. 10. 15. 11. 10.  4. 16.  0.  8.  1.  1. 15. 10.
  3.  1.  3.  0. 10. 16.  0.  3.  0. 11.  3. 11.  0.  0. 15. 22.  8.  0.
 29. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  8.  3. 10. 10.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.] 
adversary owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[44.18969 ]
 [39.374695]
 [39.39866 ]
 [39.39866 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10. 10.] 
cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10  0 10 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6
  6  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 10. 15.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 44 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -5.043302059173584
desired expected reward: 29.96816062927246



action possibilites: [-1] 
expected returns: [[81.06911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 10. 15.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.845879316329956
desired expected reward: 33.55281066894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.5014 ]
 [74.5014 ]
 [77.07535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 3. 10. 15.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -6.136898994445801
desired expected reward: 74.93220520019531






Player: 1 
cards in hand: [ 3. 10. 15.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  0. 16.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
  0 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  3.  6.  8.  0.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  3.  6.  8.  0.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [22.  3.  6.  8.  0.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [22.  3.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
expected returns: [[75.81175 ]
 [75.62115 ]
 [75.699425]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  6.  8.  0.] 
cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 15. 15.  0.  4.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -6.273586273193359
desired expected reward: 57.292667388916016



action possibilites: [-1] 
expected returns: [[60.521416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 6. 0. 3.] 
cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 15. 15.  0.  4.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: LIBRARY: skip_action_card - action 0
Learning step: -5.231605052947998
desired expected reward: 70.6351318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[59.29    ]
 [59.358078]
 [59.29    ]
 [61.13358 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 6. 0. 3.] 
cards in discard: [ 8.  6.  6.  0.  0.  0.  3. 16.  3.  3.  6.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 15. 15.  0.  4.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1
Learning step: -4.464602947235107
desired expected reward: 56.05681228637695






Player: 1 
cards in hand: [ 8. 15. 15.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 15.  0.  4.] 
cards in discard: [ 0. 16.  3. 10. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10  0 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  4.] 
cards in discard: [ 0. 16.  3. 10. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  4.] 
cards in discard: [ 0. 16.  3. 10. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 22. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  4.] 
cards in discard: [ 0. 16.  3. 10. 15.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[52.28311]
 [48.7184 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [25. 14. 29. 22. 15.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -6.698629856109619
desired expected reward: 54.434940338134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.8311  ]
 [47.8311  ]
 [52.028934]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 21. 29. 17. 29.  8.  3.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [25. 14. 29. 22. 15.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -6.272271156311035
desired expected reward: 46.01084518432617



buy possibilites: [-1] 
expected returns: [[56.326675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  6. 10.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [25. 14. 29. 22. 15.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -407.0 

action type: buy - action 6.0
Learning step: -21.47420310974121
desired expected reward: 26.356897354125977






Player: 1 
cards in hand: [25. 14. 29. 22. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 29. 22. 15.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14. 29. 22. 15.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6. 16.  3.  6.  6.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14. 29. 15.  1.  0.  3.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6. 16.  3.  6.  6.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 29. 15.  1.  0.  3.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  5.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6. 16.  3.  6.  6.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 29. 15.  1.  0.  3.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  4.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 6. 16.  3.  6.  6.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[10.581206]
 [ 9.892294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  6.  6.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  4.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11] -> size -> 45 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -7.931797981262207
desired expected reward: 48.39487838745117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.070883]
 [10.070883]
 [10.853544]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  6.  6.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 21. 29. 17. 29.  8.  2.  4.  4.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11] -> size -> 45 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1.0
Learning step: -5.640219211578369
desired expected reward: 4.940986156463623



buy possibilites: [-1] 
expected returns: [[10.932891]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  3.  6.  6.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  4.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11] -> size -> 45 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action 0.0
Learning step: -7.107553958892822
desired expected reward: 2.963325023651123






Player: 1 
cards in hand: [ 0.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  4.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  4.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[79.13997]
 [75.60989]
 [75.60989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 1.  0. 29.  3. 16.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11] -> size -> 46 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -4.140185832977295
desired expected reward: 6.792705059051514





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[76.19888]
 [76.32484]
 [76.19888]
 [80.16399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 1.  0. 29.  3. 16.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11] -> size -> 46 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: take_action - action -1.0
Learning step: -7.533552646636963
desired expected reward: 71.60640716552734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 29.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  3. 16.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  3  8 15  3 22 10  8 25  3 16 15
 10 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  4.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 22.  0. 10.  0.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 22.  0. 10.  0.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 21. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 22.  0. 10.  0.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 20. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [ 8. 22.  0. 10.  0.] 
adversary cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [ 8. 22.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 10.] 
expected returns: [[74.42354 ]
 [69.72404 ]
 [70.090485]
 [69.74886 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 10.  0.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 20. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [29. 29. 11. 11.  0.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1] -> size -> 47 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1.0
Learning step: -7.2188944816589355
desired expected reward: 72.9450912475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[70.820206]
 [71.03529 ]
 [70.820206]
 [76.328384]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 10.  0.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 20. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [29. 29. 11. 11.  0.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1] -> size -> 47 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -6.895699977874756
desired expected reward: 67.52784729003906



buy possibilites: [-1] 
expected returns: [[93.17756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 22.  0. 10.  0.] 
cards in discard: [ 6.  6.  3.  0.  6. 10.  0.  6. 16.  3.  6.  6.  0.  3.  0.  8.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 20. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [29. 29. 11. 11.  0.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1] -> size -> 47 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -127.0 

action type: buy - action 0.0
Learning step: -7.794516086578369
desired expected reward: 63.02571105957031






Player: 1 
cards in hand: [29. 29. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 11.  0.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 29. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 20. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 0. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.7071173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  8. 10.  8.  3.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.
 29. 11. 29. 11.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -9.425467491149902
desired expected reward: 83.75209045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.8802522]
 [1.8802522]
 [1.8051208]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  8. 10.  8.  3.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.
 29. 11. 29. 11.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -4.878159999847412
desired expected reward: -3.4739975929260254



buy possibilites: [-1] 
expected returns: [[12.065898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  8. 10.  8.  3.] 
adversary cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.
 29. 11. 29. 11.] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -127.0 

action type: buy - action 0.0
Learning step: -6.172530174255371
desired expected reward: -4.292276859283447






Player: 1 
cards in hand: [15.  8. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10.  8.  3.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.
 29. 11. 29. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  3.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.
 29. 11. 29. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  3.] 
cards in discard: [ 0. 16.  3. 10. 15.  1. 15.  8. 15.  4. 11. 22. 10. 25. 14. 29. 15.  1.
  0.  3. 11.  0.  0.  0.  3. 16. 16.  1. 16.  1.  0. 29.  0. 11.  1.  0.
 29. 11. 29. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [3. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 6. 3. 3.] 
adversary owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.605255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [0. 3. 0. 6. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  1.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -4.49467658996582
desired expected reward: 7.571221351623535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[43.370743]
 [43.318108]
 [43.370743]
 [42.254005]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [0. 3. 0. 6. 3. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  1.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -6.0074262619018555
desired expected reward: 36.59782791137695



Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3. 6. 3. 0. 0.] 
cards in discard: [0. 3. 0. 6. 3. 3. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  6  8  8 16  0  8  0  3  3 22  6 10  6  3  3  0  3  6  6  6  0
  6  0  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 19. 29. 17. 29.  8.  2.  3.  3.  0.  9.  4.  5. 10.  0.  8.  5.] 
adversary cards in hand: [15.  1.  1.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 11 11 10 15 16 16 15  1 29 29 10  8  8 15  3 22 10  8 25  3 16 15 10
 14  1  0  0  0  0  8  1  4 29 29  0  1  3  0 11  3  0  1 11 11 16  1  1
  0] -> size -> 49 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -90    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -627 

action type: buy - action 0.0
Learning step: -33.51853561401367
desired expected reward: 9.85219955444336



