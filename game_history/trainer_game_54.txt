 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[329.48138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1 -120    0    0   20    0    0    0    0   -4    0    0
    4    0] 
sum of rewards: -606 

action type: buy - action 8.0
Learning step: -29.896759033203125
desired expected reward: -37.9615592956543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[306.721  ]
 [317.4038 ]
 [315.05026]
 [287.13455]
 [325.72495]
 [315.35556]
 [313.29016]
 [332.31058]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.42876148223877
desired expected reward: 323.3865966796875



buy possibilites: [-1] 
expected returns: [[316.6284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -8.078372955322266
desired expected reward: 306.97186279296875






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.56494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -8.326238632202148
desired expected reward: 308.3021545410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[285.42847]
 [297.4955 ]
 [294.93832]
 [266.54056]
 [290.69006]
 [307.09848]
 [295.11032]
 [299.82483]
 [276.98987]
 [292.8805 ]
 [290.66977]
 [315.54834]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.334994316101074
desired expected reward: 305.2286376953125



buy possibilites: [-1] 
expected returns: [[321.05942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -8.09758472442627
desired expected reward: 277.330810546875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.42007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.24815845489502
desired expected reward: 311.8112487792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[275.8979 ]
 [283.34213]
 [259.28027]
 [283.9479 ]
 [298.4695 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [ 3.  0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.733197212219238
desired expected reward: 295.9251708984375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [ 3.  0.  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3. 10.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[304.55478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: discard_down_to_3_cards - action 1
Learning step: -5.841068267822266
desired expected reward: 237.0508575439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[277.02576]
 [288.42593]
 [286.19696]
 [258.28214]
 [298.6982 ]
 [286.13943]
 [284.2263 ]
 [307.2237 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -9.062079429626465
desired expected reward: 295.5391845703125



buy possibilites: [-1] 
expected returns: [[304.48764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -9.050314903259277
desired expected reward: 267.97540283203125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 27. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.85156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [ 3. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: discard_down_to_3_cards - action 0
Learning step: -6.408730983734131
desired expected reward: 238.64117431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[272.1076 ]
 [284.1489 ]
 [281.69855]
 [251.75781]
 [293.67996]
 [281.76068]
 [279.64206]
 [301.10727]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [ 3. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -9.77934455871582
desired expected reward: 296.6101989746094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [ 3. 14.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 14.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 14.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -9.206363677978516
desired expected reward: 291.90087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[283.94257]
 [294.98303]
 [292.501  ]
 [265.2118 ]
 [303.55582]
 [292.79626]
 [290.60794]
 [310.0894 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -9.570815086364746
desired expected reward: 297.0513610839844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[280.24957]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -9.47950267791748
desired expected reward: 286.0866394042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[249.71814]
 [261.05573]
 [258.69946]
 [230.53511]
 [270.03445]
 [258.80322]
 [256.7572 ]
 [277.0842 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -9.098666191101074
desired expected reward: 273.07037353515625



buy possibilites: [-1] 
expected returns: [[275.1435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -19.0 

action type: buy - action 8.0
Learning step: -7.699432373046875
desired expected reward: 251.10379028320312






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.1815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 14.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -8.25040054321289
desired expected reward: 266.8930969238281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[271.77835]
 [281.94485]
 [279.1579 ]
 [253.9677 ]
 [276.06787]
 [289.19388]
 [280.11554]
 [283.64368]
 [263.99057]
 [277.57416]
 [275.6103 ]
 [294.10287]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 14.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -9.156064987182617
desired expected reward: 282.2561340332031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 14.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0.  0.  3.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0.  0.  3.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0.  0.  3.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[303.44485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: discard_down_to_3_cards - action 1
Learning step: -6.89645528793335
desired expected reward: 247.3876495361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[278.0255 ]
 [287.09406]
 [257.93335]
 [287.22784]
 [305.22455]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -9.644808769226074
desired expected reward: 295.58856201171875



buy possibilites: [-1] 
expected returns: [[285.25375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 3. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -13 

action type: buy - action 8.0
Learning step: -8.593184471130371
desired expected reward: 278.63470458984375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 10.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.12466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 8. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8] -> size -> 17 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -8.901225090026855
desired expected reward: 276.3525390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[274.0138 ]
 [281.65424]
 [278.6188 ]
 [260.9488 ]
 [277.0624 ]
 [286.52054]
 [280.51053]
 [282.56775]
 [267.93665]
 [277.6046 ]
 [275.9791 ]
 [290.579  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 8. 0. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8] -> size -> 17 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -8.875292778015137
desired expected reward: 276.07861328125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 8.  0.  0.  3.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  3.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [8. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[283.0558]
 [266.056 ]
 [266.056 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -9.344596862792969
desired expected reward: 281.2344055175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[257.66302]
 [266.2548 ]
 [237.91602]
 [267.14532]
 [283.25336]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -8.93828296661377
desired expected reward: 272.5163879394531



buy possibilites: [-1] 
expected returns: [[246.98611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -51.0 

action type: buy - action 0.0
Learning step: -9.87596607208252
desired expected reward: 247.78709411621094






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 14.] 
cards in discard: [ 8.  0.  0.  3.  3. 10. 10. 10.  0.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[240.6945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 8. 8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0] -> size -> 19 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -7.986425876617432
desired expected reward: 238.99969482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.82785]
 [232.32776]
 [207.22128]
 [232.93794]
 [246.33185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0. 8. 8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0] -> size -> 19 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -7.695837497711182
desired expected reward: 232.8766326904297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 0. 0. 3. 0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[261.04044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 8. 0. 0. 3. 0. 3. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0] -> size -> 20 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -7.061152935028076
desired expected reward: 229.5974578857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[248.83238]
 [256.71353]
 [253.84605]
 [239.52435]
 [235.16891]
 [252.06339]
 [262.07376]
 [255.33104]
 [269.70367]
 [257.49722]
 [242.32593]
 [247.31183]
 [252.60762]
 [238.89491]
 [250.81355]
 [265.5293 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 8. 0. 0. 3. 0. 3. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 8 8 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0] -> size -> 20 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -8.081683158874512
desired expected reward: 250.6640167236328



buy possibilites: [-1] 
expected returns: [[257.49734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  8.  0.  0.  3.  0.  3.  0.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0] -> size -> 20 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 29 

action type: buy - action 25.0
Learning step: -6.241496562957764
desired expected reward: 263.46221923828125






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[218.84804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3. 10. 10.  8.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  3.  0. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10] -> size -> 21 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -9.032832145690918
desired expected reward: 248.46450805664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[200.28395]
 [210.6305 ]
 [208.26253]
 [182.44516]
 [204.75572]
 [218.41956]
 [208.5743 ]
 [212.37383]
 [192.54233]
 [206.47572]
 [204.48615]
 [224.16663]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3. 10. 10.  8.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  3.  0. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10] -> size -> 21 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -7.04116678237915
desired expected reward: 210.38259887695312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [14.  3. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10. 10.  8.] 
cards in discard: [ 0. 10.  3.  0.  0.  3.  0. 10.  3.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10. 10.  8.] 
cards in discard: [ 0. 10.  3.  0.  0.  3.  0. 10.  3.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10. 10.  8.] 
cards in discard: [ 0. 10.  3.  0.  0.  3.  0. 10.  3.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[271.9207 ]
 [253.22594]
 [253.22594]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -6.2961530685424805
desired expected reward: 217.87046813964844



action possibilites: [-1] 
expected returns: [[317.48624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: trash_cards_n_from_hand - action 0
Learning step: -6.403755187988281
desired expected reward: 263.5401611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[293.41638]
 [302.67664]
 [272.03644]
 [303.33728]
 [321.63455]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -8.896307945251465
desired expected reward: 308.5899353027344



buy possibilites: [-1] 
expected returns: [[361.48477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -8.087410926818848
desired expected reward: 285.3289489746094






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[274.64566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 0. 8. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -13.056696891784668
desired expected reward: 348.4280700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[251.53769]
 [258.6621 ]
 [235.7434 ]
 [259.07385]
 [273.45023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 0. 8. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -8.541876792907715
desired expected reward: 261.1266784667969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 3. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 3.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[252.7973 ]
 [255.78569]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8. 10. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 14. 10.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -8.545737266540527
desired expected reward: 264.9044494628906



action possibilites: [-1] 
expected returns: [[279.93478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 14. 10.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 10 

action type: take_action - action 25.0
Learning step: -5.846625804901123
desired expected reward: 247.05653381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[257.25897]
 [268.31723]
 [265.00995]
 [238.5076 ]
 [275.39084]
 [266.21298]
 [263.1116 ]
 [279.79315]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 26. 30.  8.  9. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 14. 10.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -7.392843723297119
desired expected reward: 272.54193115234375






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14. 10.  3.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  3.  0.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 26. 30.  8.  9. 10. 10.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  0.  0.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.  0.  8.  3.  3.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[202.70921]
 [192.53664]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  0  8  8  0 25  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -9.647204399108887
desired expected reward: 270.1459655761719



action possibilites: [-1] 
expected returns: [[267.99948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 1
Learning step: -2.519979953765869
desired expected reward: 176.47938537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[243.89015]
 [256.00912]
 [252.69373]
 [223.24794]
 [264.4419 ]
 [253.71124]
 [250.67369]
 [270.04202]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -7.089158535003662
desired expected reward: 260.9103088378906






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[223.33801]
 [212.46017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3. 10.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.184636116027832
desired expected reward: 260.8573913574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[205.57285]
 [213.10799]
 [211.03513]
 [192.02681]
 [208.66258]
 [218.7474 ]
 [211.79327]
 [214.64511]
 [199.83638]
 [209.93552]
 [208.6483 ]
 [222.67113]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3. 10.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.742308139801025
desired expected reward: 213.956787109375



buy possibilites: [-1] 
expected returns: [[227.26778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [25.  3.  0.  3.  0.  0.  3.  8.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3. 10.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -7.265117645263672
desired expected reward: 198.30772399902344






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 10.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
action values: 3 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[224.2942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 10. 11.  0. 14.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.936641216278076
desired expected reward: 220.3311309814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[198.51654]
 [207.71822]
 [206.03993]
 [182.73047]
 [202.51375]
 [215.39256]
 [205.83379]
 [209.63521]
 [191.93806]
 [204.44286]
 [202.84534]
 [221.40672]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 10. 11.  0. 14.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.946038722991943
desired expected reward: 216.46499633789062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 11.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  0. 14.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 14.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 14.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[261.5248 ]
 [246.06645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.  8. 10. 11.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -5.896365642547607
desired expected reward: 215.5103759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.20442]
 [241.0481 ]
 [238.26291]
 [212.24672]
 [248.9475 ]
 [238.98248]
 [236.47218]
 [254.44086]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 26. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.  8. 10. 11.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.00980281829834
desired expected reward: 251.62478637695312



buy possibilites: [-1] 
expected returns: [[218.70685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 25. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.  8. 10. 11.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -6.942241191864014
desired expected reward: 231.32064819335938






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.  8. 10. 11.
 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 3. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.  8. 10. 11.
 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 25. 30.  8.  9. 10.  9.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 3. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [10. 10.  3.  0.  0.  0.  0.  0. 10. 10.  3.  0.  3. 10.  0.  8. 10. 11.
 14. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  9. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3. 3. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[224.457 ]
 [227.5575]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [0. 0. 0. 3. 0. 3. 3. 0. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  9. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -5.941707134246826
desired expected reward: 212.76513671875



action possibilites: [-1] 
expected returns: [[266.92215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3. 3. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0 11  6] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 25.0
Learning step: -4.233165264129639
desired expected reward: 220.5450897216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[254.00497]
 [261.17554]
 [259.12338]
 [241.28479]
 [257.04657]
 [266.04282]
 [259.81708]
 [262.11194]
 [248.31506]
 [257.92114]
 [256.41257]
 [269.87802]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3. 3. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0 11  6] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -6.433769226074219
desired expected reward: 260.4883728027344






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10
  0 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[189.0941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -8.293843269348145
desired expected reward: 261.5841369628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[166.05482]
 [175.23897]
 [173.36508]
 [148.93709]
 [182.67567]
 [173.29446]
 [171.68335]
 [188.33932]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -4.401088237762451
desired expected reward: 184.49032592773438



buy possibilites: [-1] 
expected returns: [[200.5612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10.  0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 37 

action type: buy - action 10.0
Learning step: -1.949652910232544
desired expected reward: 164.2959442138672






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [ 6.  8.  0. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 6.  8.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 6.  8.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 6.  8.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9. 10.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 6.  8.  0. 10.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[194.03163]
 [180.92268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10. 10.] 
adversary cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -4.861029624938965
desired expected reward: 195.70018005371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[171.98914]
 [181.24924]
 [178.71419]
 [156.95013]
 [187.47684]
 [179.40916]
 [177.06435]
 [191.89574]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10. 10.] 
adversary cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29] -> size -> 27 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -4.3602824211120605
desired expected reward: 185.69435119628906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 10.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10. 11.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10. 11.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10. 11.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[216.87077]
 [200.66718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.  0.  0.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -3.882434606552124
desired expected reward: 188.01332092285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[198.03394]
 [206.79448]
 [205.17883]
 [185.6026 ]
 [201.81236]
 [214.49075]
 [204.76619]
 [208.46225]
 [192.43271]
 [203.59618]
 [202.00217]
 [220.53552]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [10.  0.  3.  0.  0.  3.  0.  0.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0] -> size -> 28 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -4.987325191497803
desired expected reward: 209.9352569580078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 11.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  9.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [ 6.  8.  0. 10.  3. 29. 10. 10.  0.  0.  0.  0. 14.  0. 10.  0.  0.  6.
 10. 11. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[155.58646]
 [156.57661]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 25. 30.  8.  8. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0] -> size -> 30 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -6.590875148773193
desired expected reward: 213.94464111328125



action possibilites: [-1] 
expected returns: [[169.95406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action 25.0
Learning step: -1.982459306716919
desired expected reward: 153.14605712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[147.46608]
 [155.17693]
 [153.01575]
 [134.05438]
 [160.41974]
 [153.68687]
 [151.6964 ]
 [163.859  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -2.9646263122558594
desired expected reward: 166.9894256591797



buy possibilites: [-1] 
expected returns: [[113.1434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.  8.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: -4.377578258514404
desired expected reward: 143.08851623535156






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0.  3.] 
cards in discard: [6. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[159.47202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: -0.6190498471260071
desired expected reward: 112.52435302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[157.6896 ]
 [162.1715 ]
 [160.07733]
 [149.49069]
 [159.43301]
 [164.26323]
 [161.5216 ]
 [162.4185 ]
 [153.61153]
 [159.47719]
 [158.38823]
 [164.75505]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -2.864814043045044
desired expected reward: 156.60720825195312



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  6.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[103.58816 ]
 [ 95.771385]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: -4.492476940155029
desired expected reward: 160.26263427734375



action possibilites: [-1] 
expected returns: [[136.64865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: trash_cards_n_from_hand - action 4
Learning step: 1.1519325971603394
desired expected reward: 88.60517120361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.77703]
 [110.50878]
 [141.67314]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: -1.3431366682052612
desired expected reward: 135.30551147460938



buy possibilites: [-1] 
expected returns: [[151.11319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  0. 10.  8.  0.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 19.0 

action type: buy - action 0.0
Learning step: -1.7869106531143188
desired expected reward: 121.99010467529297






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 25. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [3. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[144.1685]
 [130.7059]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -3.444124698638916
desired expected reward: 147.6690673828125



action possibilites: [-1] 
expected returns: [[185.21622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.8733440637588501
desired expected reward: 127.94083404541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[163.59525]
 [170.02158]
 [152.73253]
 [168.74104]
 [184.76898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 11.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -3.8558831214904785
desired expected reward: 181.36033630371094






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[123.188675]
 [124.99315 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  0.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  7. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -6.115806579589844
desired expected reward: 178.65316772460938



action possibilites: [-1] 
expected returns: [[130.7296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0. 8.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 29 

action type: take_action - action 25.0
Learning step: -1.6750946044921875
desired expected reward: 119.65512084960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[114.24292 ]
 [120.395004]
 [117.89545 ]
 [ 99.476944]
 [116.68855 ]
 [123.68343 ]
 [119.31333 ]
 [120.81349 ]
 [107.699615]
 [116.9013  ]
 [115.443016]
 [125.364746]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 8.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 29.  0.] 
adversary cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -2.396251678466797
desired expected reward: 128.33334350585938






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 10.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 6.  0.  0.  3. 14.  0.  3. 10.  3.  0.  0.  6.  3.  8.  3.  0. 10.  0.
  0. 11. 10.  0. 11.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[118.53603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -2.701176881790161
desired expected reward: 122.66356658935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 95.21045 ]
 [103.78713 ]
 [102.003845]
 [ 85.20831 ]
 [ 81.50939 ]
 [ 98.96481 ]
 [110.63622 ]
 [101.95767 ]
 [117.640594]
 [105.09457 ]
 [ 88.7738  ]
 [ 95.26643 ]
 [100.39968 ]
 [ 85.41482 ]
 [ 98.6848  ]
 [115.796295]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  8.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -2.5476531982421875
desired expected reward: 115.9883804321289



buy possibilites: [-1] 
expected returns: [[105.22754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3. 25.  0.  0.  3.  0.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 22.5 

action type: buy - action 11.0
Learning step: -2.039191484451294
desired expected reward: 108.5970230102539






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  7.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[85.47754]
 [72.54523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -2.5073113441467285
desired expected reward: 102.72023010253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[70.92092 ]
 [76.643974]
 [59.69632 ]
 [76.63341 ]
 [88.21195 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 10.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -1.4910749197006226
desired expected reward: 83.52378845214844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [11.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 10.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 30. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[107.7265 ]
 [104.57036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0.  0.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  8. 14.  6.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -1.1010665893554688
desired expected reward: 87.11087799072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 86.15536 ]
 [ 96.21227 ]
 [ 93.39129 ]
 [ 71.12811 ]
 [ 90.4972  ]
 [102.740524]
 [ 94.16846 ]
 [ 97.13777 ]
 [ 78.033485]
 [ 91.539764]
 [ 89.23059 ]
 [106.94996 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0.  0.  3. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0.  8. 14.  6.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -2.2207205295562744
desired expected reward: 105.50578308105469



buy possibilites: [-1] 
expected returns: [[74.556915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0.  0.  3. 10.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  8. 14.  6.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 50 

action type: buy - action 15.0
Learning step: -0.28399887681007385
desired expected reward: 88.94659423828125






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [10.  0.  8. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 14.  6.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  6.  6.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  0.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0  6 11 10  0
 11  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 24. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 14.  8.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 23. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[112.77676]
 [115.89271]
 [104.32159]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.] 
cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  6. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: discard_down_to_3_cards - action 1
Learning step: -3.8335556983947754
desired expected reward: 122.1010513305664



action possibilites: [-1] 
expected returns: [[128.55136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  5. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: -1.9522297382354736
desired expected reward: 113.94047546386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[117.26401]
 [122.10314]
 [107.90489]
 [121.77413]
 [131.45634]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 23. 30.  8.  5. 10.  7.  6.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -2.672814130783081
desired expected reward: 125.87854766845703



buy possibilites: [-1] 
expected returns: [[105.87108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 0.  0.  3. 10.  3. 15.  0.  0.  0.  0. 11.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  5. 10.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 26 

action type: buy - action 8.0
Learning step: -2.4066083431243896
desired expected reward: 119.36753845214844






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  5. 10.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 23. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 23. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.267622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -5.117532253265381
desired expected reward: 100.75354766845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 6.7683854]
 [ 9.088423 ]
 [ 9.125345 ]
 [ 2.71111  ]
 [ 7.539932 ]
 [12.888855 ]
 [ 8.480986 ]
 [10.228086 ]
 [ 5.563627 ]
 [ 8.654898 ]
 [ 8.205725 ]
 [16.3395   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -0.4141402840614319
desired expected reward: 11.85348129272461



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 25.  8.  0. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 25.  8.  0. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 25.  8.  0. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 25.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8. 15.] 
expected returns: [[72.288445]
 [61.701557]
 [73.00001 ]
 [62.584133]
 [60.828617]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  8.  0. 15.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  5.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0. 29.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: 0.662756085395813
desired expected reward: 17.00225067138672



action possibilites: [-1] 
expected returns: [[104.318825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 15.  8.  0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0. 29.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: -0.35282784700393677
desired expected reward: 72.6471939086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.115395]
 [ 96.34766 ]
 [ 81.18086 ]
 [ 97.46324 ]
 [105.1232  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 15.  8.  0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0. 29.] 
adversary cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -2.0475261211395264
desired expected reward: 102.27130126953125






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 29.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 22. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 10.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6] -> size -> 43 
action values: 2 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 22. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 10.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 10.] 
cards in discard: [ 8. 29.  6.  0. 10.  6.  0.  1.  0. 10. 11.  0.  0. 10.  0.  3. 10. 14.
  8.  0.  6.  6. 16.  3. 11.  3.  0.  3.  0.  0. 10.  0.  0.  0.  0.  6.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[92.41854]
 [89.36826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 14.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -3.2905776500701904
desired expected reward: 101.83261108398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[80.7274  ]
 [86.01988 ]
 [85.114784]
 [71.09244 ]
 [83.05972 ]
 [90.36216 ]
 [84.87535 ]
 [86.99055 ]
 [76.74021 ]
 [84.12823 ]
 [83.14156 ]
 [93.82926 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 29. 30. 21. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 14.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -2.700385332107544
desired expected reward: 89.71817016601562



buy possibilites: [-1] 
expected returns: [[-0.22278595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [ 0.  0.  0.  0.  3. 25. 10.  8.  0. 15.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 14.  6.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -3.710752248764038
desired expected reward: 81.40403747558594






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [11. 14.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  6.  8.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  6.  8.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  6.  8.  0.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  3.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[ 4.138233 ]
 [-3.3584807]
 [-3.535837 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3.  6. 10. 29.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: 0.5083760023117065
desired expected reward: 0.2855900526046753





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-4.5240135]
 [-5.7436905]
 [ 6.62542  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  3.  6. 10. 29.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: 0.32104453444480896
desired expected reward: 4.459280967712402



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  6. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 10. 29.] 
cards in discard: [ 0. 11. 14.  6.  8.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 15.] 
adversary cards in discard: [10.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 29.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 15.] 
adversary cards in discard: [10.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 29.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  8.  3.  0. 15.] 
adversary cards in discard: [10.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  8.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[29.264194]
 [25.292347]
 [23.512878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 15.] 
cards in discard: [10.  3.  8.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: 0.7477719187736511
desired expected reward: 7.373200416564941





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.00255 ]
 [27.357811]
 [19.1207  ]
 [27.725046]
 [31.64447 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3.  0. 15.] 
cards in discard: [10.  3.  8.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -0.35086965560913086
desired expected reward: 28.913330078125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 29. 30. 20. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  8.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [11.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[11.459979 ]
 [ 9.049182 ]
 [ 6.2326307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [29.  1.  3.  0.  3.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -1.3817424774169922
desired expected reward: 29.948171615600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.388881 ]
 [11.78363  ]
 [12.083999 ]
 [ 7.2582636]
 [13.833148 ]
 [11.467771 ]
 [11.864418 ]
 [15.791209 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [29.  1.  3.  0.  3.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -0.30382150411605835
desired expected reward: 11.156149864196777



buy possibilites: [-1] 
expected returns: [[66.61558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29.  1.  3.  0.  3.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 17 

action type: buy - action 10.0
Learning step: 1.7556297779083252
desired expected reward: 13.62004280090332






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [29.  1.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  0.  3.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 29. 30. 19. 30.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[29.766178]
 [30.772236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10. 11.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0. 10. 10. 16.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -4.192966938018799
desired expected reward: 62.422611236572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.245396]
 [24.440071]
 [23.314442]
 [11.511126]
 [21.520748]
 [28.186745]
 [23.324081]
 [25.159725]
 [15.715093]
 [22.327835]
 [21.254894]
 [30.914997]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [10.  3.  8.  0.  3.  0.  8.  3.  0. 15. 10. 11.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 29. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 6.  0. 10. 10. 16.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -2.421389579772949
desired expected reward: 27.34478759765625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 10. 16.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11
  6 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 10.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [11. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[41.137203]
 [38.35472 ]
 [32.38911 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -2.205029249191284
desired expected reward: 28.70996856689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.372856]
 [19.655659]
 [40.62372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1] -> size -> 47 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -2.793273687362671
desired expected reward: 38.34391403198242



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  0.] 
adversary cards in discard: [11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  0.] 
adversary cards in discard: [11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  0.  0.] 
adversary cards in discard: [11. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [ 0.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[83.29669]
 [74.70313]
 [70.99262]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  0.  0.] 
cards in discard: [11. 10.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -1.7702007293701172
desired expected reward: 38.853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.12775 ]
 [77.354355]
 [75.19139 ]
 [57.0491  ]
 [82.17051 ]
 [75.918945]
 [73.888916]
 [84.997795]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  0.  0.] 
cards in discard: [11. 10.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 19. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -3.896822452545166
desired expected reward: 79.3998794555664



buy possibilites: [-1] 
expected returns: [[73.71618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 15.  0.  0.] 
cards in discard: [11. 10.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -18.0 

action type: buy - action 3.0
Learning step: -3.0009560585021973
desired expected reward: 72.19044494628906






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [ 0.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[28.938793]
 [23.354816]
 [24.186462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  8.  3. 11.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -4.065941333770752
desired expected reward: 69.65023803710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.000011]
 [25.49899 ]
 [17.281223]
 [25.757145]
 [30.509464]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  8.  3. 11.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -1.8158127069473267
desired expected reward: 27.122968673706055



buy possibilites: [-1] 
expected returns: [[74.98848]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  8.  3. 11.] 
adversary cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -50.0 

action type: buy - action 0.0
Learning step: -1.9627596139907837
desired expected reward: 21.037248611450195






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10.  3.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3. 11.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 11.  0.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 11 10  0 11  6
 29  0 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0
 10] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 11. 14.  6.  8.  0. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.  3.  0.
  4. 29.  1.  3.  0.  3.  0.  1. 16.  6.  0. 10.  0.  0.  6.  6. 10.  0.
 10. 10.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[45.78611 ]
 [39.881413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -3.746018648147583
desired expected reward: 71.24246215820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[40.32012 ]
 [43.69282 ]
 [42.358425]
 [35.513885]
 [45.696033]
 [43.17352 ]
 [47.637096]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -2.26291561126709
desired expected reward: 43.523189544677734



buy possibilites: [-1] 
expected returns: [[56.25783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [11. 10.  3.  3.  0.  3.  0.  8. 15.  0.  0.  0.  0.  3.  0. 10.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -50.0 

action type: buy - action 0.0
Learning step: -3.169180154800415
desired expected reward: 37.15093994140625






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0] -> size -> 26 
adversary victory points: 5
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[96.043465]
 [97.59806 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  4.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10] -> size -> 47 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -1.6239866018295288
desired expected reward: 54.633846282958984



action possibilites: [-1] 
expected returns: [[32.758656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  3.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6] -> size -> 48 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action 25.0
Learning step: -4.142833232879639
desired expected reward: 93.4552230834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[23.909285]
 [27.266123]
 [26.243145]
 [20.638727]
 [25.250237]
 [29.689842]
 [26.573431]
 [27.641771]
 [22.390755]
 [24.82646 ]
 [31.865147]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 28. 30. 18. 29.  8.  3.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6] -> size -> 48 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -0.9739290475845337
desired expected reward: 31.784727096557617



buy possibilites: [-1] 
expected returns: [[58.33388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.  3.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6] -> size -> 48 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -311.0 

action type: buy - action 6.0
Learning step: -15.269424438476562
desired expected reward: 5.3693084716796875






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 10.  3. 10.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  8.  0.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 10.  3. 10.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  9.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  8.  0.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  8.  0.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0  6] -> size -> 27 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0. 15.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[55.264973]
 [47.34634 ]
 [48.68762 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  8.  0.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3
  0  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [14.  0.  8.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -2.7670652866363525
desired expected reward: 55.56681442260742



action possibilites: [-1] 
expected returns: [[34.822872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [14.  0.  8.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action 15.0
Learning step: -1.6338024139404297
desired expected reward: 45.71253967285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[27.267103]
 [32.19015 ]
 [31.041897]
 [21.232187]
 [18.665215]
 [29.433262]
 [35.311752]
 [31.34024 ]
 [39.1807  ]
 [32.761665]
 [23.37587 ]
 [26.985163]
 [21.230602]
 [29.113867]
 [37.729717]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [14.  0.  8.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -1.0008069276809692
desired expected reward: 33.82206344604492



buy possibilites: [-1] 
expected returns: [[35.506897]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [14.  0.  8.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 49 

action type: buy - action 25.0
Learning step: 1.289870262145996
desired expected reward: 40.4705696105957






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [14.  0.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0. 16.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  0. 16.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 18. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  0. 16.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  0.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [ 3.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[8.038665 ]
 [4.3356752]
 [4.756814 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8.  0.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  4.  1.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3] -> size -> 50 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -3.165595769882202
desired expected reward: 32.34130096435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.6437674]
 [4.305359 ]
 [9.392171 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  8.  0.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 17. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  4.  1.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3] -> size -> 50 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -1.770349144935608
desired expected reward: 6.268314838409424



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  4.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  4.  1.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.  3.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  4.  1.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 17. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.  3.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  4.  1.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.  3.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
adversary victory points: 4
player victory points: 8 





Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[47.786808]
 [45.979977]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.  3.  3. 10.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1.0
Learning step: -1.4526008367538452
desired expected reward: 7.939573764801025





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[39.183186]
 [42.806004]
 [40.969727]
 [32.52431 ]
 [44.261715]
 [42.312813]
 [44.202408]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.  3.  3. 10.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  5.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -3.473998785018921
desired expected reward: 44.312801361083984



buy possibilites: [-1] 
expected returns: [[6.842967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 6. 25.  0.  0.  0.  0. 10.  3. 25. 15.  0.  8.  0.  3.  3. 10.  8.  0.
  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3. 11. 10. 29.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -39.0 

action type: buy - action 8.0
Learning step: -3.9116737842559814
desired expected reward: 38.40113067626953






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10. 29.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8] -> size -> 28 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11. 10. 29.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8] -> size -> 28 
adversary victory points: 4
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[18.904158]
 [19.210999]
 [17.54468 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 16. 29.  8.  2.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3] -> size -> 51 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -1.9658674001693726
desired expected reward: 4.877099514007568



action possibilites: [-1] 
expected returns: [[28.332687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6] -> size -> 52 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action 25.0
Learning step: -1.373063087463379
desired expected reward: 17.837905883789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.478909]
 [22.856977]
 [14.471692]
 [23.266035]
 [28.3574  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 10. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 28. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6] -> size -> 52 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1
Learning step: -1.8872959613800049
desired expected reward: 26.445390701293945



buy possibilites: [-1] 
expected returns: [[58.357338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 10. 10.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 28. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6] -> size -> 52 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -51.0 

action type: buy - action 0.0
Learning step: -2.1577908992767334
desired expected reward: 16.258827209472656






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 15.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 15.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 15.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [ 3.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[54.521294]
 [49.957687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 15.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  6.  0. 10.  8.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -3.2618370056152344
desired expected reward: 55.09550094604492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.066128]
 [50.94804 ]
 [45.448616]
 [50.733376]
 [54.718018]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 15.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  6.  0. 10.  8.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -3.086050271987915
desired expected reward: 51.435245513916016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [10.  6.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 10.  8.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  8.  6.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 16. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 6. 0.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
adversary victory points: 4
player victory points: 8 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[38.092678]
 [38.203907]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 29.  8.  1.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3] -> size -> 54 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1.0
Learning step: -3.9268176555633545
desired expected reward: 50.79119873046875



action possibilites: [-1] 
expected returns: [[140.98969]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8. 0.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6] -> size -> 55 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -20 

action type: take_action - action 25.0
Learning step: 0.2620723843574524
desired expected reward: 38.46598434448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[129.08128 ]
 [133.41827 ]
 [131.76854 ]
 [130.76201 ]
 [136.79668 ]
 [132.59048 ]
 [133.846   ]
 [125.433304]
 [130.0092  ]
 [138.56352 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8. 0.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 27. 30. 15. 29.  8.  0.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6] -> size -> 55 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1
Learning step: -5.039287090301514
desired expected reward: 135.9503936767578



buy possibilites: [-1] 
expected returns: [[12.972808]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8. 0.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6] -> size -> 55 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -51.0 

action type: buy - action 0.0
Learning step: -8.712176322937012
desired expected reward: 120.36912536621094






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.  3.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0. 25.  3.  0.  0.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  6.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0. 25.  3.  0.  0.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  6.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  4.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0. 25.  3.  0.  0.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  6.] 
cards in discard: [ 0.  0. 10.  3. 10.  6. 16.  1.  3.  0.  0.  0.  3. 14.  0.  8.  0. 16.
  3.  3.  0. 10.  4.  1.  3.  3. 11. 10. 29.  6.  1.  0.  0.  0.  3.  3.
  3. 10. 10.  6.  0.  8.  6.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0. 25.  3.  0.  0.
  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [3. 8. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[83.64384]
 [73.09492]
 [73.09492]
 [73.09492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 8.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0. 25.  3.  0.  0.
  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8] -> size -> 56 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -0.38842445611953735
desired expected reward: 12.584383010864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[67.08494]
 [82.70452]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 8. 8.] 
cards in discard: [ 0. 25.  0.  0.  3. 11. 10. 10.  3.  3.  0.  0. 15.  0. 25.  3.  0.  0.
  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8] -> size -> 56 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -3.942185640335083
desired expected reward: 79.7016372680664



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [0.] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.020176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  0.  6.] 
adversary cards in discard: [0. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0] -> size -> 57 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -4.379771709442139
desired expected reward: 78.32473754882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[43.00548 ]
 [49.785954]
 [48.03803 ]
 [54.027637]
 [48.33727 ]
 [56.166817]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  0.  6.] 
adversary cards in discard: [0. 0. 6. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0] -> size -> 57 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -3.2441632747650146
desired expected reward: 54.7760124206543



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  0.  6.] 
cards in discard: [0. 0. 6. 3. 6. 0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  6.] 
cards in discard: [0. 0. 6. 3. 6. 0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  6.] 
cards in discard: [0. 0. 6. 3. 6. 0. 0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[57.35009]
 [50.7393 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [3. 0. 0. 6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0] -> size -> 58 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -3.0979485511779785
desired expected reward: 53.06886291503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[46.798492]
 [49.78844 ]
 [49.6763  ]
 [52.913372]
 [49.083046]
 [55.832844]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [3. 0. 0. 6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 11.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0] -> size -> 58 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -3.207991123199463
desired expected reward: 54.14210891723633



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [10.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.  3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3.  0.  8. 11.] 
adversary cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0] -> size -> 58 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  3.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3.  0.  8. 11.] 
adversary cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3.  0.  8. 11.] 
adversary cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3.  0.  8. 11.] 
adversary cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [25.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
expected returns: [[48.883972]
 [49.527565]
 [41.23739 ]
 [46.0317  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  8. 11.] 
cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 4.  3.  0. 29.  1.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -3.2554614543914795
desired expected reward: 52.577396392822266



action possibilites: [-1] 
expected returns: [[69.56333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11.  3.  8.] 
cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 4.  3.  0. 29.  1.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action 25.0
Learning step: -1.4612027406692505
desired expected reward: 48.06634521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.907658]
 [70.00901 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 11.  3.  8.] 
cards in discard: [3. 0. 0. 6. 0. 0. 3. 0. 8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 4.  3.  0. 29.  1.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1
Learning step: -2.5305309295654297
desired expected reward: 67.03279876708984






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 4.  3.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3.  0. 29.  1.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  0. 29.  1.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  0. 29.  1.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  0.  3.  0. 10.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [25.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[-8.889413]
 [-9.214474]
 [-8.791273]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0. 10.] 
cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -5.02832555770874
desired expected reward: 60.55057907104492



action possibilites: [-1. 25.] 
expected returns: [[23.802502]
 [23.062826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -10 

action type: take_action - action 10.0
Learning step: 0.4717644155025482
desired expected reward: -8.319497108459473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[19.971548]
 [23.147564]
 [22.568518]
 [26.2294  ]
 [22.467339]
 [28.62533 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -1.1395095586776733
desired expected reward: 22.662967681884766






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  0.  6.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8. 10.
 25.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8. 10.
 25.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8. 10.
 25.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [ 8.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[22.172773]
 [16.352385]
 [14.993486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8. 10.
 25.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  3.  0. 14.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -2.521686553955078
desired expected reward: 26.103620529174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[14.02453 ]
 [16.5656  ]
 [15.661148]
 [20.66345 ]
 [16.048807]
 [23.731878]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  0.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  0.  3.  0.  8.  0. 25.  3.  0.  8. 11.  3.  8. 10.
 25.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  3.  0. 14.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -2.178640127182007
desired expected reward: 19.99412727355957



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [29.  3.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 14.  3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 10.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.711136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: discard_down_to_3_cards - action 0
Learning step: -0.7153632044792175
desired expected reward: 14.861912727355957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[59.27269 ]
 [66.15399 ]
 [64.457664]
 [70.90633 ]
 [64.662   ]
 [74.28623 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -3.5336315631866455
desired expected reward: 68.17750549316406



buy possibilites: [-1] 
expected returns: [[-5.603868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 10.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -13 

action type: buy - action 1.0
Learning step: -4.083786964416504
desired expected reward: 62.07020568847656






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 25.  0.  0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1] -> size -> 31 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  8. 25.  0.  0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1] -> size -> 31 
adversary victory points: 4
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  8. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[63.011738]
 [59.7663  ]
 [63.989765]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 25.  0.  0.] 
cards in discard: [10. 10.  1.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  8.  1.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: 0.15423476696014404
desired expected reward: -5.4496331214904785



action possibilites: [-1] 
expected returns: [[-6.7781706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  8.  1.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -10 

action type: take_action - action 25.0
Learning step: -3.851997137069702
desired expected reward: 60.13776779174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[-6.9772153]
 [-7.6988316]
 [-6.972641 ]
 [-7.2446027]
 [-7.55898  ]
 [-6.7781706]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  8.  1.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1
Learning step: -0.36747294664382935
desired expected reward: -7.145643711090088



buy possibilites: [-1] 
expected returns: [[98.942184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 10.  8.  1.  3.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: 0.5250598788261414
desired expected reward: -6.452155590057373






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [10. 10.  8.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  1.  3.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0
 29  0  6  0  3  6 10  8  1  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6
 16  3  3  6  1  3  6  8  0  0  8 11 11] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29
  0  6  0  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3
  3  6  1  3  6  8  0  0  8 11 11] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29
  0  6  0  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3
  3  6  1  3  6  8  0  0  8 11 11] -> size -> 59 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[29.846693]
 [24.078793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29
  0  6  0  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3
  3  6  1  3  6  8  0  0  8 11 11] -> size -> 59 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -5.351720333099365
desired expected reward: 93.59046173095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[20.549791]
 [25.290522]
 [23.77557 ]
 [22.547844]
 [28.146385]
 [24.352644]
 [25.54604 ]
 [16.537453]
 [21.72986 ]
 [29.639242]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29
  0  6  0  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3
  3  6  1  3  6  8  0  0  8 11 11] -> size -> 59 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -1.9283173084259033
desired expected reward: 27.918371200561523



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [10.  3.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.  0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  3  3 10  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29
  0  6  0  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3
  3  6  1  3  6  8  0  0  8 11 11] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3. 15.  8.  6.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29  0  6  0
  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1
  3  6  8  0  0  8 11 11] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3. 15.  8.  6.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29  0  6  0
  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1
  3  6  8  0  0  8 11 11] -> size -> 56 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3. 15.  8.  6.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29  0  6  0
  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1
  3  6  8  0  0  8 11 11  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [25.  3. 15.  8.  6.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [25.  3. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.  8.] 
expected returns: [[5.1364164]
 [4.7823133]
 [1.730073 ]
 [1.6298056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 15.  8.  6.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16. 10.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29  0  6  0
  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1
  3  6  8  0  0  8 11 11  0] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -1.4328737258911133
desired expected reward: 28.206375122070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.8200693]
 [5.3891892]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 15.  8.  6.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16. 10.] 
adversary cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29  0  6  0
  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1
  3  6  8  0  0  8 11 11  0] -> size -> 57 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -0.13537514209747314
desired expected reward: 3.5827784538269043



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16. 10.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11  6 29  0 29  0  6  0
  3  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1
  3  6  8  0  0  8 11 11  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 29.  8.  0.  8.  5.  2.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0. 25.  3. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0. 25.  3. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0. 25.  3. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0.  0.  6.  3.  6.  0.  0.  6. 16.  0.  0.  6.  8. 10. 11.  0.  0.  3.
  0. 11.  4.  3.  0. 29.  1. 10.  8.  3.  0.  6.  3.  0.  3. 11. 29. 14.
  3.  3.  1. 10.  3.  0.  0.  8. 10. 10.  0.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0. 25.  3. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[114.1597]
 [107.6216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0. 25.  3. 15.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8  0] -> size -> 58 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: 1.7194788455963135
desired expected reward: 7.108664512634277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 99.86224 ]
 [102.2388  ]
 [102.28583 ]
 [108.823944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [10. 10.  1.  0.  0.  0.  0. 25.  3.  8.  0.  0.  0.  3.  0.  8.  0.  0.
  0. 25.  3. 15.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8  0] -> size -> 58 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -3.8595314025878906
desired expected reward: 110.30015563964844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8  0] -> size -> 58 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  8.  5.  1.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
adversary victory points: 4
player victory points: 5 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 1 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 1 

Remodel: 0 
Workshop: 1 
Chapel: 4 
Witch: 2 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 25.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  8  8  0 25  0  0  3 10  0  0 11 15  8  3 10  3  0
  0  6 25  8  0  0  1  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 15. 29.  8.  0.  8.  5.  0.  8.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0 14  3  8 10  0  0 10  0 10  0 10  0 11 29  0 29  0  6  0  3
  6 10  8  0  3  6 16  3  0  6  3  0  3  4  1  0 10  6 16  3  3  6  1  3
  6  8  0  0  8 11 11  0  8  0  8] -> size -> 59 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5 -500    4  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -511 

action type: buy - action -1.0
Learning step: -30.991195678710938
desired expected reward: 77.83273315429688



