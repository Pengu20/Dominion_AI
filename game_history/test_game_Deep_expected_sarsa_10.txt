 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.0076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0 -160    0    0
    0    0] 
sum of rewards: -165 

action type: buy - action 0.0
Learning step: -6.4464569091796875
desired expected reward: -10.285030364990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[77.18634 ]
 [78.98068 ]
 [79.54526 ]
 [76.94467 ]
 [82.44047 ]
 [80.08156 ]
 [80.646126]
 [80.207756]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.76978302001953



buy possibilites: [-1] 
expected returns: [[90.45125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 82.44046020507812






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[81.99396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.45124816894531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[79.81795]
 [81.62134]
 [82.18835]
 [79.57513]
 [79.76194]
 [85.09768]
 [82.72727]
 [83.49632]
 [82.43293]
 [83.2943 ]
 [84.23631]
 [82.85748]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.7300796508789



buy possibilites: [-1] 
expected returns: [[82.915306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 8.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.09767150878906






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[85.35477]
 [87.68645]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.9153060913086



action possibilites: [-1] 
expected returns: [[82.101425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.84745788574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[82.189064]
 [83.983406]
 [84.54797 ]
 [81.947395]
 [82.13314 ]
 [87.4803  ]
 [85.084274]
 [85.8521  ]
 [84.791336]
 [85.65052 ]
 [86.60023 ]
 [85.21049 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.10142517089844



buy possibilites: [-1] 
expected returns: [[86.662415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 28.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.48030090332031






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  0.  0.  0.  3.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[90.91922 ]
 [93.397804]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.66241455078125



action possibilites: [-1] 
expected returns: [[84.36383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.56816864013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.59888 ]
 [85.25242 ]
 [82.32722 ]
 [85.857124]
 [86.00744 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.36383056640625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.186386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.0074462890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[84.07783 ]
 [85.943   ]
 [86.529724]
 [83.82676 ]
 [89.60972 ]
 [87.093094]
 [87.687836]
 [87.22529 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.86709594726562



buy possibilites: [-1] 
expected returns: [[86.13784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 89.6097183227539






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  6. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3.  0.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[79.623474]
 [80.116104]
 [80.116104]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.1378402709961



action possibilites: [-1. 10.] 
expected returns: [[88.36264 ]
 [88.859665]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 77.842529296875



action possibilites: [-1. 11.] 
expected returns: [[85.94376]
 [88.49267]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11] -> size -> 16 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 88.85966491699219



action possibilites: [-1.] 
expected returns: [[80.67844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.94088745117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.26043 ]
 [82.25625 ]
 [82.883064]
 [79.991905]
 [86.103836]
 [83.4812  ]
 [84.10801 ]
 [83.63314 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  5. 10. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.67843627929688



buy possibilites: [-1] 
expected returns: [[82.794876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 86.10383605957031






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10. 10. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[65.97473]
 [66.43161]
 [68.34631]
 [68.34631]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10.  9. 10. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [25. 10.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.79487609863281



action possibilites: [-1] 
expected returns: [[78.143196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [25. 10.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.58057403564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.63453]
 [80.24109]
 [77.36853]
 [80.84421]
 [80.99515]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [25. 10.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.14319610595703






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  4. 10.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[67.00997 ]
 [69.161606]
 [69.161606]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [10. 11.  0. 10. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.99514770507812



action possibilites: [-1] 
expected returns: [[74.51251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [10. 11.  0. 10. 11.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.52066040039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[75.69431 ]
 [77.915016]
 [75.46767 ]
 [78.42277 ]
 [78.542534]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [10. 11.  0. 10. 11.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.51251220703125






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15. 11.  0.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0. 10. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15. 11.  0.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0. 10. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25. 10.  0.  0.  1.  0.  3. 11. 15. 11.  0.  0.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 10.  0.] 
adversary cards in discard: [10. 11.  0. 10. 11.  0. 10. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10] -> size -> 20 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[51.64254 ]
 [51.993027]
 [53.45965 ]
 [51.993027]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.  0.] 
cards in discard: [10. 11.  0. 10. 11.  0. 10. 11.  0. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.54252624511719



action possibilites: [-1] 
expected returns: [[32.560913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10. 11.  0. 10. 11.  0. 10. 11.  0. 11.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.62986755371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.955843]
 [31.61859 ]
 [29.78672 ]
 [32.0033  ]
 [32.106365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10. 11.  0. 10. 11.  0. 10. 11.  0. 11.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.5609130859375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[57.55933 ]
 [60.016113]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.106361389160156



action possibilites: [-1] 
expected returns: [[63.29973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.31231689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[63.9992  ]
 [66.68267 ]
 [63.725792]
 [67.2952  ]
 [67.44868 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.29972839355469






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 11. 10. 10.  0.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 11. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[66.09301 ]
 [66.48952 ]
 [68.132996]
 [66.48952 ]
 [66.48952 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 10.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.44867706298828



action possibilites: [-1] 
expected returns: [[59.96658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 63.991668701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[58.751907]
 [58.5218  ]
 [61.642353]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.96657943725586






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[11.483907]
 [11.692694]
 [12.626013]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11. 25. 15.  1.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.642356872558594



action possibilites: [-1] 
expected returns: [[1.1953838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 25. 15.  1.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 12.074435234069824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-1.0664781 ]
 [-0.15353322]
 [-1.1444004 ]
 [ 0.0744164 ]
 [ 0.14117908]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 25. 15.  1.  0.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.1953837871551514






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [11. 25. 15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 15.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 15.  1.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 14.  0. 11.  0.  0.  1.  0.  0.  0. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8. 10. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 30. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  1.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11. 10.] 
adversary cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6] -> size -> 25 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[-1.621316  ]
 [-0.83001995]
 [-1.4816761 ]
 [-0.83001995]
 [-1.4816761 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11. 10.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -365 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.14118003845214844



action possibilites: [-1] 
expected returns: [[-0.5896063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.
  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -1.0398722887039185





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.4893572]
 [-2.56611  ]
 [-1.2005093]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 10.] 
cards in discard: [10. 11.  0.  3.  3.  0. 10. 11. 10. 10. 10.  0. 10. 11.  3. 10.  0.  0.
  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.5896062850952148






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  6. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  6. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10.  6. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15] -> size -> 26 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [10.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[50.204292]
 [50.625114]
 [52.37839 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.2005088329315186



action possibilites: [-1] 
expected returns: [[70.417816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  1. 14.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.106971740722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.48706 ]
 [71.72667 ]
 [69.26044 ]
 [72.242256]
 [72.36219 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  0.] 
cards in discard: [15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  1. 14.  0. 10.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.41781616210938






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0. 10.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10.  0.  0. 11.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 10.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 27. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 10.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 11.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[26.106482]
 [27.746023]
 [26.40314 ]
 [27.746023]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1. 14.  0.  1.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
  361    0] 
sum of rewards: -4 

action type: discard_down_to_3_cards - action 3
Learning step: 0
desired expected reward: -4.105738639831543



action possibilites: [-1] 
expected returns: [[19.830584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1. 14.  0.  1.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.31822967529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.632627]
 [17.490156]
 [19.442053]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1. 14.  0.  1.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.830583572387695






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1. 14.  0.  1.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 10.  0.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1. 14.  0.  1.
  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 29. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 10.  0.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 25. 11. 15.  1.  0.  0.  0.  0.  3.  0.  1.  0.  0.  1. 14.  0.  1.
  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [10. 10. 10. 10.  0.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [10. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[0.9586079]
 [1.0946169]
 [1.0946169]
 [1.0946169]
 [1.0946169]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10.  0.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.442052841186523



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[-2.2595513]
 [-2.1990051]
 [-2.1990051]
 [-2.1990051]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  0.  3.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 1.0946180820465088



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-2.243299 ]
 [-2.184117 ]
 [-2.184117 ]
 [-1.9401433]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3. 11.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15] -> size -> 28 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -2.199004888534546



action possibilites: [-1. 10. 10.] 
expected returns: [[1.8537691]
 [2.0395958]
 [2.0395958]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -2.020703077316284



action possibilites: [-1. 10. 11.] 
expected returns: [[20.048002]
 [20.368212]
 [21.72954 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15] -> size -> 29 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 2.03959584236145



action possibilites: [-1. 10.] 
expected returns: [[3.8015225]
 [4.0353374]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 100   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 21.29842185974121



action possibilites: [-1. 10.] 
expected returns: [[16.20065 ]
 [16.566717]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 4.035337448120117



action possibilites: [-1.] 
expected returns: [[7.024808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
action values: 4 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 16.56671714782715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[6.4317436]
 [7.981867 ]
 [6.2783604]
 [8.35739  ]
 [8.44797  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 11. 10. 11. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.024807929992676






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  3.  0. 10.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15. 10. 10. 11. 10.
 11. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3. 10.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  3.  0. 10.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15. 10. 10. 11. 10.
 11. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  3.  0. 10.] 
adversary cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15. 10. 10. 11. 10.
 11. 10. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 3. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-4.1051903]
 [-4.0733733]
 [-4.0733733]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0. 10.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15. 10. 10. 11. 10.
 11. 10. 10.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.447972297668457



action possibilites: [-1. 10. 15.] 
expected returns: [[-4.0411973]
 [-4.0139427]
 [-3.9731295]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10. 15.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15. 10. 10. 11. 10.
 11. 10. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10
  6 15 15 15 15 15] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -4.073372840881348



action possibilites: [-1. 10.] 
expected returns: [[-3.49473  ]
 [-3.4593406]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [15. 11. 10.  6.  0.  0.  0.  0. 15. 11. 10. 11. 15. 15. 10. 10. 11. 10.
 11. 10. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -3.9731295108795166



action possibilites: [-1.] 
expected returns: [[82.81496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15] -> size -> 29 
action values: 2 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -3.4593405723571777





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[79.40729 ]
 [81.157135]
 [81.70747 ]
 [79.17251 ]
 [79.35242 ]
 [84.53332 ]
 [82.23313 ]
 [82.97817 ]
 [81.9484  ]
 [83.69825 ]
 [82.35416 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  3.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.81495666503906



buy possibilites: [-1] 
expected returns: [[67.6742]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 15. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: -21.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.53331756591797






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [1. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0. 10.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11] -> size -> 30 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0. 10.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11] -> size -> 30 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0. 10.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11] -> size -> 30 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [15.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
expected returns: [[10.38503  ]
 [11.212946 ]
 [11.7453165]
 [10.627446 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  0. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.67420196533203



action possibilites: [-1] 
expected returns: [[23.312407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: -11 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.395111083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.069448]
 [21.69677 ]
 [19.903433]
 [22.070948]
 [22.18001 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  1. 10.  3.  3.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.312406539916992






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 1.  1. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 10.  3.  3.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  0.  3. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3.  3. 25.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  9. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  0.  3. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15] -> size -> 31 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3.  3.  0. 15.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3
  0  1  3  8  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  0.  3. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6] -> size -> 32 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  0.  3. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6] -> size -> 32 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  0.  3. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6] -> size -> 32 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 25. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  2.] 
adversary cards in hand: [10. 15.  0.  3. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6] -> size -> 32 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [10. 15.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[1.8172903]
 [2.0497363]
 [2.589557 ]
 [3.1010602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  3. 11.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  2.] 
adversary cards in hand: [ 0.  3. 14. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0. 15. 10. 25. 15.  1.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -425 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.180011749267578



action possibilites: [-1] 
expected returns: [[-2.869855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  3.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 14. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0. 15. 10. 25. 15.  1.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.7641327381134033





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.2486086]
 [-3.2625122]
 [-3.016012 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  3.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  1.] 
adversary cards in hand: [ 0.  3. 14. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0. 15. 10. 25. 15.  1.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.8698549270629883






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 11.  0.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0. 15. 10. 25. 15.  1.  1.
  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 10. 10. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15] -> size -> 33 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 11.  0.] 
cards in discard: [ 8.  0.  0.  0.  0. 11.  1.  1.  1.  3.  3.  0. 15. 10. 25. 15.  1.  1.
  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  1.] 
adversary cards in hand: [10. 10. 10. 10. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15] -> size -> 33 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10. 11.] 
expected returns: [[-3.3518386]
 [-3.3295574]
 [-3.3295574]
 [-3.3295574]
 [-3.3295574]
 [-3.2764034]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10. 11.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  1.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.016012191772461



action possibilites: [-1] 
expected returns: [[-3.3117805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -3.2927792072296143





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.3565598]
 [-3.3587606]
 [-3.3157837]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  0.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.3117804527282715






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 15. 10. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15] -> size -> 34 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9. 10.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 15. 10. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15] -> size -> 34 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  0. 15. 10. 11.] 
adversary cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15] -> size -> 34 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[-1.104369  ]
 [-1.0107555 ]
 [-1.0723561 ]
 [-0.95609736]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10. 11.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9.  9.  9. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  0.  0.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.3157835006713867



action possibilites: [-1] 
expected returns: [[-2.5745018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  0.  0.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   64    0] 
sum of rewards: -41 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -1.1070196628570557





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-2.587464 ]
 [-2.552199 ]
 [-2.589665 ]
 [-2.540681 ]
 [-2.5466878]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  9.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  0.  0.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.5745017528533936



buy possibilites: [-1] 
expected returns: [[-2.6141262]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.] 
cards in discard: [11. 10. 15. 10.  3.  3.  0. 15. 11. 15.  0.  0. 10.  6. 15. 11. 10. 15.
  0.  3. 15. 11. 10. 10. 10. 10. 14.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  8.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [10. 11.  0.  0.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0  -10    0    0
   16    0] 
sum of rewards: -99 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -2.540680170059204






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  1.] 
cards in discard: [29. 15.  0.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  8.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [29. 15.  0.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  8.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  8. 10.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  3. 15.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3. 15.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[22.530315]
 [23.429312]
 [24.000437]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  8.  9.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 25.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23] -> size -> 32 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.614126205444336



action possibilites: [-1] 
expected returns: [[22.061357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 25.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23] -> size -> 32 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0  -20    0    0
   64    0] 
sum of rewards: -61 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 22.42179298400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.268602]
 [19.113081]
 [21.284159]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  6.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [15. 11.  3. 25.  1.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23] -> size -> 32 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.061357498168945






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [15. 11.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 25.  1.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  2.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0. 11.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 25.  1.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0. 11.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 25.  1.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0. 11.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 25.  1.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [10. 14. 15.  0. 11.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [10. 14. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 15. 11.] 
expected returns: [[-1.0814806]
 [-1.0565101]
 [-1.0939876]
 [-1.0108495]
 [-0.973372 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 15.  0. 11.] 
cards in discard: [14. 11.  0.  3. 15.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  7.  9.  0. 10.  0.] 
adversary cards in hand: [ 1.  0.  0.  3. 14.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.284160614013672



action possibilites: [-1] 
expected returns: [[7.819619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14. 15.  0.] 
cards in discard: [14. 11.  0.  3. 15.  6. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  6.  9.  0. 10.  0.] 
adversary cards in hand: [ 1.  0.  0.  3. 14.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0  -30    0    0
   64    0] 
sum of rewards: -71 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -1.0819448232650757





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.6103086]
 [5.487114 ]
 [7.295308 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14. 15.  0.] 
cards in discard: [14. 11.  0.  3. 15.  6. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  6.  9.  0. 10.  0.] 
adversary cards in hand: [ 1.  0.  0.  3. 14.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.819619178771973






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 14.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  6.  9.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 15. 10. 15.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6. 14. 11. 10. 14. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14 14] -> size -> 38 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  6.  9.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6. 14. 11. 10. 14. 15.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14 14] -> size -> 38 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  1.  7.  9.  9.  6.  9.  0. 10.  0.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [14. 11.  0.  3. 15.  6. 14. 11. 10. 14. 15.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14 14] -> size -> 38 
adversary victory points: 1
player victory points: 5 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 1 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 10. 15.] 
cards in discard: [14. 11.  0.  3. 15.  6. 14. 11. 10. 14. 15.  0. 10. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 11 10 11 10 11 10 11 10 10 10 10 10 10  6
 15 15 15 15 15 11 15  6 15 15 14  8 14 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  8. 10.  0.  7.  9.  9.  6.  9.  0. 10.  0.] 
adversary cards in hand: [1. 0. 0. 3.] 
adversary cards in discard: [29. 15.  0.  0.  0.  0.  8. 23. 10. 11.  0.  0.  1.  0. 11.  0. 11. 15.
  3. 25.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 10  1  0 11 25 11 15  0  1 14  0  3  0
  1  3  8  1 15 29  8 23 11  0 11] -> size -> 35 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0      -30        0     -600      809        0] 
sum of rewards: -2999946 

action type: discard_down_to_3_cards - action 0
Learning step: -119997.6640625
desired expected reward: -120001.9296875



