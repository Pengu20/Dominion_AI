 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.30426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[   -5  -500     9   -10     0     0     0  -300     0     0     0   -26
     0 -1800    63     0] 
sum of rewards: -2569 

action type: discard_down_to_3_cards - action 2
Learning step: -256.6582946777344
desired expected reward: -259.0752258300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[309.88126]
 [332.31244]
 [337.08282]
 [302.37018]
 [340.4905 ]
 [312.98288]
 [317.38318]
 [332.0802 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 333.09234619140625



buy possibilites: [-1] 
expected returns: [[298.27133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 340.4905090332031






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[297.86795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 298.2713317871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[280.47607]
 [303.84546]
 [308.63522]
 [272.2826 ]
 [278.86835]
 [311.95703]
 [283.79782]
 [294.26254]
 [280.09454]
 [288.58765]
 [298.95395]
 [303.89185]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 298.3590087890625



buy possibilites: [-1] 
expected returns: [[267.47595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 311.95703125






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[252.01964]
 [258.94757]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 267.4759521484375



action possibilites: [-1] 
expected returns: [[253.19778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -293 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 257.7325744628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.14359]
 [252.17233]
 [256.69937]
 [222.75981]
 [260.22403]
 [233.5671 ]
 [238.09413]
 [253.05544]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  7. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0
desired expected reward: 253.19778442382812



buy possibilites: [-1] 
expected returns: [[227.50665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  6. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 25 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 260.22406005859375






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  6. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  6. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[247.91252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: 0
desired expected reward: 227.50665283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[235.62375]
 [257.29984]
 [261.7461 ]
 [228.06874]
 [264.6094 ]
 [238.47704]
 [242.9233 ]
 [256.80713]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  6. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 247.5910186767578



buy possibilites: [-1] 
expected returns: [[219.63628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 11. 11.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  3.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 264.6094055175781






Player: 1 
cards in hand: [15.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  0. 11.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29.  0.  0.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[200.71718]
 [207.72418]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: 0
desired expected reward: 219.6362762451172



action possibilites: [-1] 
expected returns: [[214.86171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -304 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 205.6112823486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[192.64548]
 [212.81654]
 [217.05516]
 [185.75626]
 [220.39766]
 [195.80244]
 [199.89597]
 [213.83273]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  5. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: 0
desired expected reward: 214.86170959472656



buy possibilites: [-1] 
expected returns: [[189.05565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 220.3976593017578






Player: 1 
cards in hand: [ 3.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11] -> size -> 17 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  3.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11] -> size -> 17 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[167.5543]
 [174.7635]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  1.  0.] 
adversary cards in discard: [ 0.  3.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: 0
desired expected reward: 189.05564880371094



action possibilites: [-1] 
expected returns: [[215.59422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  7. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  1.  0.] 
adversary cards in discard: [ 0.  3.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -315 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 172.62078857421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[194.43027]
 [214.56178]
 [218.689  ]
 [187.33676]
 [221.39323]
 [197.1345 ]
 [201.26172]
 [214.22256]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  7. 10.  4. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  1.  0.] 
adversary cards in discard: [ 0.  3.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 215.59422302246094



buy possibilites: [-1] 
expected returns: [[200.72264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  7. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  1.  0.] 
adversary cards in discard: [ 0.  3.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 3 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 221.3932647705078






Player: 1 
cards in hand: [ 0. 15.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  1.  0.] 
cards in discard: [ 0.  3.  3. 29.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  7. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 0.  3.  3. 29.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  7. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 0.  3.  3. 29.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 30. 30.  8.  7. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 0.  3.  3. 29.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[152.01039]
 [158.66011]
 [158.66011]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11. 11.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: 0
desired expected reward: 200.72264099121094



action possibilites: [-1] 
expected returns: [[187.53542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -336 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 154.89027404785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[169.0641 ]
 [161.53807]
 [191.20973]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [ 6. 11. 11.  0.  6.  0.  0.  6. 11. 11.  3.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: 0
desired expected reward: 187.53541564941406






Player: 1 
cards in hand: [ 0. 29.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  3. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6] -> size -> 20 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6] -> size -> 20 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6] -> size -> 20 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[147.04372]
 [152.5168 ]
 [152.5168 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [29. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 191.20973205566406



action possibilites: [-1] 
expected returns: [[114.64189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  5. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [29. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 149.54847717285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.713936]
 [120.8579  ]
 [ 95.02753 ]
 [102.925446]
 [117.1906  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  5. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [29. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.64189147949219



buy possibilites: [-1] 
expected returns: [[203.39604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 11.] 
cards in discard: [6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  5. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [29. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -28 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 120.85791015625






Player: 1 
cards in hand: [3. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [29. 11.  0. 29.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  5. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [29. 11.  0. 29.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  5. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3] -> size -> 22 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[158.69417]
 [165.41696]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 11.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  5. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: 0
desired expected reward: 203.3960418701172



action possibilites: [-1] 
expected returns: [[150.82356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 162.11985778808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[137.34695]
 [132.19228]
 [153.29108]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.8235626220703






Player: 1 
cards in hand: [ 0.  3.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[208.22038]
 [215.58737]
 [215.58737]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0. 11.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  4. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 11.  0. 29.] 
adversary cards in discard: [10. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.2910614013672



action possibilites: [-1] 
expected returns: [[99.17326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 11.  0. 29.] 
adversary cards in discard: [10. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -358 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 207.6573944091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 83.76161 ]
 [105.15629 ]
 [ 78.05827 ]
 [ 86.256775]
 [101.99526 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 11.  0. 29.] 
adversary cards in discard: [10. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.17326354980469



buy possibilites: [-1] 
expected returns: [[133.49956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 11.  0. 29.] 
adversary cards in discard: [10. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -39 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 105.1562728881836






Player: 1 
cards in hand: [29.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  0. 29.] 
cards in discard: [10. 15.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3] -> size -> 25 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  0. 29.] 
cards in discard: [10. 15.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3] -> size -> 25 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  0. 29.] 
cards in discard: [10. 15.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3] -> size -> 25 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[88.85681]
 [93.09881]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  3. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.4995574951172



action possibilites: [-1] 
expected returns: [[109.58418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -358 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 90.08120727539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.57842]
 [110.22511]
 [ 85.25375]
 [ 93.43965]
 [108.43192]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.58418273925781



buy possibilites: [-1] 
expected returns: [[87.72058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  0.  6. 11.  6. 11.  0.  3.  6.  3.  6.  3. 11.  0.  6.
  0. 11.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -39 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 110.22512817382812






Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3] -> size -> 27 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 26. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3] -> size -> 27 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10. 15.  3.  0.  3.  0. 29.  3. 11.  0. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [11.  3.  6.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3] -> size -> 27 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11.  3.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[134.20825]
 [140.72603]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  2. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.7205810546875



action possibilites: [-1] 
expected returns: [[147.58746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 17 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -358 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 138.39501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[128.42323]
 [122.25072]
 [147.73985]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 17 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.58746337890625






Player: 1 
cards in hand: [ 3.  3.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [22.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  6.  0.  6. 11.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[181.88866]
 [189.76546]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  6. 11.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  1. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  3.] 
adversary cards in discard: [22. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 17 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.73988342285156



action possibilites: [-1] 
expected returns: [[156.0235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  3.] 
adversary cards in discard: [22. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -80    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -369 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 181.05638122558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[136.64404]
 [157.58469]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  0. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  0.  3.] 
adversary cards in discard: [22. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.02349853515625






Player: 1 
cards in hand: [ 0. 15.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  3.] 
cards in discard: [22. 15.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [11.  6.  3.  3.  0.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [22. 15.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  0. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [11.  6.  3.  3.  0.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [22. 15.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 26. 30.  8.  0. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [11.  6.  3.  3.  0.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6] -> size -> 29 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11.  6.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[158.99077]
 [165.05357]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  3.  0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0. 10.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [22. 15.  3.  3.  1. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 157.58470153808594



action possibilites: [-1] 
expected returns: [[123.99347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0.  9.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [22. 15.  3.  3.  1. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -53 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 160.31271362304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[104.7894 ]
 [124.04491]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  0.  9.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [10.  0. 29.  0. 29.] 
adversary cards in discard: [22. 15.  3.  3.  1. 15.  3.  0.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: 0
desired expected reward: 123.99346923828125






Player: 1 
cards in hand: [10.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0. 29.] 
cards in discard: [22. 15.  3.  3.  1. 15.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0.  9.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 11.  0.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16] -> size -> 30 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  0. 29.] 
cards in discard: [22. 15.  3.  3.  1. 15.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  0.  9.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 11.  0.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16] -> size -> 30 
adversary victory points: -4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[106.11237]
 [110.83234]
 [110.83234]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0.  9.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.04490661621094



action possibilites: [-1] 
expected returns: [[120.495026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  0.  8.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -53 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 107.92274475097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[103.51799 ]
 [122.761314]
 [106.36349 ]
 [121.216644]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  0.  8.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.49502563476562



buy possibilites: [-1] 
expected returns: [[106.047775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  0.  8.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -50 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 122.76130676269531






Player: 1 
cards in hand: [ 3. 29. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  0.  8.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3] -> size -> 32 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 25. 30.  8.  0.  8.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3. 11.  0.  6.] 
adversary cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3] -> size -> 32 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[118.96993 ]
 [126.074234]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  6.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3. 11.  6.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  0.  8.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 22. 15. 15.  0.] 
adversary cards in discard: [ 3. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.04777526855469



action possibilites: [-1] 
expected returns: [[119.07176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3. 11.  6.  0. 11.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 22. 15. 15.  0.] 
adversary cards in discard: [ 3. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -42 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 123.25663757324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 97.23831 ]
 [118.74229 ]
 [100.0088  ]
 [115.862976]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3. 11.  6.  0. 11.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 22. 15. 15.  0.] 
adversary cards in discard: [ 3. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.07176208496094



buy possibilites: [-1] 
expected returns: [[92.071335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [ 6. 11.  3.  6.  3.  3.  6. 11.  6.  6.  0.  6. 16. 11.  6.  3.  3.  0.
 16.  3. 11.  6.  0. 11.  0. 16.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 22. 15. 15.  0.] 
adversary cards in discard: [ 3. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -39 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 118.74229431152344






Player: 1 
cards in hand: [ 0. 22. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 15. 15.  0.] 
cards in discard: [ 3. 29. 29.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3] -> size -> 34 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  0.] 
cards in discard: [ 3. 29. 29.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3] -> size -> 34 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 15.  0.] 
cards in discard: [ 3. 29. 29.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 24. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3] -> size -> 34 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 15.  0.] 
cards in discard: [ 3. 29. 29.  0. 11. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  6.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3] -> size -> 34 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11.  6.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[168.62457]
 [175.18364]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  7.  3. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 29.  0. 11. 15. 15. 22. 15.  0.] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.07133483886719



action possibilites: [-1] 
expected returns: [[182.48071]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  3. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 29.  0. 11. 15. 15. 22. 15.  0.] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -31 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 168.78781127929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[161.83012]
 [183.30312]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  3. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 1. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 29.  0. 11. 15. 15. 22. 15.  0.] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.480712890625






Player: 1 
cards in hand: [3. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [ 3. 29. 29.  0. 11. 15. 15. 22. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  3. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0. 16.  0.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [ 3. 29. 29.  0. 11. 15. 15. 22. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  3. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0. 16.  0.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [ 3. 29. 29.  0. 11. 15. 15. 22. 15.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  0. 16.  0.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[89.41862]
 [71.85466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  3.] 
cards in discard: [16. 11.  6.  3.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 11. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 183.3031463623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[72.519424]
 [92.044556]
 [74.9288  ]
 [89.10131 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  3.] 
cards in discard: [16. 11.  6.  3.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  0.  6.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 11. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11] -> size -> 17 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.8375015258789



buy possibilites: [-1] 
expected returns: [[78.67818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  3.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  0.  6.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 11. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -49 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 92.04457092285156






Player: 1 
cards in hand: [ 3. 11. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  0.  6.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3] -> size -> 36 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  0.  5.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3] -> size -> 36 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 23. 30.  8.  0.  5.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3] -> size -> 36 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.] 
cards in discard: [16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 23. 30.  8.  0.  5.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  6.  3. 11.  3.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3] -> size -> 36 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.419615]
 [27.884611]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 11.  3.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  5.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22. 15.  0.  0. 29.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.67817687988281



action possibilites: [-1] 
expected returns: [[106.93789]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  4.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22. 15.  0.  0. 29.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0  -2   0   0  16   0] 
sum of rewards: -22 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 25.61492156982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 90.43376]
 [106.5762 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 23. 30.  8.  0.  4.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22. 15.  0.  0. 29.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 10.] 
adversary owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.9378890991211






Player: 1 
cards in hand: [22. 15.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  0.  0. 29.] 
cards in discard: [16.  0. 11.  3. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  4.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11. 11.  3.  6. 16.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16] -> size -> 37 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 29.] 
cards in discard: [16.  0. 11.  3. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 23. 30.  8.  0.  4.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11. 11.  3.  6. 16.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16] -> size -> 37 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0. 29.] 
cards in discard: [16.  0. 11.  3. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 23. 30.  8.  0.  4.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11. 11.  3.  6. 16.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16] -> size -> 37 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 11.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
expected returns: [[63.49467 ]
 [67.648186]
 [67.648186]
 [47.062004]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  6. 16.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  4.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 15.  1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 10. 15. 22.  0. 29.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 106.57621002197266



action possibilites: [-1] 
expected returns: [[95.02739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6. 16.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  3.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 15.  1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 10. 15. 22.  0. 29.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0  -3   0   0  16   0] 
sum of rewards: -23 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 64.73835754394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[76.85057]
 [95.78006]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  6. 16.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  3.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 15.  1.] 
adversary cards in discard: [16.  0. 11.  3. 11.  0. 10. 15. 22.  0. 29.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.02738952636719






Player: 1 
cards in hand: [ 3.  3.  3. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 15.  1.] 
cards in discard: [16.  0. 11.  3. 11.  0. 10. 15. 22.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  0.  3.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11.  6.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16] -> size -> 38 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 15.  1.] 
cards in discard: [16.  0. 11.  3. 11.  0. 10. 15. 22.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 23. 30.  8.  0.  3.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11.  6.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16] -> size -> 38 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 15.  1.] 
cards in discard: [16.  0. 11.  3. 11.  0. 10. 15. 22.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  3.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 6.  0.  3. 11.  6.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16] -> size -> 38 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[89.7353 ]
 [94.60791]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.  6.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  3.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  0.  3. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.78006744384766



action possibilites: [-1] 
expected returns: [[134.26012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  0.  3. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0  -4   0   0  16   0] 
sum of rewards: -34 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 91.51016998291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[117.784676]
 [134.06906 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [22.  0.  3. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.26011657714844






Player: 1 
cards in hand: [22.  0.  3. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3. 15. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 16.  0.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.] 
cards in discard: [22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 16.  0.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.] 
cards in discard: [22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2. 10. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 16.  0.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.] 
cards in discard: [22.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 16.  0.] 
adversary cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[44.756565]
 [35.895275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 16.  0.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16. 11.  6.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 10. 11.  3. 29.] 
adversary cards in discard: [22.  8. 29.  0.  3. 15.  3.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 134.06907653808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.55553 ]
 [44.756565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 16.  0.] 
cards in discard: [16. 11.  6.  3.  6.  0.  3.  3.  0. 16.  0.  3. 16. 11.  0.  6.  3.  3.
 16. 11. 11.  3.  6. 16. 16. 11.  6.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 10. 11.  3. 29.] 
adversary cards in discard: [22.  8. 29.  0.  3. 15.  3.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.75654602050781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3. 29.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 29.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 29.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[125.70245]
 [130.22221]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  2.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 11.  1.  0.  0.] 
adversary cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0] -> size -> 21 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.75654602050781



action possibilites: [-1] 
expected returns: [[133.89177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 11.  1.  0.  0.] 
adversary cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0] -> size -> 21 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0  -5   0   0  16   0] 
sum of rewards: -35 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 127.44871520996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[115.462456]
 [134.57881 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 11.  1.  0.  0.] 
adversary cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29.] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0] -> size -> 21 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: 0
desired expected reward: 133.8917694091797






Player: 1 
cards in hand: [ 3. 11.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  0.  0.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  2.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0. 11. 16.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  1.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0. 11. 16.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  1.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0. 11. 16.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [22.  8. 29.  0.  3. 15.  3.  0. 11.  3. 10.  3. 29. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  0.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [11.  0. 11. 16.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0. 11. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
expected returns: [[60.728325]
 [64.85365 ]
 [64.85365 ]
 [49.207706]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 16.  3.] 
cards in discard: [16. 11.  3.  6.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  1.  0.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 16. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0 11 11] -> size -> 23 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 134.5788116455078



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 11. 16.  3.] 
cards in discard: [16. 11.  3.  6.  6.  0. 16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6 11 11  6 11  6 11  6  6  3  6  6
  3  6  3  6  6 16 16  3 16  3 16  3 16 16 16 16 16] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  0.  0.  0.  9. 10.  8. 10. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 16. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 15 11 29  1  0  3 29 10  0 15 22 15 11 16  0  3  8  0 11 11] -> size -> 23 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -60    0    0   20    0    0    0    0   -6    0    0
   16    0] 
sum of rewards: -536 

action type: gain_card_n - action 3
Learning step: -59.91274642944336
desired expected reward: 3.2147064208984375



