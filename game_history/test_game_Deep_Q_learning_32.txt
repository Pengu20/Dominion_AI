 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.72119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1.0
Learning step: -120003.7890625
desired expected reward: -120004.1328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.932646]
 [26.51071 ]
 [24.755157]
 [14.394379]
 [24.340137]
 [29.917025]
 [25.094515]
 [31.823923]
 [19.08286 ]
 [23.338957]
 [25.66093 ]
 [24.560343]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.044504165649414



buy possibilites: [-1] 
expected returns: [[29.344404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.82391929626465






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.078451]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.344404220581055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.120731]
 [25.338667]
 [23.932905]
 [15.436453]
 [28.274775]
 [24.159365]
 [22.793613]
 [24.425734]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.35597801208496



buy possibilites: [-1] 
expected returns: [[23.357126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 28.274778366088867






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[20.311893]
 [25.365889]
 [27.362394]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.357126235961914



action possibilites: [-1. 11.] 
expected returns: [[25.80549 ]
 [28.440252]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.33325958251953



action possibilites: [-1] 
expected returns: [[34.785088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.324607849121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[30.586313]
 [36.118324]
 [34.667397]
 [27.083908]
 [25.63298 ]
 [34.329674]
 [38.975967]
 [34.89489 ]
 [44.17025 ]
 [40.6678  ]
 [29.94155 ]
 [34.908325]
 [33.443954]
 [29.3763  ]
 [35.473564]
 [35.03344 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.78508758544922



buy possibilites: [-1] 
expected returns: [[34.504425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 44.170249938964844






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  3.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[52.77893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.504425048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.73478 ]
 [54.787476]
 [43.23681 ]
 [55.224815]
 [53.664124]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.66950988769531



buy possibilites: [-1] 
expected returns: [[38.040123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 55.224815368652344






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 7 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.909533]
 [30.77101 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 14.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 251   0] 
sum of rewards: 246 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 21.674545288085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.645346]
 [30.72643 ]
 [21.692009]
 [30.953917]
 [31.092447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 14.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.784013748168945



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.  0.] 
cards in discard: [ 0. 14.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 14 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 14.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 14.  0.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 14.  0.  1.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[27.828539]
 [26.753414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [0. 3. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.092443466186523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.393866]
 [28.573187]
 [27.19555 ]
 [18.663279]
 [31.248106]
 [27.446426]
 [26.068789]
 [27.143875]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [0. 3. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.483314514160156



buy possibilites: [-1] 
expected returns: [[28.69419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [ 0.  3.  8.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.248109817504883






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 25. 29.] 
adversary cards in discard: [ 0.  3.  8.  0.  0. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 25. 29.] 
adversary cards in discard: [ 0.  3.  8.  0.  0. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 25. 29.] 
adversary cards in discard: [ 0.  3.  8.  0.  0. 11.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[17.12593 ]
 [22.895432]
 [30.385756]
 [25.024916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 25. 29.] 
cards in discard: [ 0.  3.  8.  0.  0. 11.  0.  0. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  1.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.694189071655273



action possibilites: [-1] 
expected returns: [[32.736046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  1.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.171655654907227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.593927]
 [31.088884]
 [21.129826]
 [31.366842]
 [31.22502 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  8.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  1.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.736045837402344



buy possibilites: [-1] 
expected returns: [[30.794744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 29.  0.  3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  1.  3.  0.  0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 31.36684226989746






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [14.  1.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.  0.  0.] 
cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 10.  0.  8.] 
adversary cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[51.476883]
 [53.50918 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 32.879180908203125



action possibilites: [-1] 
expected returns: [[68.15014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 53.482261657714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.48551 ]
 [58.050743]
 [67.20225 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 25.  3. 11.  0. 29.  0.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  1.] 
adversary cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.15013885498047






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  1.] 
cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16. 14.  1.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  1.] 
cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16. 14.  1.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  0.  1.] 
cards in discard: [ 1.  0.  0.  0.  3.  3.  6. 16. 14.  1.  3.  0.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.748747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3. 14. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 67.2022476196289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.370977]
 [29.83809 ]
 [28.408003]
 [19.590914]
 [32.6578  ]
 [28.620773]
 [27.190687]
 [28.842377]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  8.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3. 14. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.127355575561523



buy possibilites: [-1] 
expected returns: [[11.796967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3. 14. 22.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 32.657798767089844






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3. 14. 22.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 22.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 30. 30.  8.  9.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 22.  0.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  8. 25.  0.  3.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  8. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[32.67382]
 [32.87628]
 [42.39399]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.  0.  3.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15.  1.  1.  0.  6.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.796966552734375



action possibilites: [-1] 
expected returns: [[23.318047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 11. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15.  1.  1.  0.  6.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.6826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.110857]
 [25.598679]
 [15.344366]
 [25.993092]
 [24.543522]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  3. 11. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  7.  8.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15.  1.  1.  0.  6.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.31804656982422



buy possibilites: [-1] 
expected returns: [[40.87702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  3. 11. 29.] 
cards in discard: [11.  3.  3.  0.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  7.  7.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [15.  1.  1.  0.  6.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 25.993093490600586






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [15.  1.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  1.  0.  6.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  7.  7.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  1.  0.  6.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  7.  7.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  1.  0.  6.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  7.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[23.828587]
 [23.964838]
 [27.49617 ]
 [22.693897]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  7.  9.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.87702178955078



action possibilites: [-1] 
expected returns: [[27.594133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  7.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 28.226511001586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.78773 ]
 [19.007378]
 [28.23483 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  7.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.594133377075195






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  7.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  3. 14. 22.  0.  0.  6.  4. 15.  1.  1.  0.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.272547]
 [19.805998]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10. 11.  3.  0.  8. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 28.23483657836914



action possibilites: [-1] 
expected returns: [[16.087498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 11.  3.  0.  8. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  9.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.215904235839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.562433]
 [18.661646]
 [17.419302]
 [11.037132]
 [17.203379]
 [21.073072]
 [17.63928 ]
 [22.450232]
 [14.062834]
 [16.558207]
 [18.042475]
 [17.453897]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 11.  3.  0.  8. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  9.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.08749771118164



buy possibilites: [-1] 
expected returns: [[50.452805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 11.  3.  0.  8. 10. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 22.450231552124023






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  3.  8. 25.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10. 10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 29. 29.  8.  8.  9.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  3.  8. 25.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10. 10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  8.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [29.  3.  3.  8. 25.] 
adversary cards in discard: [10. 11.  3.  0.  8. 10. 10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  3.  3.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.] 
expected returns: [[-4.799396 ]
 [-0.5133722]
 [-5.3115067]
 [ 2.8254347]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  8. 25.] 
cards in discard: [10. 11.  3.  0.  8. 10. 10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  8.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 3. 8. 6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16] -> size -> 24 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.45280456542969



action possibilites: [-1] 
expected returns: [[80.39303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  8. 11.  8.] 
cards in discard: [10. 11.  3.  0.  8. 10. 10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 3. 8. 6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.9336676597595215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[71.57047]
 [64.7015 ]
 [79.54682]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  8. 11.  8.] 
cards in discard: [10. 11.  3.  0.  8. 10. 10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [0. 1. 3. 8. 6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16
  6] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.39302825927734






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 8. 6.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[37.451836]
 [36.180107]
 [37.60009 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 25  8 11  8 11  8 10 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 79.54683685302734



action possibilites: [-1] 
expected returns: [[9.025993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 36.48841857910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 5.875263 ]
 [10.467983 ]
 [ 9.1970415]
 [ 2.0068893]
 [12.943971 ]
 [ 9.412633 ]
 [ 8.141693 ]
 [ 9.27638  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  7.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.025993347167969



buy possibilites: [-1] 
expected returns: [[13.616669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  6.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 22.  6.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 12.9439697265625






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 22.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 22.  6.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  6.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6.  1.  3. 14.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  6.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6.  1.  3. 14.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  6.  6.  9.  8.  9. 10.  7.  9.  9.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6.  1.  3. 14.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 3. 25. 10.  0.  3.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 25. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[52.281227]
 [62.52072 ]
 [52.78266 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10.  0.  3.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  7.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [15.  0. 16.  0.  4.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15. 22.  0.  0.  3.  6.  1.
  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.616668701171875



action possibilites: [-1] 
expected returns: [[40.58915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 11. 29.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [15.  0. 16.  0.  4.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15. 22.  0.  0.  3.  6.  1.
  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.319976806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.459023]
 [34.308258]
 [40.95585 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3. 11. 29.] 
cards in discard: [11.  8.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 28. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [15.  0. 16.  0.  4.] 
adversary cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15. 22.  0.  0.  3.  6.  1.
  3. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.589149475097656






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [15.  0. 16.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 16.  0.  4.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15. 22.  0.  0.  3.  6.  1.
  3. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  8.  3. 11. 10.] 
adversary cards in discard: [11.  8.  0.  0.  0. 25.  3. 10.  0.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 16.  0.  4.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15. 22.  0.  0.  3.  6.  1.
  3. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  8.  3. 11. 10.] 
adversary cards in discard: [11.  8.  0.  0.  0. 25.  3. 10.  0.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 16.  0.  4.] 
cards in discard: [16.  0.  0.  3.  1.  0.  6.  3.  8.  1.  6. 15. 22.  0.  0.  3.  6.  1.
  3. 14.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  8.  3. 11. 10.] 
adversary cards in discard: [11.  8.  0.  0.  0. 25.  3. 10.  0.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 8.  8.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 10.] 
expected returns: [[ 0.7478764 ]
 [ 1.0232239 ]
 [ 1.0232239 ]
 [ 4.713306  ]
 [-0.23003864]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 11. 10.] 
cards in discard: [11.  8.  0.  0.  0. 25.  3. 10.  0.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  7.  9.  8.] 
adversary cards in hand: [ 1.  8.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.955841064453125



action possibilites: [-1] 
expected returns: [[4.479348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 10.] 
cards in discard: [11.  8.  0.  0.  0. 25.  3. 10.  0.  3. 11. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  8.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 6.0827789306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.9512162]
 [-1.6589553]
 [ 4.171028 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3. 10.] 
cards in discard: [11.  8.  0.  0.  0. 25.  3. 10.  0.  3. 11. 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  8.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.479348182678223






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  1. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  1. 22.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3
 15  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22.  0.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [ 8.  8. 11. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 8.  8. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 29.] 
expected returns: [[21.537682]
 [20.073961]
 [20.073961]
 [23.989223]
 [25.781668]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 29.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [3. 3. 3. 3. 6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.1710286140441895



action possibilites: [-1.  8.  8. 11.] 
expected returns: [[20.813961]
 [20.17486 ]
 [20.17486 ]
 [24.079802]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  6.  9.  8.] 
adversary cards in hand: [3. 3. 3. 3. 6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.47083282470703



action possibilites: [-1] 
expected returns: [[56.029297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  5.  9.  8.] 
adversary cards in hand: [3. 3. 3. 3. 6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.448137283325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[50.225952]
 [55.051765]
 [44.91987 ]
 [55.283028]
 [57.20269 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  5.  9.  8.] 
adversary cards in hand: [3. 3. 3. 3. 6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.029296875






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 6.] 
cards in discard: [ 0.  8.  1. 22.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10.  3. 29.  0.  0.] 
adversary cards in discard: [10. 29. 11.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 6.] 
cards in discard: [ 0.  8.  1. 22.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  5.  9.  8.] 
adversary cards in hand: [10.  3. 29.  0.  0.] 
adversary cards in discard: [10. 29. 11.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[50.529243]
 [50.139755]
 [58.53608 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0.  0.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.20269012451172



action possibilites: [-1. 10. 11.] 
expected returns: [[37.503044]
 [37.154648]
 [43.367928]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  5.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.19660949707031



action possibilites: [-1] 
expected returns: [[15.018515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.072998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.35329  ]
 [16.117498 ]
 [14.841221 ]
 [ 7.302104 ]
 [19.366835 ]
 [15.014345 ]
 [13.7714615]
 [15.333914 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  6.  6.  9.  8.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.018514633178711



buy possibilites: [-1] 
expected returns: [[-6.164073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  5.  6.  9.  8.  9. 10.  4.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  1. 14.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 19.366846084594727






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 14.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  5.  6.  9.  8.  9. 10.  4.  9.  8.] 
adversary cards in hand: [10. 25. 11.  0. 10.] 
adversary cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11. 29. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 14.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  5.  6.  9.  8.  9. 10.  4.  9.  8.] 
adversary cards in hand: [10. 25. 11.  0. 10.] 
adversary cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11. 29. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 14.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [10. 25. 11.  0. 10.] 
adversary cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11. 29. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10. 25. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11. 10.] 
expected returns: [[37.14222 ]
 [36.531548]
 [47.087646]
 [41.696503]
 [36.531548]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 11.  0. 10.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11. 29. 11. 10.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  6.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 6.  4. 15.  3.  6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14] -> size -> 28 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.1640729904174805



action possibilites: [-1] 
expected returns: [[4.7415304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10. 11.  0.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11. 29. 11. 10.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 6.  4. 15.  3.  6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.087646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 1.8937731 ]
 [ 3.6783233 ]
 [-0.08703899]
 [ 3.769373  ]
 [ 4.0501437 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10. 11.  0.] 
cards in discard: [10. 29. 11.  8.  8.  0.  3. 10. 11. 29. 11. 10.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 6.  4. 15.  3.  6.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.741530418395996






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 6.  4. 15.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  4. 15.  3.  6.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [10.  8. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 3. 6.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [10.  8. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 3. 6.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [10.  8. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  8. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.  8.] 
expected returns: [[57.338158]
 [53.75869 ]
 [55.084335]
 [53.75869 ]
 [55.084335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 15.  0.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6. 15.
  6.  4.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.050142288208008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.897186]
 [45.442955]
 [56.25937 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 15.  0.] 
adversary cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6. 15.
  6.  4.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.00556945800781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 15.  0.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6. 15.
  6.  4.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15
  6  3  0 14  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 29.  0. 11.  0.] 
adversary cards in discard: [10.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6. 15.
  6.  4.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 29.  0. 11.  0.] 
adversary cards in discard: [10.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6. 15.
  6.  4.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  5.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 29.  0. 11.  0.] 
adversary cards in discard: [10.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [ 0.  8.  1. 22.  0.  3.  3.  3.  3.  6. 14.  0.  0.  0.  1. 14.  6. 15.
  6.  4.  3.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  4.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 8. 29.  0. 11.  0.] 
adversary cards in discard: [10.  8. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 29.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
expected returns: [[21.81297 ]
 [24.040573]
 [28.832836]
 [27.623306]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 11.  0.] 
cards in discard: [10.  8. 10.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  4.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 1. 15.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.259361267089844



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[-1.683852 ]
 [-1.0687656]
 [ 1.3170104]
 [ 1.3170104]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0. 11.] 
cards in discard: [10.  8. 10.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  4.  6.  9.  8.  8. 10.  4.  9.  8.] 
adversary cards in hand: [ 1. 15.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.774822235107422



action possibilites: [-1] 
expected returns: [[27.542078]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [10.  8. 10.  8.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  4.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 1. 15.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.2283425331115723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.754229]
 [29.555525]
 [28.473562]
 [23.01662 ]
 [31.597273]
 [28.694164]
 [27.612253]
 [27.935831]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [10.  8. 10.  8.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  4.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 1. 15.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.542078018188477



buy possibilites: [-1] 
expected returns: [[6.3219843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 1. 15.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.59727668762207






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1. 15.  8.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  8.  6. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [11. 10.  3.  0. 25.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  6. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [11. 10.  3.  0. 25.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  6. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [11. 10.  3.  0. 25.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[-9.029847 ]
 [-8.27153  ]
 [-9.029847 ]
 [-4.9824414]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0. 25.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  5.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3. 22.] 
adversary cards in discard: [15.  1.  8.  6. 16.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.32198429107666



action possibilites: [-1] 
expected returns: [[11.290959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  0. 11.  0.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3. 22.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.982438564300537





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 8.430801 ]
 [10.208155 ]
 [ 6.3678455]
 [10.240428 ]
 [10.858549 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  0. 11.  0.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  3. 22.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.290959358215332






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 14.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  3. 22.] 
cards in discard: [15.  1.  8.  6. 16.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  3.  3.  0.  0.] 
cards in discard: [15.  1.  8.  6. 16.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [22. 16. 15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  3.  3.  0.  0.] 
cards in discard: [15.  1.  8.  6. 16.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [22. 16. 15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  3.  3.  0.  0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [22. 16. 15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [10. 29.  3.  0. 11.] 
adversary cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 29.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[-5.9309907]
 [-7.0360937]
 [-3.7771235]
 [-4.6128078]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  0. 11.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  6.  4.  0. 14.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.858549118041992



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[ 0.12128663]
 [-1.4050258 ]
 [ 2.2475204 ]
 [-1.4050258 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11. 10.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  3.  9.  8.] 
adversary cards in hand: [ 6.  6.  4.  0. 14.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -3.777122974395752



action possibilites: [-1] 
expected returns: [[-6.215192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6.  6.  4.  0. 14.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 3.2569875717163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-8.328802 ]
 [-6.475993 ]
 [-9.029846 ]
 [-6.2965903]
 [-6.320465 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  6.  9.  8.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6.  6.  4.  0. 14.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.215191841125488



buy possibilites: [-1] 
expected returns: [[-3.2428193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10.] 
cards in discard: [10.  8. 10.  8.  3. 10. 11. 29. 11.  8.  0.  0. 11. 25. 11. 10.  3.  0.
 11.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  5.  9.  8.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 6.  6.  4.  0. 14.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -6.296588897705078






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  4.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  4.  0. 14.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  5.  9.  8.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 4. 0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  5.  9.  8.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 3.  8. 25.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 4. 0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  5.  9.  8.  8. 10.  2.  9.  8.] 
adversary cards in hand: [ 3.  8. 25.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 4. 0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [ 3.  8. 25.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[15.558693 ]
 [14.6583805]
 [20.597767 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 25.] 
cards in discard: [0. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  4.  8.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -8.651439666748047



action possibilites: [-1] 
expected returns: [[0.24432015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  3.  8.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.59776496887207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.0843415 ]
 [-5.5849934 ]
 [ 0.03692818]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  3.  8.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [ 3.  0.  1.  0. 11.] 
adversary cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.24432015419006348






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  0. 11.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  3.  8.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [11. 10. 11. 29.  8.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [11. 10. 11. 29.  8.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [11. 10. 11. 29.  8.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [15.  1.  8.  6. 16.  6.  3. 22. 16. 15.  3.  3. 14.  3.  3.  0.  0. 10.
 14.  6.  6.  4.  0.  6. 16.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [11. 10. 11. 29.  8.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 10. 11. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 29.  8.] 
expected returns: [[-1.9958053 ]
 [ 0.83190656]
 [-1.8419352 ]
 [ 0.83190656]
 [ 1.5333056 ]
 [-1.0988479 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 29.  8.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.03692817687988281



action possibilites: [-1. 11. 10. 11.  8. 11.] 
expected returns: [[-9.029846]
 [-8.992479]
 [-9.029846]
 [-8.992479]
 [-9.029846]
 [-8.992479]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  8. 11.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  1.  9.  8.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.533304214477539



action possibilites: [-1] 
expected returns: [[8.700705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 11.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -8.333122253417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[6.323262 ]
 [3.7563696]
 [8.365111 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8. 11.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.700704574584961






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [10.  0. 10. 10.  8.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [10.  0. 10. 10.  8.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.  8.] 
expected returns: [[15.458151]
 [13.420097]
 [13.420097]
 [13.420097]
 [14.370064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.  8.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14.  6.  3. 16. 22.] 
adversary cards in discard: [6. 6. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 8.3651123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.453156]
 [ 8.258724]
 [15.542662]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.  8.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14.  6.  3. 16. 22.] 
adversary cards in discard: [6. 6. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.458152770996094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [14.  6.  3. 16. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3. 16. 22.] 
cards in discard: [6. 6. 6. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 10.  8.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3. 16. 22.] 
cards in discard: [6. 6. 6. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 10.  8.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3. 16. 22.] 
cards in discard: [6. 6. 6. 0. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0. 10.  8.  3. 11.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-9.029847]
 [-9.029847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  3. 11.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14.  3.  3.  3. 15.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.542661666870117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-9.029847]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3. 11.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14.  3.  3.  3. 15.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.029847145080566



buy possibilites: [-1] 
expected returns: [[-6.5788007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  3. 11.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14.  3.  3.  3. 15.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 25.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -9.029847145080566






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  3. 15.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [29. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.  0.  0. 10.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  3.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [29. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.  0.  0. 10.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  3.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [29. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.  0.  0. 10.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  3.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [29. 11.  3.  0. 10.] 
adversary cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.  0.  0. 10.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 11.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[-8.589949 ]
 [-6.4923873]
 [-7.3232503]
 [-9.029847 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  0. 10.] 
cards in discard: [ 0.  0. 25.  3.  8. 11. 10. 10. 29. 11. 10. 11.  8. 11. 10.  0. 10. 10.
  8.  0.  0. 10.  8.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 6. 15.  0. 16.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.578800678253174



action possibilites: [-1. 11. 10.] 
expected returns: [[30.749357]
 [33.24047 ]
 [28.996042]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  3.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 6. 15.  0. 16.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.524398803710938



action possibilites: [-1] 
expected returns: [[-0.5315795]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6. 15.  0. 16.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.329933166503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.008665 ]
 [-5.139754 ]
 [-0.6662978]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [ 0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6. 15.  0. 16.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0  0] -> size -> 37 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.5315794944763184






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 16.  0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 15  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6
  3  0 14  6 11  6  3 10  6 16  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  5.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 8. 10. 10. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 8. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 11. 10.] 
expected returns: [[11.193701]
 [10.942698]
 [10.23292 ]
 [10.23292 ]
 [12.985612]
 [10.23292 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 11. 10.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  7.] 
adversary cards in hand: [16.  1.  4.  8.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.6662960052490234



action possibilites: [-1] 
expected returns: [[13.09194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [16.  1.  4.  8.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.283758163452148





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.038616]
 [ 8.747721]
 [13.025829]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10. 10.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [16.  1.  4.  8.  0.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8  0] -> size -> 38 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.091939926147461






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [16.  1.  4.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  4.  8.  0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  8  0 16  6  3 15  6  3
  0 14  6 11  6  3 10  6 16  1  0  0  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  4.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 8. 11.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 8. 11.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 26. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 8. 11.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 0.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 8. 11.  0. 10. 10.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 11.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 10.] 
expected returns: [[-8.912696]
 [-9.029846]
 [-8.497427]
 [-9.029846]
 [-9.029846]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  3.  1.  3. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.025840759277344



action possibilites: [-1] 
expected returns: [[-8.104431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  1.  3. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -7.988204002380371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-8.741524]
 [-9.021149]
 [-8.074909]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  1.  3. 10.] 
adversary cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.10443115234375






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  3. 10.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 6.] 
cards in discard: [ 6.  6.  6.  0.  0.  0. 14.  6.  3. 16. 22.  0. 15. 14.  3.  3.  3.  8.
  0. 16.  6.  0.  0.  8.  3. 16.  1.  4.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[-4.903871 ]
 [-2.9399736]
 [-5.7291694]
 [-2.9399736]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.  0.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 1.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -8.074912071228027



action possibilites: [-1] 
expected returns: [[-8.354098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 1.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -2.165239095687866





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-9.029846]
 [-8.635407]
 [-9.029846]
 [-8.543193]
 [-8.314325]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 1.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.354098320007324






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  6. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8. 29. 10. 11.  8.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1.  6. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  9.  4.] 
adversary cards in hand: [ 8. 29. 10. 11.  8.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1.  6. 11.] 
cards in discard: [22.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  4.] 
adversary cards in hand: [ 8. 29. 10. 11.  8.] 
adversary cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 8. 29. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 11.  8.] 
expected returns: [[14.131584]
 [13.715565]
 [16.33636 ]
 [13.148943]
 [15.522165]
 [13.715565]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 11.  8.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  4.] 
adversary cards in hand: [14. 14.  0.  0.  6.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -8.314329147338867



action possibilites: [-1. 10. 11.  8.] 
expected returns: [[1.6267557]
 [0.5026393]
 [3.8576226]
 [1.3761446]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  4.] 
adversary cards in hand: [14. 14.  0.  0.  6.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.277009963989258



action possibilites: [-1] 
expected returns: [[-7.0044756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [14. 14.  0.  0.  6.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 4.731120586395264





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-7.186447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.] 
cards in discard: [ 0. 15. 29. 11.  3. 10.  3. 15. 11.  8. 10. 10. 10. 15. 11.  8.  0. 10.
 10. 15. 11. 10.  0. 11.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [14. 14.  0.  0.  6.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.0044755935668945






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [14. 14.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  0.  0.  6.] 
cards in discard: [22.  1.  0.  1.  6. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [11. 10.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.] 
cards in discard: [22.  1.  0.  1.  6. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0. 25.  0.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.] 
cards in discard: [22.  1.  0.  1.  6. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 25. 29.  8.  3.  7.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0. 25.  0.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0. 25.  0.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 3.5174732]
 [10.442408 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [11. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  3.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [22.  6.  6.  8.  1.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16] -> size -> 42 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -0.9376288652420044



action possibilites: [-1] 
expected returns: [[-9.029847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.] 
cards in discard: [11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [22.  6.  6.  8.  1.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.442404747009277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-9.029846]
 [-9.029846]
 [-9.029846]
 [-9.029846]
 [-9.029846]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.] 
cards in discard: [11. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 25. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [22.  6.  6.  8.  1.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.029847145080566



buy possibilites: [-1] 
expected returns: [[-4.536027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.] 
cards in discard: [11. 10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [22.  6.  6.  8.  1.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6] -> size -> 43 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -9.029847145080566






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [22.  6.  6.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  6.  8.  1.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [10. 29. 11. 11. 15.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  6.  8.  1.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 25. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [10. 29. 11. 11. 15.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  6.  8.  1.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [10. 29. 11. 11. 15.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 29. 11. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11. 15.] 
expected returns: [[0.50369024]
 [0.19901323]
 [3.4387364 ]
 [2.3523264 ]
 [2.3523264 ]
 [0.88800526]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 11. 15.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0.  3.  3.  6. 16.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.536026954650879



action possibilites: [-1. 10. 11. 11. 15.] 
expected returns: [[-9.029846]
 [-9.029846]
 [-9.029846]
 [-9.029846]
 [-9.029846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 15.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0.  3.  3.  6. 16.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.2201972007751465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-9.029847]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11. 15.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0] -> size -> 36 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0.  3.  3.  6. 16.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.029847145080566



buy possibilites: [-1] 
expected returns: [[-8.487379]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11. 15.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0.  3.  3.  6. 16.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.] 
adversary owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -20.   0.   0.
   0.   0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -9.029847145080566






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  6. 16.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0
 14  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [10. 15. 10. 11.  0.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [10. 15. 10. 11.  0.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [10. 15. 10. 11.  0.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 15. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 11.] 
expected returns: [[2.2933893]
 [1.9258361]
 [3.1705647]
 [1.9258361]
 [6.157752 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 11.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  3.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.48737907409668



action possibilites: [-1] 
expected returns: [[-9.029847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 49 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 6.546655654907227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-9.029847]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.029847145080566



buy possibilites: [-1] 
expected returns: [[-9.029847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -40.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -9.029847145080566






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [ 8.  8.  8. 29. 10.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [ 8.  8.  8. 29. 10.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  8.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 29. 10.] 
expected returns: [[11.399965]
 [ 9.893571]
 [ 9.893571]
 [ 9.893571]
 [14.769524]
 [ 8.790664]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 29. 10.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.029847145080566



action possibilites: [-1.  8.  8.  8. 10.] 
expected returns: [[2.7649612]
 [1.3963394]
 [1.3963394]
 [1.3963394]
 [1.0032301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8. 10.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.943143844604492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.25151372]
 [-1.0848693 ]
 [ 2.3786206 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  8. 10.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.7649574279785156






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [10. 15.  3.  0. 11.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  3.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [10. 15.  3.  0. 11.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [10. 15.  3.  0. 11.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 15.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[14.948425]
 [15.767103]
 [16.3733  ]
 [18.5582  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  0. 11.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  2.] 
adversary cards in hand: [16.  0.  4. 15.  0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.378615379333496



action possibilites: [-1] 
expected returns: [[-9.029847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [16.  0.  4. 15.  0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 19.439905166625977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-9.029847]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [16.  0.  4. 15.  0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.029847145080566



buy possibilites: [-1] 
expected returns: [[-0.39338446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  3.  0.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [16.  0.  4. 15.  0.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -60.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -9.029847145080566






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [16.  0.  4. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  4. 15.  0.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0. 10. 15.  3.  8.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  4. 15.  0.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0. 10. 15.  3.  8.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 41 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  4. 15.  0.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0. 10. 15.  3.  8.] 
adversary cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 41 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[ 1.5822725 ]
 [-0.00227785]
 [ 1.9840546 ]
 [ 1.400085  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  3.  8.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11
 10 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3.  6. 16.  6.  8.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.3933844566345215



action possibilites: [-1] 
expected returns: [[2.0739188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3.  6. 16.  6.  8.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 1.9840431213378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-0.26844835]
 [ 2.157167  ]
 [ 1.5394549 ]
 [-2.2539113 ]
 [ 3.3921008 ]
 [ 1.5841961 ]
 [ 2.0739174 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  3.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3.  6. 16.  6.  8.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.0739188194274902



buy possibilites: [-1] 
expected returns: [[3.9344234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.] 
cards in discard: [11. 10.  0. 25.  0.  0. 15.  3.  0.  0. 29. 10. 11. 11. 15. 15.  0. 11.
 10. 15. 10.  0. 10. 29.  8.  8.  8. 10. 15.  0. 11. 10. 15.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3.  6. 16.  6.  8.] 
adversary cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 3.392101287841797






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 16.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.  6.  8.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11] -> size -> 41 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.  6.  8.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0] -> size -> 46 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11] -> size -> 41 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 16.  6.  8.] 
cards in discard: [22.  1.  0.  1.  6. 11. 16. 14. 14.  0.  0.  6.  6.  3. 22.  6.  6.  8.
  1.  0. 16.  3.  3.  6.  0.  3.  3.  0. 10.  8.  3.  0.  0.  3.  0.  0.
 16.  0.  4. 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0.  0.  3. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11] -> size -> 41 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-9.029847]
 [-9.029847]
 [-9.029847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  1. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.9344234466552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-9.029846]
 [-9.029846]
 [-9.029846]
 [-9.029846]
 [-9.029846]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  1. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.029847145080566



buy possibilites: [-1] 
expected returns: [[-4.611274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11. 11.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0.  3.  1. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0] -> size -> 47 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -70.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -9.029847145080566






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 14. 11.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3. 10. 11. 10. 25.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 14. 11.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 24. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3. 10. 11. 10. 25.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 14. 11.] 
cards in discard: [3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 23. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 3. 10. 11. 10. 25.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 25.] 
expected returns: [[10.292294]
 [10.783516]
 [12.416906]
 [10.783516]
 [14.020983]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10. 25.] 
cards in discard: [ 0.  0.  0.  3. 11. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  2.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [6. 1. 8. 3. 4.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3] -> size -> 48 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.611273765563965



action possibilites: [-1] 
expected returns: [[0.41531277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.  0. 10.] 
cards in discard: [ 0.  0.  0.  3. 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [6. 1. 8. 3. 4.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3
  6] -> size -> 49 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.020980834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.6059623 ]
 [-4.87097   ]
 [-0.59901786]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 10.  0. 10.] 
cards in discard: [ 0.  0.  0.  3. 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [6. 1. 8. 3. 4.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.] 
adversary owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3
  6] -> size -> 49 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.4153127670288086






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [6. 1. 8. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 8. 3. 4.] 
cards in discard: [ 3.  0.  3.  1. 14. 11.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 14  0  1  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14
  6 11  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3
  6] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0. 11.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4.] 
cards in discard: [ 3.  0.  3.  1. 14. 11.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0. 11.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4.] 
cards in discard: [ 3.  0.  3.  1. 14. 11.  6.] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 0. 11.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-5.7318487]
 [-4.841986 ]
 [-4.841986 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  1.] 
adversary cards in hand: [ 8.  3.  0. 16. 14.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.] 
adversary owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.5990169048309326



action possibilites: [-1] 
expected returns: [[-7.1798177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [ 8.  3.  0. 16. 14.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.] 
adversary owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -4.413181304931641





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-8.886061 ]
 [-6.3968086]
 [-7.0516424]
 [-9.029846 ]
 [-5.084663 ]
 [-6.9972878]
 [-6.5277395]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  2.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [ 8.  3.  0. 16. 14.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.] 
adversary owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.1798176765441895



buy possibilites: [-1] 
expected returns: [[-9.029847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [ 8.  3.  0. 16. 14.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.] 
adversary owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -5.084664821624756






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 16. 14.] 
cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [ 8.  0. 29.  0. 29.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11. 11.  0.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 16. 14.] 
cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [ 8.  0. 29.  0. 29.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11. 11.  0.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[ 0.7553034]
 [-1.2456287]
 [ 0.6748972]
 [ 0.6748972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.  0. 29.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11. 11.  0.  0.
  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [16.  6.  3.  6.  0.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.  8.  3.  0. 16. 14.] 
adversary owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.029847145080566





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-3.1639314 ]
 [-1.9909811 ]
 [-4.1456    ]
 [-2.125777  ]
 [-0.12500048]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 29.  0. 29.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11. 11.  0.  0.
  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [16.  6.  3.  6.  0.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.  8.  3.  0. 16. 14.] 
adversary owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.7553000450134277



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [16.  6.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3.  6.  0.] 
cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.  8.  3.  0. 16. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11
  6  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  1.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [15.  0. 10. 10.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11. 11.  0.  0.
  0. 11.  8.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
adversary victory points: 3
player victory points: 2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 4 
Witch: 1 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  0. 10. 10.  8.] 
cards in discard: [ 0.  0.  0.  3. 11. 11. 25.  3. 10. 11. 10.  0. 10. 15. 11. 11.  0.  0.
  0. 11.  8.  0. 29.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 25  8 11  8 11  8 10 10 29 11 10 10 10 11 10
 11 10  8 10  0 15 15 15 15 15  0  0 15  0 15  0 11  0 15 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 23. 29.  8.  0.  6.  1.  2.  9.  8.  8. 10.  0.  8.  0.] 
adversary cards in hand: [6. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  1. 14. 11.  6.  8.  6.  4.  8.  3.  0. 16. 14.  6.] 
adversary owned cards: [ 0  3  0 14  0  1  6 16 22  3  6  4  0 16  6  3 15  6  3  0 14  6 11  6
  3 10  6 16  1  0  0  8  0  8  3  0 22 16  6  3  0  8  0  0  3  6  6] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000055 

action type: buy - action -1.0
Learning step: 120002.2109375
desired expected reward: 120002.0859375



