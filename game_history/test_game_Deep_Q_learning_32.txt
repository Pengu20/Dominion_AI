 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.46515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0 -160    0    0
    0    0] 
sum of rewards: -165 

action type: buy - action 0.0
Learning step: -7.938298225402832
desired expected reward: 25.519153594970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[108.7401  ]
 [113.13813 ]
 [110.543976]
 [101.630615]
 [115.71156 ]
 [113.75395 ]
 [111.1107  ]
 [111.86088 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 114.0369873046875



buy possibilites: [-1] 
expected returns: [[108.88185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 115.71157836914062






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[106.777176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.88185119628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[105.058685]
 [109.0303  ]
 [106.728775]
 [ 98.34283 ]
 [108.42712 ]
 [111.2579  ]
 [109.56578 ]
 [112.4909  ]
 [102.82753 ]
 [107.25705 ]
 [106.783966]
 [107.73519 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.13819885253906



buy possibilites: [-1] 
expected returns: [[109.49334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.49090576171875






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[102.13735 ]
 [106.00278 ]
 [107.202324]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.49333953857422



action possibilites: [-1. 11.] 
expected returns: [[87.414215]
 [90.69464 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.13099670410156



action possibilites: [-1] 
expected returns: [[101.90906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.73130798339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 95.71174 ]
 [100.538704]
 [ 97.7634  ]
 [ 90.32099 ]
 [ 87.54569 ]
 [ 99.82304 ]
 [103.35215 ]
 [101.21315 ]
 [110.547   ]
 [104.91078 ]
 [ 93.018166]
 [ 96.48395 ]
 [ 98.408905]
 [ 91.657005]
 [ 97.84511 ]
 [ 99.12624 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.9090576171875



buy possibilites: [-1] 
expected returns: [[124.86632]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 110.5469970703125






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[107.99974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.86631774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[104.67491 ]
 [108.51071 ]
 [106.2724  ]
 [ 98.249954]
 [110.7532  ]
 [109.05307 ]
 [106.77976 ]
 [107.22923 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.52699279785156



buy possibilites: [-1] 
expected returns: [[121.51137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 25. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 110.75318908691406






Player: 1 
cards in hand: [3. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[104.93859 ]
 [104.990845]
 [110.215775]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.51136779785156



action possibilites: [-1. 10.] 
expected returns: [[110.91574 ]
 [110.751526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.9586181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[104.056114]
 [108.63258 ]
 [105.950485]
 [ 96.25377 ]
 [107.91523 ]
 [111.14525 ]
 [109.25093 ]
 [112.52205 ]
 [101.47128 ]
 [106.56886 ]
 [105.98099 ]
 [106.73308 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.91574096679688



buy possibilites: [-1] 
expected returns: [[138.59755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 112.52204895019531






Player: 1 
cards in hand: [3. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 11.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[137.4044]
 [140.4933]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.59754943847656



action possibilites: [-1] 
expected returns: [[144.87616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.12413024902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[141.61282]
 [143.38635]
 [134.99371]
 [146.13567]
 [145.22084]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.87615966796875



buy possibilites: [-1] 
expected returns: [[170.36595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 146.13565063476562






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  1.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  1.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[126.64082]
 [129.72658]
 [135.85594]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 170.36595153808594



action possibilites: [-1] 
expected returns: [[136.44753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 135.40280151367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[133.72429]
 [138.04086]
 [135.58475]
 [126.4778 ]
 [140.50401]
 [138.62   ]
 [136.16391]
 [137.04503]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 136.44752502441406



buy possibilites: [-1] 
expected returns: [[132.91582]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3. 10.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 14.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 140.50401306152344






Player: 1 
cards in hand: [ 3. 10. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  8.  0.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  8.  0.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  3.  8.  0.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29. 11.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[162.59193]
 [168.60587]
 [167.13574]
 [165.10979]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  8.  0.] 
cards in discard: [11. 25.  0. 11.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 132.9158172607422



action possibilites: [-1. 11.  8. 10.] 
expected returns: [[139.09561]
 [142.68161]
 [140.83218]
 [138.35666]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 168.29522705078125



action possibilites: [-1] 
expected returns: [[150.51187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 145.15069580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.54117]
 [148.55956]
 [139.3834 ]
 [151.55368]
 [151.21309]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.51187133789062



buy possibilites: [-1] 
expected returns: [[136.4983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 151.55368041992188






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.  8. 29. 11.  3.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.  3. 14.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.  8. 29. 11.  3.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 6. 10.  3. 14.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.  8. 29. 11.  3.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[103.117905]
 [107.147316]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [11. 25.  0. 11.  0.  0.  3. 10. 10.  8. 29. 11.  3.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.49830627441406



action possibilites: [-1. 29.] 
expected returns: [[120.48445]
 [124.82892]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.21073150634766



action possibilites: [-1. 11.] 
expected returns: [[137.03061]
 [140.19194]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 124.82891845703125



action possibilites: [-1] 
expected returns: [[130.5051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 142.2454833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[130.41812 ]
 [134.33888 ]
 [132.03137 ]
 [125.96045 ]
 [123.65293 ]
 [133.71568 ]
 [136.49956 ]
 [134.88643 ]
 [142.20905 ]
 [137.64693 ]
 [128.12126 ]
 [130.87128 ]
 [132.57892 ]
 [126.950485]
 [132.04204 ]
 [132.53932 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.50509643554688



buy possibilites: [-1] 
expected returns: [[192.89531]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 29.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 142.2090606689453






Player: 1 
cards in hand: [14. 29.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  3.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[143.79422]
 [142.37154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [15. 14. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 492   0] 
sum of rewards: 487 

action type: discard_down_to_3_cards - action 8
Learning step: 0
desired expected reward: 200.26295471191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.87132]
 [132.00845]
 [143.98892]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [15. 14. 29.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 144.45567321777344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [15. 14. 29.  3.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  0. 25.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [15. 14. 29.  3.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  0. 25.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [15. 14. 29.  3.  1.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  0. 25.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[114.83394 ]
 [112.6319  ]
 [116.10096 ]
 [121.039276]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 25.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.98895263671875



action possibilites: [-1] 
expected returns: [[166.42564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  8. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 121.42412567138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[167.52512]
 [168.9995 ]
 [162.50494]
 [171.2088 ]
 [170.90724]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.  8. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  8.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.42564392089844



buy possibilites: [-1] 
expected returns: [[165.91579]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.  8. 11.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  0.  3.  0.  8.  3.  0. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 171.2088165283203






Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8] -> size -> 24 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  7.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8] -> size -> 24 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [15. 14. 29.  3.  1.  3. 11.  3.  0.  0.  0.  6.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8] -> size -> 24 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11.  3.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[129.36674 ]
 [132.43575 ]
 [130.34274 ]
 [127.735214]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 165.91578674316406



action possibilites: [-1] 
expected returns: [[129.49863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 132.99270629882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.82977]
 [121.44385]
 [130.98235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  3.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.49862670898438






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  8. 25.  0.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  8. 25.  0.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  8. 25.  0.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  0.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.] 
expected returns: [[158.61446]
 [162.69427]
 [158.5858 ]
 [168.20262]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 25.  0.] 
cards in discard: [10. 11.  3.  8. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  6.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.98236083984375



action possibilites: [-1] 
expected returns: [[135.83759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  0.  0. 29.] 
cards in discard: [10. 11.  3.  8. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  6.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 167.66419982910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[133.1875 ]
 [137.97258]
 [135.36378]
 [125.46027]
 [140.78986]
 [138.58727]
 [135.97849]
 [138.25227]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  0.  0. 29.] 
cards in discard: [10. 11.  3.  8. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  6.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  6.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.83758544921875



buy possibilites: [-1] 
expected returns: [[183.17552]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  0.  0. 29.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  5.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  6.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 140.7898712158203






Player: 1 
cards in hand: [ 3. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  6.] 
cards in discard: [0. 3. 0. 0. 0. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  5.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 1.] 
cards in discard: [0. 3. 0. 0. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  5.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 1.] 
cards in discard: [0. 3. 0. 0. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  5.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 1.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  4.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[152.21437]
 [150.17068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  4.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 183.17552185058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[147.06323]
 [150.92511]
 [148.84297]
 [141.01321]
 [153.2375 ]
 [151.4254 ]
 [149.3372 ]
 [151.33774]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  4.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 152.21437072753906



buy possibilites: [-1] 
expected returns: [[173.11464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  3.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 153.2375030517578






Player: 1 
cards in hand: [ 3.  0. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  8.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  3.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 11.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 11.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  7. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 11.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 11.] 
adversary cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [25. 10. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 11.] 
expected returns: [[168.19786]
 [174.93251]
 [164.77156]
 [164.77156]
 [168.97414]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 10.  0. 11.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  6. 15. 29.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.  3. 11.  3.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11  3] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 173.11463928222656



action possibilites: [-1] 
expected returns: [[168.80098]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11. 11.  8.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  6. 15. 29.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.  3. 11.  3.
  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11  3  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 174.93251037597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[165.75575]
 [160.12605]
 [170.24927]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11. 11.  8.] 
cards in discard: [10. 11.  3.  8. 10.  3. 11. 25. 29.  0.  8.  0.  0. 29. 11.  0.  3.  0.
  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 14.  6. 15. 29.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.  3. 11.  3.
  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11  3  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 168.8009796142578






Player: 1 
cards in hand: [ 0. 14.  6. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6. 15. 29.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  6. 11. 10.  3.  0.  3.  6.  1. 11.  3. 11.  3.
  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 14. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6. 15. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11
 11  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6. 11.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  8. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 29. 10.] 
expected returns: [[141.5298 ]
 [144.79945]
 [142.81865]
 [146.23038]
 [146.23038]
 [140.28647]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 170.249267578125



action possibilites: [-1. 11.  8. 29. 10.] 
expected returns: [[114.964966]
 [117.24377 ]
 [115.456604]
 [118.52919 ]
 [113.310234]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 144.5622100830078



action possibilites: [-1. 11.  8. 10.] 
expected returns: [[119.04277]
 [121.78203]
 [120.21767]
 [118.18414]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 118.52922058105469



action possibilites: [-1] 
expected returns: [[106.863434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 123.99726867675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[103.98166 ]
 [107.91866 ]
 [105.7111  ]
 [ 97.56507 ]
 [110.17114 ]
 [108.441734]
 [106.23417 ]
 [107.32694 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  2.  6.  8.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.86343383789062



buy possibilites: [-1] 
expected returns: [[117.22148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  3.] 
cards in discard: [10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  1.  6.  8.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 11.  0.  0.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 110.17115783691406






Player: 1 
cards in hand: [ 6.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  0.] 
cards in discard: [ 3. 29. 15. 14.  6. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  1.  6.  8.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  1.  6.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  1.  6.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 25. 11.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[118.60863]
 [121.18593]
 [129.15479]
 [121.18593]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 25. 11.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  6. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29  8] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.22148132324219



action possibilites: [-1] 
expected returns: [[150.93275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11. 25. 11.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29  8  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.15478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.77269]
 [148.47745]
 [141.01964]
 [150.8609 ]
 [151.14195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11. 25. 11.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29  8  6] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.93275451660156






Player: 1 
cards in hand: [3. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11
  3  6  3 29  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[121.363686]
 [123.50037 ]
 [121.809586]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0. 10. 11.  1.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.1419219970703



action possibilites: [-1] 
expected returns: [[95.17468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 10. 11.  1.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.53962707519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[91.546745]
 [86.247406]
 [95.398796]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 6.  0. 10. 11.  1.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.1746826171875






Player: 1 
cards in hand: [ 6.  0. 10. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 11.  1.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10. 11.
  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10. 11.  1.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  5.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10. 11.
  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10. 11.  1.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  8. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10. 11.
  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 10.] 
expected returns: [[137.37198]
 [134.2824 ]
 [134.2824 ]
 [136.41728]
 [134.2824 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8. 10.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10. 11.
  0.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.
  8.  6.  0. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.39878845214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[131.67867]
 [125.28656]
 [137.2612 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  8. 10.] 
cards in discard: [10. 11. 29. 29. 11.  8. 10.  0.  3. 25.  0.  0. 11. 11. 25. 11. 10. 11.
  0.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.
  8.  6.  0. 10. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 137.37197875976562



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.
  8.  6.  0. 10. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 3. 29. 15. 14.  6. 11. 29.  8. 11.  6.  0.  0.  0.  6.  0.  8.  0.  3.
  8.  6.  0. 10. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[136.61981]
 [136.66866]
 [134.86154]
 [134.86154]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 25 11 29 10  8 11 10  8 10 25  8
 10 11 11 10 11 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 137.26121520996094



action possibilites: [-1] 
expected returns: [[146.3413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 134.82797241210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[140.95134]
 [143.3844 ]
 [133.54347]
 [146.8973 ]
 [147.2834 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.34129333496094






Player: 1 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 11. 29.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 11. 29.  0.] 
adversary cards in discard: [ 8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 10. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[136.54926]
 [133.98059]
 [133.98059]
 [138.0679 ]
 [139.47977]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 29.  0.] 
cards in discard: [ 8. 10.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  1. 11.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.2834014892578



action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[ 98.34893]
 [ 96.8782 ]
 [ 96.8782 ]
 [101.19323]
 [101.19323]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0. 11.] 
cards in discard: [ 8. 10.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  1. 11.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 139.47976684570312



action possibilites: [-1] 
expected returns: [[129.00804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [ 8. 10.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  1. 11.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.60003662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[125.179146]
 [126.94342 ]
 [119.14796 ]
 [129.54788 ]
 [129.6476  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [ 8. 10.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  1. 11.] 
adversary cards in discard: [0. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.00804138183594






Player: 1 
cards in hand: [ 8. 14.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  1. 11.] 
cards in discard: [0. 0. 6. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 25. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  1. 11.] 
cards in discard: [0. 0. 6. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 25. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  1. 11.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 25. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 10. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25. 11.] 
expected returns: [[176.6869 ]
 [185.08469]
 [173.31657]
 [185.08469]
 [178.13306]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10. 25. 11.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  5. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8 10] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.64759826660156



action possibilites: [-1] 
expected returns: [[100.64044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25. 11.  3.  3.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 185.08470153808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 99.26161]
 [ 92.05203]
 [104.90773]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 25. 11.  3.  3.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8 10  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.64044189453125






Player: 1 
cards in hand: [ 8.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10.  0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 10 29  6  0 15 11  6  8  0  6 11 11  3  6
  3 29  8  6  0  8 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 10.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  0. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[149.296  ]
 [152.74213]
 [146.89912]
 [146.89912]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0. 10.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6  3] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.90774536132812



action possibilites: [-1. 10. 10.] 
expected returns: [[178.184  ]
 [174.93507]
 [174.93507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6  3] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 148.6752471923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[172.4155 ]
 [176.96397]
 [174.61285]
 [165.24371]
 [179.73169]
 [177.53433]
 [178.43216]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  1.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6  3] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 178.1840057373047



buy possibilites: [-1] 
expected returns: [[150.62843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  3.  3. 29.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6  3] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 179.73170471191406






Player: 1 
cards in hand: [11.  3.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 29.  8.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  1  3 14 29  6  0 15 11  6  8  0  6 11 11  3  6  3
 29  8  6  0  8 10  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11] -> size -> 31 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11] -> size -> 31 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11] -> size -> 31 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  3. 11.] 
adversary cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11] -> size -> 31 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[145.691  ]
 [144.34312]
 [146.659  ]
 [146.659  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  3. 11.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.62843322753906



action possibilites: [-1] 
expected returns: [[164.1205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 11.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 144.3431396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.67213]
 [149.76634]
 [164.1823 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 11.] 
cards in discard: [ 8. 10.  0.  0. 10. 29. 11. 10. 10.  0. 11. 25.  0. 10. 25. 11.  3.  3.
  8. 11. 29.  0. 10.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 164.12049865722656






Player: 1 
cards in hand: [ 0.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  4.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  3.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 11.] 
expected returns: [[131.64224]
 [128.39833]
 [128.39833]
 [135.08643]
 [133.33253]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 29. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  3.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.18231201171875



action possibilites: [-1. 10. 11.] 
expected returns: [[137.1942 ]
 [133.9171 ]
 [139.36395]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.] 
cards in discard: [ 0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  3.  8.  6.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 130.3440704345703



action possibilites: [-1] 
expected returns: [[111.74494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 0. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  3.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 136.79612731933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[108.47873 ]
 [109.97746 ]
 [102.888306]
 [112.4514  ]
 [111.72392 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 0. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  3.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.74494171142578



buy possibilites: [-1] 
expected returns: [[135.84575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 0. 10. 15.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  2.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 112.45140075683594






Player: 1 
cards in hand: [ 6. 29. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 15.  6.  0.] 
cards in discard: [ 0.  0.  6.  0.  3. 10.  8. 14.  0.  1. 11.  6.  3.  8.  0.  6.  0.  0.
  8. 11.  3.  8. 11.  0.  0.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  2.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  2.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  2.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [15.  0.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [29.  0.  0. 11. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[169.773  ]
 [172.106  ]
 [170.93681]
 [170.93681]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11. 11.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.8457489013672



action possibilites: [-1.] 
expected returns: [[153.74715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 168.9097137451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[151.47874]
 [155.67224]
 [153.43074]
 [144.72025]
 [155.17238]
 [156.20659]
 [159.57698]
 [149.44833]
 [153.64186]
 [156.23555]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 153.7471466064453



buy possibilites: [-1] 
expected returns: [[172.18968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 159.5769500732422






Player: 1 
cards in hand: [11.  3.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0. 11.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  3. 11.  3.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29] -> size -> 35 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0. 11.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  3. 11.  3.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29] -> size -> 35 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0. 11.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [10. 10.  3. 11.  3.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29] -> size -> 35 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[170.43845]
 [168.22597]
 [168.22597]
 [171.19374]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11.  3.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 172.18968200683594



action possibilites: [-1] 
expected returns: [[165.80035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 169.7477264404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[161.36848]
 [154.98415]
 [166.02052]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  3.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0] -> size -> 34 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 165.80035400390625






Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 25. 10. 25.  8.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 25. 10. 25.  8.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [15. 25. 10. 25.  8.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15. 25. 10. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 10. 25.  8.] 
expected returns: [[157.85008]
 [154.88844]
 [163.1766 ]
 [155.0226 ]
 [163.1766 ]
 [156.6122 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 10. 25.  8.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  4. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [14. 10.  6.  8.  6.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.0205535888672



action possibilites: [-1] 
expected returns: [[163.07297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25.  8.  0.  8.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [14. 10.  6.  8.  6.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 163.17662048339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[152.54005]
 [145.1272 ]
 [161.09511]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 25.  8.  0.  8.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [14. 10.  6.  8.  6.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.07296752929688






Player: 1 
cards in hand: [14. 10.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  6.  8.  6.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 10. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3. 25. 15. 10. 25.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  8.  6.  0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 10. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3. 25. 15. 10. 25.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  6.  0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 3.  0. 11. 10. 11.] 
adversary cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3. 25. 15. 10. 25.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[147.39836]
 [149.17851]
 [146.14526]
 [149.17851]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10. 11.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3. 25. 15. 10. 25.  8.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 6.  6. 11.  8.  0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.09512329101562



action possibilites: [-1] 
expected returns: [[139.54097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3. 25. 15. 10. 25.  8.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 6.  6. 11.  8.  0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 149 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 147.80955505371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[133.97055]
 [127.5123 ]
 [138.58891]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [ 0. 10. 15.  8. 29. 11. 10.  0. 11. 11. 29. 29.  0.  0.  0. 15. 11. 10.
 10.  3.  3. 25. 15. 10. 25.  8.  0.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 6.  6. 11.  8.  0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.5409698486328






Player: 1 
cards in hand: [ 6.  6. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  8.  0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[142.52309]
 [141.17036]
 [143.60881]
 [138.71667]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  5.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0. 11.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.58888244628906



action possibilites: [-1] 
expected returns: [[112.06319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0. 11.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 141.1703643798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[109.49025 ]
 [111.48316 ]
 [102.82895 ]
 [114.2048  ]
 [114.693375]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0. 11.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.06318664550781






Player: 1 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0. 11.  6.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 25.  8.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0. 11.  6.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 25.  8.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [15.  0.  8. 29.  6.  6.  0.  0. 11.  3.  8.  0. 11.  4.  0.  1.  0.  3.
  0.  6. 10. 14.  6.  8.  6.  0.  0. 11.  6.  6.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [ 0. 25.  8.  0. 11.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 11.] 
expected returns: [[136.54654]
 [144.38414]
 [135.70998]
 [137.91734]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  0. 11.] 
cards in discard: [15. 11.  0.  0.  8. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  3. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0  0] -> size -> 38 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.693359375



action possibilites: [-1] 
expected returns: [[150.58238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11. 11.  0.] 
cards in discard: [15. 11.  0.  0.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0  0  6] -> size -> 39 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 144.3841094970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[146.14998]
 [150.3648 ]
 [148.18187]
 [139.52426]
 [150.89906]
 [151.66461]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11. 11.  0.] 
cards in discard: [15. 11.  0.  0.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [3. 8. 0. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0  0  6] -> size -> 39 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.58238220214844






Player: 1 
cards in hand: [3. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  1 14  6  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6
  0  8 10  6  3  0  3  8  8  0  4  6  0  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 11. 10.  0.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 11. 10.  0.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 11. 10.  0.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [10. 29. 11. 10.  0.] 
adversary cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10. 29. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10.] 
expected returns: [[171.60808]
 [168.7652 ]
 [175.31248]
 [173.64424]
 [168.7652 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 10.  0.] 
cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.6646270751953



action possibilites: [-1. 10. 29.] 
expected returns: [[158.72313]
 [154.36139]
 [161.53929]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.] 
cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0. 11. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 170.73556518554688



action possibilites: [-1.] 
expected returns: [[144.98755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0. 11. 10. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 156.3887176513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[139.9136 ]
 [143.80833]
 [141.71515]
 [133.60504]
 [144.31459]
 [144.18803]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0. 11. 10. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 25. 29.  8.  2. 10.  0.  1.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 144.987548828125



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 5 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0.] 
cards in discard: [15. 11.  0.  0.  8. 10. 25.  0.  8.  0. 11. 11.  0. 11. 10. 10. 11.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 11 29 10  8 11 10  8 10 25  8 10
 11 11 10 11 10 10 11 15 15  8 29 15 15 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 25. 29.  8.  2. 10.  0.  0.  8.  5.  9. 10.  0. 10.  4.] 
adversary cards in hand: [15.  0. 11.  0.  0.] 
adversary cards in discard: [6. 0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  1 14  0 15 11  6  8  0  6 11 11  3  6  3 29  8  6  0  8 10
  6  3  0  3  8  8  0  4  6  0  0  6  0] -> size -> 37 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      40       0       0
       0       0     -40       0       0       8       0] 
sum of rewards: 3000093 

action type: buy - action 8.0
Learning step: 119997.9453125
desired expected reward: 120142.2578125



