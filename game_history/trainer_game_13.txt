 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.048965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.910850524902344
desired expected reward: 9.450868606567383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.336727]
 [21.152405]
 [20.95187 ]
 [19.52407 ]
 [22.47898 ]
 [21.863838]
 [21.663305]
 [22.287601]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5973519086837769
desired expected reward: 21.846965789794922



buy possibilites: [-1] 
expected returns: [[22.36444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.48372945189476013
desired expected reward: 20.4681396484375






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.657162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5596347451210022
desired expected reward: 21.804805755615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.508234]
 [24.32391 ]
 [24.123373]
 [22.695572]
 [23.894384]
 [25.65048 ]
 [25.035341]
 [25.596436]
 [24.194077]
 [24.83481 ]
 [25.00975 ]
 [25.459103]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6366731524467468
desired expected reward: 24.24889373779297



buy possibilites: [-1] 
expected returns: [[25.936901]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5121769905090332
desired expected reward: 25.1383056640625






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  3.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.44993 ]
 [25.641308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6566799283027649
desired expected reward: 25.280221939086914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.69252 ]
 [24.30766 ]
 [22.879862]
 [25.219631]
 [25.643387]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6636815667152405
desired expected reward: 25.071685791015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.551403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6595616936683655
desired expected reward: 24.983827590942383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.384075]
 [24.199753]
 [23.99922 ]
 [22.57142 ]
 [23.770226]
 [25.526327]
 [24.911186]
 [25.47228 ]
 [24.06992 ]
 [24.71065 ]
 [24.885595]
 [25.334946]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6335240006446838
desired expected reward: 24.103618621826172



buy possibilites: [-1] 
expected returns: [[27.11038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3. 11.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [10.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.47166046500205994
desired expected reward: 24.238988876342773






Player: 1 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [10.  0.  0.  0.  3. 15.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.101536]
 [26.292915]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6856101751327515
desired expected reward: 26.42477035522461



action possibilites: [-1] 
expected returns: [[26.69704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.49377569556236267
desired expected reward: 24.378549575805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.765533]
 [25.581207]
 [25.380672]
 [23.952873]
 [26.907784]
 [26.292643]
 [26.092104]
 [26.716406]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07843116670846939
desired expected reward: 26.618608474731445






Player: 1 
cards in hand: [ 0.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  9. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.349972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 10.  3.] 
adversary cards in discard: [11.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6733959913253784
desired expected reward: 26.04300880432129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.601181]
 [25.416859]
 [25.216322]
 [23.788523]
 [26.743431]
 [26.12829 ]
 [25.927757]
 [26.552052]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  8. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 10.  3.] 
adversary cards in discard: [11.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6738059520721436
desired expected reward: 25.811538696289062



buy possibilites: [-1] 
expected returns: [[26.06279]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16. 11.  0.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 10.  3.] 
adversary cards in discard: [11.  0.  0. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.12092176079750061
desired expected reward: 26.031780242919922






Player: 1 
cards in hand: [ 0.  3.  1. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 10.  3.] 
cards in discard: [11.  0.  0. 15.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [11.  0.  0. 15.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [11.  0.  0. 15.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [11.  0.  0. 15.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[27.563763]
 [27.76001 ]
 [26.955147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.641662061214447
desired expected reward: 25.421127319335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.712267]
 [26.317856]
 [24.909012]
 [27.219917]
 [27.629257]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7019001245498657
desired expected reward: 27.00896453857422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[29.50587 ]
 [29.702118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [11.  0. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15. 10.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.666496217250824
desired expected reward: 26.962757110595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.77172 ]
 [28.377308]
 [26.968462]
 [29.279366]
 [29.688704]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [11.  0. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 15. 10.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7379359006881714
desired expected reward: 28.894927978515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 15. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10. 10. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[27.431099]
 [25.894316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  0.] 
cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 11.  0.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.75791335105896
desired expected reward: 28.9307918548584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.768595]
 [26.573463]
 [26.374184]
 [24.965338]
 [27.881828]
 [27.276243]
 [27.076965]
 [27.685581]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  0.] 
cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 11.  0.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6934580206871033
desired expected reward: 26.84961700439453



buy possibilites: [-1] 
expected returns: [[27.47667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  0.] 
cards in discard: [11.  0. 10.  3.  0.  3.  0. 11.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 1. 11.  0.  0.  3.] 
adversary cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.11869880557060242
desired expected reward: 26.454763412475586






Player: 1 
cards in hand: [ 1. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  9. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  9. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [10. 10.  3.  0.  0.  0. 15. 29. 15. 10.  0.  3.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.671535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6613428592681885
desired expected reward: 26.815326690673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.474306]
 [29.279171]
 [29.079891]
 [27.671047]
 [28.85451 ]
 [30.58754 ]
 [29.981953]
 [30.53352 ]
 [29.149174]
 [29.782677]
 [29.954037]
 [30.391293]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  8. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7323123812675476
desired expected reward: 29.07314109802246



buy possibilites: [-1] 
expected returns: [[30.24163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.6719215512275696
desired expected reward: 29.310033798217773






Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 16. 11.] 
adversary cards in discard: [8. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10.  9.  7.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 16. 11.] 
adversary cards in discard: [8. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10.  9.  7.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 16. 11.] 
adversary cards in discard: [8. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[27.24445 ]
 [25.707664]
 [27.440697]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16. 11.] 
cards in discard: [8. 3. 0. 3. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10.  9.  7.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7731387615203857
desired expected reward: 29.46849250793457



action possibilites: [-1] 
expected returns: [[31.26432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.] 
cards in discard: [ 8.  3.  0.  3.  1.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10.  9.  6.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.2794635593891144
desired expected reward: 25.906522750854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.485722]
 [30.09131 ]
 [28.682467]
 [30.993368]
 [31.40271 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 16.] 
cards in discard: [ 8.  3.  0.  3.  1.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10.  9.  6.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1688825786113739
desired expected reward: 31.09543800354004



buy possibilites: [-1] 
expected returns: [[30.02264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 16.] 
cards in discard: [ 8.  3.  0.  3.  1.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  6.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.10822688788175583
desired expected reward: 30.199535369873047






Player: 1 
cards in hand: [8. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  6.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  0.  0.  3.] 
adversary cards in discard: [ 8.  3.  0.  3.  1.  0. 11.  3. 11.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  6.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  0.  0.  3.] 
adversary cards in discard: [ 8.  3.  0.  3.  1.  0. 11.  3. 11.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 3. 0.] 
cards in discard: [ 3.  0. 10.  0.  0.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [11. 10.  0.  0.  3.] 
adversary cards in discard: [ 8.  3.  0.  3.  1.  0. 11.  3. 11.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[24.659168]
 [24.864143]
 [24.069492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  3.] 
cards in discard: [ 8.  3.  0.  3.  1.  0. 11.  3. 11.  0.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  8. 11. 10. 15.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3. 11.  8.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7916104793548584
desired expected reward: 29.231029510498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.930185]
 [23.526571]
 [22.135933]
 [24.418118]
 [24.80953 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.  3.] 
cards in discard: [ 8.  3.  0.  3.  1.  0. 11.  3. 11.  0.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  8. 11. 10. 15.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  3. 11.  8.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6420058012008667
desired expected reward: 24.09279441833496



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8. 11. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11. 10. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11. 10. 15.] 
cards in discard: [ 3.  0. 10.  0.  0.  3. 11.  8.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.  8. 11. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 15.  3.] 
cards in discard: [ 3.  0. 10.  0.  0.  3. 11.  8.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10. 15.  3.] 
cards in discard: [ 3.  0. 10.  0.  0.  3. 11.  8.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[28.85367 ]
 [28.46226 ]
 [29.058645]
 [28.263992]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 15. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5916143655776978
desired expected reward: 24.217914581298828



action possibilites: [-1.  8. 11.] 
expected returns: [[29.098747]
 [28.707335]
 [29.30372 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 15. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.09506681561470032
desired expected reward: 28.25533676147461



action possibilites: [-1.  8.] 
expected returns: [[29.537155]
 [29.145742]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 15. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0.7434991598129272
desired expected reward: 30.24340057373047



action possibilites: [-1] 
expected returns: [[27.752857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 15. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 2
Learning step: 1.1215804815292358
desired expected reward: 28.44906234741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.010574]
 [25.216322]
 [27.889915]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 15. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.0975102186203003
desired expected reward: 28.850366592407227



buy possibilites: [-1] 
expected returns: [[27.223352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 15. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action 0.0
Learning step: 1.155527949333191
desired expected reward: 27.166099548339844






Player: 1 
cards in hand: [ 3. 15. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 15.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  1.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  1.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  1.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  1.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 16.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[28.83015 ]
 [27.324316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  1.  0.] 
cards in discard: [10.  0. 10. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6692553162574768
desired expected reward: 26.554096221923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.19521 ]
 [27.98986 ]
 [27.791595]
 [26.400963]
 [27.568718]
 [29.27953 ]
 [28.68314 ]
 [29.224487]
 [27.858059]
 [28.484879]
 [28.652712]
 [29.07455 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  1.  0.] 
cards in discard: [10.  0. 10. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  5. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7196838855743408
desired expected reward: 28.210765838623047



buy possibilites: [-1] 
expected returns: [[28.231215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  1.  0.] 
cards in discard: [10.  0. 10. 11.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 11.  3.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.5731185078620911
desired expected reward: 27.91175651550293






Player: 1 
cards in hand: [ 8.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  3.] 
cards in discard: [ 1. 15.  3. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8. 10.  3.  0. 16.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  3.] 
cards in discard: [ 1. 15.  3. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8. 10.  3.  0. 16.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  3.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [10.  0. 10. 11.  8. 10.  3.  0. 16.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[23.743141]
 [23.948116]
 [23.948116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [10.  0. 10. 11.  8. 10.  3.  0. 16.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8. 11.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7450750470161438
desired expected reward: 27.48613929748535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.104683]
 [22.688614]
 [21.327017]
 [23.57434 ]
 [23.965752]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [10.  0. 10. 11.  8. 10.  3.  0. 16.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8. 10.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8. 11.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6238167881965637
desired expected reward: 23.212661743164062



buy possibilites: [-1] 
expected returns: [[25.440926]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [10.  0. 10. 11.  8. 10.  3.  0. 16.  1.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8.  9.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8. 11.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.515321731567383
desired expected reward: 11.811697006225586






Player: 1 
cards in hand: [ 1.  3. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  8. 11.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  9.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6] -> size -> 20 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  8. 11.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8.  9.  9.  5.  7. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6] -> size -> 20 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  8. 11.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  9.  9.  5.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6] -> size -> 20 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  1.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.864006]
 [27.088428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  9.  9.  5.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0. 29.  3.  0.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.  1.  3. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.628443717956543
desired expected reward: 24.812480926513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.172224]
 [25.760012]
 [24.383228]
 [26.64554 ]
 [27.008904]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 27. 30.  8.  9.  9.  5.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0. 29.  3.  0.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.  1.  3. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6862408518791199
desired expected reward: 26.3013916015625



buy possibilites: [-1] 
expected returns: [[28.231564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  3.  3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0. 29.  3.  0.] 
adversary cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.  1.  3. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6087352633476257
desired expected reward: 24.563486099243164






Player: 1 
cards in hand: [10.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3.  0.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.  1.  3. 10.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3.  0.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.  1.  3. 10.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  6. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3.  0.] 
cards in discard: [ 1. 15.  3. 10. 15.  0.  8.  0.  0. 11.  3.  8.  1.  3. 10.  8. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0] -> size -> 21 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.359066]
 [23.796225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 0. 11.  1.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  1. 29. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7427759170532227
desired expected reward: 27.488788604736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.807922]
 [23.59519 ]
 [23.395708]
 [22.018927]
 [24.869024]
 [24.28124 ]
 [24.08176 ]
 [24.6446  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 0. 11.  1.  3.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  1. 29. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6315527558326721
desired expected reward: 23.80034065246582



buy possibilites: [-1] 
expected returns: [[24.939503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  1. 29. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.07058807462453842
desired expected reward: 24.011173248291016






Player: 1 
cards in hand: [11.  1. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29. 15.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 11.  3. 10. 11.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 11.  3. 10. 11.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 11.  3. 10. 11.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6. 11.  3. 10. 11.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[20.902136]
 [21.121874]
 [20.351126]
 [21.121874]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3. 10. 11.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.678425669670105
desired expected reward: 24.261077880859375



action possibilites: [-1] 
expected returns: [[26.419716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10. 11.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.357740581035614
desired expected reward: 21.679956436157227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.661522]
 [23.872528]
 [26.498201]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10. 11.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07685497403144836
desired expected reward: 26.34286117553711






Player: 1 
cards in hand: [ 3.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 1. 15. 11.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10. 16.  0.  8.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10. 11.  6.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 1. 15. 11.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  5. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10. 16.  0.  8.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10. 11.  6.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  4. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10. 16.  0.  8.] 
adversary cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10. 11.  6.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.] 
expected returns: [[25.106564]
 [24.547737]
 [23.65947 ]
 [24.743202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.  0.  8.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10. 11.  6.  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  4. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  3.  8.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1
  8] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6863025426864624
desired expected reward: 25.81189727783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.383917]
 [23.959375]
 [22.611473]
 [24.826319]
 [25.185862]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0.  8.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10. 11.  6.  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  4. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  3.  8.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1
  8] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6487621665000916
desired expected reward: 24.45780372619629



buy possibilites: [-1] 
expected returns: [[27.631084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0.  8.] 
cards in discard: [ 0. 11.  1.  3.  3.  3. 10.  3. 10.  0.  0.  0. 10. 11.  6.  3. 10. 11.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  3.  8.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1
  8] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.36466312408447266
desired expected reward: 24.461654663085938






Player: 1 
cards in hand: [10.  8. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  3.  8.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10 15 10  1 11 15 10 29  8  8  3 11  1  0  8  8  1
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 16.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.  8.] 
expected returns: [[26.194935]
 [24.724789]
 [25.831573]
 [25.632092]
 [25.831573]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7075046300888062
desired expected reward: 26.923580169677734



action possibilites: [-1. 16.  8.  8.] 
expected returns: [[26.453342]
 [24.983196]
 [26.089981]
 [26.089981]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  8.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  3 11 10 16 11  1  8 11  3 10  0 10  6  0 10 10  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.04872298985719681
desired expected reward: 25.680265426635742



action possibilites: [-1.] 
expected returns: [[21.545467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.4843783974647522
desired expected reward: 26.879344940185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.879517]
 [19.091995]
 [21.67861 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6189813613891602
desired expected reward: 22.164447784423828



buy possibilites: [-1] 
expected returns: [[22.858536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  0.  3.] 
adversary cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.6936292052268982
desired expected reward: 20.573143005371094






Player: 1 
cards in hand: [ 0. 10.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 11.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  9. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [ 1. 15. 11.  1. 29.  8.  3.  0.  0.  1. 15.  0.  8. 10.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0
 29  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  3.  3. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[22.943825]
 [22.409294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  3. 10.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5961424112319946
desired expected reward: 22.262393951416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.27571 ]
 [20.49239 ]
 [23.074806]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  3. 10.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 15.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0
 29  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.611007571220398
desired expected reward: 22.423152923583984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 15.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 10  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[20.730484]
 [20.195957]
 [20.195957]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 11. 29.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6271102428436279
desired expected reward: 22.447694778442383



action possibilites: [-1. 10. 11.] 
expected returns: [[20.316395]
 [19.79314 ]
 [20.55949 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 11. 29.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.05586341768503189
desired expected reward: 20.29535675048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.629732]
 [19.394741]
 [19.19712 ]
 [17.866716]
 [20.632683]
 [20.063955]
 [19.866333]
 [20.389587]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  3. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 11. 29.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.047679804265499115
desired expected reward: 20.364072799682617



buy possibilites: [-1] 
expected returns: [[22.193956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 11.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10. 11. 29.  0.  8.] 
adversary cards in discard: [ 8. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.14111794531345367
desired expected reward: 20.20507049560547






Player: 1 
cards in hand: [10. 11. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.  0.  8.] 
cards in discard: [ 8. 15.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  1. 11.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8. 10.  0.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29.  0.  8.] 
cards in discard: [ 8. 15.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  1. 11.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8. 10.  0.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11.  1. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[23.98774 ]
 [24.230839]
 [24.230839]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  3.  0.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8. 10.  0.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  5.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5620755553245544
desired expected reward: 21.631881713867188



action possibilites: [-1] 
expected returns: [[25.443127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  0.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8. 10.  0.  0.  0. 10. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.31577739119529724
desired expected reward: 22.694957733154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.858315]
 [24.62467 ]
 [24.427046]
 [23.087372]
 [25.879793]
 [25.298836]
 [25.09696 ]
 [25.631487]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  0.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8. 10.  0.  0.  0. 10. 11. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.051146507263183594
desired expected reward: 25.391979217529297



buy possibilites: [-1] 
expected returns: [[23.138313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  0.] 
cards in discard: [ 0. 10.  8.  0.  6.  3.  3.  3. 10.  8. 10.  0.  0.  0. 10. 11. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [11.  0.  0.  1.  0.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.022797144949436188
desired expected reward: 23.83551788330078






Player: 1 
cards in hand: [11.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8. 10. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [10.  8. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  8. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10.] 
expected returns: [[24.00194 ]
 [23.478683]
 [23.676306]
 [23.478683]
 [23.478683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 1.  0. 29.  1.  0.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0 14] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.594298243522644
desired expected reward: 22.544015884399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.327559]
 [21.556618]
 [24.088757]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 1.  0. 29.  1.  0.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0 14] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6320476531982422
desired expected reward: 23.466562271118164



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  1.  0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1. 10.] 
adversary cards in discard: [10.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 8.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 15  1 11 15 10 29  8  3 11  1  0  8  8  1  8  0 29
  0  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1. 10.] 
adversary cards in discard: [10.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1. 10.] 
adversary cards in discard: [10.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 27. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1. 10.] 
adversary cards in discard: [10.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1. 10.] 
adversary cards in discard: [10.  8. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[24.262383]
 [24.536486]
 [23.76469 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1. 10.] 
cards in discard: [10.  8. 10.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  8. 15.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3. 29.
  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6015728712081909
desired expected reward: 22.957359313964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.899809]
 [23.671606]
 [23.46786 ]
 [22.120043]
 [23.251368]
 [24.916906]
 [24.348856]
 [24.846848]
 [23.51975 ]
 [24.145111]
 [24.291546]
 [24.642805]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1. 10.] 
cards in discard: [10.  8. 10.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  4.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  8. 15.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3. 29.
  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6266613602638245
desired expected reward: 23.68242645263672



buy possibilites: [-1] 
expected returns: [[23.711115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1. 10.] 
cards in discard: [10.  8. 10.  0. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  3.  3.  8. 15.] 
adversary cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3. 29.
  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5135404467582703
desired expected reward: 24.403366088867188






Player: 1 
cards in hand: [ 3.  3.  3.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  8. 15.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3. 29.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 11.  3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3. 29.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 11.  3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 8.] 
cards in discard: [ 8. 15.  0.  3. 10. 11. 29.  0.  8.  0. 14. 11.  0.  0.  1.  0.  3. 29.
  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 11.  3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11] -> size -> 26 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.98688]
 [22.25519]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 11.  3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6287808418273926
desired expected reward: 23.082334518432617



action possibilites: [-1] 
expected returns: [[19.635668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.25253620743751526
desired expected reward: 22.7071475982666





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.056643]
 [17.301271]
 [19.745062]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.056682929396629333
desired expected reward: 19.692350387573242



buy possibilites: [-1] 
expected returns: [[21.877394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.1380133479833603
desired expected reward: 18.194656372070312






Player: 1 
cards in hand: [ 3.  0.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.798838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 1. 14. 29.  8.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5774340033531189
desired expected reward: 21.299959182739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.37033 ]
 [21.125753]
 [20.926332]
 [19.607107]
 [22.344637]
 [21.788635]
 [21.589214]
 [22.076328]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 26. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 1. 14. 29.  8.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5787216424942017
desired expected reward: 21.220115661621094



buy possibilites: [-1] 
expected returns: [[20.439585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 1. 14. 29.  8.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5031743049621582
desired expected reward: 20.423158645629883






Player: 1 
cards in hand: [ 1. 14. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 29.  8.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  8.  3.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  8.  3.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  8.  3.  3.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10. 11. 11.  0.  8.] 
adversary cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3] -> size -> 29 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8.] 
expected returns: [[18.235743]
 [17.748629]
 [18.504051]
 [18.504051]
 [17.94805 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.  8.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [11.  8. 29.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5715489387512207
desired expected reward: 19.8680362701416



action possibilites: [-1] 
expected returns: [[15.246995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [11.  8. 29.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.36153846979141235
desired expected reward: 17.646703720092773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.584286]
 [12.828916]
 [15.272704]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  8.] 
cards in discard: [10.  8. 10.  0. 10. 11.  0.  0. 11.  1. 10. 10.  0. 11.  6.  3.  0.  3.
  3.  3.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [11.  8. 29.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1413833647966385
desired expected reward: 15.388378143310547






Player: 1 
cards in hand: [11.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29.  3.  0.] 
cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1] -> size -> 30 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 29.  3.  0.] 
cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1] -> size -> 30 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 29.  3.  0.] 
cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1] -> size -> 30 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.30617 ]
 [20.580275]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  2. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.39274904131889343
desired expected reward: 14.87995433807373



action possibilites: [-1] 
expected returns: [[19.607016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  1. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.2455866038799286
desired expected reward: 17.92182159423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.20353 ]
 [18.94242 ]
 [18.742659]
 [17.45419 ]
 [20.13195 ]
 [19.592815]
 [19.393059]
 [19.84442 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  1. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0639868900179863
desired expected reward: 19.671003341674805



buy possibilites: [-1] 
expected returns: [[23.957792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [8. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.17377229034900665
desired expected reward: 19.766590118408203






Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8] -> size -> 32 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8] -> size -> 32 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [ 0.  8.  0.  0. 29.  1. 14.  8.  3.  3.  0. 11.  8. 29.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 11. 10.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8] -> size -> 32 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[19.267855]
 [18.811792]
 [19.55836 ]
 [18.811792]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 10.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6671165823936462
desired expected reward: 23.29067611694336



action possibilites: [-1] 
expected returns: [[24.040094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.589614987373352
desired expected reward: 20.34981346130371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[22.46921 ]
 [23.025803]
 [21.697163]
 [24.163301]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.02861337549984455
desired expected reward: 24.0114803314209



buy possibilites: [-1] 
expected returns: [[22.616253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  0.  8. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.013394336216151714
desired expected reward: 22.482603073120117






Player: 1 
cards in hand: [11.  0.  8. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 10. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 11.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 15.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0
  0  1] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [17. 24. 30. 25. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 10. 11.  6.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[20.9537  ]
 [20.487677]
 [21.250513]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  6.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  6.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6083241701126099
desired expected reward: 22.0079288482666



action possibilites: [-1] 
expected returns: [[20.939579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  5.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.5061630606651306
desired expected reward: 21.962913513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.364222]
 [18.610071]
 [21.022167]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  5.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03114927187561989
desired expected reward: 20.970727920532227



buy possibilites: [-1] 
expected returns: [[20.627821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  5.] 
adversary cards in hand: [11.  0.  8.  0.  0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: 14.0 

action type: buy - action 0.0
Learning step: 0.05566549301147461
desired expected reward: 19.41988754272461






Player: 1 
cards in hand: [11.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.  0.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  5.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.  0.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  1. 10.  5.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  0.  0.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.513502]
 [19.253721]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11
  0 11 10  0  3  1  8  8 15  0 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5650339126586914
desired expected reward: 20.062786102294922



action possibilites: [-1] 
expected returns: [[22.386793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.16734500229358673
desired expected reward: 17.424556732177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.804588]
 [20.040682]
 [22.448877]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  9.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.002762431977316737
desired expected reward: 22.389554977416992



buy possibilites: [-1] 
expected returns: [[24.244827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.896649360656738
desired expected reward: 11.14403247833252






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  1.  0. 11.  8.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0  6] -> size -> 34 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [10.  1.  0. 11.  8.] 
adversary cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.] 
adversary owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0  6] -> size -> 34 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10.  1.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[17.910875]
 [17.476534]
 [18.220428]
 [17.682617]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 11.  8.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6893719434738159
desired expected reward: 23.555456161499023



action possibilites: [-1. 11.  8.] 
expected returns: [[20.475094]
 [20.787773]
 [20.24451 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  8.  3.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 11 10 11  1 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10
  0  3  1  8  8 15  0 15  0  6] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1415790319442749
desired expected reward: 17.61811065673828



action possibilites: [-1. 11.] 
expected returns: [[21.925152]
 [22.237831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.6948428750038147
desired expected reward: 20.272876739501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.454618]
 [19.690714]
 [22.098911]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  8.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6129371523857117
desired expected reward: 22.538087844848633



buy possibilites: [-1] 
expected returns: [[19.089886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.] 
cards in discard: [ 8.  8. 11.  3.  1.  0.  3. 15.  0. 11.  0.  0. 10. 10. 15.  0. 11.  0.
  3. 10.  6.  6.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 30.  8.  7.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 29.  0.  3.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.340277671813965
desired expected reward: 11.350438117980957






Player: 1 
cards in hand: [ 3. 29.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  8.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 15 10 29  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0
  1  3 15 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  7.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  7.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 24. 30.  8.  7.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 30.  8.  7.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 8.  0. 10. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6] -> size -> 34 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 10.] 
expected returns: [[16.50485 ]
 [16.28153 ]
 [16.07989 ]
 [16.807755]
 [16.07989 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 11. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 30.  8.  7.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [14.  1. 29.  1.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5500536561012268
desired expected reward: 18.539831161499023



action possibilites: [-1] 
expected returns: [[16.737267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [14.  1. 29.  1.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.837410926818848
desired expected reward: 6.60099983215332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.285083]
 [14.545145]
 [16.877743]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [14.  1. 29.  1.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11410754919052124
desired expected reward: 16.85137367248535



buy possibilites: [-1] 
expected returns: [[19.826305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10. 10.] 
cards in discard: [6. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [14.  1. 29.  1.  8.] 
adversary cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: 14.0 

action type: buy - action 0.0
Learning step: 0.1696237474679947
desired expected reward: 15.454705238342285






Player: 1 
cards in hand: [14.  1. 29.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1. 29.  1.  8.] 
cards in discard: [ 3. 15. 10. 15. 11.  8.  0. 10. 11.  0.  8.  0.  0.  3.  0.  0.  3.  0.
  0.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11.] 
cards in discard: [14.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 11.] 
cards in discard: [14.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 11.] 
cards in discard: [14.  8. 22.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 11.  0.  0. 10.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[19.046356]
 [19.35904 ]
 [18.609423]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 10.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5444936752319336
desired expected reward: 19.281810760498047



action possibilites: [-1. 11.] 
expected returns: [[22.659275]
 [22.980476]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.13615579903125763
desired expected reward: 18.74557876586914



action possibilites: [-1.] 
expected returns: [[18.111689]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -2  0  0  0  0] 
sum of rewards: 33 

action type: gain_card_n - action 0
Learning step: 0.5486347675323486
desired expected reward: 21.59990119934082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[16.764103]
 [17.498547]
 [17.29133 ]
 [16.01535 ]
 [18.67396 ]
 [18.355968]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 24. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6923035979270935
desired expected reward: 18.803991317749023



buy possibilites: [-1] 
expected returns: [[16.333288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0 18  0] 
sum of rewards: 50 

action type: buy - action 1.0
Learning step: 1.1465431451797485
desired expected reward: 18.645090103149414






Player: 1 
cards in hand: [ 0.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  0  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3
 15 10  0 22] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 15.  6.  6. 11.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 38 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 23. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 15.  6.  6. 11.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 38 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 23. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 15.  6.  6. 11.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 38 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 15.  6.  6. 11.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 38 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[17.84496 ]
 [17.554245]
 [18.166094]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  6. 11.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0
  3  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4518670439720154
desired expected reward: 15.881421089172363



action possibilites: [-1] 
expected returns: [[14.04856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 22. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.07088252902030945
desired expected reward: 17.6251277923584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[12.53631 ]
 [13.253178]
 [13.050442]
 [11.810475]
 [14.403201]
 [14.092057]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 22. 30. 24. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.16959385573863983
desired expected reward: 14.218153953552246



buy possibilites: [-1] 
expected returns: [[14.397106]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 30. 23. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -3.  0.  0.  2.  0.] 
sum of rewards: 14.0 

action type: buy - action 3.0
Learning step: 0.17965635657310486
desired expected reward: 13.230096817016602






Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 23. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 10. 10.  8.  0.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 22. 30. 23. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 10. 10.  8.  0.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 30. 22. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 10. 10.  8.  0.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[21.5281  ]
 [21.107414]
 [21.107414]
 [21.316738]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8.  0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 22. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.35807886719703674
desired expected reward: 14.039027214050293



action possibilites: [-1. 10.  8.] 
expected returns: [[23.274326]
 [22.85364 ]
 [23.062965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 22. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.05938825383782387
desired expected reward: 21.16680335998535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[21.641857]
 [22.174423]
 [20.885517]
 [23.24987 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 30. 22. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.014706573449075222
desired expected reward: 23.259620666503906



buy possibilites: [-1] 
expected returns: [[19.801105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  8.  3.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0  8  0] 
sum of rewards: 19 

action type: buy - action 3.0
Learning step: 0.11267892271280289
desired expected reward: 22.28710174560547






Player: 1 
cards in hand: [ 3.  0. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  8.  3.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 6. 15. 11.  1.  3.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3] -> size -> 39 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  8.  3.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 6. 15. 11.  1.  3.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3] -> size -> 39 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6. 15. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[23.180693]
 [22.887028]
 [23.501896]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 11.  1.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.
  3.  0. 15.  8.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4998842775821686
desired expected reward: 19.30122184753418



action possibilites: [-1] 
expected returns: [[17.385952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.
  3.  0. 15.  8.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.05405839905142784
desired expected reward: 22.832971572875977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.843869]
 [16.35971 ]
 [15.11129 ]
 [17.401325]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.
  3.  0. 15.  8.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10086822509765625
desired expected reward: 17.486820220947266



buy possibilites: [-1] 
expected returns: [[16.954596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  3.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0. 11.  3.  0.] 
adversary cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.
  3.  0. 15.  8.  3.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: 10.0 

action type: buy - action 0.0
Learning step: 0.0032328700181096792
desired expected reward: 15.847102165222168






Player: 1 
cards in hand: [10.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.
  3.  0. 15.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0. 15.  6. 11.  1.  3.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [14.  8. 22. 29.  1.  1. 11.  1. 15.  3.  3.  0.  3.  8.  0.  0.  8.  0.
  3.  0. 15.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 3.  8.  0. 11.  0.] 
adversary cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0. 15.  6. 11.  1.  3.] 
adversary owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[22.377869]
 [22.178703]
 [22.708183]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 11.  0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0. 15.  6. 11.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 11 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3
  1  8  8 15  0 15  0  6  6  6  0  0  1  3  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 22. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4226093590259552
desired expected reward: 16.531986236572266



action possibilites: [-1] 
expected returns: [[16.870905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0. 15.  6. 11.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 22. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.026401519775390625
desired expected reward: 20.051166534423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.291857]
 [14.541349]
 [16.870905]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0. 15.  6. 11.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 22. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1100732758641243
desired expected reward: 16.98097801208496



buy possibilites: [-1] 
expected returns: [[16.303707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 6.  0. 11.  8.  0. 10. 10.  0.  1. 10. 11.  3.  0.  0.  0.  3. 15.  6.
  6. 11.  3. 10.  0. 10.  8.  0.  3.  0. 15.  6. 11.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 22. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: 0.042433202266693115
desired expected reward: 15.33428955078125






Player: 1 
cards in hand: [ 0. 22. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 22.  8. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  1.  3.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 22. 15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 22. 15. 10.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 22. 15. 10.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 7 
card supply: [11. 22. 30. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 3. 1. 0.] 
cards in discard: [2.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 22. 15. 10.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3  2] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[9.157676]
 [8.969876]
 [8.769978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  8. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 14.  3. 15.  0.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3  2] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5445669889450073
desired expected reward: 15.759140014648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.7101703]
 [7.003776 ]
 [9.210002 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  8. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 14.  3. 15.  0.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3  2] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.33840224146842957
desired expected reward: 8.81927490234375



buy possibilites: [-1] 
expected returns: [[12.97337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  8. 10.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 14.  3. 15.  0.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3  2] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: -0.3950847089290619
desired expected reward: 7.315085411071777






Player: 1 
cards in hand: [ 0. 14.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 15.  0.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8  0 29  0  0 14  3  0  0  0  1  3 15
 10  0 22  1  3  2] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  1. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  1. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  9. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  1. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 0.  3.  1. 15.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[17.310099]
 [17.033142]
 [17.117222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 15.  8.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [29. 11.  0.  8.  1.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3587605953216553
desired expected reward: 12.614608764648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[15.999548]
 [16.717678]
 [16.512386]
 [15.265297]
 [17.864332]
 [17.544373]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 15.  8.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 29. 21. 30.  8.  6.  9.  3.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [29. 11.  0.  8.  1.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4919227361679077
desired expected reward: 16.818174362182617



buy possibilites: [-1] 
expected returns: [[16.37026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 15.  8.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  3.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [29. 11.  0.  8.  1.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -311.0 

action type: buy - action 6.0
Learning step: -9.616070747375488
desired expected reward: 5.649227142333984






Player: 1 
cards in hand: [29. 11.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  8.  1.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  3.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  0.  1. 10. 15.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 41 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  8.  1.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  3.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  0.  1. 10. 15.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 41 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  8.  1.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  2.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 6.  0.  1. 10. 15.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.] 
adversary owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 41 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  1. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[16.493893]
 [16.095726]
 [16.216936]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 10. 15.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10  0 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8
  8 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  2.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.469812273979187
desired expected reward: 15.900447845458984



action possibilites: [-1] 
expected returns: [[12.192708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 10.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  2.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.09151536971330643
desired expected reward: 16.30845069885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[10.678021 ]
 [11.382764 ]
 [11.18086  ]
 [10.096823 ]
 [ 9.963092 ]
 [10.988754 ]
 [12.519015 ]
 [13.038459 ]
 [12.445452 ]
 [11.217154 ]
 [10.9060755]
 [10.206075 ]
 [11.926562 ]
 [12.201446 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 22. 29. 21. 30.  8.  5.  9.  2.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11] -> size -> 31 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2068498730659485
desired expected reward: 12.399558067321777



buy possibilites: [-1] 
expected returns: [[14.382644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1. 10.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 5 
card supply: [10. 22. 29. 21. 30.  8.  4.  9.  2.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11] -> size -> 31 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -291.0 

action type: buy - action 6.0
Learning step: -8.877875328063965
desired expected reward: 1.0852165222167969






Player: 1 
cards in hand: [ 8.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  3.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  4.  9.  2.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [ 2. 10. 22. 15. 10.  0.  8.  0.  1.  3.  1.  0. 14. 15. 14.  3.  0. 11.
 29. 11.  0.  8.  1. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[17.890469]
 [17.492302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10. 11.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0] -> size -> 33 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3953016698360443
desired expected reward: 13.98734188079834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.640276]
 [16.141945]
 [14.917206]
 [17.147783]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10. 11.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0] -> size -> 33 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.49590492248535156
desired expected reward: 16.703908920288086



buy possibilites: [-1] 
expected returns: [[15.439318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [10. 11.  3.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0] -> size -> 33 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -7.  0.  0.  0.  0.] 
sum of rewards: -12.0 

action type: buy - action 0.0
Learning step: -0.667095422744751
desired expected reward: 14.97318172454834






Player: 1 
cards in hand: [10. 11.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  8.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0] -> size -> 42 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[15.197955]
 [15.52792 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  0.  0.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  8. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 14.  0.  1.  8.] 
adversary cards in discard: [ 0. 10. 11.  3.  3.  8.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.45152223110198975
desired expected reward: 14.98779582977295



action possibilites: [-1] 
expected returns: [[14.520279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 14.  0.  1.  8.] 
adversary cards in discard: [ 0. 10. 11.  3.  3.  8.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -8  0  0 16  0] 
sum of rewards: 23 

action type: gain_card_n - action 7
Learning step: 0.43541377782821655
desired expected reward: 14.003718376159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[12.979222]
 [13.492047]
 [12.24007 ]
 [14.52028 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 3. 14.  0.  1.  8.] 
adversary cards in discard: [ 0. 10. 11.  3.  3.  8.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15667064487934113
desired expected reward: 14.676949501037598






Player: 1 
cards in hand: [ 3. 14.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  1.  8.] 
cards in discard: [ 0. 10. 11.  3.  3.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 11. 10.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3. 14. 11.  6.  6.  0.  0.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0 14] -> size -> 43 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [ 0. 10. 11.  3.  3.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3. 14. 11.  6.  6.  0.  0. 11.  8.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0 14] -> size -> 43 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [ 0. 10. 11.  3.  3.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  1.  0. 10.  8.  7. 10.  0.  9.  5.] 
adversary cards in hand: [ 0. 10.  0.] 
adversary cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3. 14. 11.  6.  6.  0.  0. 11.  8.] 
adversary owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0 14] -> size -> 43 
adversary victory points: 0
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 0 
Workshop: 3 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 0.  0.  3.  6.  8. 10.  6.  0.  3.  1. 15.  8.  6. 15.  6.  1. 10.  0.
 10.  0.  0.  3.  3. 14. 11.  6.  6.  0.  0. 11.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10 11 11  3 10 10  6  0 10 10  8  0  8 11  0 11 10  0  3  1  8  8
 15  0 15  0  6  6  6  0  0  1  3  3  0  0  0  6  6  0 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 22. 29. 21. 30.  8.  4.  9.  0.  0. 10.  8.  7. 10.  0.  9.  5.] 
adversary cards in hand: [3. 0. 1. 8.] 
adversary cards in discard: [ 0. 10. 11.  3.  3.  8. 11.] 
adversary owned cards: [ 3  3 11 15 10  8  3 11  8  8  1  8 29  0  0 14  3  0  0  0  1  3 15 10
  0 22  1  3  2 14 11 11  0  0 11] -> size -> 35 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[   -5  -500     0     0     0     0     0     0     0     0     0    -8
     0 -1800    36     0] 
sum of rewards: -2277 

action type: discard_down_to_3_cards - action 8
Learning step: -68.861083984375
desired expected reward: -50.49138259887695



