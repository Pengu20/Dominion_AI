 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.6932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   7  30   0   0  20   0   0   0   0 -17   0   0   9   0] 
sum of rewards: 544 

action type: gain_card_n - action 7
Learning step: 27.22210121154785
desired expected reward: 26.780065536499023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[319.80344]
 [320.2578 ]
 [320.19296]
 [319.80386]
 [322.12808]
 [323.1071 ]
 [321.85516]
 [327.3786 ]
 [322.86618]
 [321.92874]
 [324.0445 ]
 [335.33777]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.665472984313965
desired expected reward: 327.7449951171875



buy possibilites: [-1] 
expected returns: [[332.64517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -10.1056547164917
desired expected reward: 309.6977844238281






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8. 0. 3. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[353.08917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.780949592590332
desired expected reward: 323.8642272949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[342.7547 ]
 [343.20206]
 [343.13803]
 [342.7551 ]
 [345.99515]
 [344.77072]
 [344.84274]
 [357.96295]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.958887100219727
desired expected reward: 343.4326477050781



buy possibilites: [-1] 
expected returns: [[327.00607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -9.142122268676758
desired expected reward: 336.8530578613281






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 1 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[331.31558]
 [319.36234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 3] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.094560623168945
desired expected reward: 317.9114990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[314.4581 ]
 [314.83932]
 [314.4585 ]
 [316.46896]
 [329.66748]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 3] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.523409843444824
desired expected reward: 322.6619873046875



buy possibilites: [-1] 
expected returns: [[335.93387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 3] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: -7.333451747894287
desired expected reward: 307.5058288574219






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 8. 0. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[326.0643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 3 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -9.005597114562988
desired expected reward: 326.92828369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[310.723  ]
 [311.2484 ]
 [311.17215]
 [310.87582]
 [310.72342]
 [313.3998 ]
 [314.5231 ]
 [313.08588]
 [318.34738]
 [319.4223 ]
 [314.24677]
 [315.91333]
 [313.16864]
 [314.56076]
 [315.60025]
 [328.53955]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 3 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -8.745253562927246
desired expected reward: 317.5257263183594



buy possibilites: [-1] 
expected returns: [[325.41937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3. 11.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 1 3 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 17.0 

action type: buy - action 14.0
Learning step: -7.540402412414551
desired expected reward: 306.70635986328125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [1. 3. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 1. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 1 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 1. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14] -> size -> 14 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[340.3062 ]
 [327.01578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [16.  1.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -8.289423942565918
desired expected reward: 317.12994384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[321.71164]
 [322.20767]
 [322.13596]
 [321.7121 ]
 [325.31104]
 [323.94763]
 [324.0265 ]
 [338.6423 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [16.  1.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -9.23068904876709
desired expected reward: 331.349609375



buy possibilites: [-1] 
expected returns: [[315.17743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [16.  1.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -10.044089317321777
desired expected reward: 311.6675109863281






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.  1.  3.  8.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 0.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.  1.  3.  8.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 0.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.  1.  3.  8.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 0.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[314.69516]
 [299.8783 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 0.  0. 11.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.890044212341309
desired expected reward: 306.2873840332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[296.41782]
 [296.96164]
 [296.88464]
 [296.41824]
 [299.18222]
 [300.3459 ]
 [298.85413]
 [305.4199 ]
 [300.05234]
 [298.93973]
 [301.4585 ]
 [314.8692 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 0.  0. 11.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.951991081237793
desired expected reward: 305.07696533203125



buy possibilites: [-1] 
expected returns: [[308.44272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 0.  0. 11.  0.  3.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 16.0
Learning step: -6.226136684417725
desired expected reward: 288.0958251953125






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16] -> size -> 16 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.28522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  0.  8.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.596864700317383
desired expected reward: 299.8458557128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[290.66113]
 [290.99188]
 [290.66293]
 [292.39545]
 [304.29858]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  0.  8.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.689690589904785
desired expected reward: 296.8779296875



buy possibilites: [-1] 
expected returns: [[287.6446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  0.  8.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -7.797767639160156
desired expected reward: 284.59765625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 16.  0.  8.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  1  3  1 16  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 14.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8] -> size -> 17 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[348.1737 ]
 [334.22287]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [8. 0. 0. 3. 3. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10. 10. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.766213417053223
desired expected reward: 280.8783874511719



action possibilites: [-1] 
expected returns: [[307.13058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 28 

action type: gain_card_n - action 9
Learning step: -8.33224105834961
desired expected reward: 324.5213317871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[293.99118]
 [294.5289 ]
 [294.4553 ]
 [293.99377]
 [296.71112]
 [297.8588 ]
 [296.3901 ]
 [302.8269 ]
 [297.5715 ]
 [296.47592]
 [298.95193]
 [312.07858]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -7.6640520095825195
desired expected reward: 299.4665222167969



buy possibilites: [-1] 
expected returns: [[332.05783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [1. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -7.77825927734375
desired expected reward: 286.21295166015625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [1. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0. 14.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [16.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[278.41373]
 [260.2756 ]
 [261.25082]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0. 14.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -10.705619812011719
desired expected reward: 321.3522033691406



action possibilites: [-1] 
expected returns: [[285.42947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -5.506168365478516
desired expected reward: 252.06045532226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.67987]
 [278.28012]
 [278.20108]
 [277.68277]
 [280.7369 ]
 [282.02957]
 [280.37595]
 [287.62686]
 [281.7072 ]
 [280.4768 ]
 [283.25995]
 [298.02283]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8. 10.  8.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -6.9300737380981445
desired expected reward: 278.4993896484375



buy possibilites: [-1] 
expected returns: [[308.5303]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.] 
cards in discard: [ 8.  0.  0.  3.  3.  3. 10.  0. 11.  0.  0.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 51 

action type: buy - action 16.0
Learning step: -4.544915199279785
desired expected reward: 276.1920166015625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[300.96085]
 [287.68835]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  1.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.878958702087402
desired expected reward: 299.6513366699219



action possibilites: [-1.] 
expected returns: [[317.43286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  1.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 10.0
Learning step: -6.147639751434326
desired expected reward: 279.6499328613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[300.22946]
 [300.72144]
 [300.6531 ]
 [300.23184]
 [303.78946]
 [302.4403 ]
 [302.52066]
 [316.94305]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  1.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -8.058012008666992
desired expected reward: 309.3748474121094



buy possibilites: [-1] 
expected returns: [[329.9702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 16.  1.] 
adversary cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 32.0 

action type: buy - action 3.0
Learning step: -6.063892364501953
desired expected reward: 295.7005310058594






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 16.  1.] 
cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16. 14.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3] -> size -> 21 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 16.  1.] 
cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16. 14.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3] -> size -> 21 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 16.  1.] 
cards in discard: [15.  1.  1.  3.  0.  0.  3.  0.  0.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16. 14.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3] -> size -> 21 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[276.7545]
 [259.2009]
 [260.1967]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16. 14.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8. 10.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  1.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -10.035636901855469
desired expected reward: 319.9345703125



action possibilites: [-1] 
expected returns: [[296.18506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  1.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    4    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -281 

action type: gain_card_n - action 2
Learning step: -21.92824363708496
desired expected reward: 268.919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[282.99472]
 [283.0018 ]
 [296.83487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  1.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -7.363282203674316
desired expected reward: 288.82177734375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  1.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  0. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 16.  3.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8. 10. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 16.  3.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 16.  3.  0. 14.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[221.54256]
 [204.60814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 16.  3.  0. 14.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  0.  3.] 
adversary cards in discard: [25. 14.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1 25] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    4    0    0    0    0  -60    0    0    0    0    0 -300
   42    0] 
sum of rewards: -319 

action type: discard_down_to_3_cards - action 1
Learning step: -24.6777286529541
desired expected reward: 245.82763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[206.45891]
 [206.92061]
 [206.46806]
 [208.81244]
 [225.74878]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 3. 10.  0.  3.  3.  0.  0.  6. 16.  3.  0. 14.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  0.  3.] 
adversary cards in discard: [25. 14.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1 25] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -6.302172660827637
desired expected reward: 214.43539428710938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [16.  0.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  0.  3.] 
cards in discard: [25. 14.  1.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  3  1 16  3 14  1 15  0  1 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [25. 14.  1.  0.  1.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [25. 14.  1.  0.  1.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[283.072  ]
 [271.54434]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -5.098475933074951
desired expected reward: 220.65029907226562



action possibilites: [-1] 
expected returns: [[261.5607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  9.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 34 

action type: gain_card_n - action 1
Learning step: -5.17944860458374
desired expected reward: 250.11183166503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[249.02321]
 [249.03102]
 [264.11484]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  9.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: -5.8347954750061035
desired expected reward: 255.7259063720703



buy possibilites: [-1] 
expected returns: [[242.24461]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -281.0 

action type: buy - action 6.0
Learning step: -21.05104637145996
desired expected reward: 227.97998046875






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  3.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  3.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  9.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  3.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [25. 14.  1.  0.  1.  0. 14. 16.  0.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  3.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [14.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[195.55206]
 [183.6155 ]
 [182.71138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3. 10.  3.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.957703590393066
desired expected reward: 234.2869110107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[172.35698]
 [172.37003]
 [187.05269]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3. 10.  3.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -5.32570219039917
desired expected reward: 180.48048400878906



buy possibilites: [-1] 
expected returns: [[197.44102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3. 10.  3.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   4   0   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action 0.0
Learning step: -5.725426197052002
desired expected reward: 166.6315460205078






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [16.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 16  3 14  1 15  0  1 25 14 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 24. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 24. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [3. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[189.63307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11. 15. 25.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -5.684892654418945
desired expected reward: 191.75613403320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[161.6827 ]
 [162.0694 ]
 [162.02362]
 [161.80153]
 [161.69556]
 [163.64954]
 [164.49797]
 [163.42683]
 [167.44257]
 [168.38832]
 [164.3029 ]
 [165.54266]
 [163.50084]
 [164.52559]
 [165.30666]
 [176.35371]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  8.  9. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11. 15. 25.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -5.727656841278076
desired expected reward: 182.5904998779297



buy possibilites: [-1] 
expected returns: [[261.14835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  8.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14. 11. 15. 25.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 49 

action type: buy - action 25.0
Learning step: -0.046289827674627304
desired expected reward: 167.39625549316406






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [14. 11. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 15. 25.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 15. 25.  0.] 
cards in discard: [ 3.  0. 16.  0.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  8.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 16.  6.  8.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15. 25.  0.] 
cards in discard: [ 3.  0. 16.  0.  1.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 16.  6.  8.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15. 25.  0.] 
cards in discard: [ 3.  0. 16.  0.  1.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0. 16.  6.  8.] 
adversary cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [11.  0. 16.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8.] 
expected returns: [[159.28369]
 [149.91121]
 [149.13939]
 [148.934  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  6.  8.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3. 25.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  1.  3.  8. 11. 14. 15. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -9.67151165008545
desired expected reward: 251.47683715820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[149.20712]
 [149.219  ]
 [161.13948]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  6.  8.] 
cards in discard: [ 3.  6. 16.  3.  3.  0.  0. 14.  3.  3. 10.  3. 25.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3.  0.  1.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  1.  3.  8. 11. 14. 15. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -4.546121120452881
desired expected reward: 154.737548828125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  1.  3.] 
cards in discard: [ 3.  0. 16.  0.  1.  3.  8. 11. 14. 15. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  1.  3.] 
cards in discard: [ 3.  0. 16.  0.  1.  3.  8. 11. 14. 15. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  1.  3.] 
cards in discard: [ 3.  0. 16.  0.  1.  3.  8. 11. 14. 15. 25.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[157.74992]
 [148.19417]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -4.706153869628906
desired expected reward: 156.43328857421875



action possibilites: [-1] 
expected returns: [[214.35216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 28 

action type: gain_card_n - action 9
Learning step: -1.065961480140686
desired expected reward: 144.71173095703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[202.55159]
 [203.01671]
 [202.96143]
 [202.5671 ]
 [205.93396]
 [204.64722]
 [204.73561]
 [218.34793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -5.107519626617432
desired expected reward: 209.24464416503906






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 24. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[186.17476]
 [168.87682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [10. 11.  0.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 16. 25.] 
adversary cards in discard: [3. 8. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -7.480834484100342
desired expected reward: 210.86708068847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[165.93129]
 [166.4349 ]
 [166.3798 ]
 [165.9482 ]
 [169.94177]
 [168.2501 ]
 [168.36807]
 [186.22466]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [10. 11.  0.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  8.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 16. 25.] 
adversary cards in discard: [3. 8. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3] -> size -> 23 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -5.921853542327881
desired expected reward: 178.76043701171875



buy possibilites: [-1] 
expected returns: [[219.3465]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  7.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 16. 25.] 
adversary cards in discard: [3. 8. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -322.0 

action type: buy - action 6.0
Learning step: -19.462112426757812
desired expected reward: 146.48606872558594






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 16. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 25.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 16. 25.] 
cards in discard: [3. 8. 0. 1. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  7.  7.  8.  7.  8. 10.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  7.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  7.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 25.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 23. 30.  8.  7.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 25.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[242.34206]
 [230.8486 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 25.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  7.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.228520393371582
desired expected reward: 213.11798095703125



action possibilites: [-1] 
expected returns: [[221.55917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0. 8.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 23. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 9 

action type: take_action - action 25.0
Learning step: -6.048251152038574
desired expected reward: 224.8003387451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[202.93669]
 [203.35883]
 [202.95343]
 [205.0705 ]
 [219.66187]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0. 8.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 23. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -5.990543842315674
desired expected reward: 215.56863403320312



buy possibilites: [-1] 
expected returns: [[200.70787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0. 8.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14.  0. 14.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 27 

action type: buy - action 3.0
Learning step: -4.302013397216797
desired expected reward: 199.05679321289062






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0. 14.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 22. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  6.  0. 14.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3. 25.  3.  3.  3.  0.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 22. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3. 25.  3.  3.  3.  0.
  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 22. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3. 25.  3.  3.  3.  0.
  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  6. 14.] 
adversary cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3. 25.  3.  3.  3.  0.
  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[174.47987]
 [163.18558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 14.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3. 25.  3.  3.  3.  0.
  0.  8. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [15. 11.  1.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.  3. 14.  3.  0.  0.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[  -5    0    4    0    0    0    0  -30    0    0    0    0    0 -600
   37    0] 
sum of rewards: -594 

action type: discard_down_to_3_cards - action 2
Learning step: -33.1289176940918
desired expected reward: 111.72705078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[159.98482]
 [159.99677]
 [173.1309 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 14.] 
cards in discard: [10. 11.  0.  0.  3.  0.  6.  0.  0.  0. 16.  3.  3. 25.  3.  3.  3.  0.
  0.  8. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [15. 11.  1.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.  3. 14.  3.  0.  0.
 14.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3] -> size -> 26 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -5.052160263061523
desired expected reward: 169.427734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [15. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  1.  0.  3.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.  3. 14.  3.  0.  0.
 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  1.  0.  3.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.  3. 14.  3.  0.  0.
 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 21. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  1.  0.  3.] 
cards in discard: [ 3.  8.  0.  1.  0.  0. 14.  0. 16. 10.  0. 25.  6.  3. 14.  3.  0.  0.
 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 20. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [25.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[135.0457 ]
 [130.00996]
 [127.57981]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25
 10  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 20. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -6.281535625457764
desired expected reward: 166.84934997558594



action possibilites: [-1] 
expected returns: [[163.94862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 19. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 13 

action type: gain_card_n - action 2
Learning step: -1.3073437213897705
desired expected reward: 111.61640930175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[152.50238]
 [152.86601]
 [152.51675]
 [154.33403]
 [166.51843]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 19. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -4.214229583740234
desired expected reward: 159.73439025878906



buy possibilites: [-1] 
expected returns: [[214.33199]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [3. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 18. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 28 

action type: buy - action 3.0
Learning step: -1.4208301305770874
desired expected reward: 151.44515991210938






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 18. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 18. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 18. 30.  8.  6.  7.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 18. 30.  8.  6.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[229.90239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 18. 30.  8.  6.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 10. 14.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3 16] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[  -5    0    5    0    0    0    0  -30    0    0    0    0    0 -600
   33    0] 
sum of rewards: -597 

action type: discard_down_to_3_cards - action 1
Learning step: -31.686798095703125
desired expected reward: 108.50523376464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[215.82957]
 [216.24771]
 [216.2003 ]
 [215.84427]
 [218.83275]
 [217.68694]
 [217.764  ]
 [230.10223]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 18. 30.  8.  6.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 10. 14.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3 16] -> size -> 28 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -6.546499729156494
desired expected reward: 223.35589599609375



buy possibilites: [-1] 
expected returns: [[216.18602]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 17. 30.  8.  6.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 10. 14.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3 16] -> size -> 28 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 13.0 

action type: buy - action 3.0
Learning step: -5.2958292961120605
desired expected reward: 210.90447998046875






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10. 14.] 
cards in discard: [16. 14.  3.  0.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  6.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 14. 16.] 
cards in discard: [16. 14.  3.  0.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0
  6  3  3 16] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  6.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  5.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 8. 3. 3.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 16. 14.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 17. 30.  8.  5.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 3.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 16. 14.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 17. 30.  8.  5.  6.  8.  7.  8. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 3.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 16. 14.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  5.  6.  8.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 3.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[206.90233]
 [191.50931]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  5.  6.  8.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25] -> size -> 29 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[  -5    0    6   30    0    0    0  -30    0    0    0    0    0 -300
   25    0] 
sum of rewards: -274 

action type: discard_down_to_3_cards - action 3
Learning step: -14.259017944335938
desired expected reward: 86.97673797607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[189.15053]
 [189.17017]
 [206.52376]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  5.  6.  8.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25] -> size -> 29 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -4.377744197845459
desired expected reward: 202.52459716796875



buy possibilites: [-1] 
expected returns: [[218.87263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  8.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  0.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25] -> size -> 29 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[  -5    0    5   20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -280 

action type: buy - action 6.0
Learning step: -18.53387451171875
desired expected reward: 170.63629150390625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  8.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  8.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3.  0.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[201.82547]
 [188.51575]
 [189.45651]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 14.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  8. 14.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -5.572196006774902
desired expected reward: 213.30044555664062



action possibilites: [-1] 
expected returns: [[176.78918]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action 14.0
Learning step: -3.4950687885284424
desired expected reward: 185.96144104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[165.6735 ]
 [166.03001]
 [165.99214]
 [165.68837]
 [167.45056]
 [168.22768]
 [167.25258]
 [171.44261]
 [168.03659]
 [167.3198 ]
 [168.94446]
 [177.4773 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: -3.0282065868377686
desired expected reward: 173.76097106933594



buy possibilites: [-1] 
expected returns: [[174.14659]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 72 

action type: buy - action 14.0
Learning step: -0.8835312128067017
desired expected reward: 167.15306091308594






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14] -> size -> 31 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  7.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14] -> size -> 31 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  6. 10.  0.] 
adversary cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14. 14.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14] -> size -> 31 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[176.13211]
 [164.15634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 10.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14. 14.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  6. 15.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: -3.863028049468994
desired expected reward: 170.2835693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[163.23642]
 [163.60931]
 [163.25394]
 [165.09703]
 [177.15633]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 10.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14. 14.  3. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 17. 30.  8.  4.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  6. 15.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -4.032362937927246
desired expected reward: 172.09974670410156



buy possibilites: [-1] 
expected returns: [[176.63072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 10.  0.] 
cards in discard: [ 3.  3. 16. 25.  0.  0.  3.  6.  3.  0.  0.  0.  3.  3.  6.  6.  8.  3.
 14. 14.  3. 10.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 17. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  6. 15.] 
adversary cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -291.0 

action type: buy - action 6.0
Learning step: -18.73850440979004
desired expected reward: 144.51541137695312






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  6. 15.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10. 14. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 6.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10. 14. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 6.] 
cards in discard: [16. 14.  3.  0.  3.  1.  6. 25. 10. 16. 14.  0.  1. 11.  0. 25.  0.  3.
  0. 11. 14.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 17. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10. 14. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6] -> size -> 32 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 6. 10. 14. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 16. 11.] 
expected returns: [[71.69089 ]
 [60.671772]
 [61.447643]
 [60.80355 ]
 [61.643837]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 14. 16. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -6.935746669769287
desired expected reward: 169.69497680664062



action possibilites: [-1. 14. 16. 11.] 
expected returns: [[52.836353]
 [44.51813 ]
 [44.05749 ]
 [44.656277]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 16. 11.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 17. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action 10.0
Learning step: -0.5200098156929016
desired expected reward: 60.151771545410156



action possibilites: [-1. 14. 16.] 
expected returns: [[174.19061]
 [164.829  ]
 [164.39511]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 16.  3.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10
  6  3  3  3  3  6 14  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  3.  6.  7.  6.  7. 10.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 64 

action type: gain_card_n - action 2
Learning step: 4.857419490814209
desired expected reward: 47.56370544433594



action possibilites: [-1] 
expected returns: [[200.3915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.] 
cards in discard: [ 3. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  3.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 85 

action type: gain_card_n - action 7
Learning step: 4.012593746185303
desired expected reward: 98.93689727783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[188.18541]
 [188.19725]
 [200.47833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.] 
cards in discard: [ 3. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 11. 16.] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  3.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: -2.2211525440216064
desired expected reward: 198.17034912109375






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  1.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  3.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29] -> size -> 33 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  1.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  1.  0. 16.  3.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6] -> size -> 34 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.52701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    3    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -302 

action type: buy - action -1.0
Learning step: -22.817060470581055
desired expected reward: 177.66128540039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 94.165794]
 [ 94.39134 ]
 [ 94.36788 ]
 [ 94.17306 ]
 [ 96.10965 ]
 [ 95.33077 ]
 [ 95.38627 ]
 [103.529785]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -3.0475103855133057
desired expected reward: 99.47949981689453



buy possibilites: [-1] 
expected returns: [[102.50809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1] -> size -> 32 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -1.6131353378295898
desired expected reward: 92.77821350097656






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  0.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  0.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  7.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  0.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16.  6.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[72.566315]
 [64.6799  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 16.  6.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0. 15. 16.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -3.6708106994628906
desired expected reward: 98.8372802734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.257324]
 [62.266182]
 [71.50897 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 16.  6.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0. 15. 16.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -2.2415411472320557
desired expected reward: 70.32477569580078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 15. 16.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14. 25.  0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 16.  3.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6
  3  3 16  6 25 11  8  1 11] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14. 25.  0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14. 25.  0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  6.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14. 25.  0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6. 14. 25.  0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  6. 14. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 25.] 
expected returns: [[25.080336]
 [19.830193]
 [20.1712  ]
 [21.48128 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 14. 25.  0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 14. 25.  6.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -3.1793086528778076
desired expected reward: 68.32966613769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.307098]
 [20.312632]
 [26.383938]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 14. 25.  0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 14. 25.  6.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -0.840630829334259
desired expected reward: 24.239704132080078



buy possibilites: [-1] 
expected returns: [[65.48133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 14. 25.  0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8. 14. 25.  6.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.  -1.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -1.1920247077941895
desired expected reward: 19.115068435668945






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14. 25.  6.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.  6.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 25.  6.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[90.682686]
 [79.74283 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 11.  0.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[   -5     0     3     0     0     0     0   -90     0     0     0    -1
     0 -1200    41     0] 
sum of rewards: -1252 

action type: discard_down_to_3_cards - action 6
Learning step: -63.97429275512695
desired expected reward: 2.150623321533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.82418]
 [78.16052]
 [77.83629]
 [79.52072]
 [90.46059]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 11.  0.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -2.7910125255584717
desired expected reward: 87.89166259765625



buy possibilites: [-1] 
expected returns: [[62.45791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 11.  0.] 
adversary cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -4.185905933380127
desired expected reward: 73.63826751708984






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 11.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  6.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 1. 25.  8.  3.  1.  0. 16.  3. 11.  1.  3. 11.  0.  0. 11. 10. 15.  0.
 16.  3. 14.  0.  8. 25.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  5.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[56.061127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.  0.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  5.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  1.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[   -5     0     3     0     0     0     0  -120     0     0     0    -2
     0 -1200    41     0] 
sum of rewards: -1283 

action type: discard_down_to_3_cards - action 1
Learning step: -66.43948364257812
desired expected reward: 4.577735900878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.09566 ]
 [46.103436]
 [54.109825]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 29. 10. 11. 16.  6. 14.  6.  1.  0.  6.  0.  0.  3.  3.  0.  3. 16.
  6.  0. 10.  6. 14. 25.  0.  3.  3.  0.  0.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  5.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  1.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -1.693854570388794
desired expected reward: 52.41596984863281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10. 11.  1.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1.  6. 14.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  5.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1.  6. 14.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  5.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1.  6. 14.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[93.01607]
 [85.35268]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 16. 30.  8.  2.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -0.7885681390762329
desired expected reward: 53.321258544921875



action possibilites: [-1] 
expected returns: [[173.92696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 16. 30.  8.  2.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   3   0   0   0  20 -30   0   0   0  -3   0   0   0   0] 
sum of rewards: -15 

action type: gain_card_n - action 0
Learning step: -1.000407099723816
desired expected reward: 82.27486419677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.05202]
 [154.0719 ]
 [174.43945]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 16. 30.  8.  2.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -4.140694618225098
desired expected reward: 169.7862548828125



buy possibilites: [-1] 
expected returns: [[195.96542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [0. 6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 16. 30.  8.  1.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  1.  0.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8  8] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.   -4.
    0. -300.    0.    0.] 
sum of rewards: -297.0 

action type: buy - action 6.0
Learning step: -18.144372940063477
desired expected reward: 135.92750549316406






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  1.  0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1 16  3 14  1 15  0  1 25 14 11  3  0  8 10  3 14  0  6  3
  3 16  6 25 11  8  1 11 11  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 16. 30.  8.  1.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 16.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 16. 30.  8.  1.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 16.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 16. 30.  8.  1.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 16.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 15. 30.  8.  1.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 16.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
expected returns: [[93.84675 ]
 [89.001755]
 [86.40437 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.  3.  0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6
  3  3  3  3  6 14  6  3 29  6  1  0  0  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 15. 30.  8.  1.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16.  1.  1. 15.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.917891502380371
desired expected reward: 187.0475311279297



action possibilites: [-1] 
expected returns: [[91.64227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16.  1.  1. 15.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -30    0    0   20    0    0    0    0   -4    0 -300
    0    0] 
sum of rewards: -318 

action type: gain_card_n - action 2
Learning step: -24.066736221313477
desired expected reward: 180.50698852539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[76.60467]
 [88.04315]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 16.  1.  1. 15.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -3.414489507675171
desired expected reward: 88.227783203125






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  1.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1.  1. 15.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  1.  1.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  1.  1.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [6. 6. 6. 0. 0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [6. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[105.186035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  0.  8.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -3.7354724407196045
desired expected reward: 84.30769348144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 94.60375]
 [ 94.88082]
 [ 95.99048]
 [104.99419]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  0.  8.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -4.743131160736084
desired expected reward: 100.44290161132812



buy possibilites: [-1] 
expected returns: [[114.34041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  0.  8.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.] 
adversary owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -69.0 

action type: buy - action 0.0
Learning step: -5.6075286865234375
desired expected reward: 88.99623107910156






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  8.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  3 14  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16
  6 25 11  8  1 11 11  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 14.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 14.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 15. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 14.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  3. 14.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[104.53314 ]
 [ 94.488014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 14.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  6. 25. 25.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -5.164564609527588
desired expected reward: 109.17584228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 89.51712]
 [101.82085]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  3. 14.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  6. 25. 25.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -4.757607936859131
desired expected reward: 99.77552032470703



buy possibilites: [-1] 
expected returns: [[89.50731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  3. 14.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  6. 25. 25.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: -70.0 

action type: buy - action 0.0
Learning step: -5.666921615600586
desired expected reward: 77.94979858398438






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  6. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 25. 25.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6. 25.  0. 14.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6. 25.  0. 14.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6. 25.  0. 14.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [14.  3.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[133.99283]
 [124.19925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  3.  0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 11.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.  0. 25.  0. 11.  6. 25.  0. 14.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.2575738430023193
desired expected reward: 86.2497329711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[118.64312]
 [130.83406]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  3.  0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  8.  3. 11.] 
adversary cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.  0. 25.  0. 11.  6. 25.  0. 14.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -5.576678276062012
desired expected reward: 128.41615295410156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.  0. 25.  0. 11.  6. 25.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.  0. 25.  0. 11.  6. 25.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 8. 10. 11.  1.  6. 14.  3.  8.  0.  0. 15.  3. 16.  1.  1.  3.  8.  0.
  0.  0. 25.  0. 11.  6. 25.  0. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[121.32704 ]
 [112.591064]
 [112.591064]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0  0] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -5.627267360687256
desired expected reward: 125.20679473876953



action possibilites: [-1. 10. 25.] 
expected returns: [[114.868416]
 [106.459915]
 [109.108665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 25.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0  0] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 10.0
Learning step: -3.8386123180389404
desired expected reward: 108.75245666503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[105.489845]
 [105.665504]
 [106.41589 ]
 [114.868416]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 25.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0  0] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.992826223373413
desired expected reward: 110.87561798095703






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  3  0  8 10  3 14  0  6  3  3 16  6 25
 11  8  1 11 11  8  8  3  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  5. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 16.  0.  8.  6.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 16.  0.  8.  6.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 16.  0.  8.  6.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [14.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 16.  0.  8.  6.] 
adversary cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 1. 16.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[96.6831  ]
 [86.87826 ]
 [86.734314]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  8.  6.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  1  0  0  0  6  6  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 14. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 15. 10.  0.  6.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14  0] -> size -> 36 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -4.898548126220703
desired expected reward: 109.96989440917969



action possibilites: [-1] 
expected returns: [[95.8005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 15. 10.  0.  6.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0  -6   0   0   4   0] 
sum of rewards: 5 

action type: gain_card_n - action 2
Learning step: -4.312648296356201
desired expected reward: 130.050537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.40745 ]
 [95.800514]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [ 0.  6. 11.  3.  3.  0.  3.  6. 16. 29.  3.  0.  0.  6.  6.  6.  0.  0.
  0.  0.  6.  6.  3. 14. 14.  3.  3.  3.  0. 10. 10.  3.  0.  0. 25.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 15. 10.  0.  6.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14  0] -> size -> 36 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -2.4172286987304688
desired expected reward: 93.38327026367188






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 8. 15. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.  0.  6.] 
cards in discard: [14.  0. 16.  0.  0. 14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  6.  3.] 
cards in discard: [14.  0. 16.  0.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 16  1 15  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11
  8  1 11 11  8  8  3  3  0  0 14  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [14.  0. 16.  0.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [14.  0. 16.  0.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [16.  0.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[66.035416]
 [58.128002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -4.0325846672058105
desired expected reward: 91.76791381835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[58.446133]
 [58.694252]
 [59.70193 ]
 [67.80247 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 13. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -2.5578346252441406
desired expected reward: 63.47757339477539



buy possibilites: [-1] 
expected returns: [[47.42515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  3.  0.] 
cards in discard: [3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [1. 3. 3. 3. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0 -7  0  0  8  0] 
sum of rewards: -1 

action type: buy - action 3.0
Learning step: -1.9176464080810547
desired expected reward: 56.77660369873047






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  5.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 3. 0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[82.655205]
 [72.334526]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -0.7137857675552368
desired expected reward: 46.71136474609375



action possibilites: [-1.] 
expected returns: [[85.16198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -0.8443029522895813
desired expected reward: 71.4902114868164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[73.24838 ]
 [73.55426 ]
 [74.788445]
 [84.82553 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -1.6124597787857056
desired expected reward: 83.54952239990234






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 12. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 8. 3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[115.79422]
 [105.68768]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  3 14  0 16  8 10  0 16  3  6  3  6  0 25 10  6  3
  3  3  3  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16. 25.  1.  3.  0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11  3] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -2.336054563522339
desired expected reward: 82.4894790649414



action possibilites: [-1] 
expected returns: [[114.622635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16. 25.  1.  3.  0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11  3] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: trash_cards_n_from_hand - action 10
Learning step: -2.8355050086975098
desired expected reward: 102.45478057861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.5381 ]
 [113.28609]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16. 25.  1.  3.  0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11  3] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -3.4882454872131348
desired expected reward: 111.13439178466797



buy possibilites: [-1] 
expected returns: [[133.12044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [16. 25.  1.  3.  0.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11  3] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.  20. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -38.0 

action type: buy - action 0.0
Learning step: -3.781695604324341
desired expected reward: 93.75640869140625






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [16. 25.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 25.  1.  3.  0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10  3 14  0  6  3  3 16  6 25 11  8
  1 11 11  8  8  3  3  0  0 14  0 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  4. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[116.71501]
 [111.36611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6.  3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8. 25. 11.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1. 16. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -4.732937812805176
desired expected reward: 128.3874969482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[112.73125]
 [118.95209]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8. 25. 11.] 
adversary cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1. 16. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -3.870972156524658
desired expected reward: 112.84403228759766



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  8. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 25. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8. 25. 11.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1. 16. 25.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  9.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 16. 25.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25. 11.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1. 16. 25.  1.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 16. 25.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 25. 11.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1. 16. 25.  1.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 16. 25.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 25. 11.] 
cards in discard: [14.  0. 16.  0.  0. 14. 10.  8.  0.  6.  3. 11.  1.  3.  3.  3.  0.  3.
  6.  8.  0.  0.  0. 14.  1. 16. 25.  1.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 16. 25.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  3. 16. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[37.05053 ]
 [31.680752]
 [33.42672 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16. 25.  0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  1. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -5.823380947113037
desired expected reward: 113.12870788574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.518757]
 [36.83406 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16. 25.  0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  1. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.7363404035568237
desired expected reward: 35.3141975402832



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [16.  0.  1. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 14. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 14.  0. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1. 14.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 14.  0. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1. 14.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 22. 30. 11. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 14.  0. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1. 14.] 
cards in discard: [1. 3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 30. 10. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 14.  0. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 6. 14.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[85.7488 ]
 [73.48946]
 [73.73103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0. 11.  0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 10. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  8. 25.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -1.2227338552474976
desired expected reward: 35.61133575439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[66.46217 ]
 [66.82362 ]
 [68.275406]
 [80.43181 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0. 11.  0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 30. 10. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  8. 25.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -3.824592351913452
desired expected reward: 81.92420196533203



buy possibilites: [-1] 
expected returns: [[137.25854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0. 11.  0.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  8. 25.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0  -6   0   0   8   0] 
sum of rewards: -10 

action type: buy - action 3.0
Learning step: -0.7528640627861023
desired expected reward: 66.07076263427734






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [16.  0.  3.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  8. 25.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  6.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  8.  1.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  6.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  8.  1.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  3. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  6.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  8.  1.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  6.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[96.22515]
 [89.80741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  6.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0. 25.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.361456394195557
desired expected reward: 131.8970947265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[83.74681 ]
 [84.074356]
 [85.42048 ]
 [96.22515 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  6.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0. 25.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -3.4217522144317627
desired expected reward: 92.80339050292969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0. 25.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0. 29.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0. 11.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0. 29.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0. 11.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0. 29.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0. 11.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  3.] 
adversary cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0. 29.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[106.1559]
 [ 95.6095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0. 29.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29. 14. 14.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -3.127256155014038
desired expected reward: 93.09788513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 91.662254]
 [ 91.97501 ]
 [ 93.22284 ]
 [104.10985 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  3.] 
cards in discard: [ 3. 16.  0.  6.  3.  0. 10.  3.  6.  0.  0.  3.  0.  8.  0.  6.  0. 10.
  6.  3.  6.  3. 16. 25.  0.  3.  6. 14.  0. 11.  0. 29.  3.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29. 14. 14.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -3.638758420944214
desired expected reward: 100.4710922241211



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 6. 29. 14. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 14. 14.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  6.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.303415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 4
Learning step: -1.3087061643600464
desired expected reward: 26.05195426940918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[21.338371]
 [21.620316]
 [21.59046 ]
 [23.382998]
 [22.598715]
 [22.65574 ]
 [31.457546]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30.  9. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -1.514674425125122
desired expected reward: 27.788740158081055



buy possibilites: [-1] 
expected returns: [[40.51444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 14.  3.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0. -7.  0.  0.  2.  0.] 
sum of rewards: -6.0 

action type: buy - action 3.0
Learning step: -0.46794816851615906
desired expected reward: 21.12251091003418






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 14.  3.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 10.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3. 14.  3.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3. 10.] 
adversary cards in discard: [6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[30.192404]
 [27.52819 ]
 [25.798113]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 10.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -1.443022608757019
desired expected reward: 39.071414947509766



action possibilites: [-1. 29.] 
expected returns: [[109.621475]
 [103.30543 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 10.0
Learning step: 2.063990354537964
desired expected reward: 27.862098693847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[104.57988 ]
 [104.907715]
 [106.25064 ]
 [117.087265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [6. 3. 3. 0. 0. 0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -2.072617769241333
desired expected reward: 107.54888916015625






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  4.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  3.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[126.74114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  3.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  1. 10.  8.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -3.0526883602142334
desired expected reward: 114.03459167480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[122.25448 ]
 [122.597916]
 [122.565155]
 [124.816986]
 [123.83355 ]
 [123.913605]
 [133.93973 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  3.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  1. 10.  8.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -3.5536389350891113
desired expected reward: 123.1875



buy possibilites: [-1] 
expected returns: [[32.858437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  1. 10.  8.  0.] 
adversary cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0 -8  0  0 18  0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: -5.051534175872803
desired expected reward: 119.76544952392578






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 1.  1. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 10.  8.  0.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 16  1  0  1 25 14  0  8 10 14  0  6  3  3 16  6 25 11  8  1
 11 11  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 25.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 25.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  4.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 25.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 1.  3. 11. 16.  0.  1. 14. 14. 25. 16.  0.  3.  8.  1.  0.  0. 25.  0.
  3. 11.  0.  0. 11. 14.  1. 29. 14.  6.  0.  6.  8.  8.  3. 14.  3. 11.
  0.  0.  3. 11.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 25.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 6.  3. 25.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[17.798079]
 [17.860796]
 [17.886118]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 25.  3. 14.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -1.2912330627441406
desired expected reward: 31.567203521728516



action possibilites: [-1] 
expected returns: [[85.20519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 14.  6. 16.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: 1.9740768671035767
desired expected reward: 19.834875106811523





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[79.389595]
 [85.000275]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14.  6. 16.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -1.4533510208129883
desired expected reward: 83.75183868408203



buy possibilites: [-1] 
expected returns: [[89.59207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 14.  6. 16.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8] -> size -> 45 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   4   0   0   0  20 -30   0   0   0  -9   0   0   0   0] 
sum of rewards: -20 

action type: buy - action 0.0
Learning step: -2.953658103942871
desired expected reward: 76.4359359741211






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [29.  3. 14.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 14.  3. 11.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  8.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 14.  3.] 
cards in discard: [29.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 14.  3.] 
cards in discard: [29.] 
cards in deck: 40 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 14.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[91.77845 ]
 [83.066925]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 14.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -2.550913095474243
desired expected reward: 87.0411605834961



action possibilites: [-1] 
expected returns: [[65.66933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action 14.0
Learning step: -1.7531133890151978
desired expected reward: 81.8603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[53.729202]
 [54.082157]
 [54.04696 ]
 [55.500214]
 [56.304733]
 [55.313778]
 [59.49787 ]
 [56.092937]
 [55.389343]
 [57.012417]
 [65.669334]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -1.0355767011642456
desired expected reward: 64.63375091552734



buy possibilites: [-1] 
expected returns: [[81.77148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    4.    0.    0.    0.   20.    0.    0.    0.    0.  -10.
   0.    0.    4.5   0. ] 
sum of rewards: 13.5 

action type: buy - action 10.0
Learning step: -0.25460854172706604
desired expected reward: 55.134727478027344






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6. 10.  0. 11.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  3.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[41.829727]
 [33.569176]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 16. 14. 25.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: discard_down_to_3_cards - action 9
Learning step: -0.40847617387771606
desired expected reward: 23.947307586669922



action possibilites: [-1.] 
expected returns: [[46.51809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 16. 14. 25.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 10.0
Learning step: 0.3681980073451996
desired expected reward: 33.937381744384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[36.937   ]
 [37.19041 ]
 [38.22382 ]
 [46.518066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 16. 14. 25.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -0.46402856707572937
desired expected reward: 46.05406188964844






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [11.  0. 16. 14. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16. 14. 25.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11. 10.  6.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16. 25.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11. 10.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16. 25.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11. 10.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16. 25.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [3. 6. 3.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11. 10.  6.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[81.31158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11. 10.  6.
  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1. 11.  8.  1.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10] -> size -> 48 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: discard_down_to_3_cards - action 0
Learning step: 1.6125568151474
desired expected reward: 4.951631546020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[68.16168]
 [81.31157]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  0. 10.  0.  0. 29.  3.  3. 11.  6.  0.  6.  0.  0.
  0. 25.  6.  3.  3. 14.  6. 16. 10. 14.  0.  3.  0.  3.  8. 11. 10.  6.
  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1. 11.  8.  1.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.] 
adversary owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10] -> size -> 48 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.4163739681243896
desired expected reward: 78.89520263671875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  8.  1.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  1  0  1 25 14  0  8 14  0  6  3  3 16  6 25 11  8  1 11 11
  8  8  3  3  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[38.615944]
 [35.344315]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  6  0 25 10  6  3  3  3  3
  6 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  2.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [1. 1. 8. 0. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 45 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -2.779139280319214
desired expected reward: 78.53244018554688



action possibilites: [-1] 
expected returns: [[32.753212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [1. 1. 8. 0. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 45 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  20   0   0  20   0   0   0   0 -10   0   0   4   0] 
sum of rewards: 34 

action type: gain_card_n - action 2
Learning step: -0.14024506509304047
desired expected reward: 51.403602600097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[27.49484 ]
 [27.631363]
 [27.615902]
 [28.45412 ]
 [28.086784]
 [28.110981]
 [31.838196]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  5. 10.  9.] 
adversary cards in hand: [1. 1. 8. 0. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 45 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1
Learning step: 1.0117825269699097
desired expected reward: 33.76499557495117



buy possibilites: [-1] 
expected returns: [[8.213709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [1. 1. 8. 0. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
adversary owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 45 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  20   0   0  20   0   0   0   0 -11   0   0  18   0] 
sum of rewards: 47 

action type: buy - action 10.0
Learning step: 1.1298812627792358
desired expected reward: 29.24085807800293






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [1. 1. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 8. 0. 8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8  1 11 11  8  8  3  3
  0  0 14  0 11  3 14  1 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.828636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16.  6. 11.  6.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1
Learning step: 0.9229588508605957
desired expected reward: 9.136667251586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[10.427685 ]
 [10.466033 ]
 [10.611892 ]
 [11.7773695]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 21. 30.  8. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16.  6. 11.  6.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: 0.5046001672744751
desired expected reward: 15.333236694335938



buy possibilites: [-1] 
expected returns: [[66.209045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30.  7. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 16.  6. 11.  6.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0] -> size -> 43 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  30   0   0   0   0   0   0   0 -12   0   0   8   0] 
sum of rewards: 27 

action type: buy - action 3.0
Learning step: 2.316401958465576
desired expected reward: 12.782432556152344






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6. 11.  6.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30.  7. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 47 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 47 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 47 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  6.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  6.  8.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 47 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[71.02711 ]
 [61.039635]
 [60.95831 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  6.  8.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 14  0 16  8 10  0 16  3  3  0 25 10  6  3  3  3  3  6
 14  6  3 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: -0.7948374152183533
desired expected reward: 65.4142074584961



action possibilites: [-1] 
expected returns: [[76.23704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: trash_cards_n_from_hand - action 9
Learning step: 1.112329125404358
desired expected reward: 65.17241668701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[65.15457]
 [75.31996]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1
Learning step: 0.3821159303188324
desired expected reward: 76.61915588378906



buy possibilites: [-1] 
expected returns: [[64.46981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 3. 3. 8.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  30   0   0  20 -30   0   0   0 -10   0   0   0   0] 
sum of rewards: 12 

action type: buy - action 0.0
Learning step: -1.2071583271026611
desired expected reward: 63.94742202758789






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 10.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 10.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 8.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 14. 10.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[11.175435]
 [10.196252]
 [10.143592]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14. 10.  0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0] -> size -> 46 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1
Learning step: -1.3853282928466797
desired expected reward: 63.08448028564453



action possibilites: [-1. 14.] 
expected returns: [[69.12197 ]
 [63.202774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  0.  0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0] -> size -> 46 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 53 

action type: take_action - action 10.0
Learning step: 3.6394100189208984
desired expected reward: 13.783003807067871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[60.845802]
 [61.066616]
 [61.04533 ]
 [62.453583]
 [61.83352 ]
 [61.881104]
 [68.184364]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0.  0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0] -> size -> 46 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 52 

action type: take_action - action -1.0
Learning step: 0.5648571252822876
desired expected reward: 69.68682861328125



buy possibilites: [-1] 
expected returns: [[25.431696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  0.  0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0.  0.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0] -> size -> 46 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   7  30   0   0  20   0   0   0   0 -11   0   0  18   0] 
sum of rewards: 59 

action type: buy - action 10.0
Learning step: 0.4281578063964844
desired expected reward: 62.309261322021484






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  1.  7.  7.  2. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10] -> size -> 46 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10] -> size -> 46 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10] -> size -> 46 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10] -> size -> 46 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[19.758884]
 [15.862174]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  3  0 25 10  3  3  3  3  6 14  6  3
 29  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 14.  0. 25.  1.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10] -> size -> 48 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1
Learning step: 0.7343766093254089
desired expected reward: 26.166072845458984



action possibilites: [-1] 
expected returns: [[119.32259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 14.  0. 25.  1.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10] -> size -> 48 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  20   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: 39 

action type: gain_card_n - action 1
Learning step: 2.3589084148406982
desired expected reward: 46.864959716796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[112.101814]
 [112.32337 ]
 [112.301125]
 [113.66513 ]
 [113.10686 ]
 [119.32259 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 14.  0. 25.  1.] 
adversary cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10] -> size -> 48 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1
Learning step: -1.3407516479492188
desired expected reward: 117.98184204101562






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0. 25.  1.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10. 11.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0. 25.  1.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10. 11.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  7.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0. 25.  1.] 
cards in discard: [29. 11. 29.  3. 14.  3.  0. 14.  8. 14.  0.  0. 10. 14. 11.  0. 16. 25.
  0.  8.  0.  8.  8.  3.  0. 11.  0. 16.  6.  6.  0.  8.  0.  3.  3.  8.
  8. 10. 11.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 25. 11.  3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[53.93378 ]
 [53.072823]
 [52.764656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25. 11.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29] -> size -> 49 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1.0
Learning step: -3.7160308361053467
desired expected reward: 115.60655975341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.47184]
 [53.93378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25. 11.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29] -> size -> 49 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1.0
Learning step: -0.4476657807826996
desired expected reward: 53.486114501953125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1. 25.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1. 25.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  2. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1. 25.] 
cards in discard: [14.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[62.840683]
 [54.20073 ]
 [54.96503 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  0.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1.0
Learning step: -0.34187832474708557
desired expected reward: 53.59190368652344



action possibilites: [-1. 11.] 
expected returns: [[49.21894]
 [41.67762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action 10.0
Learning step: 0.3726610243320465
desired expected reward: 54.573387145996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[39.61199]
 [39.86971]
 [49.21894]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: 0.5712515115737915
desired expected reward: 49.790191650390625



buy possibilites: [-1] 
expected returns: [[64.1246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  20.   0.   0.  20. -30.   0.   0.   0. -12.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -0.5877963900566101
desired expected reward: 39.02420425415039






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [14.  0.  0. 10.  1. 25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [29.  6.  3.  6.  3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0. 10.  0.  3.
 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0] -> size -> 47 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [14.  0.  0. 10.  1. 25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14] -> size -> 50 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2. 10.  9.] 
adversary cards in hand: [29.  6.  3.  6.  3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0. 10.  0.  3.
 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0] -> size -> 47 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14 22] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [29.  6.  3.  6.  3.] 
adversary cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0. 10.  0.  3.
 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0] -> size -> 47 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [29.  6.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[55.441154]
 [53.44139 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  6.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0. 10.  0.  3.
 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [11.  8.  8.  6.  3.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14 22] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: -0.9286203384399414
desired expected reward: 63.19598388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.51361 ]
 [55.441154]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  6.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0. 10.  0.  3.
 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [11.  8.  8.  6.  3.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14 22] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1.0
Learning step: -0.5135505795478821
desired expected reward: 54.9276008605957



buy possibilites: [-1] 
expected returns: [[58.325783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  6.  3.] 
cards in discard: [ 8. 10. 16.  0.  0.  0.  3.  0.  3.  6.  0.  3.  0.  8.  6. 10. 10.  3.
  0. 14.  0.  0.  1. 16.  0.  0.  0.  3.  0. 25. 11.  3.  0. 10.  0.  3.
 11.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [11.  8.  8.  6.  3.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14 22] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  20   0   0   0 -30   0   0   0 -13   0   0   0   0] 
sum of rewards: -22 

action type: buy - action 0.0
Learning step: -2.3633508682250977
desired expected reward: 49.1502685546875






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [11.  8.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  6.  3.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0  8 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0
 14  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10
 29 14 22] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  3.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [ 6.  0.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [ 6.  0.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[44.339073]
 [40.24418 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 14.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [ 3. 14.  0. 29. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: -0.9092373251914978
desired expected reward: 57.41654586791992



action possibilites: [-1] 
expected returns: [[-0.5875201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [14. 29. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action 14.0
Learning step: 0.024571610614657402
desired expected reward: 40.26875305175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[4.2106733]
 [4.167607 ]
 [4.1697145]
 [3.8056593]
 [3.99122  ]
 [2.17836  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  2.  9.  9.] 
adversary cards in hand: [14. 29. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1
Learning step: 2.1650631427764893
desired expected reward: 1.577543020248413



buy possibilites: [-1] 
expected returns: [[28.60338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [10.] 
cards in deck: 43 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  9.] 
adversary cards in hand: [14. 29. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0] -> size -> 51 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  20   0   0  20   0   0   0   0 -14   0   0  18   0] 
sum of rewards: 45 

action type: buy - action 10.0
Learning step: 2.6940152645111084
desired expected reward: 6.685232162475586






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [14. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29. 11.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  9.] 
adversary cards in hand: [14. 10.  3.  0.  0.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  8.] 
adversary cards in hand: [14. 10.  3.  0.  0.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  8.] 
adversary cards in hand: [14. 10.  3.  0.  0.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  8.] 
adversary cards in hand: [14. 10.  3.  0.  0.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [14. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[36.7993 ]
 [35.72906]
 [35.65925]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  3.  0.  0.] 
cards in discard: [10. 14.  6.  0.  3.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  8.] 
adversary cards in hand: [ 3.  0. 14. 14.  8.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1
Learning step: 0.4332137107849121
desired expected reward: 29.03659439086914



action possibilites: [-1] 
expected returns: [[16.374542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 14.  6.  0.  3.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 14.  8.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action 14.0
Learning step: 0.644304096698761
desired expected reward: 36.37336349487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[12.328219]
 [12.463757]
 [12.450869]
 [12.982648]
 [13.283699]
 [14.478444]
 [13.199032]
 [12.942112]
 [13.540622]
 [16.939299]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 14.  6.  0.  3.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  6.  1. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 14.  8.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1
Learning step: 1.543469786643982
desired expected reward: 17.918012619018555



buy possibilites: [-1] 
expected returns: [[63.666924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10 29] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 14.  8.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  20   0   0  20   0   0   0   0 -15   0   0  32   0] 
sum of rewards: 58 

action type: buy - action 29.0
Learning step: 3.608583450317383
desired expected reward: 18.087032318115234






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  9.  8.] 
adversary cards in hand: [16.  0. 25.  1. 11.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10 29] -> size -> 50 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  9.  8.] 
adversary cards in hand: [16.  1. 11.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10 29] -> size -> 50 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  9.  8.] 
adversary cards in hand: [16.  1. 11.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10 29] -> size -> 50 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  9.  8.] 
adversary cards in hand: [16.  1. 11.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10 29] -> size -> 50 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [16.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[5.5109425]
 [2.8924096]
 [3.0308049]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1. 11.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29
  6  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0
 10 29] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  9.  8.] 
adversary cards in hand: [25. 10.  0. 29.  3.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: discard_down_to_3_cards - action 4
Learning step: -0.1623893827199936
desired expected reward: 25.89166831970215



action possibilites: [-1] 
expected returns: [[22.588348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [25. 10.  0. 29.  3.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  20   0   0  20   0   0   0   0 -15   0   0  25   0] 
sum of rewards: 51 

action type: gain_card_n - action 11
Learning step: 0.9192396402359009
desired expected reward: 43.69920349121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[19.80559 ]
 [19.859995]
 [21.75869 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [25. 10.  0. 29.  3.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1
Learning step: 1.3847074508666992
desired expected reward: 23.97305679321289






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [25. 10.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 29.  3.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22. 16.  1.] 
adversary owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 11.  8.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22. 16.  1.] 
adversary owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3. 11.  8.] 
cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22. 16.  1.] 
adversary owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.0797796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22. 16.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  8.  3. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8. 25. 10.  0. 29.  3. 11.
  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: buy - action -1.0
Learning step: 0.008860588073730469
desired expected reward: 21.76755142211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[2.1554518]
 [2.144817 ]
 [3.110518 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22. 16.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  8.  3. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8. 25. 10.  0. 29.  3. 11.
  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  6 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 21 

action type: take_action - action -1.0
Learning step: 1.003308653831482
desired expected reward: 3.0830883979797363



Player 0 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 1 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 2 
Workshop: 2 
Chapel: 1 
Witch: 1 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [10. 14.  6.  0.  3.  6. 29. 14. 10.  3.  0.  0.  0. 25. 22. 16.  1.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  0 16  8  0 16  3  0 25 10  3  3  3  3  6 14  6  3 29  6
  0  0  0  6  6  0  0  3  3  0  3  3 11  0 10  8 10  3  0 10  1  0  0 10
 29 22  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 20. 30.  6. 30.  8.  0.  6.  2.  0.  7.  5.  1. 10.  1.  8.  8.] 
adversary cards in hand: [ 0.  0.  8.  3. 11.] 
adversary cards in discard: [14.  0.  0. 10.  1. 25. 22.  0.  0. 29.  0.  1.  0.  8. 11.  6.  3.  3.
  0. 15.  0. 11. 14. 29.  3. 14.  0. 14.  0.  8. 25. 10.  0. 29.  3. 11.
  8.] 
adversary owned cards: [ 0  0 16  0 25 14  0 14  0  6  3 16  6 25  8 11 11  8  8  3  3  0  0 14
  0 11  3 14 29  0  1  3 14  0  1 11  8 29  8 10  0  0  3  0  0  8 10 29
 14 22  0 15  0  0] -> size -> 54 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[ -5 500   6  20   0   0   0 -30   0   0   0 -16   0   0   0   0] 
sum of rewards: 475 

action type: buy - action 0.0
Learning step: 23.642227172851562
desired expected reward: 25.797679901123047



