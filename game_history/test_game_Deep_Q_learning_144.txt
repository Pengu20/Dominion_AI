 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[100.27131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: buy - action -1
Learning step: -120000.0
desired expected reward: -120125.0390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 88.93275 ]
 [108.21727 ]
 [ 99.28892 ]
 [ 66.89279 ]
 [116.440704]
 [107.82057 ]
 [ 99.33718 ]
 [100.244705]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 101.21902465820312



buy possibilites: [-1] 
expected returns: [[90.29651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 116.44068908691406






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.318985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.2965087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 92.271484]
 [109.168915]
 [100.79201 ]
 [ 72.73245 ]
 [106.53797 ]
 [116.11883 ]
 [108.291626]
 [122.346344]
 [ 84.66776 ]
 [ 99.8995  ]
 [100.043724]
 [ 99.74881 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.24555969238281



buy possibilites: [-1] 
expected returns: [[83.834625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 122.34635925292969






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.47083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.83462524414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[80.716965]
 [89.673515]
 [60.20535 ]
 [96.85028 ]
 [86.088684]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 86.30957794189453



buy possibilites: [-1] 
expected returns: [[82.14041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 96.85031127929688






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 88.51662 ]
 [109.38532 ]
 [102.746346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 11.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.14041137695312



action possibilites: [-1. 11.] 
expected returns: [[107.49115]
 [123.43045]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.91934967041016



action possibilites: [-1] 
expected returns: [[100.15247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.47555541992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.40177 ]
 [108.32675 ]
 [ 99.46571 ]
 [ 72.48731 ]
 [ 65.30614 ]
 [103.798386]
 [119.88174 ]
 [108.47366 ]
 [142.31226 ]
 [125.63185 ]
 [ 82.38322 ]
 [ 97.77951 ]
 [ 99.55942 ]
 [ 77.912636]
 [103.29037 ]
 [102.103386]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.15247344970703



buy possibilites: [-1] 
expected returns: [[90.40347]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 142.31224060058594






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 89.2769 ]
 [105.25711]
 [122.75545]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.40347290039062



action possibilites: [-1] 
expected returns: [[87.801605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 122.77565002441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 83.625015]
 [101.80162 ]
 [ 94.14851 ]
 [ 59.17104 ]
 [ 98.88805 ]
 [105.452896]
 [101.23229 ]
 [110.993774]
 [ 79.17932 ]
 [ 93.58359 ]
 [ 92.32245 ]
 [ 90.839066]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.80160522460938



buy possibilites: [-1] 
expected returns: [[83.96893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 110.9937973022461






Player: 1 
cards in hand: [16.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [6. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[112.94366 ]
 [124.751785]
 [132.30396 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  8 10 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 6.  1. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.96893310546875



action possibilites: [-1] 
expected returns: [[83.05745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 6.  1. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 138.26922607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.93063 ]
 [53.1581  ]
 [83.342255]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [29. 25. 11.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 6.  1. 16.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.05744934082031






Player: 1 
cards in hand: [ 3.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [ 6.  1. 16.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29] -> size -> 13 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [ 6.  1. 16.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29] -> size -> 13 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 81.65579]
 [100.53111]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.3422622680664



action possibilites: [-1. 11.] 
expected returns: [[ 91.74219 ]
 [105.098656]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.95561218261719



action possibilites: [-1] 
expected returns: [[81.478874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 112.30500793457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 63.42602 ]
 [ 89.70235 ]
 [ 81.336395]
 [ 35.71638 ]
 [ 83.31598 ]
 [ 96.555244]
 [ 90.00821 ]
 [101.24958 ]
 [ 65.06847 ]
 [ 81.987625]
 [ 83.06145 ]
 [ 81.00789 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.47887420654297



buy possibilites: [-1] 
expected returns: [[96.09598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 101.24958038330078






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [25.  3.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[ 96.32759 ]
 [128.45512 ]
 [115.74979 ]
 [ 88.741585]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1  1] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.09597778320312



action possibilites: [-1] 
expected returns: [[51.953983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10.  8.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.57896423339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.45607 ]
 [57.7292  ]
 [36.26594 ]
 [64.388954]
 [51.92522 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10.  8.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8.  8.  9.  8.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.953983306884766



buy possibilites: [-1] 
expected returns: [[48.996902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10.  8.  0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8.  9.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 64.38899230957031






Player: 1 
cards in hand: [ 6.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  0.  0.] 
cards in discard: [1. 3. 3. 0. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  6  1  1  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8.  9.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  8.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0. 6. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  8. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 29.] 
expected returns: [[39.46997 ]
 [50.95324 ]
 [41.651955]
 [56.759235]
 [56.759235]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.99690246582031



action possibilites: [-1. 11.  8. 29.] 
expected returns: [[67.15975 ]
 [83.61564 ]
 [74.174545]
 [88.089294]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.6727409362793



action possibilites: [-1. 11.  8. 29.] 
expected returns: [[68.25404 ]
 [81.584885]
 [74.83496 ]
 [85.77043 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.08927917480469



action possibilites: [-1. 11.  8.] 
expected returns: [[69.11268 ]
 [88.30391 ]
 [79.590256]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.77043914794922



action possibilites: [-1] 
expected returns: [[81.1868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 98.804931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 52.73048 ]
 [ 75.150055]
 [ 66.30642 ]
 [ 27.810562]
 [ 18.583502]
 [ 68.55543 ]
 [ 95.83805 ]
 [ 76.83934 ]
 [121.62239 ]
 [104.004105]
 [ 51.6073  ]
 [ 66.93619 ]
 [ 68.08656 ]
 [ 45.12735 ]
 [ 75.710655]
 [ 82.87816 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.18679809570312



buy possibilites: [-1] 
expected returns: [[121.73894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [10. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 121.62239074707031






Player: 1 
cards in hand: [ 0.  3.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8.  9.  8.  7.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  8.  7.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  8.  7.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0.] 
cards in discard: [ 3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 10.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 91.80313 ]
 [123.37909 ]
 [103.156334]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 10.  3.] 
cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.73893737792969



action possibilites: [-1] 
expected returns: [[82.30664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  8.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  7.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.29939270019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.098434]
 [110.03511 ]
 [103.64215 ]
 [ 99.005226]
 [104.94032 ]
 [107.32648 ]
 [100.93355 ]
 [ 87.57971 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  8.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  7.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.306640625



buy possibilites: [-1] 
expected returns: [[78.063416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  8.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  8.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 110.03512573242188






Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 28. 30.  8.  7.  9.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1] -> size -> 19 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[38.104805]
 [47.209827]
 [54.46178 ]
 [33.59618 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.06341552734375



action possibilites: [-1. 11. 10.] 
expected returns: [[70.96854]
 [86.10234]
 [68.13632]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  8.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.58228302001953



action possibilites: [-1] 
expected returns: [[42.34438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.89752197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 14.224705]
 [ 37.203693]
 [ 29.420479]
 [-18.826473]
 [ 53.441273]
 [ 38.289173]
 [ 30.405834]
 [ 43.503918]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  8.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.34437942504883



buy possibilites: [-1] 
expected returns: [[58.341007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  3.  0.] 
adversary cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 53.44131851196289






Player: 1 
cards in hand: [ 6. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  3.  0.] 
cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  7.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  8. 29.  3. 25.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  8. 29.  3. 25.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 29. 11.  0.  3.  1.  0.  6. 16.  0.  0.  3.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8.  7.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  8. 29.  3. 25.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[66.9344  ]
 [80.575775]
 [84.94498 ]
 [98.01755 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 29.  3. 25.] 
cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.341007232666016



action possibilites: [-1] 
expected returns: [[46.50057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 29.  3.  8. 10.] 
cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  6.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.7779541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[45.022305]
 [49.98173 ]
 [28.70789 ]
 [56.102863]
 [47.98697 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 29.  3.  8. 10.] 
cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  6.  8.  7.  7.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.50056838989258



buy possibilites: [-1] 
expected returns: [[118.47073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 29.  3.  8. 10.] 
cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  6.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 56.10287857055664






Player: 1 
cards in hand: [6. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 8.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  6.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.  8. 25.  1.  8. 29.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 8.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8.  6.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.  8. 25.  1.  8. 29.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 8.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  6.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.  8. 25.  1.  8. 29.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[76.92668 ]
 [86.08908 ]
 [96.885315]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.  8. 25.  1.  8. 29.  3.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 16.] 
adversary cards in discard: [6. 0. 6. 3. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.47073364257812



action possibilites: [-1. 10. 25.] 
expected returns: [[ 80.982086]
 [ 85.42496 ]
 [107.908966]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 25.] 
cards in discard: [10. 11. 29. 11.  3.  0. 10.  0.  8. 25.  1.  8. 29.  3.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  6.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 16.] 
adversary cards in discard: [6. 0. 6. 3. 0. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 96.88533020019531



action possibilites: [-1] 
expected returns: [[42.20113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  5.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 16.] 
adversary cards in discard: [6. 0. 6. 3. 0. 3. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.90895080566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[54.904472]
 [58.510036]
 [54.54846 ]
 [44.217144]
 [58.82443 ]
 [58.121838]
 [56.841496]
 [62.287785]
 [44.37638 ]
 [52.37645 ]
 [48.252174]
 [46.32001 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 30.  8.  5.  8.  7.  6.  8.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 16.] 
adversary cards in discard: [6. 0. 6. 3. 0. 3. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.20112991333008



buy possibilites: [-1] 
expected returns: [[110.48696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8. 29.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  3.  0.  3. 16.] 
adversary cards in discard: [6. 0. 6. 3. 0. 3. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.28780746459961






Player: 1 
cards in hand: [16.  3.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3. 16.] 
cards in discard: [6. 0. 6. 3. 0. 3. 8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 10. 11.  1. 10.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.] 
cards in discard: [6. 0. 6. 3. 0. 3. 8. 6. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 10. 11.  1. 10.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.] 
cards in discard: [6. 0. 6. 3. 0. 3. 8. 6. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 10. 11.  1. 10.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.] 
cards in discard: [6. 0. 6. 3. 0. 3. 8. 6. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 10. 11.  1. 10.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 10.] 
expected returns: [[33.63927 ]
 [42.92374 ]
 [26.000332]
 [40.374332]
 [26.000332]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  1. 10.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.4869613647461



action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[54.878216]
 [57.50578 ]
 [64.160995]
 [57.50578 ]
 [57.50578 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1. 10. 10.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.27675247192383



action possibilites: [-1] 
expected returns: [[79.52341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10. 10.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 69.6290054321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[79.2615  ]
 [83.11052 ]
 [79.450874]
 [62.11047 ]
 [87.456856]
 [82.19428 ]
 [78.4971  ]
 [83.429535]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 10.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  7.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.52340698242188



buy possibilites: [-1] 
expected returns: [[92.46716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10. 10.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  1.  0.  0. 11.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.45684814453125






Player: 1 
cards in hand: [29.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 11.] 
cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0. 11.] 
cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  5.  8.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0. 11.] 
cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10
 11] -> size -> 25 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[96.16555]
 [97.62338]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.4671630859375



action possibilites: [-1] 
expected returns: [[85.70364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 95.14215850830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[88.59935 ]
 [84.889755]
 [81.240875]
 [85.74087 ]
 [87.744   ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 85.70364379882812



buy possibilites: [-1] 
expected returns: [[135.72165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 25.  0.  0.  0. 10.  8. 29. 10. 11. 29. 11. 10.  1. 10. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 88.5993423461914






Player: 1 
cards in hand: [6. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  6.  3.  0.  3.  8.  6.  3.  0. 16.  3.  3. 16. 16. 29.  1.  0.
  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0. 11.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8. 25.] 
expected returns: [[62.781483]
 [71.69122 ]
 [67.63705 ]
 [59.502247]
 [81.67251 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  8. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  5.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.72164916992188



action possibilites: [-1] 
expected returns: [[11.377459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  8. 29.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 81.54714965820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -10.446045]
 [-123.57373 ]
 [  10.898088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  8. 29.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.377458572387695






Player: 1 
cards in hand: [3. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 1.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-14.177015  ]
 [-11.3649025 ]
 [ -0.60270214]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0.  0.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.898090362548828



action possibilites: [-1. 10.] 
expected returns: [[59.941555]
 [67.51703 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -0.6026797294616699



action possibilites: [-1.] 
expected returns: [[20.087347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 67.51704406738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[38.29681 ]
 [40.731724]
 [37.081623]
 [27.087654]
 [20.677069]
 [41.94129 ]
 [34.346264]
 [38.882496]
 [41.69155 ]
 [34.87317 ]
 [29.98219 ]
 [33.857178]
 [35.2324  ]
 [31.547058]
 [31.28983 ]
 [22.350502]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 27. 30.  8.  4.  7.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.08734703063965



buy possibilites: [-1] 
expected returns: [[43.801075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 3.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 67.0 

action type: buy - action 16.0
Learning step: 0
desired expected reward: 41.941287994384766






Player: 1 
cards in hand: [3. 6. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [6. 0. 3. 0. 0. 6. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16] -> size -> 26 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 3.] 
cards in discard: [6. 0. 3. 0. 0. 6. 1. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 10. 29.  0.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16] -> size -> 26 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 29.] 
expected returns: [[ 97.598  ]
 [ 90.12803]
 [101.76743]
 [ 90.12803]
 [106.01637]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 29.  0.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 16. 29.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.80107498168945



action possibilites: [-1. 10. 11. 10. 11.] 
expected returns: [[92.6835  ]
 [96.578865]
 [99.95931 ]
 [96.578865]
 [99.95931 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0. 11.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 16. 29.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.016357421875



action possibilites: [-1] 
expected returns: [[110.461464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 16. 29.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.6036376953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[103.11302 ]
 [105.93736 ]
 [ 92.507706]
 [110.67911 ]
 [111.095566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 11.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  1. 16. 16. 29.] 
adversary cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.46146392822266






Player: 1 
cards in hand: [ 0.  1. 16. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16. 16. 29.] 
cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3
  0 16  0  6  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 25. 10. 10.  8.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0. 10. 29. 11.
 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 29.] 
cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 25. 10. 10.  8.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0. 10. 29. 11.
 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16. 29.] 
cards in discard: [6. 0. 3. 0. 0. 6. 1. 0. 3. 6. 6. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 1. 25. 10. 10.  8.] 
adversary cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0. 10. 29. 11.
 10. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.  8.] 
expected returns: [[ 90.385254]
 [112.06141 ]
 [ 87.62593 ]
 [ 87.62593 ]
 [ 92.74287 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 10. 10.  8.] 
cards in discard: [25. 29.  0. 11.  8. 29.  8. 16. 29. 10.  0.  0.  0.  3.  0. 10. 29. 11.
 10. 10.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  4.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 16.  8. 11.  3.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 111.09556579589844



action possibilites: [-1] 
expected returns: [[-12.063153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 16.  8. 11.  3.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.0614013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-46.734035]
 [-24.42577 ]
 [-32.831688]
 [-66.05817 ]
 [-12.757362]
 [-24.51375 ]
 [-32.60521 ]
 [-21.598324]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  6.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 16.  8. 11.  3.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.063153266906738



buy possibilites: [-1] 
expected returns: [[-17.420628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  8.  0.  8.] 
cards in discard: [11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 16.  8. 11.  3.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -12.75735855102539






Player: 1 
cards in hand: [ 3. 16.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8. 11.  3.] 
cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0
 16  0  6  0  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 10. 29.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.] 
cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 10. 29.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.] 
cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 10. 29.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[10.167587]
 [22.320534]
 [18.272137]
 [11.87768 ]
 [22.320534]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10. 29.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.42062759399414



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[54.653645]
 [62.061634]
 [57.255558]
 [66.64527 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 29.  3.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.32052230834961



action possibilites: [-1. 11. 10.  8.] 
expected returns: [[31.845081]
 [40.360325]
 [29.15784 ]
 [34.51383 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  3.  8.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.64527893066406



action possibilites: [-1] 
expected returns: [[74.85652]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.42552185058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[63.67564 ]
 [74.97712 ]
 [69.11464 ]
 [55.462307]
 [83.46318 ]
 [74.70916 ]
 [68.84666 ]
 [76.20185 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  5.  6.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.85652160644531



buy possibilites: [-1] 
expected returns: [[102.7257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  8.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  4.  6.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 83.46318054199219






Player: 1 
cards in hand: [0. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  4.  6.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 16. 29.  0.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  4.  6.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 16. 29.  0.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 6.  0.  3.  0.  0.  6.  1.  0.  3.  6.  6.  0.  3.  0. 16.  1. 16. 29.
  6.  8.  3. 16.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  4.  5.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0. 16. 29.  0.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  0. 16. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 29.] 
expected returns: [[59.856945]
 [69.73761 ]
 [62.31106 ]
 [71.55897 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16. 29.  0.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  4.  5.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.72570037841797



action possibilites: [-1. 11. 16. 25.] 
expected returns: [[101.856125]
 [109.74398 ]
 [ 88.55438 ]
 [123.6924  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  0. 25.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  3.  6.  4.  5.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.5589599609375



action possibilites: [-1] 
expected returns: [[90.1719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  0. 10.  0.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.69239807128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 88.091034]
 [ 92.056915]
 [ 89.80504 ]
 [ 80.63498 ]
 [ 92.01251 ]
 [ 95.82062 ]
 [ 91.17922 ]
 [100.08516 ]
 [ 83.892586]
 [ 88.91443 ]
 [ 89.08804 ]
 [ 91.79965 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  0. 10.  0.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  5. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.1718978881836



buy possibilites: [-1] 
expected returns: [[103.28508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  0. 10.  0.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.08517456054688






Player: 1 
cards in hand: [6. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8. 29.
 29. 25. 11.  0. 16.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8. 29.
 29. 25. 11.  0. 16.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 6. 22.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0. 10. 10. 11. 29.] 
adversary cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8. 29.
 29. 25. 11.  0. 16.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[115.56563]
 [108.51793]
 [108.51793]
 [121.85716]
 [124.12956]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 29.] 
cards in discard: [11. 25.  1. 10. 10.  8.  0.  8. 10. 11. 29. 29. 11.  0. 10.  3.  8. 29.
 29. 25. 11.  0. 16.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.28507995605469



action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[63.598103]
 [44.193756]
 [44.193756]
 [67.566925]
 [73.58181 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 124.12956237792969



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[76.35202 ]
 [75.930885]
 [75.930885]
 [85.38816 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  3.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 73.58179473876953



action possibilites: [-1] 
expected returns: [[88.6967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.49479675292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 49.248856 ]
 [ 73.44454  ]
 [ 64.57012  ]
 [ 12.2012615]
 [ 66.156624 ]
 [ 95.46233  ]
 [ 76.09166  ]
 [100.702965 ]
 [ 49.101273 ]
 [ 67.23546  ]
 [ 78.13336  ]
 [ 90.40924  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  4. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.69670104980469



buy possibilites: [-1] 
expected returns: [[74.20589]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.7029800415039






Player: 1 
cards in hand: [ 0.  3.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [11. 10. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29] -> size -> 33 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [11. 10. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29] -> size -> 33 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [11. 10. 10. 11. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29] -> size -> 33 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 10. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 11. 10.] 
expected returns: [[71.42906 ]
 [80.99896 ]
 [78.153564]
 [78.153564]
 [80.99896 ]
 [78.153564]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 11. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  6.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22  0] -> size -> 34 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.20588684082031



action possibilites: [-1] 
expected returns: [[121.863754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22  0] -> size -> 34 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 139 

action type: gain_card_n - action 4
Learning step: 0
desired expected reward: 87.88629913330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.52734 ]
 [113.18233 ]
 [122.680756]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [0. 6. 0. 8. 6.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22  0] -> size -> 34 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.86375427246094






Player: 1 
cards in hand: [0. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 6.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 16  1  1  6  3  8  3 29  6 16  0  6  0  6  3  0 16
  0  6  0  0  0  6  8  6 22  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16] -> size -> 34 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0
  0  6  8  6 22  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16] -> size -> 34 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0
  0  6  8  6 22  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16] -> size -> 34 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[49.27148 ]
 [45.908802]
 [53.11507 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  2.  9. 10.] 
adversary cards in hand: [ 0.  6. 16.  1.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0
  0  6  8  6 22  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.6807861328125



action possibilites: [-1] 
expected returns: [[103.18042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  6. 16.  1.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0
  0  6  8  6 22  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.32168197631836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.91601 ]
 [ 96.76911 ]
 [ 91.73906 ]
 [100.156494]
 [104.46372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  6. 16.  1.  3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.] 
adversary owned cards: [ 0  0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0
  0  6  8  6 22  0] -> size -> 30 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.180419921875






Player: 1 
cards in hand: [ 0.  6. 16.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  1.  3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0
  0  6  8  6 22  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 29. 16.  1.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 29. 16.  1.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 29. 16.  1.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 16.] 
expected returns: [[62.288776]
 [57.389843]
 [68.31654 ]
 [59.0835  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 16.  1.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.46369934082031



action possibilites: [-1. 10. 16. 25.] 
expected returns: [[69.075775]
 [71.36336 ]
 [76.512794]
 [82.0194  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  1. 25.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  2.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.3165283203125



action possibilites: [-1] 
expected returns: [[59.502247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 16.  1. 10. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  1.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6] -> size -> 31 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 82.01937866210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.939907]
 [51.185154]
 [49.253365]
 [27.703205]
 [49.94917 ]
 [63.371464]
 [52.054066]
 [68.2742  ]
 [44.986416]
 [49.384468]
 [53.193966]
 [60.929485]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.  1. 10. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  1.  5.  4.  5.  8.  3. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6] -> size -> 31 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.50224685668945



buy possibilites: [-1] 
expected returns: [[56.99483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 16.  1. 10. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0.  0. 29.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6] -> size -> 31 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 68.27420043945312






Player: 1 
cards in hand: [ 6.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  0. 29.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  1.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  8. 25. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3. 29. 29. 25. 10.  0. 16.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  0. 16.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  1.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  8. 25. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3. 29. 29. 25. 10.  0. 16.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  0. 16.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 26. 30.  8.  1.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  8. 25. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3. 29. 29. 25. 10.  0. 16.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  0. 16.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 25. 30.  8.  1.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  8. 25. 11. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3. 29. 29. 25. 10.  0. 16.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 25. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25. 11. 29.] 
expected returns: [[64.90518 ]
 [65.60831 ]
 [65.60831 ]
 [83.186325]
 [70.59682 ]
 [74.18785 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25. 11. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10. 10.  0. 16. 11. 10. 10. 11. 10. 10. 11.  8.
  0.  0.  3. 29. 29. 25. 10.  0. 16.  1. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  1.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [0. 8. 0. 6. 3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.99483108520508



action possibilites: [-1] 
expected returns: [[78.12546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [0. 8. 0. 6. 3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6  3  6] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.18631744384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[37.364796]
 [78.82469 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [0. 8. 0. 6. 3.] 
adversary cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.  6.] 
adversary owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6  3  6] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.12545776367188






Player: 1 
cards in hand: [0. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 3.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16  1  1  3  8  3 29 16  0  6  0  6  3  0 16  0  6  0  0  0
  6  8  6 22  0  3  6  3  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0.  0. 11. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0.  0. 11. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0.  0. 11. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6. 22.  6.  1.  0.  0.  0.  0.  0.  3.  3. 16.  3.  8.  3. 16.  6.  1.
  3.  6.  3. 29.  6.  3.  0.  0. 16.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0.  0. 11. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[73.92801]
 [78.5215 ]
 [83.42386]
 [78.5215 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9. 10.] 
adversary cards in hand: [29.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.82465362548828



action possibilites: [-1] 
expected returns: [[86.26154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 89 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 88.21720886230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[76.66055]
 [78.31938]
 [83.27421]
 [87.92063]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.26154327392578






Player: 1 
cards in hand: [29.  0.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  3.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [10. 29. 10. 16. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  3.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [10. 29. 10. 16. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  3.  8.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [10. 29. 10. 16. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 29. 10. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 16. 10.] 
expected returns: [[103.560074]
 [ 93.374695]
 [114.82914 ]
 [ 93.374695]
 [ 91.837   ]
 [ 93.374695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10. 16. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.92063903808594



action possibilites: [-1. 10. 16. 10. 29.] 
expected returns: [[ 98.62908 ]
 [119.890945]
 [132.7094  ]
 [119.890945]
 [111.92453 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 10. 29.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11 29  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11
  0 16 10 11 10 11 29 10 29 16 10 29 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  2. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 96.63618469238281



action possibilites: [-1] 
expected returns: [[117.669464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.9794921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[139.46616]
 [118.67451]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.66946411132812



buy possibilites: [-1] 
expected returns: [[110.5495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0.  30.   0.   0.  40.   0.   0.   0.   0. -30.   0.   0.
   0.   0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 139.46620178222656






Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [29.  3. 29. 29. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  5.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [29.  3. 29. 29. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [29.  3. 29. 29. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29.  3. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 10.] 
expected returns: [[41.230858]
 [47.726913]
 [47.726913]
 [47.726913]
 [36.585293]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 29. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.54949951171875



action possibilites: [-1. 29. 10. 11.] 
expected returns: [[71.32773 ]
 [80.77554 ]
 [65.79187 ]
 [74.680756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10. 11.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.46181106567383



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[68.47172]
 [75.29198]
 [72.71511]
 [78.21961]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 69.9266357421875



action possibilites: [-1] 
expected returns: [[92.11431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.  0.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.21963500976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[65.46485 ]
 [83.83772 ]
 [77.060074]
 [98.552826]
 [85.781845]
 [79.01076 ]
 [92.084465]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29.  0.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  4.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.11431121826172



buy possibilites: [-1] 
expected returns: [[121.83844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29.  0.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 98.55282592773438






Player: 1 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  1. 16.  8. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11. 29. 29. 25. 10. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0 11] -> size -> 39 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  4.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  1. 16.  8. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11. 29. 29. 25. 10. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0 11] -> size -> 39 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  1. 16.  8. 10.] 
adversary cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11. 29. 29. 25. 10. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0 11] -> size -> 39 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 16.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
expected returns: [[129.53929 ]
 [129.64868 ]
 [129.36955 ]
 [127.514694]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 16.  8. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11. 29. 29. 25. 10. 11. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25  1 10 11  8 29 10 11  0
 16 10 11 10 11 29 10 29 16 10 29 15 29  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1. 10. 10.  1.  9.  9.] 
adversary cards in hand: [22.  6.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.83843994140625



action possibilites: [-1] 
expected returns: [[80.182755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11. 29. 29. 25. 10. 11. 29.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [22.  6.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 144.4584503173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[65.10629]
 [80.18272]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.] 
cards in discard: [25.  8.  8. 11. 29. 11.  0. 15. 11. 10.  0.  0. 10. 10. 29.  0. 29. 16.
 10. 10. 29.  3. 11. 29. 29. 25. 10. 11. 29.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [22.  6.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.18275451660156






Player: 1 
cards in hand: [22.  6.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.  3.  0.  3.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.  3.  0.  3.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[82.79554]
 [82.56835]
 [66.7612 ]
 [66.7612 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 6.  1.  6. 16.  8.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.18275451660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[47.578125]
 [65.94678 ]
 [71.238525]
 [83.90417 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 6.  1.  6. 16.  8.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.79554748535156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  1.  6. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  6. 16.  8.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  6  0  6  3  0 16  0  6  0  0  0  6  8  6
 22  0  3  6  3  6  0  0  8  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  8.  0. 16. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 8.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  8.  0. 16. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 8.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  8.  0. 16. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29.  8.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16. 29.] 
expected returns: [[69.31181 ]
 [75.69972 ]
 [56.48485 ]
 [51.118477]
 [75.69972 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 16. 29.] 
cards in discard: [ 0. 11.  0. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.9041748046875



action possibilites: [-1. 16. 29. 11.] 
expected returns: [[33.440273]
 [32.2323  ]
 [42.641567]
 [40.70154 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 29. 11.] 
cards in discard: [ 0. 11.  0. 10. 10.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.283409118652344



action possibilites: [-1. 16.] 
expected returns: [[13.904026 ]
 [ 8.8894615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.4110221862793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-9.943562 ]
 [17.10907  ]
 [12.204184 ]
 [11.003231 ]
 [23.10289  ]
 [17.336678 ]
 [25.594269 ]
 [-0.2117734]
 [13.17226  ]
 [15.023472 ]
 [14.348267 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  1.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.904037475585938



buy possibilites: [-1] 
expected returns: [[70.81328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 16. 16.  3.  6.] 
adversary cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8.] 
adversary owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 25.59429168701172






Player: 1 
cards in hand: [ 0. 16. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  3.  6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 16  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22
  0  3  6  3  6  0  0  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  3.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10. 25.  0. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10. 25.  0. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10. 25.  0. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 0. 29.  0.  6.  3.  8.  8.  0.  0.  0.  1.  3.  8.  6.  0.  0.  3.  6.
 22.  6.  3.  0.  3.  3. 16.  1.  6.  8. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10. 25.  0. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 10. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 29.] 
expected returns: [[140.53648]
 [129.21408]
 [129.21408]
 [158.80962]
 [147.26979]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25.  0. 29.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  6. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11  0] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.81327819824219



action possibilites: [-1] 
expected returns: [[124.11485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 29. 14.  8.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  6. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11  0] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 158.80960083007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.96854]
 [125.27965]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 29. 14.  8.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  6. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11  0] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.11485290527344






Player: 1 
cards in hand: [ 0.  6. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  8.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0
  3  6  3  6  0  0  8  8  3 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10. 25. 10.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3
  6  3  6  0  0  8  8  3 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10. 25. 10.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3
  6  3  6  0  0  8  8  3 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10. 25. 10.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10. 15. 10. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 25. 10.] 
expected returns: [[105.33019]
 [121.53215]
 [115.52465]
 [121.53215]
 [122.45099]
 [121.53215]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 25. 10.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8.  0.  6. 11.] 
adversary owned cards: [ 3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3
  6  3  6  0  0  8  8  3 11  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.27963256835938



action possibilites: [-1] 
expected returns: [[132.25087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 10. 29. 11.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8.  0.  6. 11.] 
adversary owned cards: [ 3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3
  6  3  6  0  0  8  8  3 11  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 122.45098876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[101.38358]
 [132.51045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10. 10. 29. 11.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8.  0.  6. 11.] 
adversary owned cards: [ 3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3
  6  3  6  0  0  8  8  3 11  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 132.25086975097656






Player: 1 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [ 8.  0.  6. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  3  8  3 29 16  0  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3
  6  3  6  0  0  8  8  3 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 29. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 8.  0.  6. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 29. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 8.  0.  6. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 11.  8. 29. 29.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 29.] 
expected returns: [[174.87987]
 [179.05986]
 [166.56664]
 [186.13748]
 [186.13748]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 29. 29.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 132.5104522705078



action possibilites: [-1. 29.] 
expected returns: [[157.13628]
 [169.95833]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 184.9047088623047



action possibilites: [-1.] 
expected returns: [[99.90946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 138.9088134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[52.864716]
 [74.91394 ]
 [84.93561 ]
 [99.90946 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.90946197509766






Player: 1 
cards in hand: [6. 6. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 29. 11. 16.  0.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 29. 11. 16.  0.] 
adversary cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 29. 11. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 16.] 
expected returns: [[36.2412  ]
 [12.320599]
 [44.0281  ]
 [36.892242]
 [11.184711]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 16.  0.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11. 29. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.90946197509766



action possibilites: [-1. 11. 16. 10.] 
expected returns: [[ -8.550484]
 [-12.319405]
 [-14.101771]
 [-18.317896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 10.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11. 29. 29.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 42.993465423583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.404616]
 [ -8.550484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16. 10.] 
cards in discard: [ 0. 11.  0. 10. 10.  8. 11. 29. 29. 29.  0. 16.  0. 25. 10. 10.  0. 29.
 14.  8. 25. 10. 15. 10. 10. 29. 11. 11.  8.  0. 11. 29. 29.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.55043888092041






Player: 1 
cards in hand: [29.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  8.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 24. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[76.04332]
 [83.6478 ]
 [63.12692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  6.  0.  8. 22.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -8.55043888092041



action possibilites: [-1. 10. 10.] 
expected returns: [[62.849743]
 [46.69553 ]
 [46.69553 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  6.  0.  8. 22.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 66.64096069335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.867825]
 [62.663166]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [0. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  6.  0.  8. 22.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.849735260009766






Player: 1 
cards in hand: [ 3.  6.  0.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  8. 22.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0. 10.  0. 16.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  8. 22.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0. 10.  0. 16.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  8. 22.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0. 10.  0. 16.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [29.  0. 10.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 16.] 
expected returns: [[34.847626]
 [44.21533 ]
 [36.56668 ]
 [36.7344  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0. 16.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 16. 16.  6.  0.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.663143157958984



action possibilites: [-1. 10. 29.] 
expected returns: [[87.493965]
 [82.08801 ]
 [94.87673 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 16. 16.  6.  0.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.9989128112793



action possibilites: [-1. 10.] 
expected returns: [[75.22319]
 [67.85388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 16. 16.  6.  0.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.72564697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[67.889984]
 [68.946396]
 [73.64169 ]
 [76.90743 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 16. 16.  6.  0.] 
adversary cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.] 
adversary owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3  0] -> size -> 34 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.22319030761719






Player: 1 
cards in hand: [ 3. 16. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16.  6.  0.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  3  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3
  6  0  0  8  8  3 11  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [25. 25.  8. 29.  0.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [25. 25.  8. 29.  0.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.] 
cards in discard: [ 8.  0.  6. 11.  8.  0.  3.  6.  6.  1.  3.  6.  8.  3.  3. 29.  0.  0.
  0.  0.  3.  6.  0.  8. 22.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [25. 25.  8. 29.  0.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [25. 25.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.  8. 29.] 
expected returns: [[151.26794]
 [165.2415 ]
 [165.2415 ]
 [151.72021]
 [159.74258]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  8. 29.  0.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.90740966796875



action possibilites: [-1] 
expected returns: [[106.34621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 29.  0. 10. 11.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 165.24143981933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 89.06322]
 [107.0482 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8. 29.  0. 10. 11.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 106.34620666503906






Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 16. 11. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 26. 30. 23. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 16. 11. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 26. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 16. 11. 10. 11.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 16. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 11. 10. 11.] 
expected returns: [[61.943844]
 [70.7555  ]
 [78.0284  ]
 [70.7555  ]
 [72.55398 ]
 [70.7555  ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 11. 10. 11.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16
 10 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  6.  0. 29.  1.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0.] 
adversary owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 107.04814147949219



action possibilites: [-1] 
expected returns: [[146.6262]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  6.  0. 29.  1.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0.] 
adversary owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 85.88875579833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[112.06891]
 [149.23042]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  6.  0. 29.  1.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0.] 
adversary owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1  3] -> size -> 35 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.62620544433594






Player: 1 
cards in hand: [ 8.  6.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 29.  1.] 
cards in discard: [3. 0. 1. 0. 3. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 29 16  6  3  0 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6
  0  0  8  8  3 11  0  3  0  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [14. 15. 29. 10. 29.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [3. 0. 1. 0. 3. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [14. 15. 29. 10. 29.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [3. 0. 1. 0. 3. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 22. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [14. 15. 29. 10. 29.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [3. 0. 1. 0. 3. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [14. 15. 29. 10. 29.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [14. 15. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 29. 10. 29.] 
expected returns: [[55.03697 ]
 [22.43117 ]
 [44.101955]
 [60.14941 ]
 [34.43461 ]
 [60.14941 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15. 29. 10. 29.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.23040771484375



action possibilites: [-1. 14. 15. 10.] 
expected returns: [[60.438557]
 [13.874695]
 [38.49059 ]
 [26.342407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15. 10.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.934207916259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 1.6662831]
 [60.570736 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15. 10.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [8. 3. 0. 6. 3.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.43855667114258






Player: 1 
cards in hand: [8. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29. 29. 14. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29. 29. 14. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 3.] 
cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 10.  0. 29. 11.] 
adversary cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29. 29. 14. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[61.45506 ]
 [57.393826]
 [49.16583 ]
 [62.343853]
 [57.393826]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 11.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29. 29. 14. 15. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  6.  8. 22.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1. 0. 8. 3. 0. 6. 3.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.570735931396484



action possibilites: [-1. 11. 10.] 
expected returns: [[75.590385]
 [75.23682 ]
 [54.147633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29. 29. 14. 15. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  6.  8. 22.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1. 0. 8. 3. 0. 6. 3.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 53.89854049682617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[31.762554]
 [52.130836]
 [60.018   ]
 [75.590385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 0.  0. 29.  3. 10. 10.  0. 16. 10.  0. 29. 29. 10. 25. 25.  8. 29.  0.
 10. 11.  1. 16. 11. 10. 11. 29. 29. 29. 14. 15. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  6.  8. 22.] 
adversary cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1. 0. 8. 3. 0. 6. 3.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.59037780761719






Player: 1 
cards in hand: [ 0.  3.  6.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  8. 22.] 
cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1. 0. 8. 3. 0. 6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  8. 22.] 
cards in discard: [3. 0. 1. 0. 3. 0. 3. 8. 1. 0. 8. 3. 0. 6. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.  8.] 
expected returns: [[75.10574 ]
 [53.403454]
 [53.403454]
 [59.44472 ]
 [59.44472 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [16. 11.  3.  0.  6.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.59037780761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.4213]
 [76.3394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [16. 11.  3.  0.  6.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.] 
adversary owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 75.10575866699219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 11.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  3.  0.  6.] 
cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8  3 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8
  8  3 11  0  3  0  1  3  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  3.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29. 11. 10. 15. 11.] 
adversary cards in discard: [10. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.] 
cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29. 11. 10. 15. 11.] 
adversary cards in discard: [10. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.] 
cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29. 11. 10. 15. 11.] 
adversary cards in discard: [10. 10.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29. 11. 10. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 15. 11.] 
expected returns: [[48.70485 ]
 [57.052006]
 [50.593113]
 [37.62672 ]
 [39.34652 ]
 [50.593113]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 15. 11.] 
cards in discard: [10. 10.  0.  8.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.33939361572266



action possibilites: [-1. 10. 15. 16.] 
expected returns: [[16.733395]
 [13.784098]
 [13.20833 ]
 [17.804548]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 16.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 10 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10
 11 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: 42.80421829223633



action possibilites: [-1] 
expected returns: [[13.212105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0 -50   0   0 125   0] 
sum of rewards: 80 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 82.32288360595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.397663]
 [13.237404]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.212104797363281



buy possibilites: [-1] 
expected returns: [[40.731754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  40.   0.   0.   0.   0. -60.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 22.39765167236328






Player: 1 
cards in hand: [0. 6. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14. 10. 29.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 25. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14. 10. 29.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [ 3.  0.  1.  0.  3.  0.  3.  8.  1.  0.  8.  3.  0.  6.  3.  0.  3.  6.
  8. 22.  8. 16. 11.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 14. 10. 29.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 29.] 
expected returns: [[91.57772 ]
 [81.17857 ]
 [86.438614]
 [94.38703 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 10. 29.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.731754302978516



action possibilites: [-1. 14. 10. 29.] 
expected returns: [[52.56365 ]
 [53.682896]
 [57.67146 ]
 [62.325726]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 29.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.7319564819336



action possibilites: [-1. 11.] 
expected returns: [[46.161   ]
 [49.853558]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.22285842895508



action possibilites: [-1] 
expected returns: [[48.75553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 42.465843200683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[32.28555 ]
 [36.595184]
 [41.21187 ]
 [48.426327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.755531311035156






Player: 1 
cards in hand: [ 0.  8.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  6. 16.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8 16  3 16  0  6  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8
  3 11  0  3  0  1  3  3  0  8  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [29. 29. 25. 29. 10.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0
  3  0  1  3  3  0  8  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [29. 29. 25. 29. 10.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  8 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0
  3  0  1  3  3  0  8  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [29. 29. 25. 29. 10.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [29. 29. 25. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 29. 10.] 
expected returns: [[102.74254 ]
 [102.22732 ]
 [102.22732 ]
 [109.704956]
 [102.22732 ]
 [ 86.71188 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 29. 10.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 8. 16.  0.  0.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 1  1  8 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0
  3  0  1  3  3  0  8  1] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.426334381103516



action possibilites: [-1] 
expected returns: [[118.79489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 10. 10. 25.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 8. 16.  0.  0.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 1  1  8 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0
  3  0  1  3  3  0  8  1] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 109.7049560546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 69.22848]
 [119.90567]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 10. 10. 25.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 8. 16.  0.  0.  1.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 1  1  8 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0
  3  0  1  3  3  0  8  1] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.79489135742188






Player: 1 
cards in hand: [ 8. 16.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0.  1.] 
cards in discard: [8. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  8 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0
  3  0  1  3  3  0  8  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  2.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 29.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11. 25. 29. 29. 29. 10. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [8. 0. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  1 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0  3
  0  1  3  3  0  8  1  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  1.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 29.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11. 25. 29. 29. 29. 10. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [8. 0. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1  1 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0  3
  0  1  3  3  0  8  1  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  1.  8.  0.  9.  9.  1.  9.  8.] 
adversary cards in hand: [ 0.  8. 11.  0. 29.] 
adversary cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11. 25. 29. 29. 29. 10. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
adversary victory points: 1
player victory points: 2 


Player 1 won the game! 



Player 0 bought cards:
Copper: 3 
Silver: 1 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 1 
Workshop: 6 
Chapel: 3 
Witch: 2 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  8. 11.  0. 29.] 
cards in discard: [10. 10.  0.  8.  8. 11. 11. 23.  0. 29. 16. 15.  0.  0. 14. 10. 15. 29.
 29. 11. 25. 29. 29. 29. 10. 10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 25 29 10 29  8 10 25 10 11  8 29 10 11  0 16 10 11
 10 11 29 10 29 16 10 29 15 29  0 11 14 29  1 23  0 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  0.  5.  2.  1.  8.  0.  9.  9.  0.  9.  8.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 8.  0.  8. 10.] 
adversary owned cards: [ 1  1 16  0  0  0  0  6  8  6 22  0  3  6  3  6  0  0  8  8  3 11  0  3
  0  1  3  3  0  8  1  8 10] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000035 

action type: buy - action -1.0
Learning step: -120006.1953125
desired expected reward: -119886.2890625



