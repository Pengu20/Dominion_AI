 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.32776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -9.307679176330566
desired expected reward: 171.8459014892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[330.22318]
 [330.38562]
 [330.26883]
 [330.2481 ]
 [331.9294 ]
 [333.58188]
 [332.04367]
 [338.5919 ]
 [333.59494]
 [331.9641 ]
 [335.2127 ]
 [345.82236]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.02009105682373
desired expected reward: 338.9324951171875



buy possibilites: [-1] 
expected returns: [[308.93362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -9.603087425231934
desired expected reward: 323.9787902832031






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[334.20035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.9766526222229
desired expected reward: 300.95697021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[322.15372]
 [322.31635]
 [322.19937]
 [322.17865]
 [325.49014]
 [323.9605 ]
 [323.88068]
 [337.6559 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.589113235473633
desired expected reward: 326.8566589355469



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.10028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.791857719421387
desired expected reward: 327.864013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[303.83514]
 [303.99777]
 [303.88077]
 [303.86008]
 [307.1716 ]
 [305.64194]
 [305.56207]
 [319.3373 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.158854484558105
desired expected reward: 310.4383850097656



buy possibilites: [-1] 
expected returns: [[292.79587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -7.890195369720459
desired expected reward: 297.6718444824219






Player: 1 
cards in hand: [ 3.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[343.44504]
 [331.02695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.098300933837891
desired expected reward: 285.69757080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[332.64484]
 [332.8107 ]
 [332.69135]
 [332.67035]
 [336.05048]
 [334.48944]
 [334.40784]
 [348.46854]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.797554016113281
desired expected reward: 335.5732116699219



buy possibilites: [-1] 
expected returns: [[347.355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [10.  3.  3.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 8.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -24.468029022216797
desired expected reward: 308.2023010253906






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8.  3.  0. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[314.4913 ]
 [300.71603]
 [302.32553]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -11.554079055786133
desired expected reward: 335.8009338378906



action possibilites: [-1] 
expected returns: [[325.96338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 1 

action type: gain_card_n - action 6
Learning step: -7.70742130279541
desired expected reward: 294.12451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[307.85303]
 [307.89865]
 [307.878  ]
 [309.65985]
 [323.3552 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -9.423213958740234
desired expected reward: 316.5401611328125



buy possibilites: [-1] 
expected returns: [[299.10645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [8. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: -8.50309944152832
desired expected reward: 301.1567687988281






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.78552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  8. 11. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.080405235290527
desired expected reward: 290.0260314941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[299.26596]
 [299.43106]
 [299.3152 ]
 [299.29233]
 [302.62482]
 [301.08615]
 [301.0087 ]
 [314.82965]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  8. 11. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.997262954711914
desired expected reward: 303.3203430175781



buy possibilites: [-1] 
expected returns: [[324.02777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  8. 11. 10.  0.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 11.] 
adversary cards in discard: [10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10] -> size -> 13 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -24.373991012573242
desired expected reward: 274.9183044433594






Player: 1 
cards in hand: [ 3.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [10.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 11.] 
cards in discard: [10.  3.  0.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[297.82483]
 [284.03256]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -11.317710876464844
desired expected reward: 312.7100524902344



action possibilites: [-1.] 
expected returns: [[309.27017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -7.951455116271973
desired expected reward: 277.24920654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[294.42792]
 [294.61304]
 [294.48276]
 [294.45758]
 [298.20502]
 [296.47424]
 [296.38763]
 [311.93762]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -9.443116188049316
desired expected reward: 299.8270568847656



buy possibilites: [-1] 
expected returns: [[314.38284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 1.0
Learning step: -7.45703649520874
desired expected reward: 287.1559753417969






Player: 1 
cards in hand: [11.  8.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1] -> size -> 17 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[339.70264]
 [325.7022 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 1. 10.  3.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -9.950592994689941
desired expected reward: 304.4322509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[327.90182]
 [328.07   ]
 [327.95197]
 [327.92862]
 [331.3235 ]
 [329.75592]
 [329.67706]
 [343.75632]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 1. 10.  3.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -11.156332969665527
desired expected reward: 327.2606201171875



buy possibilites: [-1] 
expected returns: [[335.60016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 11.  8.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 1.0
Learning step: -9.652499198913574
desired expected reward: 318.41754150390625






Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [ 0. 11.  8.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1] -> size -> 18 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0. 11.  8.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0. 11.  8.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [ 0. 11.  8.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  8.  6.  0.] 
adversary cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1] -> size -> 18 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  3.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[268.9439 ]
 [256.76465]
 [255.2288 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  6.  0.] 
cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -12.6217679977417
desired expected reward: 322.9783935546875



action possibilites: [-1] 
expected returns: [[346.00476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0.] 
cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: gain_card_n - action 0
Learning step: -7.051242351531982
desired expected reward: 245.6757354736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[328.2276 ]
 [328.25912]
 [347.11804]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0.] 
cards in discard: [ 1. 10.  3.  6.  0.  0.  0.  1.  0.  8.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -10.45221996307373
desired expected reward: 335.55255126953125






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[295.30548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 10.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -12.396103858947754
desired expected reward: 334.7218933105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[286.61456]
 [286.7664 ]
 [286.65994]
 [286.63876]
 [288.1835 ]
 [289.70447]
 [288.28918]
 [294.2984 ]
 [289.7158 ]
 [288.21817]
 [291.20212]
 [300.9306 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 10.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.961145401000977
desired expected reward: 286.02984619140625



buy possibilites: [-1] 
expected returns: [[281.96268]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 6.] 
cards in discard: [14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 10.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -2 

action type: buy - action 14.0
Learning step: -8.01574993133545
desired expected reward: 281.7000427246094






Player: 1 
cards in hand: [ 0. 11.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 10.] 
cards in discard: [8. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [14.  0.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14] -> size -> 20 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [ 8.  0.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [14.  0.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14] -> size -> 20 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [ 8.  0.  3. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 1. 0. 0.] 
adversary cards in discard: [14.  0.  3.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14] -> size -> 20 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 6. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.21967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [14.  0.  3.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3. 14. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -9.240527153015137
desired expected reward: 272.7221374511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[282.17545]
 [282.33438]
 [282.22266]
 [282.34314]
 [282.19345]
 [283.84506]
 [285.46597]
 [283.96072]
 [288.76257]
 [290.35342]
 [285.47455]
 [286.94116]
 [283.88367]
 [285.3589 ]
 [287.05682]
 [297.4082 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [14.  0.  3.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3. 14. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.82653522491455
desired expected reward: 281.6226806640625



buy possibilites: [-1] 
expected returns: [[304.76797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 0. 0.] 
cards in discard: [14.  0.  3.  0.  1.  6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3. 14. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0 14] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -26.0 

action type: buy - action 15.0
Learning step: -8.795564651489258
desired expected reward: 278.26129150390625






Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [ 8.  0.  3. 14. 11.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 11  3 10  8  0  0 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [14.  0.  3.  0.  1.  6. 15.  0.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15] -> size -> 21 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  3. 14. 11.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [14.  0.  3.  0.  1.  6. 15.  0.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  3. 14. 11.  0.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [14.  0.  3.  0.  1.  6. 15.  0.  6.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15] -> size -> 21 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[251.38164]
 [239.6735 ]
 [238.19759]
 [238.19759]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  8.] 
cards in discard: [14.  0.  3.  0.  1.  6. 15.  0.  6.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -11.011995315551758
desired expected reward: 293.7559814453125



action possibilites: [-1] 
expected returns: [[243.30542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [14.  0.  3.  0.  1.  6. 15.  0.  6.  1.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 5 

action type: gain_card_n - action 9
Learning step: -6.191310882568359
desired expected reward: 232.12232971191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[230.6556 ]
 [230.69731]
 [230.6715 ]
 [232.23662]
 [244.14117]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [14.  0.  3.  0.  1.  6. 15.  0.  6.  1.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.090017795562744
desired expected reward: 236.2154083251953






Player: 1 
cards in hand: [ 3.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  6. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 22 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 11.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 22 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [15. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[290.57706]
 [281.5156 ]
 [278.78824]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  8.] 
adversary cards in discard: [ 8.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -7.0703654289245605
desired expected reward: 237.07083129882812



action possibilites: [-1] 
expected returns: [[242.84679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  8.] 
adversary cards in discard: [ 8.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 15.0
Learning step: -8.689017295837402
desired expected reward: 270.3723449707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[230.03293]
 [230.18019]
 [230.07666]
 [230.04956]
 [233.08453]
 [231.6891 ]
 [231.6175 ]
 [244.64528]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  8.] 
adversary cards in discard: [ 8.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.087254524230957
desired expected reward: 235.75953674316406



buy possibilites: [-1] 
expected returns: [[285.23322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3. 10.  8.] 
adversary cards in discard: [ 8.  3.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 1.0
Learning step: -4.391263008117676
desired expected reward: 225.7889404296875






Player: 1 
cards in hand: [14.  3.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3. 10.  8.] 
cards in discard: [ 8.  3.  0.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3. 10.  8.] 
cards in discard: [ 8.  3.  0.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[236.38713]
 [225.23708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [ 1. 15. 10.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -10.301077842712402
desired expected reward: 274.93212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[226.65735]
 [226.6953 ]
 [226.67188]
 [228.11316]
 [239.50061]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [ 1. 15. 10.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.742881774902344
desired expected reward: 226.73480224609375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  6.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  6.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  6.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[230.62685]
 [219.99635]
 [221.18639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  6.] 
cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.1319580078125
desired expected reward: 231.36863708496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[220.37244]
 [220.40936]
 [220.38655]
 [221.78328]
 [232.41379]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  6.] 
cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.681828498840332
desired expected reward: 222.64913940429688



buy possibilites: [-1] 
expected returns: [[208.62158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  6.] 
cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  8.  3.  0.  3.] 
adversary cards in discard: [ 1. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 8.0
Learning step: -6.97207498550415
desired expected reward: 214.8112030029297






Player: 1 
cards in hand: [14.  8.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  3.] 
cards in discard: [ 1. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.  8.  0.  0.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  0.  3.] 
cards in discard: [ 1. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  0.  1.] 
adversary cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.  8.  0.  0.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[236.26843]
 [222.63844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.  8.  0.  0.  8. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -6.471583843231201
desired expected reward: 202.14999389648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[213.99454]
 [214.14925]
 [214.03807]
 [214.15709]
 [214.0043 ]
 [215.67667]
 [217.30275]
 [215.7911 ]
 [220.6301 ]
 [222.22993]
 [217.31123]
 [218.7882 ]
 [215.7114 ]
 [217.19685]
 [218.9026 ]
 [229.34142]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.  8.  0.  0.  8. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.068554878234863
desired expected reward: 227.5522918701172



buy possibilites: [-1] 
expected returns: [[211.61664]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [ 1. 15. 10.  3.  3.  0.  3.  6.  8.  0.  8.  0.  0.  8. 11.  6. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  8. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -16.0 

action type: buy - action 29.0
Learning step: -7.150122165679932
desired expected reward: 215.07981872558594






Player: 1 
cards in hand: [ 3.  8.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 10.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[233.57283]
 [221.65872]
 [223.05743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  1. 14.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [ 0. 10.  3.  8.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1  0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -6.705284118652344
desired expected reward: 204.91134643554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[225.10643]
 [225.2426 ]
 [225.14517]
 [225.24849]
 [225.11497]
 [226.57526]
 [228.00038]
 [226.67812]
 [230.90755]
 [232.30623]
 [228.00691]
 [229.29625]
 [226.60818]
 [227.9041 ]
 [229.3991 ]
 [238.52231]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  1. 14.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [ 0. 10.  3.  8.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1  0] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.67488431930542
desired expected reward: 224.8274383544922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 0. 10.  3.  8.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 11  3 10  8  0  0 14  8  1  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 15.  1.  0.  6.] 
adversary cards in discard: [ 1.  0. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10.  3.  8.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 15.  1.  0.  6.] 
adversary cards in discard: [ 1.  0. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10.  3.  8.  8.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 15.  1.  0.  6.] 
adversary cards in discard: [ 1.  0. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10.  3.  8.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 15.  1.  0.  6.] 
adversary cards in discard: [ 1.  0. 10.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 15.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[203.896  ]
 [197.67642]
 [194.80804]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  1.  0.  6.] 
cards in discard: [ 1.  0. 10.  1. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.691299438476562
desired expected reward: 229.83102416992188



action possibilites: [-1. 15.] 
expected returns: [[263.03287]
 [253.69208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  6.  0.] 
cards in discard: [ 1.  0. 10.  1. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 29.0
Learning step: -4.110708236694336
desired expected reward: 191.5223388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[253.48906]
 [253.62819]
 [253.52849]
 [253.63464]
 [253.4978 ]
 [254.99344]
 [256.45142]
 [255.0982 ]
 [259.4284 ]
 [260.86847]
 [256.4586 ]
 [257.77884]
 [255.0264 ]
 [256.3538 ]
 [257.8836 ]
 [267.36447]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  0.  6.  0.] 
cards in discard: [ 1.  0. 10.  1. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -7.560344219207764
desired expected reward: 255.47251892089844






Player: 1 
cards in hand: [ 0.  0. 14.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[200.87207]
 [190.6396 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 8.] 
adversary cards in discard: [ 0.  0.  0. 14.  3. 11.] 
adversary owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -10.190126419067383
desired expected reward: 257.1743469238281



action possibilites: [-1] 
expected returns: [[209.8212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 8.] 
adversary cards in discard: [ 0.  0.  0. 14.  3. 11.] 
adversary owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 4
Learning step: -5.3589253425598145
desired expected reward: 181.23910522460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[202.39636]
 [202.40231]
 [211.79544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 8.] 
adversary cards in discard: [ 0.  0.  0. 14.  3. 11.] 
adversary owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -6.60615873336792
desired expected reward: 203.2150421142578






Player: 1 
cards in hand: [0. 8. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 8.] 
cards in discard: [ 0.  0.  0. 14.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8 11  3 10  8  0  0 14  8  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0. 14.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  0. 14.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 0.] 
adversary cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[205.93294]
 [195.42819]
 [195.42819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -7.374143123626709
desired expected reward: 204.42129516601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[195.28548]
 [195.32004]
 [195.29306]
 [196.68002]
 [207.35355]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 29. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -7.029824733734131
desired expected reward: 197.9729461669922



buy possibilites: [-1] 
expected returns: [[174.24075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 8. 0.] 
cards in discard: [ 1.  0. 10.  1. 14. 29. 15.  1.  0.  6.  0.  8.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 3.0
Learning step: -6.145585060119629
desired expected reward: 189.17445373535156






Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  3. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  6.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3] -> size -> 23 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8.  6.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[222.43355]
 [212.18048]
 [212.1215 ]
 [213.32541]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  3. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 11.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -4.573108196258545
desired expected reward: 169.6676483154297



action possibilites: [-1] 
expected returns: [[208.53554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 10.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 11.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 22 

action type: gain_card_n - action 8
Learning step: -4.621960639953613
desired expected reward: 203.65823364257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[198.4569 ]
 [198.46138]
 [209.95941]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3. 10.] 
cards in discard: [14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  8. 10.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 11.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -5.5624098777771
desired expected reward: 202.97312927246094



buy possibilites: [-1] 
expected returns: [[195.08195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3. 10.] 
cards in discard: [14.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14. 11.  8.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -20.783727645874023
desired expected reward: 177.6776885986328






Player: 1 
cards in hand: [ 0.  0. 14. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 11.  8.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 8. 8. 3.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  7. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[183.6237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -20    0    0    0  -30    0    0    0    0    0 -900
   92    0] 
sum of rewards: -863 

action type: discard_down_to_3_cards - action 0
Learning step: -49.4751091003418
desired expected reward: 159.23660278320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[170.2621 ]
 [170.26753]
 [183.98228]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -6.435310363769531
desired expected reward: 176.252685546875



buy possibilites: [-1] 
expected returns: [[211.74913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -6.498749732971191
desired expected reward: 163.7633514404297






Player: 1 
cards in hand: [ 8. 14.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  1.  0. 29.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  1.  0. 29.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[129.44022 ]
 [120.33843 ]
 [124.687035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0. 29.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  3. 11.] 
adversary cards in discard: [ 8. 14.  0. 10.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -9.03350830078125
desired expected reward: 202.7156219482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[119.309044]
 [119.41194 ]
 [119.33841 ]
 [119.31307 ]
 [120.42923 ]
 [121.52439 ]
 [120.512764]
 [124.80937 ]
 [121.527084]
 [120.460754]
 [122.590706]
 [129.5973  ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0. 29.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 28. 30.  8.  7. 10.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  3. 11.] 
adversary cards in discard: [ 8. 14.  0. 10.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.946114540100098
desired expected reward: 123.94983673095703



buy possibilites: [-1] 
expected returns: [[115.93701]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  0. 29.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 14.  0.  3. 11.] 
adversary cards in discard: [ 8. 14.  0. 10.  3.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 7 

action type: buy - action 16.0
Learning step: -3.0628786087036133
desired expected reward: 117.36634063720703






Player: 1 
cards in hand: [ 8. 14.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  3. 11.] 
cards in discard: [ 8. 14.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  9.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  6. 14. 15.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  3.] 
cards in discard: [ 8. 14.  0. 10.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  6. 14. 15.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  3.] 
cards in discard: [ 8. 14.  0. 10.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  6. 14. 15.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  3.] 
cards in discard: [ 8. 14.  0. 10.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  6. 14. 15.] 
adversary cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  6. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[109.37911 ]
 [103.322655]
 [104.123665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 14. 15.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -4.664372444152832
desired expected reward: 111.27263641357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.541595]
 [ 99.61281 ]
 [ 99.56177 ]
 [ 99.54438 ]
 [101.18603 ]
 [100.423874]
 [100.38502 ]
 [107.244934]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 14. 15.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.437343120574951
desired expected reward: 104.9417724609375



buy possibilites: [-1] 
expected returns: [[145.76625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 14. 15.] 
cards in discard: [14.  6. 11.  8.  6.  3. 10.  8.  8.  0.  0.  3.  3. 16. 10.  0.  1.  0.
 29. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  6. 10.  9.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0] -> size -> 15 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -7 

action type: buy - action 10.0
Learning step: -2.089510440826416
desired expected reward: 98.2955093383789






Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16 10] -> size -> 28 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16 10] -> size -> 28 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16 10] -> size -> 28 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[189.60863]
 [181.46605]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14
  6  0 16 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  7.  9.  8.  3. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  3.] 
adversary cards in discard: [10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -4.406956195831299
desired expected reward: 141.3592987060547



action possibilites: [-1] 
expected returns: [[170.80022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  6.  9.  8.  3. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  3.] 
adversary cards in discard: [10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -316 

action type: gain_card_n - action 2
Learning step: -19.891502380371094
desired expected reward: 138.79864501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[163.7284 ]
 [163.8177 ]
 [163.75482]
 [163.7311 ]
 [165.65565]
 [164.77528]
 [164.73195]
 [172.62996]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 28. 30.  8.  6.  9.  8.  3. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  3.] 
adversary cards in discard: [10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -5.607431411743164
desired expected reward: 165.19277954101562



buy possibilites: [-1] 
expected returns: [[219.73596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [6. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 28. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14. 10.  0.  3.] 
adversary cards in discard: [10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -14.0 

action type: buy - action 8.0
Learning step: -3.994704484939575
desired expected reward: 160.7805633544922






Player: 1 
cards in hand: [ 0. 14. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  0.  3.] 
cards in discard: [10.  8.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29. 11.  0.  3.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3. 11.] 
cards in discard: [10.  8.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 28. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29. 11.  0.  3.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [10.  8.  8.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29. 11.  0.  3.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [10.  8.  8.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 28. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29. 11.  0.  3.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [10.  8.  8.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [15. 29. 11.  0.  3.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [15. 29. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
expected returns: [[174.32513]
 [167.28862]
 [169.49033]
 [166.22882]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 11.  0.  3.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6
  0 16 10  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -9.478405952453613
desired expected reward: 210.25755310058594



action possibilites: [-1] 
expected returns: [[165.71782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 26. 30. 27. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 15.0
Learning step: -5.914952278137207
desired expected reward: 160.9571075439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[156.44797]
 [156.56415]
 [156.4823 ]
 [156.4515 ]
 [158.92944]
 [157.79541]
 [157.73819]
 [167.98515]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 27. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -6.002798080444336
desired expected reward: 159.71502685546875



buy possibilites: [-1] 
expected returns: [[159.08409]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -13.0 

action type: buy - action 3.0
Learning step: -4.8947224617004395
desired expected reward: 151.58755493164062






Player: 1 
cards in hand: [ 3.  3.  0. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  8. 14.  6.  8.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 29.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 14.  6.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[82.92947 ]
 [76.439606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 14.  0.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[   -5     0     0   -30     0     0     0     0     0     0     0     0
     0 -1200    80     0] 
sum of rewards: -1155 

action type: discard_down_to_3_cards - action 0
Learning step: -62.204559326171875
desired expected reward: 62.85289001464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.077324]
 [75.07989 ]
 [83.357346]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  6.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 14.  0.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.135910511016846
desired expected reward: 78.7935562133789



buy possibilites: [-1] 
expected returns: [[106.98558]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 14.  0.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -346 

action type: buy - action 6.0
Learning step: -18.646820068359375
desired expected reward: 56.43305969238281






Player: 1 
cards in hand: [ 0. 11.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 14.  0.] 
cards in discard: [ 1. 14.  3.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0. 10.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 1. 14.  3.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 1. 14.  3.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2. 10.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [ 1. 14.  3.  3.  0. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[109.32367]
 [102.69951]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -40     0     0     0     0     0     0     0     0
     0 -1500    71     0] 
sum of rewards: -1475 

action type: discard_down_to_3_cards - action 2
Learning step: -76.2147216796875
desired expected reward: 20.895401000976562



action possibilites: [-1.] 
expected returns: [[104.557205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -24 

action type: take_action - action 10.0
Learning step: -3.982438802719116
desired expected reward: 98.71707153320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 99.386696]
 [ 99.473045]
 [ 99.41232 ]
 [ 99.38934 ]
 [101.21831 ]
 [100.38206 ]
 [100.3391  ]
 [108.23137 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 26. 30.  8.  5.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -4.243738651275635
desired expected reward: 100.31346893310547



buy possibilites: [-1] 
expected returns: [[100.296165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 25. 30. 26. 30.  8.  4.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  8.] 
adversary cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -337.0 

action type: buy - action 6.0
Learning step: -18.97062873840332
desired expected reward: 68.57521057128906






Player: 1 
cards in hand: [ 0.  0.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  4.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 26. 30.  8.  4.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  8.] 
cards in discard: [ 1. 14.  3.  3.  0. 29. 25. 14.  0. 11.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[161.65546]
 [153.06265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6. 10.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [14. 10.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -4.817065238952637
desired expected reward: 95.4791030883789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[154.14633]
 [154.24307]
 [154.17566]
 [154.24208]
 [154.14806]
 [155.18773]
 [156.2098 ]
 [155.2673 ]
 [158.26477]
 [159.25354]
 [156.20891]
 [157.11789]
 [155.22237]
 [156.12935]
 [157.19766]
 [163.71693]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6. 10.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  8.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [14. 10.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -7.903743267059326
desired expected reward: 153.75169372558594



buy possibilites: [-1] 
expected returns: [[113.85329]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [ 6.  8. 16.  3.  1.  0.  3. 15. 29. 11.  3.  8.  8.  6.  6. 14.  6.  3.
 10.  6. 10.  6.  0.  1. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [14. 10.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -62.5 

action type: buy - action 11.0
Learning step: -8.373790740966797
desired expected reward: 147.83599853515625






Player: 1 
cards in hand: [14. 10.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3 10  0  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3. 10.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3. 10.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3. 10.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3. 10.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  3. 10.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 14.] 
expected returns: [[127.44277]
 [119.93595]
 [119.93595]
 [119.97117]
 [120.78512]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  8. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -6.297175884246826
desired expected reward: 107.55611419677734



action possibilites: [-1. 10.  8. 14. 11.] 
expected returns: [[111.55421]
 [104.91046]
 [104.94613]
 [105.68788]
 [105.68869]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 14. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 10.0
Learning step: -5.940636157989502
desired expected reward: 113.98959350585938



action possibilites: [-1.  8. 14. 11.  8.] 
expected returns: [[113.87278 ]
 [106.864685]
 [107.6336  ]
 [107.634575]
 [106.864685]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14. 11.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 10.0
Learning step: -4.143771171569824
desired expected reward: 100.76669311523438



action possibilites: [-1.  8. 14.  8.] 
expected returns: [[108.556435]
 [104.03015 ]
 [104.53637 ]
 [104.03015 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14.  8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11 10] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  60   0   0   0   0   0   0   0   9   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: -2.9083547592163086
desired expected reward: 104.7474594116211



action possibilites: [-1.  8.  8.] 
expected returns: [[112.75002 ]
 [103.055305]
 [103.055305]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10. 11. 14.] 
owned cards: [ 0  0  0  3  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0
 16 10  6  8  3  6  6 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 13 

action type: take_action - action 14.0
Learning step: -2.174586772918701
desired expected reward: 102.36180114746094



action possibilites: [-1] 
expected returns: [[111.96515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10. 11. 14.  8.] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.500254511833191
desired expected reward: 100.88914489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[103.26128]
 [103.29261]
 [103.26311]
 [104.44155]
 [113.62251]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10. 11. 14.  8.] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  4.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 22 

action type: take_action - action -1
Learning step: -2.109375
desired expected reward: 109.85577392578125



buy possibilites: [-1] 
expected returns: [[125.91511]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10. 11. 14.  8.] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  3.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -80.    0.    0.  100.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -289.0 

action type: buy - action 6.0
Learning step: -16.780067443847656
desired expected reward: 86.48306274414062






Player: 1 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  3.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  6.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6] -> size -> 33 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 25. 30.  8.  3.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  6.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6] -> size -> 33 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  6. 11.  6.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6] -> size -> 33 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[63.740593]
 [58.860157]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.  6.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  7.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29.  3.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -9.362427711486816
desired expected reward: 116.55268096923828



action possibilites: [-1] 
expected returns: [[117.72994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29.  3.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -60 

action type: gain_card_n - action 5
Learning step: -2.879668951034546
desired expected reward: 47.692176818847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.59196]
 [109.59345]
 [118.44364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  8.  3. 29.  3.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.] 
adversary owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -6.794439792633057
desired expected reward: 110.93550109863281






Player: 1 
cards in hand: [ 3.  8.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 29.  3.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  3  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [29.  6.  3.  3.  1.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [29.  6.  3.  3.  1.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [29.  6.  3.  3.  1.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [29.  6.  3.  3.  1.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29.  6.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[61.47821 ]
 [58.045155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  3.  1.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 25.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.  0.  8. 29.  3.] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -8.024681091308594
desired expected reward: 110.4189453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.687897]
 [54.712593]
 [54.68916 ]
 [55.565193]
 [62.10107 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  3.  1.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  2.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 25.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.  0.  8. 29.  3.] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -5.246420860290527
desired expected reward: 56.23179244995117



buy possibilites: [-1] 
expected returns: [[71.853355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  3.  1.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 25.] 
adversary cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.  0.  8. 29.  3.] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -61 

action type: buy - action 8.0
Learning step: -4.211559295654297
desired expected reward: 51.3536376953125






Player: 1 
cards in hand: [ 0.  0. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 25.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.  0.  8. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [8. 1. 6. 3. 0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11  8] -> size -> 35 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 25.] 
cards in discard: [ 0.  8. 14. 10.  3.  0.  1.  0.  0.  1.  0.  8. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [8. 1. 6. 3. 0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.] 
adversary owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11  8] -> size -> 35 
adversary victory points: -4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [8. 1. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[71.43187]
 [65.0973 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 3. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  6  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16
 10  6  8  3  6  6 11 10  6 11  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -5.501433372497559
desired expected reward: 66.35192108154297



action possibilites: [-1] 
expected returns: [[86.997765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.2612671852111816
desired expected reward: 63.113067626953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[75.729126]
 [75.804596]
 [75.75289 ]
 [75.730354]
 [77.28918 ]
 [76.57726 ]
 [76.54356 ]
 [82.89736 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 25. 30.  8.  3.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1
Learning step: -4.506709575653076
desired expected reward: 82.49105834960938



buy possibilites: [-1] 
expected returns: [[58.276604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -349.0 

action type: buy - action 6.0
Learning step: -19.925294876098633
desired expected reward: 55.80506134033203






Player: 1 
cards in hand: [ 0.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 14  8  0  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 14.  1.  8.  0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 14.  1.  8.  0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 14.  1.  8.  0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[51.45343 ]
 [45.878975]
 [45.181847]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  1.  8.  0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  8.  3.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -5.288388729095459
desired expected reward: 52.988216400146484



action possibilites: [-1] 
expected returns: [[56.4587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 8. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action 14.0
Learning step: -3.4736275672912598
desired expected reward: 42.405338287353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.7651  ]
 [48.831   ]
 [48.785946]
 [48.82906 ]
 [48.76617 ]
 [49.459156]
 [50.14032 ]
 [49.513153]
 [51.500347]
 [52.155125]
 [50.138813]
 [50.741096]
 [49.48404 ]
 [50.08481 ]
 [50.795105]
 [55.08094 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 8. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  6. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1
Learning step: -4.135465145111084
desired expected reward: 52.32323455810547



buy possibilites: [-1] 
expected returns: [[41.705025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 8. 0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  5. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -60.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
   8.   0.] 
sum of rewards: -42.0 

action type: buy - action 14.0
Learning step: -3.6685776710510254
desired expected reward: 46.470237731933594






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8.  0. 14. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  5. 10.  4. 10.  9.] 
adversary cards in hand: [15. 10. 16.  0.  0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0. 14. 14.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6 14] -> size -> 36 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8.  0. 14. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  1.  9.  8.  5. 10.  4. 10.  9.] 
adversary cards in hand: [15. 10. 16.  0.  0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0. 14. 14.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6 14] -> size -> 36 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  9.] 
adversary cards in hand: [15. 10. 16.  0.  0.] 
adversary cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0. 14. 14.  6.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6 14] -> size -> 36 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15. 10. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 16.] 
expected returns: [[40.992096]
 [36.46861 ]
 [35.10203 ]
 [35.077065]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 16.  0.  0.] 
cards in discard: [10.  6. 10. 10. 11. 14.  8.  8. 11. 11.  6.  0.  6.  6.  8. 29.  6.  3.
  3.  1.  6.  8.  1.  3.  0. 14. 14.  6.  1.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  9.] 
adversary cards in hand: [14.  0.  1.  0.  1.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -4.697970390319824
desired expected reward: 37.00705337524414



action possibilites: [-1. 15. 16.] 
expected returns: [[61.84393]
 [54.55703]
 [52.41034]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 15 10  1  8 29  3 14  6  0 16 10
  6  8  3  6  6 11 10  6 11  8  6 14] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  9.] 
adversary cards in hand: [14.  0.  1.  0.  1.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action 10.0
Learning step: -2.7569351196289062
desired expected reward: 32.34510040283203



action possibilites: [-1.] 
expected returns: [[115.079834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  0.  1.  0.  1.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  40   0   0   0   0  -1   0   0  16   0] 
sum of rewards: -14 

action type: gain_card_n - action 14
Learning step: -6.696277141571045
desired expected reward: 165.0151824951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[105.53401]
 [105.57633]
 [105.53514]
 [118.66222]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  0.  1.  0.  1.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action -1.0
Learning step: -4.73898458480835
desired expected reward: 110.34085083007812



buy possibilites: [-1] 
expected returns: [[122.189026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [15.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [14.  0.  1.  0.  1.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -60.   0.   0.  40. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -61.0 

action type: buy - action 0.0
Learning step: -5.577446937561035
desired expected reward: 99.95655059814453






Player: 1 
cards in hand: [14.  0.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.  0.  1.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  1.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15  0] -> size -> 37 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.  0.  1.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 24. 30. 25. 30.  8.  2.  9.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  1.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15  0] -> size -> 37 
adversary victory points: -4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.  0.  1.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  1.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15  0] -> size -> 37 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 14.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[84.8038 ]
 [77.29164]
 [76.34778]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  8.  1.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11 10  8  8  6  1  1  0 14 10  1  8 29  3 14  6  0 16 10  6
  8  3  6  6 11 10  6 11  8  6 14 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16. 14.  0.  1.  0.  1.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -7.762251377105713
desired expected reward: 114.42677307128906



action possibilites: [-1] 
expected returns: [[119.13338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16. 14.  0.  1.  0.  1.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: trash_cards_n_from_hand - action 12
Learning step: -2.8927950859069824
desired expected reward: 59.573123931884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.590004]
 [105.590965]
 [117.15144 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 11.  0. 29.] 
adversary cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16. 14.  0.  1.  0.  1.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16] -> size -> 20 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1
Learning step: -5.931323528289795
desired expected reward: 113.20205688476562






Player: 1 
cards in hand: [10.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0. 29.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16. 14.  0.  1.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  8.] 
adversary cards in hand: [ 6. 10. 11. 10.  3.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16. 14.  0.  1.  0.  1. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 6. 10. 11. 10.  3.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 29.] 
cards in discard: [ 8.  0. 14. 25.  3.  8.  0.  0.  8. 16. 14.  0.  1.  0.  1. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 6. 10. 11. 10.  3.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6. 10. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[75.5929 ]
 [68.95972]
 [69.72766]
 [68.95972]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 11. 10.  3.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 16. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -7.706371307373047
desired expected reward: 109.445068359375



action possibilites: [-1. 11. 10.] 
expected returns: [[120.15338]
 [114.90485]
 [114.2071 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  3.  6.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 16. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action 10.0
Learning step: -3.272273302078247
desired expected reward: 65.68744659423828



action possibilites: [-1. 11.] 
expected returns: [[143.57784]
 [135.66556]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  6.  6.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  8.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 16. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -29 

action type: take_action - action 10.0
Learning step: -4.012270450592041
desired expected reward: 110.19483184814453



action possibilites: [-1.] 
expected returns: [[50.738014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 16. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 7 

action type: gain_card_n - action 6
Learning step: -5.181180000305176
desired expected reward: 128.27452087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.991722]
 [43.992287]
 [50.255333]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
action values: 2 
buys: 1 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 8. 16. 14. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -9 

action type: take_action - action -1.0
Learning step: -1.9431427717208862
desired expected reward: 48.79487228393555






Player: 1 
cards in hand: [ 8. 16. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 14. 10.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0 10  0  3  1 25  3  0  1  0  8 16 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8.  8. 14.  8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8.  8. 14.  8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8.  8. 14.  8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [29.  8.  8. 14.  8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [29.  8.  8. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 14.  8.] 
expected returns: [[22.498928]
 [19.473272]
 [16.980349]
 [16.980349]
 [17.497423]
 [16.980349]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8. 14.  8.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  8  6  0 10  1  8 29  3 14  6  0 16 10  6  8  3  6  6
 11 10  6 11  8  6 14 15  0 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15. 29.  0. 11.] 
adversary cards in discard: [ 0.  8. 14.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 19 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -5.041894435882568
desired expected reward: 45.21343994140625



action possibilites: [-1] 
expected returns: [[55.93567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15. 29.  0. 11.] 
adversary cards in discard: [ 0.  8. 14.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 19 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: trash_cards_n_from_hand - action 11
Learning step: -1.5512354373931885
desired expected reward: 15.644523620605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.288067]
 [47.28875 ]
 [55.476112]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 15. 29.  0. 11.] 
adversary cards in discard: [ 0.  8. 14.] 
adversary owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 19 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1
Learning step: -3.6122841835021973
desired expected reward: 52.32338333129883






Player: 1 
cards in hand: [ 0. 15. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29.  0. 11.] 
cards in discard: [ 0.  8. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  0.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  8.] 
cards in discard: [ 0.  8. 14. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 14  8  0  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  0.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [ 0.  8. 14. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  0.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0.  8. 14. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 24. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  0.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [ 0.  8. 14. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [11.  0. 11. 14.  0.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  0. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
expected returns: [[26.071041]
 [22.238934]
 [22.238934]
 [22.234447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 14.  0.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 14.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1] -> size -> 19 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -5.1971049308776855
desired expected reward: 50.279014587402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[20.278631]
 [20.295567]
 [20.279057]
 [25.147762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 14.  0.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [ 3. 14.  0.  0.  8.] 
adversary cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1] -> size -> 19 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -3.763713836669922
desired expected reward: 22.307327270507812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 14.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  8.] 
cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [3. 1. 8. 6. 6.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [3. 1. 8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  7.] 
adversary cards in hand: [3. 1. 8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [3. 1. 8.] 
adversary cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.  6.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.724615]
 [21.647915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 8.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8. 15. 14.  3.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[   -5     0    -4   -50     0     0     0     0     0     0     0     0
     0 -2100    82     0] 
sum of rewards: -2077 

action type: discard_down_to_3_cards - action 5
Learning step: -106.00593566894531
desired expected reward: -51.67713928222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[21.505798]
 [21.527378]
 [21.50633 ]
 [28.278566]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 25. 30.  8.  2.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8. 15. 14.  3.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -3.8056678771972656
desired expected reward: 23.9189453125



buy possibilites: [-1] 
expected returns: [[39.123764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 8.] 
cards in discard: [15.  0. 10. 16.  0.  0.  6.  8. 29. 10. 10. 11.  6.  3.  6.  6.  8.  8.
 11.  0. 11. 14.  0.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 30. 25. 30.  8.  1.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  1.  0. 25.  0.] 
adversary cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8. 15. 14.  3.  0.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -370.0 

action type: buy - action 6.0
Learning step: -18.695032119750977
desired expected reward: 2.811298370361328






Player: 1 
cards in hand: [ 1.  1.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 25.  0.] 
cards in discard: [ 0.  8. 14. 11.  1. 29. 15.  0.  8. 15. 14.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  1.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  8.  6. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6] -> size -> 32 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  0. 15. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  8.  6. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0.  0. 15. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 23. 30. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  8.  6. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0.  0. 15. 29.] 
cards in discard: [2.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  8.  6. 10.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11.  8.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[62.50607 ]
 [57.208786]
 [56.532272]
 [56.50099 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6. 10.  3.] 
cards in discard: [6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14.  3. 14.  0.  8.] 
adversary cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[  -5    0   -6  -70    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -381 

action type: buy - action -1
Learning step: -19.70233726501465
desired expected reward: 19.42142677307129



action possibilites: [-1. 11.  8.] 
expected returns: [[52.793167]
 [48.452614]
 [47.90895 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6.  3.  0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14.  3. 14.  0.  8.] 
adversary cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -60 

action type: take_action - action 10.0
Learning step: -4.673351287841797
desired expected reward: 51.269432067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.551163]
 [51.9599  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  6.  3.  0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14.  3. 14.  0.  8.] 
adversary cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -4.57689905166626
desired expected reward: 48.21626281738281






Player: 1 
cards in hand: [14.  3. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 14.  0.  8.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  3. 11.  8.  3.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  8.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11. 11.  3.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  8.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11. 11.  3.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  8.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11. 11.  3.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[40.01224 ]
 [35.679024]
 [35.679024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  8.  0.  1.  0.] 
adversary cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0. 14.  3. 14.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[   -5     0    -6   -70     0     0     0     0     0     0     0     0
     0 -2700    82     0] 
sum of rewards: -2699 

action type: discard_down_to_3_cards - action 0
Learning step: -136.68350219726562
desired expected reward: -85.21160888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.010384]
 [40.336998]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [11.  8.  0.  1.  0.] 
adversary cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0. 14.  3. 14.  0.  8.] 
adversary owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -5.198513031005859
desired expected reward: 34.8137321472168



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  1.  0.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0. 14.  3. 14.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0. 14.  3. 14.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0. 14.  3. 14.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  7.  5. 10.  4. 10.  6.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 2. 25.  1.  1.  0.  0. 15. 29.  0. 14.  3. 14.  0.  8. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[66.471   ]
 [59.212963]
 [59.25217 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  1.  8.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -4.67178201675415
desired expected reward: 35.66521453857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[52.9783  ]
 [53.040752]
 [52.997257]
 [54.27197 ]
 [53.654945]
 [59.263847]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  1.  8.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -5.876255989074707
desired expected reward: 55.27768325805664



buy possibilites: [-1] 
expected returns: [[70.35547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  1.  8.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -111.0 

action type: buy - action 0.0
Learning step: -6.615917205810547
desired expected reward: 46.36238479614258






Player: 1 
cards in hand: [ 0.  0.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  0  8 14 29  0  0  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6.  6.  6. 10.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6.  6.  6. 10.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6.  6.  6. 10.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 6.  6.  6.  6. 10.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  6.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[57.69102]
 [52.64192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6.  6. 10.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14.  1.  8.  0.  2.] 
adversary cards in discard: [ 0.  8. 15.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0] -> size -> 20 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1
Learning step: -6.322318077087402
desired expected reward: 64.03314971923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.649803]
 [57.294205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6.  6. 10.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14.  1.  8.  0.  2.] 
adversary cards in discard: [ 0.  8. 15.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0] -> size -> 20 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -5.704225063323975
desired expected reward: 51.98680114746094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  1.  8.  0.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  8.  0.  2.] 
cards in discard: [ 0.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14. 10. 29.  8.  6.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  8.  0.  2.] 
cards in discard: [ 0.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  6.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14. 10. 29.  8.  6.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  8.  0.  2.] 
cards in discard: [ 0.  8. 15. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [14. 10. 29.  8.  6.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [14. 10. 29.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 29.  8.] 
expected returns: [[39.008556]
 [33.801395]
 [33.13914 ]
 [35.88678 ]
 [33.171017]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 29.  8.  6.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  0.  3. 14.  8.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -6.120497226715088
desired expected reward: 51.1737060546875



action possibilites: [-1] 
expected returns: [[51.952084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8.  6.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  3. 14.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action 14.0
Learning step: -3.57114839553833
desired expected reward: 30.23025131225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[45.65187 ]
 [45.673157]
 [52.42388 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  8.  6.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  3. 14.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1
Learning step: -4.5619707107543945
desired expected reward: 47.390113830566406






Player: 1 
cards in hand: [ 1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 0.  0.  0. 15. 16.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 15. 16.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  6.] 
adversary cards in hand: [ 0. 15. 16.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  5.] 
adversary cards in hand: [ 0. 15. 16.] 
adversary cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[48.68881 ]
 [43.71856 ]
 [42.170822]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 16.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6
 11  8  6 14 15  0 29  6  6  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  5.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[   -5     0    -6   -70     0     0     0   -30     0     0     0     0
     0 -2700    82     0] 
sum of rewards: -2729 

action type: discard_down_to_3_cards - action 3
Learning step: -136.4744110107422
desired expected reward: -115.67190551757812



action possibilites: [-1] 
expected returns: [[42.504623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  5.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action 15.0
Learning step: -4.279573440551758
desired expected reward: 39.43898010253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[36.282272]
 [36.35046 ]
 [36.303055]
 [37.678333]
 [37.01192 ]
 [42.70767 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  4. 10.  5.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1
Learning step: -4.318166255950928
desired expected reward: 38.186458587646484



buy possibilites: [-1] 
expected returns: [[89.80405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [ 6. 10. 11.  8.  6.  3.  0.  3.  8. 11. 11.  3.  0. 10.  6.  0.  1.  8.
  6.  6.  6.  6. 10. 14. 10. 29.  8.  6.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -43 

action type: buy - action 10.0
Learning step: -1.980004906654358
desired expected reward: 35.03191375732422






Player: 1 
cards in hand: [ 0. 25.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 29.  0.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1. 29.  0.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  6.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1. 29.  0.] 
cards in discard: [ 0.  8. 15. 11. 14.  1.  8.  0.  2.  0.  8. 15. 14.  1.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[38.385185]
 [32.841805]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  6.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1
Learning step: -7.748116493225098
desired expected reward: 82.0559310913086



action possibilites: [-1. 10.] 
expected returns: [[44.625042]
 [38.845936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6.  6. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action 10.0
Learning step: -3.71746826171875
desired expected reward: 28.50924301147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[38.37017]
 [44.8938 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6.  6. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 2 
buys: 1 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  0. 29. 15.] 
adversary cards in discard: [] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -4.339093208312988
desired expected reward: 40.28594970703125






Player: 1 
cards in hand: [ 0.  0.  0. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0. 14. 15. 10.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 6.  0. 14. 15. 10.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 14. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 10.] 
expected returns: [[31.7364  ]
 [28.418034]
 [28.859922]
 [27.980484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14. 15. 10.] 
cards in discard: [10.  3.  6.  6.  6. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [14. 14. 25.  1.  0.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: -5.632445812225342
desired expected reward: 39.261348724365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.64166]
 [23.44762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14. 15. 10.] 
cards in discard: [10.  3.  6.  6.  6. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [14. 14. 25.  1.  0.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -4.728814601898193
desired expected reward: 18.60602378845215



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 14. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14. 25.  1.  0.] 
cards in discard: [ 0.  0.  0. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [10.  6.  8.  1.  6.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14. 25.  1.  0.] 
cards in discard: [ 0.  0.  0. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 29. 25. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [10.  6.  8.  1.  6.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14. 25.  1.  0.] 
cards in discard: [ 0.  0.  0. 29. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [10.  6.  8.  1.  6.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
adversary victory points: -6
player victory points: 2 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10.  6.  8.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[26.139433]
 [22.323118]
 [22.347511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  1.  6.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 2.  8.  0. 29.  8.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 24 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: buy - action -1.0
Learning step: -5.187076568603516
desired expected reward: 18.260543823242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.503109]
 [21.513683]
 [25.851706]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8.  1.  6.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 2.  8.  0. 29.  8.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 24 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: take_action - action -1.0
Learning step: -5.335629940032959
desired expected reward: 20.803802490234375



buy possibilites: [-1] 
expected returns: [[24.595478]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8.  1.  6.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 2.  8.  0. 29.  8.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.] 
adversary owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 24 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -121.0 

action type: buy - action 0.0
Learning step: -6.571757793426514
desired expected reward: 14.93134880065918






Player: 1 
cards in hand: [ 2.  8.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  8.  0. 29.  8.] 
cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  8 14 29  1 25  3  0  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2.] 
cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2.] 
cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [11.  3.  8.  0. 11.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 2 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [11.  3.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[43.08074 ]
 [37.41683 ]
 [36.703285]
 [37.41683 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0. 11.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 1. 11.  8. 15.  3.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.  8.  2.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 21 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: buy - action -1
Learning step: -4.902667999267578
desired expected reward: 19.69281005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.027267]
 [42.2638  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0. 11.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 1. 11.  8. 15.  3.] 
adversary cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.  8.  2.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 21 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: take_action - action -1.0
Learning step: -5.828479290008545
desired expected reward: 37.25226974487305



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 11.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  8. 15.  3.] 
cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.  8.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 16. 11.  8.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 15.  3.] 
cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.  8.  2. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  0. 16. 11.  8.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 15.  3.] 
cards in discard: [ 0.  0.  0. 29. 15.  3. 14. 14. 25.  1.  0.  8.  2. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  0. 16. 11.  8.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
adversary victory points: -6
player victory points: 2 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
expected returns: [[10.620312 ]
 [ 5.2465763]
 [ 5.8357463]
 [ 5.2965646]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 11.  8.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  4.] 
adversary cards in hand: [14.  0. 15. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: buy - action -1.0
Learning step: -6.504866123199463
desired expected reward: 35.758941650390625



action possibilites: [-1] 
expected returns: [[18.464783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [14.  0. 15. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20   0   0   0   0  -1   0   0  16   0] 
sum of rewards: -56 

action type: gain_card_n - action 8
Learning step: -2.6493706703186035
desired expected reward: 2.6471896171569824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[11.8723545]
 [11.881691 ]
 [16.268875 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  8.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [14.  0. 15. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1
Learning step: -4.168184757232666
desired expected reward: 14.296598434448242



buy possibilites: [-1] 
expected returns: [[32.10453]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  8.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [14.  0. 15. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -80.   0.   0.  20. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -103.0 

action type: buy - action 0.0
Learning step: -5.021265983581543
desired expected reward: 6.851088523864746






Player: 1 
cards in hand: [14.  0. 15. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 15. 29.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [10.  3.  6.  6.  8.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0. 11.  0.  0. 16.  8.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [10.  6.  6.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0. 11.  0.  0. 16.  8.  3.  8.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  9.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [10.  6.  6.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0. 11.  0.  0. 16.  8.  3.  8.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29.  1.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [10.  6.  6.] 
adversary cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0. 11.  0.  0. 16.  8.  3.  8.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[43.540985]
 [35.83979 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0. 11.  0.  0. 16.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 1.  0.  8. 29. 15.] 
adversary cards in discard: [25. 14.  0. 15. 29.  1.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[   -5     0    -6   -80     0     0     0   -90     0     0     0    -2
     0 -2700    91     0] 
sum of rewards: -2792 

action type: discard_down_to_3_cards - action 0
Learning step: -141.6021728515625
desired expected reward: -83.56965637207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.13611 ]
 [42.792507]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.] 
cards in discard: [10.  3.  6.  6.  6. 10.  6.  0. 14. 15. 10.  0. 10.  6.  8.  1.  6. 11.
  3.  8.  0. 11. 15.  0. 11.  0.  0. 16.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 1.  0.  8. 29. 15.] 
adversary cards in discard: [25. 14.  0. 15. 29.  1.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -91 

action type: take_action - action -1.0
Learning step: -5.854384899139404
desired expected reward: 37.68659591674805



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  8. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 29. 15.] 
cards in discard: [25. 14.  0. 15. 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 6. 16.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 6. 16.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 14.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 6. 16.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 14.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 23. 29. 24. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 6. 16.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 14.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 23. 29. 23. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 6. 16.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[13.695126]
 [12.299023]
 [12.967667]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  6. 29.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 0. 11. 15.  2. 15.] 
adversary cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1.0
Learning step: -6.896231174468994
desired expected reward: 35.896270751953125



action possibilites: [-1. 16.] 
expected returns: [[20.46411 ]
 [18.110489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6.] 
cards in discard: [0. 8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 23. 29. 23. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 0. 11. 15.  2. 15.] 
adversary cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: discard_n_cards - action 8
Learning step: -4.093771934509277
desired expected reward: 5.500188827514648





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.189167]
 [20.839085]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6.] 
cards in discard: [0. 8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [12. 23. 29. 23. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 0. 11. 15.  2. 15.] 
adversary cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: -4.631928443908691
desired expected reward: 15.832182884216309



buy possibilites: [-1] 
expected returns: [[23.053797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6.] 
cards in discard: [0. 8. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 0. 11. 15.  2. 15.] 
adversary cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -90.   0.   0.  20. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -114.0 

action type: buy - action 0.0
Learning step: -6.090748310089111
desired expected reward: 12.098421096801758






Player: 1 
cards in hand: [ 0. 11. 15.  2. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  2. 15.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  5.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  2. 15.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  2. 15.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  3. 10.  3.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  2. 15.] 
cards in discard: [25. 14.  0. 15. 29.  1.  8. 15.  3. 29. 25.  1.  0.  3. 14. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3. 14.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[11.555717]
 [ 8.377802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [15.  3.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1
Learning step: -5.975788116455078
desired expected reward: 17.0780086517334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 7.5596814]
 [ 7.565934 ]
 [11.603537 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [15.  3.  0.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.422825336456299
desired expected reward: 6.132893085479736



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  3.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  1.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 8.  0. 10.  6.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  1.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  4.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 8.  0. 10.  6.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  1.  8.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 8.  0. 10.  6.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[19.824305 ]
 [15.613506 ]
 [15.5843525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  6.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [14. 25. 29. 15.  0.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1.0
Learning step: -5.242813587188721
desired expected reward: 6.360723972320557





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[14.285856]
 [14.29518 ]
 [19.033215]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  6.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [14. 25. 29. 15.  0.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.678835868835449
desired expected reward: 14.145468711853027



buy possibilites: [-1] 
expected returns: [[15.952116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  6.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [14. 25. 29. 15.  0.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8.] 
adversary owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -90.   0.   0.   0. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -135.0 

action type: buy - action 0.0
Learning step: -7.10537052154541
desired expected reward: 7.180485725402832






Player: 1 
cards in hand: [14. 25. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 25. 29. 15.  0.] 
cards in discard: [11. 15.  3.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8 14  1 25  3  1  0  8 15  0  1 15  2  0 29  0 11 15 29  3 15 25  3
 11 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  0.  6. 10.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [11.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[20.634068]
 [16.174465]
 [15.591666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 2.  3. 10.  0. 11.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1
Learning step: -5.449322700500488
desired expected reward: 10.502793312072754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[12.668131]
 [12.678829]
 [18.663551]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 2.  3. 10.  0. 11.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.744965553283691
desired expected reward: 14.889107704162598



buy possibilites: [-1] 
expected returns: [[18.981052]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6. 10.  0.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [ 2.  3. 10.  0. 11.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0] -> size -> 26 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -90.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -136.0 

action type: buy - action 0.0
Learning step: -7.006333351135254
desired expected reward: 5.661799430847168






Player: 1 
cards in hand: [ 2.  3. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 10.  0. 11.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  6.  8. 15. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 10.  0. 11.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  3.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  6.  8. 15. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 10.  0. 11.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [11.  6.  8. 15. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [11.  6.  8. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 11.] 
expected returns: [[14.288613]
 [10.045118]
 [ 9.611398]
 [10.508616]
 [10.045118]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8. 15. 11.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  3.] 
adversary cards in hand: [25. 14. 11. 15. 29.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1
Learning step: -5.748157024383545
desired expected reward: 13.232894897460938



action possibilites: [-1] 
expected returns: [[37.033573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15. 11.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [25. 14. 11. 15. 29.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20   0   0   0   0  -6   0   0  16   0] 
sum of rewards: -71 

action type: gain_card_n - action 8
Learning step: -3.197314500808716
desired expected reward: 6.414083480834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[31.736807]
 [36.100956]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 15. 11.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [25. 14. 11. 15. 29.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1
Learning step: -5.134864807128906
desired expected reward: 31.89870834350586



buy possibilites: [-1] 
expected returns: [[0.8857827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 15. 11.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [25. 14. 11. 15. 29.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20 -30   0   0   0  -7   0   0   0   0] 
sum of rewards: -118 

action type: buy - action 0.0
Learning step: -7.432461738586426
desired expected reward: 24.304340362548828






Player: 1 
cards in hand: [25. 14. 11. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 11. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14. 11. 15. 29.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  1.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0] -> size -> 42 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14. 11. 29.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  1.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0] -> size -> 42 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 14. 11. 29.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [10.  3.  1.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0] -> size -> 42 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [10.  3.  1.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[13.624875]
 [ 9.22874 ]
 [ 9.259437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  8.  6.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1
Learning step: -4.848571300506592
desired expected reward: -3.9627885818481445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.756855]
 [ 8.762473]
 [13.624875]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  8.  6.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.49225378036499
desired expected reward: 8.132623672485352



buy possibilites: [-1] 
expected returns: [[2.3842182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  8.  6.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29.] 
adversary owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5.   0.  -6. -90.   0.   0.   0. -30.   0.   0.   0.  -8.   0.   0.
   0.   0.] 
sum of rewards: -139.0 

action type: buy - action 0.0
Learning step: -7.334197998046875
desired expected reward: 1.4226579666137695






Player: 1 
cards in hand: [ 0. 15.  1.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  1.  3.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  0  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10
 11  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [ 6. 10.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [ 6. 10.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  2. 10.  2.] 
adversary cards in hand: [ 6. 10.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [11. 15.  3.  0.  1.  8. 14. 25.  0. 29.  8. 11.  2.  3. 10.  0. 11. 15.
 25. 14. 11. 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 6. 10.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[21.283842]
 [17.380617]
 [17.380617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  6. 10.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 0. 15. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1
Learning step: -4.744533538818359
desired expected reward: -2.3603153228759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.913504]
 [21.283842]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  6. 10.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 0. 15. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: take_action - action -1.0
Learning step: -5.680828094482422
desired expected reward: 15.60301399230957



buy possibilites: [-1] 
expected returns: [[27.237556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  6. 10.] 
cards in discard: [ 0.  8.  0. 29.  6. 16.  6.  3. 14.  6.  0.  0.  0.  8.  0. 10.  6.  0.
  0. 11.  0.  6. 10.  0. 15.  0. 11.  6.  8. 15. 11.  0. 10.  3.  1.  8.
  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 0. 15. 14.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0 -30   0   0   0  -9   0   0   0   0] 
sum of rewards: -140 

action type: buy - action 0.0
Learning step: -7.232830047607422
desired expected reward: 9.680669784545898






Player: 1 
cards in hand: [ 0. 15. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 14.  8. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0.  8.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 44 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 8.  0. 15.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 44 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  2.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 8.  0. 15.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 44 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8. 11.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 8.  0. 15.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 44 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[26.686327]
 [19.842888]
 [21.37865 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.] 
cards in discard: [0. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11
  8  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [14. 10.  0.  1. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[   -5     0    -6   -90     0     0     0  -300     0     0     0    -9
     0 -2700    51     0] 
sum of rewards: -3059 

action type: discard_down_to_3_cards - action 0
Learning step: -152.4275360107422
desired expected reward: -152.5557403564453



action possibilites: [-1] 
expected returns: [[9.43146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [0. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11  8
  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [14. 10.  0.  1. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action 15.0
Learning step: -4.90672492980957
desired expected reward: 16.471927642822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[8.481588 ]
 [8.489995 ]
 [8.482892 ]
 [8.690863 ]
 [8.5892935]
 [9.475996 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11  8
  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [14. 10.  0.  1. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1
Learning step: -4.32449197769165
desired expected reward: 5.106968402862549






Player: 1 
cards in hand: [14. 10.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  1. 11.] 
cards in discard: [11. 14.  0. 15.  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 8. 10.  0.  6.  0.] 
adversary cards in discard: [ 0.  0. 15.  8.] 
adversary owned cards: [ 3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11  8
  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  1. 11.] 
cards in discard: [11. 14.  0. 15.  8. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 8. 10.  0.  6.  0.] 
adversary cards in discard: [ 0.  0. 15.  8.] 
adversary owned cards: [ 3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11  8
  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  1. 11.] 
cards in discard: [11. 14.  0. 15.  8. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 8. 10.  0.  6.  0.] 
adversary cards in discard: [ 0.  0. 15.  8.] 
adversary owned cards: [ 3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11  8
  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 43 
adversary victory points: -6
player victory points: 3 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[ 1.7750149 ]
 [-0.11965615]
 [-0.12744471]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  6.  0.] 
cards in discard: [ 0.  0. 15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11 10  8  6  0 10  1  8  3  6  0 16 10  6  8  3  6  6 11 10  6 11  8
  6 14 15  0 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 25.  2. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -101 

action type: buy - action -1.0
Learning step: -5.51023006439209
desired expected reward: 3.965768814086914



action possibilites: [-1] 
expected returns: [[14.390288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0. 15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 25.  2. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: trash_cards_n_from_hand - action 12
Learning step: -3.1698081493377686
desired expected reward: -3.298011302947998





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.889512]
 [14.777787]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0. 15.  8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 25.  2. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1
Learning step: -3.9066829681396484
desired expected reward: 10.48360538482666



buy possibilites: [-1] 
expected returns: [[9.218808]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0. 15.  8.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 25.  2. 11.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -80   0   0  20 -30   0   0   0  -5   0   0   0   0] 
sum of rewards: -105 

action type: buy - action 0.0
Learning step: -5.687053203582764
desired expected reward: 7.202463626861572






Player: 1 
cards in hand: [ 3. 15. 25.  2. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 25.  2. 11.] 
cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 6. 10.  6.  6.  3.] 
adversary cards in discard: [ 0.  0. 15.  8.  0.  8.] 
adversary owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0  0] -> size -> 40 
adversary victory points: -5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  2. 11. 29. 10.] 
cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 6. 10.  6.  6.  3.] 
adversary cards in discard: [ 0.  0. 15.  8.  0.  8.] 
adversary owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0  0] -> size -> 40 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  2. 11. 29. 10.] 
cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 23. 29. 23. 30.  8.  0.  8.  1.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 6. 10.  6.  6.  3.] 
adversary cards in discard: [ 0.  0. 15.  8.  0.  8.] 
adversary owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0  0] -> size -> 40 
adversary victory points: -5
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 3 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 2 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 10.  6.  6.  3.] 
cards in discard: [ 0.  0. 15.  8.  0.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  8 10  1  8  3  6 16 10  6  8  3  6  6 11 10  6 11  8  6 14 15  0
 29  6  6  0 10  0 15  0  0  0  0 15  0  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 23. 30.  8.  0.  8.  0.  0.  8.  5.  5. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15.  2. 11. 29. 10.] 
adversary cards in discard: [11. 14.  0. 15.  8. 11.  0. 14. 10.  0.  1. 11. 11.] 
adversary owned cards: [14  8 14  1 25  3  1  8  1 15  2  0 29  0 11 15 29  3 15 25  3 11 10 11
  0 11 10 11  0 11] -> size -> 30 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[  -5 -500   -5  -80    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -590 

action type: buy - action -1
Learning step: -29.960941314697266
desired expected reward: -20.74213409423828



