 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[318.71225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1  -40    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -576 

action type: buy - action 0.0
Learning step: -28.72964859008789
desired expected reward: -30.136669158935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[300.53827]
 [304.83142]
 [305.22336]
 [297.77615]
 [305.12817]
 [310.61447]
 [305.79675]
 [311.92352]
 [303.16724]
 [306.18872]
 [307.59302]
 [320.6402 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.141205787658691
desired expected reward: 311.2270202636719



buy possibilites: [-1] 
expected returns: [[301.30087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -6.977138042449951
desired expected reward: 298.1510009765625






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[342.91476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.352173805236816
desired expected reward: 293.9486999511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[331.79544]
 [335.3806 ]
 [335.66727]
 [329.46738]
 [340.13666]
 [336.1597 ]
 [336.44635]
 [349.06277]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.816064834594727
desired expected reward: 337.422607421875



buy possibilites: [-1] 
expected returns: [[324.3256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  3.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -9.510661125183105
desired expected reward: 326.6490783691406






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.50327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.349055290222168
desired expected reward: 314.9765319824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[281.7055 ]
 [286.46518]
 [286.86905]
 [278.62735]
 [292.8157 ]
 [287.51016]
 [287.91403]
 [303.20242]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.015494346618652
desired expected reward: 300.6389465332031



buy possibilites: [-1] 
expected returns: [[321.0956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.460622787475586
desired expected reward: 273.2448425292969






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0. 29.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0. 29.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0. 29.  3.  3.  0.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3. 16.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[307.1686 ]
 [293.79184]
 [294.32773]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  8.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.83652400970459
desired expected reward: 310.25909423828125



action possibilites: [-1] 
expected returns: [[379.93234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: trash_cards_n_from_hand - action 2
Learning step: -7.421678066253662
desired expected reward: 299.9814147949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[355.1745 ]
 [360.33575]
 [352.13318]
 [360.96194]
 [377.453  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -11.378671646118164
desired expected reward: 368.5536804199219



buy possibilites: [-1] 
expected returns: [[383.13657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -11.238150596618652
desired expected reward: 343.9363098144531






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[356.54605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -12.639077186584473
desired expected reward: 370.49749755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[330.7019 ]
 [335.73196]
 [336.22385]
 [327.48273]
 [336.09418]
 [342.55396]
 [336.8722 ]
 [344.06284]
 [333.8128 ]
 [337.36407]
 [339.0027 ]
 [354.25104]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.946310997009277
desired expected reward: 348.8426208496094



buy possibilites: [-1] 
expected returns: [[371.9019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -27.5 

action type: buy - action 11.0
Learning step: -10.087870597839355
desired expected reward: 332.466064453125






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [11.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[368.91125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  4. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -11.86845874786377
desired expected reward: 360.0334167480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[349.0325 ]
 [353.83026]
 [354.25934]
 [345.93237]
 [360.27097]
 [354.8959 ]
 [355.32495]
 [371.44305]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0.  4. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -12.013776779174805
desired expected reward: 358.0589599609375



buy possibilites: [-1] 
expected returns: [[368.42294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.  0.  3.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  4. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -14 

action type: buy - action 10.0
Learning step: -10.176732063293457
desired expected reward: 345.1482238769531






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  4. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  4. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 4. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8  4 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[331.44327]
 [314.43378]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -11.658629417419434
desired expected reward: 356.7643127441406



action possibilites: [-1] 
expected returns: [[288.0566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 1
Learning step: -8.951862335205078
desired expected reward: 307.7108459472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[270.17883]
 [273.62613]
 [268.05637]
 [274.08557]
 [285.74625]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -7.766517162322998
desired expected reward: 280.29010009765625



buy possibilites: [-1] 
expected returns: [[293.89792]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  3.  0.] 
adversary cards in discard: [ 3. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 27 

action type: buy - action 3.0
Learning step: -5.718606472015381
desired expected reward: 267.9075927734375






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.  0.] 
cards in discard: [ 3. 29.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3. 29.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3. 29.  8.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 3. 29.  8.  0. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[342.82562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -6.985297679901123
desired expected reward: 286.9126281738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[329.15903]
 [332.7925 ]
 [326.8851 ]
 [333.2952 ]
 [344.83954]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 29.  8. 10.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.728278160095215
desired expected reward: 335.1427917480469



buy possibilites: [-1] 
expected returns: [[310.4669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 8. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -312.0 

action type: buy - action 6.0
Learning step: -24.958749771118164
desired expected reward: 301.9263610839844






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0. 6. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0. 6. 3. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[340.4979 ]
 [324.38953]
 [317.33484]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [3. 8. 0. 0. 6. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.689287185668945
desired expected reward: 301.777587890625



action possibilites: [-1. 11.] 
expected returns: [[306.83252]
 [298.90607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -8.617386817932129
desired expected reward: 308.4640808105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[292.90533]
 [296.20142]
 [296.51978]
 [290.82858]
 [300.67496]
 [296.9522 ]
 [297.27054]
 [308.1966 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  8.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -8.189105033874512
desired expected reward: 298.6434020996094



buy possibilites: [-1] 
expected returns: [[285.9499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  6.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: -7.299877166748047
desired expected reward: 293.3751220703125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [3. 0. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[352.73663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11. 10. 11.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -7.489633083343506
desired expected reward: 278.46026611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[319.4794 ]
 [324.66443]
 [316.43274]
 [325.28314]
 [343.7269 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11. 10. 11.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 14.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.807682991027832
desired expected reward: 331.99755859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  8. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  8. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  8. 29.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[282.10605]
 [269.8186 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [ 0.  0.  3. 14.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -12.023731231689453
desired expected reward: 331.7032165527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[266.9425 ]
 [270.82742]
 [264.65237]
 [271.2993 ]
 [283.5867 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  9.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [ 0.  0.  3. 14.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.072275161743164
desired expected reward: 273.8849792480469



buy possibilites: [-1] 
expected returns: [[285.76126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  8.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [ 0.  0.  3. 14.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -23.452991485595703
desired expected reward: 241.1993865966797






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [ 0.  0.  3. 14.  8. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  8.  9.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  6.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  0.  3. 14.  8. 29. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  6.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  0.  3. 14.  8. 29. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  6.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  0.  3. 14.  8. 29. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  6.  0.] 
adversary cards in discard: [6. 3. 3. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[343.4376 ]
 [332.84103]
 [332.84103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  6.  0.] 
cards in discard: [6. 3. 3. 0. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 14.  8. 29. 16.  0. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -8.333501815795898
desired expected reward: 277.4277648925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[322.1311]
 [327.0955]
 [319.1652]
 [327.7085]
 [343.4083]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  6.  0.] 
cards in discard: [6. 3. 3. 0. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 14.  8. 29. 16.  0. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -11.328886985778809
desired expected reward: 331.5362243652344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3. 14.  8. 29. 16.  0. 11.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3. 14.  8. 29. 16.  0. 11.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  8. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3. 14.  8. 29. 16.  0. 11.  3.  0.  3.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[273.16592]
 [261.71616]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -12.792983055114746
desired expected reward: 330.6153259277344



action possibilites: [-1.] 
expected returns: [[253.826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -7.974046230316162
desired expected reward: 252.7285919189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[233.92577]
 [238.79552]
 [239.31163]
 [230.8097 ]
 [245.47845]
 [239.92726]
 [240.44337]
 [257.50137]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.830485820770264
desired expected reward: 245.99551391601562



buy possibilites: [-1] 
expected returns: [[242.35696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  3.  3.  0.  0.  8.  0. 11. 11.  6.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [14. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 10.0
Learning step: -6.319138050079346
desired expected reward: 234.12425231933594






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [14. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[263.1193 ]
 [250.61208]
 [250.87822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: discard_down_to_3_cards - action 3
Learning step: -6.882338047027588
desired expected reward: 211.89541625976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[243.82887]
 [241.79138]
 [260.31876]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 27. 29.  8.  8.  8.  7.  7. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.980630874633789
desired expected reward: 250.82627868652344



buy possibilites: [-1] 
expected returns: [[302.98416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [0. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  7. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -22.47242546081543
desired expected reward: 219.31893920898438






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29. 14. 16.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  7. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 0.  0.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29. 14. 16.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  7. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 0.  0.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29. 14. 16.  0.  0.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  6. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [ 0.  0.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6] -> size -> 19 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[256.352 ]
 [241.1826]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  6. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 29.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -11.782483100891113
desired expected reward: 291.2016906738281



action possibilites: [-1] 
expected returns: [[237.77222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  6. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 29.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -8 

action type: gain_card_n - action 10
Learning step: -6.411417484283447
desired expected reward: 220.81442260742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[222.98282]
 [228.76378]
 [219.93384]
 [229.44572]
 [248.1877 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  6. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 29.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -7.8143815994262695
desired expected reward: 229.9578399658203



buy possibilites: [-1] 
expected returns: [[233.70822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  5. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 29.] 
adversary cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 8.0
Learning step: -7.013852119445801
desired expected reward: 222.431884765625






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 29.] 
cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  5. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8] -> size -> 21 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 29.] 
cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 27. 29.  8.  7.  8.  7.  5. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8] -> size -> 21 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 29.] 
cards in discard: [29. 14. 16.  0.  0.  3.  8.  3.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  5. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8] -> size -> 21 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[203.39215]
 [191.10974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8. 11.  6.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  5. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -9.475313186645508
desired expected reward: 224.23291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[182.93695]
 [186.91788]
 [180.59686]
 [187.40031]
 [200.02733]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8. 11.  6.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  5. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.941099643707275
desired expected reward: 192.68048095703125



buy possibilites: [-1] 
expected returns: [[183.15282]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [ 0.  0.  6.  8.  0. 10. 15.  8. 11.  6.  0.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  8.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -36 

action type: buy - action 8.0
Learning step: -7.049077033996582
desired expected reward: 180.35122680664062






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [14.  0.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  6.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8] -> size -> 22 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  6.  6. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8] -> size -> 22 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  6.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[235.80423]
 [222.145  ]
 [226.26385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6. 11.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [14.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -6.278502941131592
desired expected reward: 176.8743133544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[212.26566]
 [209.9476 ]
 [230.669  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6. 11.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [14.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.809326171875
desired expected reward: 222.76589965820312



buy possibilites: [-1] 
expected returns: [[304.66644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6. 11.  3.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 29.] 
adversary cards in discard: [14.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action 0.0
Learning step: -7.458287715911865
desired expected reward: 204.807373046875






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [29.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 29.] 
cards in discard: [14.  0.  8.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [14.  0.  8.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [14.  0.  8.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  4. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [14.  0.  8.  3. 11.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[232.4509 ]
 [218.04626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -12.413108825683594
desired expected reward: 292.2533264160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[209.51718]
 [213.26529]
 [213.7344 ]
 [207.21326]
 [219.11667]
 [214.27036]
 [214.73946]
 [229.14404]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 27. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -8.708189964294434
desired expected reward: 219.827392578125



buy possibilites: [-1] 
expected returns: [[183.23341]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -31.0 

action type: buy - action 3.0
Learning step: -8.113966941833496
desired expected reward: 205.6204071044922






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  3. 11.  0.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 24 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 8.  8.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[160.34418]
 [144.45743]
 [144.45743]
 [149.35434]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 11.  0.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -6.953664302825928
desired expected reward: 176.27975463867188



action possibilites: [-1] 
expected returns: [[254.39932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 11
Learning step: -2.2992303371429443
desired expected reward: 144.16506958007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[240.23415]
 [237.79903]
 [259.59222]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -7.81118631362915
desired expected reward: 246.588134765625



buy possibilites: [-1] 
expected returns: [[219.86513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action 0.0
Learning step: -8.758429527282715
desired expected reward: 221.34945678710938






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 15.  3.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 15.  3.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.  0.  8.  3. 11.  8. 29.  0.  3.  0. 29.  3.  8.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 15.  3.] 
adversary cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[210.93867]
 [199.92213]
 [201.23634]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15.  3.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.106178283691406
desired expected reward: 211.75894165039062



action possibilites: [-1] 
expected returns: [[184.60605]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 15.0
Learning step: -6.514376163482666
desired expected reward: 192.8458709716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[174.4641 ]
 [176.47038]
 [176.61667]
 [173.14458]
 [176.58745]
 [179.11214]
 [176.9016 ]
 [179.73924]
 [175.64003]
 [177.0479 ]
 [177.70427]
 [183.72826]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3.] 
cards in discard: [ 0. 10.  6.  6. 11.  3.  3. 10.  0.  0.  3.  0.  0.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  8. 29.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -5.905785083770752
desired expected reward: 178.70025634765625






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [29.  8. 29.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  3. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.  8. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  3. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 16.  0.  0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[225.17711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  3.  8. 14.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -5.898854732513428
desired expected reward: 177.8293914794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.27036]
 [204.07562]
 [204.32762]
 [199.44891]
 [207.85013]
 [204.70218]
 [204.95415]
 [214.39015]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  3.  8. 14.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.116376876831055
desired expected reward: 213.5528564453125



buy possibilites: [-1] 
expected returns: [[230.91147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 11.  3.  8. 14.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -8.068007469177246
desired expected reward: 193.20230102539062






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  3.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  8. 14.] 
cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 11.] 
adversary cards in discard: [0. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  3.  8. 14.] 
cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  3. 11.] 
adversary cards in discard: [0. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[222.15373]
 [208.83238]
 [212.90846]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 11.] 
cards in discard: [0. 0. 6. 0. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.481049537658691
desired expected reward: 222.430419921875



action possibilites: [-1. 11.] 
expected returns: [[160.98494]
 [149.12491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 0. 6. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 10.0
Learning step: -7.402238368988037
desired expected reward: 197.07945251464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[139.53798]
 [136.62183]
 [161.09976]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 0. 6. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  7.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.384111404418945
desired expected reward: 155.60079956054688



buy possibilites: [-1] 
expected returns: [[226.67867]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 0. 6. 0. 0. 6. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 8.] 
adversary cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -17.980819702148438
desired expected reward: 118.6409912109375






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 8.] 
cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  8. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  8. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  8. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8. 29. 29.  8.  3. 16.  0.  0.  1. 11.  3.  8. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  8. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11. 10.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 15.] 
expected returns: [[165.2    ]
 [157.24724]
 [153.71611]
 [153.42601]
 [154.83188]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  8. 15.] 
cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -10.035964965820312
desired expected reward: 216.6427001953125



action possibilites: [-1] 
expected returns: [[191.82175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  8.] 
cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 15.0
Learning step: -4.612583637237549
desired expected reward: 148.95887756347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[177.99998]
 [176.45827]
 [188.6674 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  8.] 
cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -6.72506856918335
desired expected reward: 185.0966796875






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3. 15.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3. 15.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3. 15.  3. 11. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[165.94392]
 [152.88751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3. 15.  3. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -8.060066223144531
desired expected reward: 180.60733032226562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[152.23384]
 [156.06396]
 [156.45404]
 [149.77249]
 [160.78769]
 [156.95001]
 [157.34009]
 [168.5767 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3. 15.  3. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 26. 29.  8.  6.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.9454522132873535
desired expected reward: 158.99850463867188



buy possibilites: [-1] 
expected returns: [[180.05458]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 0.  0.  6.  0.  0.  6.  6. 10.  3.  0.  3. 11.  3. 15.  3. 11. 10.  8.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 26. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -356.0 

action type: buy - action 6.0
Learning step: -20.859987258911133
desired expected reward: 121.36431884765625






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  8. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 26. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  8. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [8. 0. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  8. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3.  8. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[192.40619]
 [182.19946]
 [185.51625]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0 11 10  3  6 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0. 29.  0. 16.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -8.12192440032959
desired expected reward: 171.9326629638672



action possibilites: [-1] 
expected returns: [[217.95781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0. 29.  0. 16.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: trash_cards_n_from_hand - action 9
Learning step: -6.370832920074463
desired expected reward: 173.1268310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[190.96127]
 [188.37056]
 [211.20047]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  5.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0. 29.  0. 16.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -8.688738822937012
desired expected reward: 209.26907348632812



buy possibilites: [-1] 
expected returns: [[200.1206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0. 29.  0. 16.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0  3] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -357 

action type: buy - action 6.0
Learning step: -22.76581573486328
desired expected reward: 165.60476684570312






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [14.  0. 29.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 29.  0. 16.] 
cards in discard: [8. 0. 3. 3. 3. 0. 3. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  3 14  0  3  0 16  0  8 29  8  0  8  1  8  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  6.] 
adversary cards in discard: [6. 8. 3.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[187.8521 ]
 [173.31029]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [6. 8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  8.  3.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.] 
adversary owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10  0] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -9.769204139709473
desired expected reward: 190.3513946533203



action possibilites: [-1.  8.] 
expected returns: [[140.56181 ]
 [127.451584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [6. 8. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  8.  3.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.] 
adversary owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10  0] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 10.0
Learning step: -8.415575981140137
desired expected reward: 163.93096923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.66578]
 [130.28929]
 [130.66658]
 [124.33825]
 [135.258  ]
 [131.13556]
 [131.51285]
 [144.79442]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [6. 8. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  8.  3.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.] 
adversary owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10  0] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -6.839485168457031
desired expected reward: 133.72232055664062






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  8.  3.] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29 11  3  0  3  0 16  0  8 29  8  0  8  1  8  0  3 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  3.  1.  0. 10.  0. 16.  0. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[217.11438]
 [205.20488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -5.903571605682373
desired expected reward: 138.89085388183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[200.50885]
 [203.85751]
 [204.16905]
 [198.3366 ]
 [208.62735]
 [204.63734]
 [204.97185]
 [216.88135]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  7.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -9.293983459472656
desired expected reward: 203.24664306640625



buy possibilites: [-1] 
expected returns: [[174.24156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  6.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -49 

action type: buy - action 11.0
Learning step: -8.960932731628418
desired expected reward: 199.6664276123047






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  6.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11] -> size -> 23 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  6.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11] -> size -> 23 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.  0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11] -> size -> 23 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[155.67212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.  0.  6.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29. 16.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0. 10. 29.] 
adversary owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -8.60926628112793
desired expected reward: 165.63229370117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[143.25966]
 [141.86357]
 [152.98744]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.  0.  6.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 25. 29.  8.  4.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29. 16.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0. 10. 29.] 
adversary owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -7.698277473449707
desired expected reward: 145.7600555419922



buy possibilites: [-1] 
expected returns: [[176.77583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 6.  8.  3. 10.  0.  0.  0.  6.  8. 11.  0.  6.  0.  0. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 29.  8.  3.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [29. 16.  0.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0. 10. 29.] 
adversary owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -378.0 

action type: buy - action 6.0
Learning step: -22.015722274780273
desired expected reward: 119.84786224365234






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [29. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  0.  0.] 
cards in discard: [11.  0.  0.  0. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  3.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [11.  0.  0.  0. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 29.  8.  3.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  2. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[196.15608]
 [188.85378]
 [188.85378]
 [186.62611]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.] 
adversary owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -7.996063232421875
desired expected reward: 168.77976989746094



action possibilites: [-1] 
expected returns: [[147.33693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 15.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.] 
adversary owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -39 

action type: gain_card_n - action 9
Learning step: -7.333378791809082
desired expected reward: 166.6358184814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.99889]
 [141.47351]
 [135.88701]
 [141.92667]
 [152.89839]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 15.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.] 
adversary owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -6.510371685028076
desired expected reward: 140.82655334472656






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  0  3  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  0.  0. 10. 29.  1.  8. 29. 16.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[188.88368]
 [178.99983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 11.  0. 11.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -5.985336780548096
desired expected reward: 146.91305541992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[178.45016]
 [181.23984]
 [181.51025]
 [176.66533]
 [185.09366]
 [181.88747]
 [182.15787]
 [192.01895]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 11.  0. 11.  0. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -7.446157932281494
desired expected reward: 176.62368774414062



buy possibilites: [-1] 
expected returns: [[163.60393]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -78.0 

action type: buy - action 0.0
Learning step: -9.141419410705566
desired expected reward: 169.30873107910156






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 16  0 29  0  8  1  8  0  3 10  0  0 11  1  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  1. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [ 6. 10.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[120.5394 ]
 [111.78855]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  6.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0. 16.] 
adversary cards in discard: [8. 8. 0. 1.] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1
Learning step: -7.492892742156982
desired expected reward: 156.1110382080078



action possibilites: [-1. 10.] 
expected returns: [[111.87735]
 [106.53018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  6. 10.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0. 16.] 
adversary cards in discard: [8. 8. 0. 1.] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action 10.0
Learning step: -3.906078815460205
desired expected reward: 105.65574645996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.21147]
 [102.2404 ]
 [111.48474]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  6. 10.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  3.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0. 16.] 
adversary cards in discard: [8. 8. 0. 1.] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1.0
Learning step: -4.084239959716797
desired expected reward: 107.79312133789062



buy possibilites: [-1] 
expected returns: [[115.683685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0.  6. 10.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  2.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0. 16.] 
adversary cards in discard: [8. 8. 0. 1.] 
adversary owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -329.0 

action type: buy - action 6.0
Learning step: -18.959136962890625
desired expected reward: 83.28126525878906






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [29. 29.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0. 16.] 
cards in discard: [8. 8. 0. 1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  2.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 16.  0.] 
cards in discard: [8. 8. 0. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 25. 29.  8.  2.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [8. 8. 0. 1. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29  0 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 25. 29.  8.  2.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 8. 0. 1. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 16.] 
owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 28. 30. 25. 29.  8.  1.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
adversary victory points: -4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 8. 0. 1. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 16.] 
owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 25. 29.  8.  1.  8.  5.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
adversary victory points: -4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 16.] 
owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
adversary owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
adversary victory points: -4
player victory points: -1 





Player: 0 
cards in hand: [0. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[106.03566]
 [ 95.45306]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 8.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6
 10  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
adversary owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6 11] -> size -> 18 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: -5.437892436981201
desired expected reward: 110.24579620361328



action possibilites: [-1] 
expected returns: [[159.89403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
adversary owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6 11] -> size -> 18 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: trash_cards_n_from_hand - action 1
Learning step: -2.9077045917510986
desired expected reward: 97.19869232177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[145.38799]
 [146.6826 ]
 [144.51833]
 [153.0403 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
adversary owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6 11] -> size -> 18 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -6.146585464477539
desired expected reward: 153.7474365234375



buy possibilites: [-1] 
expected returns: [[190.23921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10. 11.  0. 11.  0. 15.  0.  0.  8.  3.  0.  0.  6. 10.  6.  3.  0.  6.
 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 1. 0. 8. 0.] 
adversary cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
adversary owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6 11] -> size -> 18 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5.   0.  -5. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -60.0 

action type: buy - action 0.0
Learning step: -5.989017963409424
desired expected reward: 139.39898681640625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 8. 0.] 
cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 16  0 29  0  8  1  8  0 10  0  0  1  8  0  8  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6  0] -> size -> 27 
adversary victory points: -5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6  0] -> size -> 27 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6  0] -> size -> 27 
adversary victory points: -5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 8.  8.  0.  1.  0.  0.  6. 11. 29. 29. 16.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6  0] -> size -> 27 
adversary victory points: -5
player victory points: -1 





Player: 0 
cards in hand: [10.  8.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[88.19781]
 [82.18854]
 [82.02921]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  6.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3 11  6 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10
  0  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11  0] -> size -> 17 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1
Learning step: -10.10533332824707
desired expected reward: 180.13388061523438



action possibilites: [-1] 
expected returns: [[137.43913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11  0] -> size -> 17 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: trash_cards_n_from_hand - action 3
Learning step: -1.457328200340271
desired expected reward: 70.5368423461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.24145]
 [124.565  ]
 [138.21992]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11  0] -> size -> 17 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -19 

action type: take_action - action -1
Learning step: -4.856550693511963
desired expected reward: 132.58258056640625






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 29  0  8  8  0 10  0  0  1  8  0  8  6 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [8. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: -1 





Player: 0 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[127.856544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [8. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  6.  0.  8.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1.0
Learning step: -6.002444744110107
desired expected reward: 132.21751403808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[109.68301]
 [112.61604]
 [112.90037]
 [107.79677]
 [116.62009]
 [113.57219]
 [124.80251]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [8. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  6.  0.  8.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -5.677047252655029
desired expected reward: 121.3697738647461



buy possibilites: [-1] 
expected returns: [[130.9723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [ 8.  6.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [29.  6.  0.  8.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -21 

action type: buy - action 10.0
Learning step: -3.7817330360412598
desired expected reward: 109.79046630859375






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [29.  6.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  8.  0.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10] -> size -> 26 
adversary victory points: -4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  8.  0.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10] -> size -> 26 
adversary victory points: -4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  8.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0. 11.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10] -> size -> 26 
adversary victory points: -4
player victory points: -1 





Player: 0 
cards in hand: [11. 10.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[135.74936]
 [128.81413]
 [125.67708]
 [128.81413]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11.  0.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  1.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.] 
adversary owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0  0] -> size -> 15 
adversary victory points: -1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: buy - action -1
Learning step: -5.6083807945251465
desired expected reward: 125.36392211914062



action possibilites: [-1] 
expected returns: [[102.361244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.] 
adversary owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0  0] -> size -> 15 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -330 

action type: gain_card_n - action 3
Learning step: -20.31294822692871
desired expected reward: 102.00857543945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 99.62156 ]
 [102.105644]
 [112.06545 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  0.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  1.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.] 
adversary owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0  0] -> size -> 15 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1
Learning step: -4.2229204177856445
desired expected reward: 98.13832092285156






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  8. 11.] 
cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 16 29  8  8  0  1  8  0  8  6 11  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 0.  8.  0. 29.  6.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 





Player: 0 
cards in hand: [ 6. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[152.28989]
 [144.76949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  6.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1.0
Learning step: -4.781417369842529
desired expected reward: 107.28404998779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[144.75444]
 [147.13803]
 [154.99261]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  6.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -6.632631778717041
desired expected reward: 143.7262420654297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  8.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  6.  3. 15.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.  6. 10.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  6.  3. 15.  0.] 
adversary cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.  6. 10.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  6.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[82.123634]
 [75.06946 ]
 [75.860176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 15.  0.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.  6. 10.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [ 8. 11.  8.  8. 16.] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1.0
Learning step: -8.476943969726562
desired expected reward: 146.51565551757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[66.894966]
 [75.99011 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  3. 15.  0.] 
cards in discard: [ 8.  6.  6. 10.  0.  0.  3.  0.  6.  6. 11. 10.  0. 11.  0.  6. 10.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  1.] 
adversary cards in discard: [ 8. 11.  8.  8. 16.] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -4.97333288192749
desired expected reward: 77.15029907226562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  1.] 
cards in discard: [ 8. 11.  8.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8. 11.  8.  8. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8. 11.  8.  8. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
adversary victory points: -5
player victory points: -1 





Player: 0 
cards in hand: [ 3.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[150.8228 ]
 [141.9759 ]
 [142.15175]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [16.  0.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: buy - action -1.0
Learning step: -3.0238735675811768
desired expected reward: 72.96622467041016



action possibilites: [-1.  8.] 
expected returns: [[129.31401 ]
 [120.299446]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 11 10  6 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6
  0 10  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [16.  0.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action 10.0
Learning step: -5.5802531242370605
desired expected reward: 135.71737670898438



action possibilites: [-1.] 
expected returns: [[126.3405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [16.  0.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: trash_cards_n_from_hand - action 5
Learning step: -3.302137851715088
desired expected reward: 109.59384155273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[112.616005]
 [115.58763 ]
 [125.2594  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [16.  0.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -4.124520301818848
desired expected reward: 122.21598052978516






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [16.  0.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  8  8  1  8  0  8  6 11  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
adversary victory points: -5
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  1  8  0  8 11  0  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
adversary victory points: -5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  1  8  0  8 11  0  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 25. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
adversary victory points: -5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  6.] 
adversary cards in discard: [10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [ 6. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[105.88245 ]
 [ 99.122215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  6.] 
cards in discard: [10.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  1. 29.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -7.424098968505859
desired expected reward: 117.83526611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 92.96175]
 [ 95.87543]
 [106.26718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  6.] 
cards in discard: [10.  8.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  1. 29.  0.  0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -6.56423282623291
desired expected reward: 99.86815643310547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [11.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  0.  0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.  0.  0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0. 10.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
adversary victory points: -5
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[100.44274]
 [ 96.19026]
 [ 94.04146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -6.670825481414795
desired expected reward: 99.59636688232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 95.67264 ]
 [ 97.51598 ]
 [ 97.60651 ]
 [ 99.864685]
 [ 97.97456 ]
 [103.33817 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  4.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -6.160407543182373
desired expected reward: 91.96785736083984



buy possibilites: [-1] 
expected returns: [[98.623795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -52 

action type: buy - action 11.0
Learning step: -5.3741984367370605
desired expected reward: 94.490478515625






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  0  8 11  0  0  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  6. 10.  6.  6.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  6. 10.  6.  6.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  6. 10.  6.  6.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [ 8.  6. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[93.93223]
 [84.64932]
 [84.86909]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  6.  6.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11. 29.] 
adversary cards in discard: [8. 0. 8. 8.] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1
Learning step: -6.490817546844482
desired expected reward: 92.13298034667969



action possibilites: [-1.  8.] 
expected returns: [[111.41962 ]
 [101.938866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 6. 0.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11. 29.] 
adversary cards in discard: [8. 0. 8. 8.] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -49 

action type: take_action - action 10.0
Learning step: -4.111918926239014
desired expected reward: 77.6614761352539





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.41914]
 [114.5044 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 6. 0.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11. 29.] 
adversary cards in discard: [8. 0. 8. 8.] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1.0
Learning step: -5.639144420623779
desired expected reward: 105.78048706054688






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11. 29.] 
cards in discard: [8. 0. 8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10. 10.  8.  6.
  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 11. 29.] 
cards in discard: [8. 0. 8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10. 10.  8.  6.
  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 11. 29.] 
cards in discard: [8. 0. 8. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  0.  3.] 
adversary cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10. 10.  8.  6.
  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[77.849686]
 [68.78539 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  3.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10. 10.  8.  6.
  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -7.550270080566406
desired expected reward: 106.95413208007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[64.117325]
 [67.37595 ]
 [78.06003 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.  3.] 
cards in discard: [10.  8.  0.  0.  6. 11.  0.  0.  6. 11.  0.  0. 11.  0. 10. 10.  8.  6.
  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -5.775000095367432
desired expected reward: 72.0746841430664



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
adversary victory points: -5
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[125.97162]
 [118.26713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  8.  3. 11.] 
adversary cards in discard: [8. 0. 0. 0. 1.] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -4.67104959487915
desired expected reward: 73.38899230957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[114.76077]
 [125.5167 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  8.  3. 11.] 
adversary cards in discard: [8. 0. 0. 0. 1.] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -6.986672401428223
desired expected reward: 117.40975952148438



buy possibilites: [-1] 
expected returns: [[127.04239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  6. 10.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  8.  3. 11.] 
adversary cards in discard: [8. 0. 0. 0. 1.] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5.   0.  -5. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -100.0 

action type: buy - action 0.0
Learning step: -7.680828094482422
desired expected reward: 107.0799560546875






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  8.  3. 11.] 
cards in discard: [8. 0. 0. 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 3.] 
cards in discard: [ 8.  0.  0.  0.  1. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 3.] 
cards in discard: [ 8.  0.  0.  0.  1. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 3.] 
cards in discard: [ 8.  0.  0.  0.  1. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[128.499  ]
 [117.68847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10  0] -> size -> 15 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1
Learning step: -7.179486274719238
desired expected reward: 119.86289978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[111.99782]
 [115.22487]
 [125.76815]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10  0] -> size -> 15 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -6.934085369110107
desired expected reward: 115.60127258300781



buy possibilites: [-1] 
expected returns: [[112.85773]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  6.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10  0] -> size -> 15 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5.   0.  -5. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -100.0 

action type: buy - action 0.0
Learning step: -8.060591697692871
desired expected reward: 103.93722534179688






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  1  8  8 11  0  0  0  0  3  0 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0. 11. 10.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[84.92526]
 [77.49864]
 [77.49864]
 [73.6788 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 10.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1
Learning step: -7.3987135887146
desired expected reward: 105.45901489257812



action possibilites: [-1] 
expected returns: [[68.67525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -34 

action type: gain_card_n - action 8
Learning step: -3.705886125564575
desired expected reward: 67.3156967163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[54.807877]
 [58.195297]
 [69.33511 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 24. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -50 

action type: take_action - action -1
Learning step: -4.5184550285339355
desired expected reward: 64.15679168701172



buy possibilites: [-1] 
expected returns: [[102.53653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 0.] 
adversary owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -31 

action type: buy - action 3.0
Learning step: -2.1526925563812256
desired expected reward: 56.042598724365234






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  8.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 10.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  1  8  8 11  0  0  0  3  0 10  0  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 10.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1  8  8 11  0  3  0 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 10.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1  8  8 11  0  3  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 10.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1  8  8 11  0  3  0 10  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 10.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
adversary victory points: -4
player victory points: 1 





Player: 0 
cards in hand: [ 0.  8.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[41.389023]
 [36.02144 ]
 [36.02144 ]
 [36.10804 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  6. 10.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10 15  8  8  0  3  0  0  6  6  6 11  6 10  0  6  0 10
  6 11  0  0 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8 11  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -7.213307857513428
desired expected reward: 95.3232192993164



action possibilites: [-1] 
expected returns: [[78.0791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8 11  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: trash_cards_n_from_hand - action 6
Learning step: -1.4508850574493408
desired expected reward: 34.70240783691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[61.47035]
 [77.85112]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8 11  0  3  0 10  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -3.6908576488494873
desired expected reward: 74.38824462890625






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8 11  0  3  0 10  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 30. 23. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 22. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[46.74526 ]
 [41.593315]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3] -> size -> 11 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1.0
Learning step: -5.784364223480225
desired expected reward: 72.06675720214844



action possibilites: [-1] 
expected returns: [[69.68225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3] -> size -> 11 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -22 

action type: gain_card_n - action 8
Learning step: -1.492201566696167
desired expected reward: 37.708839416503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[54.795914]
 [56.167225]
 [56.257626]
 [57.956226]
 [56.547794]
 [61.77015 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  6.  6.  0.  6. 10.  0.  0.  6. 15.  6.  0. 15.  3. 11.  0. 11. 10.
  0.  8.  8. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 30. 22. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3] -> size -> 11 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1
Learning step: -4.07076358795166
desired expected reward: 65.61148834228516






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [3. 8. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 22. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [3. 8. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 22. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [3. 8. 0. 1. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[69.24663 ]
 [61.921944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -4.7220659255981445
desired expected reward: 50.40946960449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[58.860752]
 [61.263947]
 [69.14724 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -5.272193431854248
desired expected reward: 61.238800048828125



buy possibilites: [-1] 
expected returns: [[54.066734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -98.0 

action type: buy - action 0.0
Learning step: -6.626536846160889
desired expected reward: 52.23421859741211






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15  0] -> size -> 30 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15  0] -> size -> 30 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [15.  3.  8.  6.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15  0] -> size -> 30 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [15.  3.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[102.52609]
 [ 96.09278]
 [ 95.25767]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  8.  6.  0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10 15  8  8  0  3  0  0  6  6 11  6 10  0  6  0 10  6 11
  0  0 15  3 15  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -3.947211503982544
desired expected reward: 50.11952209472656



action possibilites: [-1] 
expected returns: [[97.84501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15
  3 15  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: trash_cards_n_from_hand - action 11
Learning step: -4.944653511047363
desired expected reward: 89.9786605834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[84.64866]
 [97.2602 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15
  3 15  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [8. 3. 8. 3. 3.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -5.210567474365234
desired expected reward: 92.63444519042969






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 3. 3.] 
cards in discard: [10.  1.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11. 15.  8. 10.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15
  3 15  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 3. 3.] 
cards in discard: [10.  1.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11. 15.  8. 10.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15
  3 15  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 3. 3.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [ 0. 11. 15.  8. 10.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15
  3 15  0] -> size -> 27 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8. 10.] 
expected returns: [[121.51137 ]
 [114.27493 ]
 [112.00809 ]
 [110.775314]
 [111.03406 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  8. 10.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15
  3 15  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -5.758382320404053
desired expected reward: 91.50181579589844



action possibilites: [-1] 
expected returns: [[23.645332]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action 15.0
Learning step: -7.249135494232178
desired expected reward: 100.37397003173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[14.767154]
 [16.8739  ]
 [17.042456]
 [19.685158]
 [17.513609]
 [24.53974 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3
 15  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  4. 10.  7.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -3.133923292160034
desired expected reward: 20.511409759521484



buy possibilites: [-1] 
expected returns: [[61.185497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3
 15  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [1. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -30 

action type: buy - action 10.0
Learning step: -0.9990068674087524
desired expected reward: 16.514602661132812






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11. 15.  0.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10.] 
adversary owned cards: [ 0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3
 15  0 10] -> size -> 27 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11. 15.  0.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10.] 
adversary owned cards: [ 0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3
 15  0 10] -> size -> 27 
adversary victory points: -3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 15.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[10.106284 ]
 [ 7.9233084]
 [ 7.2360687]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  0.  6.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3
 15  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [1. 0. 0. 0. 8.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -6.269248962402344
desired expected reward: 54.9162483215332



action possibilites: [-1] 
expected returns: [[35.776733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [1. 0. 0. 0. 8.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action 15.0
Learning step: -1.9371122121810913
desired expected reward: 4.9046630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[32.592037]
 [33.34399 ]
 [33.372925]
 [33.37257 ]
 [34.641193]
 [34.996513]
 [32.990456]
 [33.52787 ]
 [33.787106]
 [37.980824]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [1. 0. 0. 0. 8.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1
Learning step: -3.400585174560547
desired expected reward: 32.37614822387695






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [1. 0. 0. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [1. 0. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [1. 0. 0. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 21. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [1. 0. 0. 0. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[49.10317 ]
 [46.241104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [3. 1. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.748633861541748
desired expected reward: 33.2321891784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[41.424294]
 [42.195564]
 [42.285007]
 [43.52254 ]
 [42.51043 ]
 [45.99148 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [3. 1. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -5.305327892303467
desired expected reward: 42.48129653930664



buy possibilites: [-1] 
expected returns: [[32.46806]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  8.  0. 10. 15. 11.  8. 10. 15. 11.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [3. 1. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -60 

action type: buy - action 1.0
Learning step: -4.049087047576904
desired expected reward: 31.543270111083984






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[20.83042 ]
 [17.257778]
 [18.425455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [3. 1. 0. 8. 8.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -5.120833873748779
desired expected reward: 27.347225189208984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[14.159495]
 [15.292341]
 [19.01605 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [3. 1. 0. 8. 8.] 
adversary owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.490024566650391
desired expected reward: 14.900033950805664



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [3. 1. 0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3  0 10  0  0  0  3  3  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [3. 1. 0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8  3 10  0  3  3  0  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [3. 1. 0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8  3 10  0  3  3  0  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11. 10.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[29.386583]
 [26.158724]
 [24.765371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  6.  0.] 
cards in discard: [ 8.  0.  0. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3 10  0  3  3  0  3] -> size -> 11 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -4.236937999725342
desired expected reward: 14.779108047485352





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.844004]
 [23.304316]
 [28.317715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  6.  0.] 
cards in discard: [ 8.  0.  0. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  3.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8  8  3 10  0  3  3  0  3] -> size -> 11 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -4.7897562980651855
desired expected reward: 24.452856063842773



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8  3 10  0  3  3  0  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  1.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8 10  0  3  0  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  1.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8 10  0  3  0  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  1.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1  8  8 10  0  3  0  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  1.  0. 10.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[77.24266 ]
 [70.837326]
 [71.00053 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  0. 10.] 
cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [ 0.  8.  0. 10.] 
adversary owned cards: [ 8  1  8  8 10  0  3  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1.0
Learning step: -2.7062103748321533
desired expected reward: 25.611501693725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[69.7926  ]
 [71.6473  ]
 [71.8105  ]
 [71.778984]
 [74.15543 ]
 [74.683044]
 [70.88581 ]
 [72.24106 ]
 [72.800186]
 [79.22057 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  0. 10.] 
cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [ 0.  8.  0. 10.] 
adversary owned cards: [ 8  1  8  8 10  0  3  0  3  0] -> size -> 10 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -4.959870338439941
desired expected reward: 69.74887084960938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 8.] 
cards in discard: [ 0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8  8 10  0  3  0  3  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8 10  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8 10  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  8 10  0  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.] 
adversary owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 15.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[43.33372]
 [37.9095 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  6.  0.] 
cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  8.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8 10  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1.0
Learning step: -4.997673511505127
desired expected reward: 74.22289276123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[34.95097 ]
 [36.89184 ]
 [44.046104]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  6.  0.] 
cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  8.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8 10  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -3.021111249923706
desired expected reward: 37.38930892944336



Player 1 won the game! 



Player 0 bought cards:
Copper: 11 
Silver: 1 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 4 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 15.  3.  6.  0.] 
cards in discard: [ 8.  0.  0. 11.  6.  0. 11. 10.  6.  0.  0.  8.  1.  0. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  8  8  0  0  0  6 11  6 10  0  6  0 10  6 11  0  0 15  3 15
  0 10  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 27. 30. 20. 29.  8.  0.  8.  3.  0. 10.  8.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  8.  0. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  8 10  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5 -500   -3  -30    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -568 

action type: buy - action 0.0
Learning step: -30.147550582885742
desired expected reward: 4.803422927856445



