 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.454287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -469 

action type: gain_card_n - action 8
Learning step: -14.809268951416016
desired expected reward: 9.833032608032227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.368927]
 [20.05698 ]
 [19.1659  ]
 [16.042248]
 [18.816223]
 [22.062584]
 [21.265614]
 [21.943375]
 [18.916943]
 [20.374535]
 [20.604996]
 [20.855192]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5631351470947266
desired expected reward: 20.31679916381836



buy possibilites: [-1] 
expected returns: [[19.856142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4925783574581146
desired expected reward: 17.87635040283203






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.745016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5144791603088379
desired expected reward: 19.341663360595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.955873]
 [21.64393 ]
 [20.75285 ]
 [17.607203]
 [23.649534]
 [22.852564]
 [21.961481]
 [22.44214 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5815131068229675
desired expected reward: 21.438020706176758



buy possibilites: [-1] 
expected returns: [[23.020796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.07776769250631332
desired expected reward: 23.571765899658203






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.032228]
 [23.239622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5981990098953247
desired expected reward: 22.422595977783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.79325 ]
 [20.590218]
 [17.445509]
 [22.689936]
 [22.279512]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6005590558052063
desired expected reward: 21.76308250427246



buy possibilites: [-1] 
expected returns: [[22.797415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.3513251543045044
desired expected reward: 22.338607788085938






Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.309458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6191475987434387
desired expected reward: 22.178266525268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.153975]
 [19.784187]
 [18.919891]
 [15.93736 ]
 [18.581827]
 [21.785007]
 [20.988037]
 [21.665796]
 [18.67919 ]
 [20.096952]
 [20.327417]
 [20.577612]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5530456900596619
desired expected reward: 19.90169906616211



buy possibilites: [-1] 
expected returns: [[21.521427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 11.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [10.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.4425751864910126
desired expected reward: 21.342430114746094






Player: 1 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [10.  0.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [10.  0.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [10.  0.  0. 10.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[22.101145]
 [22.511566]
 [23.308538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5536328554153442
desired expected reward: 20.96779441833496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.933271]
 [21.579433]
 [20.7061  ]
 [17.65569 ]
 [23.585041]
 [22.788073]
 [21.89699 ]
 [22.377647]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.592693030834198
desired expected reward: 21.78297233581543



buy possibilites: [-1] 
expected returns: [[22.978588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.016107844188809395
desired expected reward: 21.56332778930664






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [ 1.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [ 1.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [ 1.  8.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.539503]
 [24.746897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [ 1.  8.  0. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.58307284116745
desired expected reward: 22.39551544189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.630693]
 [23.318745]
 [22.427662]
 [19.28202 ]
 [25.32435 ]
 [24.527382]
 [23.636297]
 [24.116957]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [ 1.  8.  0. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6138505935668945
desired expected reward: 23.069786071777344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [0. 0. 3. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 0.  0.  3.  3.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 0.  0.  3.  3.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 0.  0.  3.  3.  3.  0. 29. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.468792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5854452848434448
desired expected reward: 22.892576217651367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.235128]
 [24.916042]
 [24.022655]
 [20.911682]
 [23.6776  ]
 [26.908607]
 [26.121078]
 [26.787579]
 [23.770796]
 [25.22769 ]
 [25.451714]
 [25.68149 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6540659666061401
desired expected reward: 24.955018997192383



buy possibilites: [-1] 
expected returns: [[26.48831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.37779921293258667
desired expected reward: 24.055400848388672






Player: 1 
cards in hand: [ 3.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [16.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [16.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  9.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [16.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [16.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.413275]
 [25.852865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [16.  1.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  0.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6744875907897949
desired expected reward: 25.81382179260254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.482594]
 [25.16351 ]
 [24.27012 ]
 [21.13671 ]
 [27.156075]
 [26.368547]
 [25.475157]
 [25.928957]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [16.  1.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  7.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  0.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6480193734169006
desired expected reward: 24.81791114807129



buy possibilites: [-1] 
expected returns: [[26.544113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [16.  1.  0.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  0.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.14596904814243317
desired expected reward: 27.01010513305664






Player: 1 
cards in hand: [ 0. 29.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3.  0.] 
cards in discard: [ 8. 10.  3.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 11.] 
adversary cards in discard: [16.  1.  0.  3.  3.  0. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  3.  0.] 
cards in discard: [ 8. 10.  3.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 11.] 
adversary cards in discard: [16.  1.  0.  3.  3.  0. 11.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[25.506351]
 [26.733467]
 [26.733467]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 11.] 
cards in discard: [16.  1.  0.  3.  3.  0. 11.  8.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3. 25.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6683955788612366
desired expected reward: 25.875717163085938



action possibilites: [-1] 
expected returns: [[26.714314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [16.  1.  0.  3.  3.  0. 11.  8.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3. 25.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.16970661282539368
desired expected reward: 27.862829208374023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.583355]
 [26.26427 ]
 [25.370884]
 [22.237474]
 [28.256838]
 [27.469309]
 [26.57592 ]
 [27.029722]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [16.  1.  0.  3.  3.  0. 11.  8.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3. 25.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07391292601823807
desired expected reward: 26.640399932861328



buy possibilites: [-1] 
expected returns: [[25.609318]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [16.  1.  0.  3.  3.  0. 11.  8.  0.  0.  3.  0. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3. 25.] 
adversary cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.017771301791071892
desired expected reward: 25.388654708862305






Player: 1 
cards in hand: [11.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3. 25.] 
cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3. 25.] 
cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8. 10.  9.  6.  8.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3. 25.] 
cards in discard: [ 8. 10.  3.  0. 10.  0.  0.  0. 29.  1.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.296013]
 [27.523129]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6337361335754395
desired expected reward: 24.975582122802734



action possibilites: [-1] 
expected returns: [[28.137508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.24758416414260864
desired expected reward: 25.842906951904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.377335]
 [28.058249]
 [27.164862]
 [24.031454]
 [26.81981 ]
 [30.050816]
 [29.263288]
 [29.929787]
 [26.913006]
 [28.369898]
 [28.593924]
 [28.8237  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09694124013185501
desired expected reward: 28.04056739807129



buy possibilites: [-1] 
expected returns: [[28.970224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0. 11. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 15.0
Learning step: 0.8596138954162598
desired expected reward: 29.453535079956055






Player: 1 
cards in hand: [29.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1 15] -> size -> 21 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0.] 
cards in discard: [14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1 15] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10.  0.] 
cards in discard: [14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1 15] -> size -> 21 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 10.  0.] 
cards in discard: [14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1 15] -> size -> 21 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[27.217915]
 [27.68469 ]
 [25.310339]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 16.  0.] 
cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 11  8 11  1 16 11 10  3  1 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [14.  0. 11. 29.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7355656623840332
desired expected reward: 28.23465919494629



action possibilites: [-1] 
expected returns: [[22.379438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [14.  0. 11. 29.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.1900305151939392
desired expected reward: 28.977123260498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.507582]
 [18.26352 ]
 [22.806782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 15. 11.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [14.  0. 11. 29.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0010708809131756425
desired expected reward: 22.378368377685547






Player: 1 
cards in hand: [8. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [14.  0. 11. 29.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [14.  0. 11. 29.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  6.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  5.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [ 1. 15. 11.  0.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.336872]
 [22.59733 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [ 1. 15. 11.  0.  0.  0.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  5.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 25.  3.  8.] 
adversary cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.  8.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6013811826705933
desired expected reward: 22.205398559570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.127085]
 [19.878794]
 [16.956833]
 [21.981691]
 [21.500992]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [ 1. 15. 11.  0.  0.  0.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  5.  7.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 25.  3.  8.] 
adversary cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.  8.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5792882442474365
desired expected reward: 20.837980270385742



buy possibilites: [-1] 
expected returns: [[26.511683]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [ 1. 15. 11.  0.  0.  0.  0.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 25.  3.  8.] 
adversary cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.  8.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.2910781800746918
desired expected reward: 21.690616607666016






Player: 1 
cards in hand: [ 0.  3. 25.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  3.  8.] 
cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.  8.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  3.  8.] 
cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.  8.  3.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  3.  8.] 
cards in discard: [14.  0. 11. 29.  0. 10.  0. 11.  8.  3.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[25.41614 ]
 [24.997717]
 [26.676596]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6723127961158752
desired expected reward: 25.83936882019043



action possibilites: [-1] 
expected returns: [[26.631182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.16899101436138153
desired expected reward: 27.85687255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.781948]
 [26.460829]
 [25.561705]
 [22.437618]
 [28.444357]
 [27.664606]
 [26.76548 ]
 [27.183903]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06943685561418533
desired expected reward: 26.561744689941406



buy possibilites: [-1] 
expected returns: [[25.595037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.] 
cards in discard: [10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.455783486366272
desired expected reward: 27.221263885498047






Player: 1 
cards in hand: [25.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8. 10.  9.  5.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  1.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  5.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  1.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  5.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  1.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  8.  3.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  8.  1.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[21.868841]
 [23.115374]
 [22.33562 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  8.  1.] 
cards in discard: [10. 10. 11.  0.  1.  3. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.680680274963379
desired expected reward: 15.91435718536377





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.924864]
 [21.476833]
 [20.64302 ]
 [17.765764]
 [23.36814 ]
 [22.610655]
 [21.76069 ]
 [22.153727]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  8.  1.] 
cards in discard: [10. 10. 11.  0.  1.  3. 10.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5794158577919006
desired expected reward: 21.309844970703125



buy possibilites: [-1] 
expected returns: [[20.948248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  8.  1.] 
cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.04286407306790352
desired expected reward: 21.717824935913086






Player: 1 
cards in hand: [ 8.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  6.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  5.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.882566]
 [23.340342]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  5.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5352964997291565
desired expected reward: 20.41295051574707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.93085 ]
 [22.484232]
 [21.638264]
 [18.850702]
 [21.324722]
 [24.381985]
 [23.641178]
 [24.253878]
 [21.394735]
 [22.770159]
 [22.96999 ]
 [23.12233 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  5.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5951752066612244
desired expected reward: 22.19854164123535



buy possibilites: [-1] 
expected returns: [[21.636892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [10. 10. 11.  0.  1.  3. 10.  6. 10.  3.  0. 11.  8.  1. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.47091731429100037
desired expected reward: 22.299240112304688






Player: 1 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 15.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9.  9.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 15.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8.  9.  8.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 15.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 29. 30.  8.  9.  8.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 15.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [11. 25.  0.  0.  0. 10.  8.  3.  8. 10.  8.  0.  0.  0.  3. 16. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 15.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[23.946684]
 [23.795298]
 [25.199629]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  9.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16 16] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5414471626281738
desired expected reward: 21.09544563293457



action possibilites: [-1] 
expected returns: [[21.859224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  9.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16 16] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.24864932894706726
desired expected reward: 23.611066818237305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.819607]
 [17.594954]
 [22.092201]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 29. 30.  8.  9.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16 16] -> size -> 27 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.007235812954604626
desired expected reward: 21.8664608001709



buy possibilites: [-1] 
expected returns: [[25.844639]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  0.] 
cards in discard: [1. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16 16] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.806479454040527
desired expected reward: 8.788474082946777






Player: 1 
cards in hand: [ 8. 11.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 11 10  1  0 29 25  8  8 14  0 11  0 11
  8 16 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [1. 3. 1. 0. 3.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [1. 3. 1. 0. 3.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [1. 3. 1. 0. 3.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [1. 3. 1. 0. 3.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [1. 3. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.978668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0. 3.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7156018614768982
desired expected reward: 25.129037857055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.397291]
 [19.883514]
 [19.073923]
 [17.142305]
 [16.406141]
 [18.77282 ]
 [21.694187]
 [20.977896]
 [22.964613]
 [21.568027]
 [18.83954 ]
 [18.16513 ]
 [20.152777]
 [16.741787]
 [20.340588]
 [20.48398 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 3.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5374313592910767
desired expected reward: 19.43754768371582



buy possibilites: [-1] 
expected returns: [[18.657274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 3.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.41560396552085876
desired expected reward: 19.46790885925293






Player: 1 
cards in hand: [16. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 29. 30.  8.  8.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11. 10. 10.  8.  0.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1] -> size -> 27 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11. 10. 10.  8.  0.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1] -> size -> 27 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.] 
cards in discard: [0. 8. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [11. 10. 10.  8.  0.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1] -> size -> 27 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 10. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.  8.] 
expected returns: [[18.354038]
 [19.484604]
 [18.043232]
 [18.043232]
 [18.81276 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  8.  0.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 10.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5130009055137634
desired expected reward: 18.14427375793457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.420805]
 [14.675528]
 [18.31663 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  8.  0.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 10.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5237998962402344
desired expected reward: 17.830238342285156



buy possibilites: [-1] 
expected returns: [[16.521925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  8.  0.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 10.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.46914392709732056
desired expected reward: 15.951661109924316






Player: 1 
cards in hand: [ 0.  3.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 10.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0. 11. 10. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0] -> size -> 28 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29. 10.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 29. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0. 11. 10. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0] -> size -> 28 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29. 10.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0. 11. 10. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[14.5292015]
 [14.251961 ]
 [14.251961 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0. 11. 10. 10.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49465370178222656
desired expected reward: 16.027271270751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.746496]
 [13.9515  ]
 [13.292727]
 [11.126841]
 [15.449337]
 [14.858731]
 [14.173539]
 [14.4481  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0. 11. 10. 10.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 28. 30.  8.  7.  7.  4.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.43788281083106995
desired expected reward: 14.09131908416748



buy possibilites: [-1] 
expected returns: [[16.820425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 1.  6. 11.  6. 15.  3.  0.  1.  1.  3.  1.  0.  3.  0. 11. 10. 10.  8.
  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.10785818845033646
desired expected reward: 15.557196617126465






Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0 11] -> size -> 29 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[17.635416]
 [18.965815]
 [17.32506 ]
 [18.218935]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 11  8 11  1 11 10  3  1 15  8 10 10  6 10 10
  1  6  1  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0  1] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46334826946258545
desired expected reward: 16.35707664489746



action possibilites: [-1] 
expected returns: [[20.699839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0  1] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.20228250324726105
desired expected reward: 15.704476356506348





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.044918]
 [17.052235]
 [21.095242]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 28. 30.  8.  7.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0  1] -> size -> 29 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03344358503818512
desired expected reward: 20.7332820892334



buy possibilites: [-1] 
expected returns: [[19.919535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0  1] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.852412223815918
desired expected reward: 8.199822425842285






Player: 1 
cards in hand: [16.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0.  8.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0 29 25  8  8  0 11  0 11  8 16 16
  0  6  3  0  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  6. 11. 16.  0.  0.  3.  3.  0.  3.  0. 29. 10.  0.  1. 11.
  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [ 6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11  6] -> size -> 28 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[18.130926]
 [17.851923]
 [17.851923]
 [18.655157]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.  8.] 
cards in discard: [ 6.  8.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5561577677726746
desired expected reward: 19.36337661743164



action possibilites: [-1. 10.  8.] 
expected returns: [[19.88642 ]
 [19.594992]
 [20.433886]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8.  1.] 
cards in discard: [ 6.  8.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6
  1  0 11  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1250489056110382
desired expected reward: 17.979219436645508



action possibilites: [-1. 10.] 
expected returns: [[17.170336]
 [16.874952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 6.  8.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.7247279286384583
desired expected reward: 17.5353946685791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.337742]
 [16.84933 ]
 [16.005716]
 [13.378442]
 [18.722277]
 [17.987978]
 [17.122202]
 [17.418278]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 6.  8.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7136697173118591
desired expected reward: 17.884004592895508



buy possibilites: [-1] 
expected returns: [[17.954042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 6.  8.  0. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 10.0
Learning step: 1.2648513317108154
desired expected reward: 18.387052536010742






Player: 1 
cards in hand: [ 1.  0.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 11. 10.  6.  0.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10] -> size -> 28 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  3.  5.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 11. 10.  6.  0.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10] -> size -> 28 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 25.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  2.  5.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 11. 10.  6.  0.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10] -> size -> 28 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[14.347097]
 [15.359993]
 [14.113343]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.  6.  0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  2.  5.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5336681008338928
desired expected reward: 17.420373916625977



action possibilites: [-1] 
expected returns: [[16.459349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  6.  0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  2.  5.  9.  9.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.4112532138824463
desired expected reward: 16.463584899902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.76031 ]
 [16.012781]
 [15.321688]
 [13.07619 ]
 [17.62112 ]
 [16.979185]
 [16.244638]
 [16.498384]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  6.  0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 28. 30.  8.  6.  7.  2.  5.  9.  9.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12606392800807953
desired expected reward: 16.585412979125977



buy possibilites: [-1] 
expected returns: [[17.158745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  6.  0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  9.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.6909298896789551
desired expected reward: 16.703710556030273






Player: 1 
cards in hand: [11.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  9.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[14.972074]
 [14.763212]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  1.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5084328055381775
desired expected reward: 16.650312423706055



action possibilites: [-1.] 
expected returns: [[14.054821]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.15467925369739532
desired expected reward: 14.917891502380371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[12.008076 ]
 [13.239949 ]
 [12.559095 ]
 [10.967541 ]
 [10.372479 ]
 [12.3072605]
 [14.7446165]
 [14.154562 ]
 [15.818763 ]
 [14.624755 ]
 [12.35576  ]
 [11.791274 ]
 [13.458238 ]
 [10.625172 ]
 [13.603492 ]
 [13.671816 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.16988375782966614
desired expected reward: 14.22470474243164



buy possibilites: [-1] 
expected returns: [[11.032335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 5 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 3. 16.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.20559728145599365
desired expected reward: 12.21367073059082






Player: 1 
cards in hand: [ 3. 16.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  0.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15. 11.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.
 10.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  0.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15. 11.] 
adversary cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.
 10.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  3.  1. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
expected returns: [[ 9.808808]
 [10.729087]
 [ 9.748739]
 [10.729087]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1. 15. 11.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.
 10.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3723059296607971
desired expected reward: 10.660029411315918



action possibilites: [-1] 
expected returns: [[12.934721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15. 11.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.
 10.  3.  0.  0.  1.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 10
Learning step: 0.7771758437156677
desired expected reward: 10.398466110229492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.568927]
 [12.057882]
 [10.145808]
 [13.42446 ]
 [13.01753 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15. 11.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.
 10.  3.  0.  0.  1.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  5.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.19131024181842804
desired expected reward: 13.126030921936035



buy possibilites: [-1] 
expected returns: [[12.384094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15. 11.] 
cards in discard: [ 6.  8.  0. 10. 10. 10.  8.  0. 10.  1. 10.  1. 11.  1. 10.  6.  0.  0.
 10.  3.  0.  0.  1.  0. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [10.  0.  3. 11.  6.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.41729918122291565
desired expected reward: 13.841758728027344






Player: 1 
cards in hand: [10.  0.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  6.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  6.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [8. 3. 1. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [8. 3. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.906965]
 [15.441658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0. 10. 11.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3616311252117157
desired expected reward: 12.022462844848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.360735]
 [14.745231]
 [13.979178]
 [11.513124]
 [16.409515]
 [15.764786]
 [14.989851]
 [15.230094]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0. 10. 11.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44095686078071594
desired expected reward: 14.466009140014648



buy possibilites: [-1] 
expected returns: [[13.972962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 6.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 29.  8.  0.  0.] 
adversary cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0. 10. 11.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.40410593152046204
desired expected reward: 12.956628799438477






Player: 1 
cards in hand: [ 0. 29.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0. 10. 11.  0.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 6.  0. 10. 11.  0.] 
adversary cards in discard: [0. 8. 3. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0. 10. 11.  0.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 6.  0. 10. 11.  0.] 
adversary cards in discard: [0. 8. 3. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  0.  0.] 
cards in discard: [11.  1.  0.  0.  3. 25. 29.  0. 11.  3.  8.  0.  0.  3. 16.  8.  0.  0.
  0.  0. 10. 11.  0.  3.  6.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 6.  0. 10. 11.  0.] 
adversary cards in discard: [0. 8. 3. 1. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[12.889442]
 [12.660572]
 [14.019131]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10. 11.  0.] 
cards in discard: [0. 8. 3. 1. 0. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.428955078125
desired expected reward: 13.544007301330566



action possibilites: [-1. 11.] 
expected returns: [[14.227169]
 [15.32432 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.  0.] 
cards in discard: [0. 8. 3. 1. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  7.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.226480171084404
desired expected reward: 12.887052536010742



action possibilites: [-1.] 
expected returns: [[14.469191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 4
Learning step: 1.3336204290390015
desired expected reward: 12.911818504333496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.981073 ]
 [14.191362 ]
 [13.525451 ]
 [11.316491 ]
 [15.6537895]
 [15.076278 ]
 [14.402161 ]
 [14.57881  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  2.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7661089897155762
desired expected reward: 15.235300064086914



buy possibilites: [-1] 
expected returns: [[15.25185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -1  0  0 18  0] 
sum of rewards: 52 

action type: buy - action 11.0
Learning step: 1.25053071975708
desired expected reward: 16.904321670532227






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  8. 15.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16 11] -> size -> 36 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  8. 15.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16 11] -> size -> 36 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  8. 15.  0. 10.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16 11] -> size -> 36 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[12.156231]
 [12.606977]
 [12.117508]
 [11.994047]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  0. 10.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1
  0 11  6 10 10  1  0 15  8  0 16 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 29.  1.  0.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.47844383120536804
desired expected reward: 14.773406028747559



action possibilites: [-1] 
expected returns: [[11.928253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 29.  1.  0.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.21172142028808594
desired expected reward: 12.329229354858398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.454145]
 [11.510012]
 [10.923125]
 [ 9.014978]
 [10.706877]
 [12.783018]
 [12.287944]
 [12.675743]
 [10.747382]
 [11.696513]
 [11.815583]
 [11.852931]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11. 29.  1.  0.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2145245373249054
desired expected reward: 12.142777442932129



buy possibilites: [-1] 
expected returns: [[11.038094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0. 11. 29.  1.  0.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
  4.5  0. ] 
sum of rewards: 18.5 

action type: buy - action 10.0
Learning step: 0.32000455260276794
desired expected reward: 12.016518592834473






Player: 1 
cards in hand: [ 0. 11. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  1.  0.] 
cards in discard: [15.  0. 11.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 11.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  1.  0.] 
cards in discard: [15.  0. 11.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 11.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29.  1.  0.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 3. 10. 10. 11.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[11.692358]
 [11.514736]
 [11.514736]
 [12.742526]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  3.  0. 29.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15 14] -> size -> 34 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.35470834374427795
desired expected reward: 10.683384895324707



action possibilites: [-1] 
expected returns: [[10.763627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  3.  0. 29.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15 14] -> size -> 34 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0  0  0] 
sum of rewards: 13 

action type: gain_card_n - action 0
Learning step: 0.20045839250087738
desired expected reward: 10.285780906677246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 9.350952 ]
 [ 9.865069 ]
 [ 7.7889423]
 [11.30591  ]
 [10.848895 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 22. 30. 28. 30.  8.  6.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  3.  0. 29.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15 14] -> size -> 34 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23342201113700867
desired expected reward: 10.997049331665039



buy possibilites: [-1] 
expected returns: [[10.437633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  3.  3.  0. 29.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15 14] -> size -> 34 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -288.0 

action type: buy - action 6.0
Learning step: -8.764073371887207
desired expected reward: -0.9751315116882324






Player: 1 
cards in hand: [ 8.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  0. 29.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  0 29 25  8  8  0 11  0 11  8 16  0  6  3
  0  1 11 29  0  0  0  1 15 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  0. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6] -> size -> 38 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  0. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6] -> size -> 38 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 22. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [10. 11.  0. 10.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6] -> size -> 38 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[10.140819]
 [ 9.973169]
 [11.127943]
 [ 9.973169]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3532085716724396
desired expected reward: 10.084424018859863



action possibilites: [-1] 
expected returns: [[10.672457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0  9  0] 
sum of rewards: 20 

action type: gain_card_n - action 1
Learning step: 0.41886618733406067
desired expected reward: 10.192018508911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 9.290661 ]
 [10.36352  ]
 [ 9.776141 ]
 [ 7.8046174]
 [11.648269 ]
 [11.147573 ]
 [10.708339 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  1.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23917458951473236
desired expected reward: 10.91163158416748



buy possibilites: [-1] 
expected returns: [[12.1032715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 11.  3.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 11.0
Learning step: 0.6147451996803284
desired expected reward: 12.263012886047363






Player: 1 
cards in hand: [ 6.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  3.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11. 11. 10.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11] -> size -> 40 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  3.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  1.] 
adversary cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11. 11. 10.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11] -> size -> 40 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[13.385196]
 [13.875805]
 [13.241052]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  0.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11. 11. 10.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10  6 10 10  1  6  1  0
 11  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 16.  3. 10.  8.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.37055322527885437
desired expected reward: 11.732718467712402



action possibilites: [-1] 
expected returns: [[9.2888365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11. 11. 10.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 16.  3. 10.  8.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.19019262492656708
desired expected reward: 12.101531028747559





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[7.9739265]
 [8.9804125]
 [8.427829 ]
 [6.5607557]
 [9.737027 ]
 [9.288837 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11. 11. 10.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  4.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 16.  3. 10.  8.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26313894987106323
desired expected reward: 9.55197525024414



buy possibilites: [-1] 
expected returns: [[10.247079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [ 0.  8.  3.  1.  0.  6. 16. 11. 10. 11.  6.  0.  0.  0. 10. 15.  8.  0.
 10.  0.  6. 11.  3. 10. 10.  1.  1. 11. 11. 10.  0. 10.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  3.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 16.  3. 10.  8.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -5.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 8.0
Learning step: 0.17548349499702454
desired expected reward: 9.912510871887207






Player: 1 
cards in hand: [ 8. 16.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3. 10.  8.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  3.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 15. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1.  8. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.  8.  0.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  8  0 11  0 11  8 16  0  6  3  0  1
 11 29  0  0  0  1 15 14] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  3.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 15. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11
 29  0  0  0  1 15 14  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 15. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 15. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 21. 30. 28. 30.  8.  5.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 15. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 28. 30.  8.  5.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 8. 15. 10.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 10.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 15.] 
expected returns: [[12.605737]
 [13.107088]
 [12.584945]
 [12.458307]
 [12.584945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.  1. 15.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 28. 30.  8.  5.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 25.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.  0. 10. 16.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.32347458600997925
desired expected reward: 9.923604011535645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.078265]
 [11.595572]
 [ 9.463595]
 [13.086887]
 [12.585535]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 10.  1. 15.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 21. 30. 28. 30.  8.  5.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 25.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.  0. 10. 16.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4035690128803253
desired expected reward: 12.202166557312012



buy possibilites: [-1] 
expected returns: [[12.195435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 10.  1. 15.] 
cards in discard: [6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 21. 30. 28. 30.  8.  4.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  1. 25.] 
adversary cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.  0. 10. 16.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -311.0 

action type: buy - action 6.0
Learning step: -9.485855102539062
desired expected reward: -0.022260665893554688






Player: 1 
cards in hand: [ 0.  0.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 25.] 
cards in discard: [15.  0. 11.  0.  0.  0. 14.  0. 11. 29.  1.  0.  8.  3.  0.  6.  0.  0.
 11.  3.  8.  0. 10. 16.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 28. 30.  8.  4.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 10.  6. 11.  6.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6] -> size -> 41 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 16.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 28. 30.  8.  3.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 10.  6. 11.  6.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6] -> size -> 42 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 16.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 21. 30. 28. 30.  8.  3.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 10.  6. 11.  6.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6] -> size -> 42 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 16.  0.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 21. 30. 27. 30.  8.  3.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [16. 10.  6. 11.  6.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6] -> size -> 42 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [16. 10.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11.] 
expected returns: [[11.121313]
 [10.028261]
 [10.991702]
 [12.031555]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  6. 11.  6.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 27. 30.  8.  3.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -7    0 -300
    0    0] 
sum of rewards: -312 

action type: buy - action -1
Learning step: -9.607833862304688
desired expected reward: 2.5876007080078125



action possibilites: [-1. 16. 11.  8.] 
expected returns: [[11.622417]
 [10.522487]
 [12.53266 ]
 [12.06306 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 11.  6.  8.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0  8 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11
  6 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 27. 30.  8.  3.  6.  0.  2.  9.  8.  8. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.24472282826900482
desired expected reward: 11.236424446105957



action possibilites: [-1. 11.] 
expected returns: [[12.461801]
 [13.372044]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 27. 30.  8.  3.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -7  0  0 16  0] 
sum of rewards: 44 

action type: gain_card_n - action 7
Learning step: 1.1588513851165771
desired expected reward: 11.083250999450684



action possibilites: [-1] 
expected returns: [[11.856928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 16. 11.] 
owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5    0    0    0    0    0   60    0    0    0    0   -8    0 -300
    0    0] 
sum of rewards: -253 

action type: gain_card_n - action 3
Learning step: -7.813060760498047
desired expected reward: 3.7722244262695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.471201]
 [ 8.951895]
 [11.878951]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 16. 11.] 
owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.406883716583252
desired expected reward: 13.263811111450195



buy possibilites: [-1] 
expected returns: [[13.108019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10. 16. 11.] 
owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [11.  8.  0.  8. 14.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0 -9  0  0  0  0] 
sum of rewards: 46 

action type: buy - action 0.0
Learning step: 1.2022480964660645
desired expected reward: 11.715116500854492






Player: 1 
cards in hand: [11.  8.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  8. 14.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  0.  8. 10. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 44 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  8.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 44 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  8.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 44 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[10.547022]
 [11.011139]
 [11.011139]
 [10.437344]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  1 11 10  3  1 15  8 10 10 10 10  1  6  1  0 11  6
 10 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -9
     0 -1500   133     0] 
sum of rewards: -1381 

action type: discard_down_to_3_cards - action 1
Learning step: -41.528385162353516
desired expected reward: -34.46757507324219



action possibilites: [-1] 
expected returns: [[5.1824183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.19713251292705536
desired expected reward: 10.439894676208496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.2417374]
 [3.1726515]
 [5.29326  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  2.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.34122470021247864
desired expected reward: 5.5236430168151855



buy possibilites: [-1] 
expected returns: [[4.852407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [15.  0. 10.  8.  0.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0   -9    0 -300
    0    0] 
sum of rewards: -294 

action type: buy - action 6.0
Learning step: -8.864229202270508
desired expected reward: -5.691577911376953






Player: 1 
cards in hand: [15.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  8.  0.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0
  0  0  1 15 14  8  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3. 11. 11. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[8.359287]
 [9.268061]
 [9.268061]
 [8.252634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11. 10.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2022983729839325
desired expected reward: 4.650108814239502





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.138196 ]
 [5.7788563]
 [8.432648 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 11. 10.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3232909142971039
desired expected reward: 8.03599739074707



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 11.  1.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 11.  1.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
adversary victory points: -5
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[10.961188]
 [11.89312 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.  1.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  2.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 11. 11.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.  0.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.28201577067375183
desired expected reward: 8.15063190460205



action possibilites: [-1] 
expected returns: [[11.039988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  1.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 11. 11.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.  0.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0   4   0] 
sum of rewards: 9 

action type: gain_card_n - action 5
Learning step: 0.09357979893684387
desired expected reward: 9.838249206542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 9.736055 ]
 [10.754048 ]
 [ 9.178144 ]
 [10.193571 ]
 [ 8.826575 ]
 [ 8.3019495]
 [ 9.97749  ]
 [11.495591 ]
 [12.764518 ]
 [11.8462925]
 [10.018566 ]
 [ 9.525525 ]
 [ 8.510098 ]
 [11.039284 ]
 [11.039988 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  1.  9.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 11. 11.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.  0.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23140215873718262
desired expected reward: 11.271389961242676



buy possibilites: [-1] 
expected returns: [[9.669135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.  8. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6  8 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  1.  8.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 11. 11.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.  0.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -11.
   0.    0.   12.5   0. ] 
sum of rewards: 16.5 

action type: buy - action 25.0
Learning step: 0.2135903537273407
desired expected reward: 12.978109359741211






Player: 1 
cards in hand: [ 0.  6. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11. 11.  3.] 
cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.  0.  0.
  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  1.  8.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0. 10.  1. 10.] 
adversary cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.  8. 25. 11.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6  8 25] -> size -> 46 
adversary victory points: -5
player victory points: 2 


Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 3 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 1 
Workshop: 6 
Chapel: 4 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 5 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  0. 10.  1. 10.] 
cards in discard: [ 6.  8. 15. 10.  1. 15.  6. 14.  6.  0. 10. 16. 11.  6.  6.  0. 10.  6.
  8.  8.  0.  3. 11. 11. 10.  8. 25. 11.  0.  0.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 11  1 11  3  1 15  8 10 10 10 10  1  6  1  0 11  6 10
 10  1  0 15  8  0 16 11 10  0  6  1 11  8  6  6 14  6  0  6  8 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 27. 30.  8.  1.  6.  0.  0.  8.  8.  7. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  3.] 
adversary cards in discard: [ 3. 25.  0.  0.  0.  1. 16.  0. 14. 11.  8.  0.  8.  8. 10.  0.  0.  0.
  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3 10  0 25  8  0 11  0 11  8 16  0  6  3  0  1 11 29  0  0
  0  1 14  8  0  3  8] -> size -> 31 
adversary victory points: 2
player victory points: -5 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.44007396697998
desired expected reward: -5.770938873291016



