 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[298.04495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   1  30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 526 

action type: buy - action -1.0
Learning step: 26.2287540435791
desired expected reward: 27.65365219116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[273.8289 ]
 [285.96976]
 [282.82385]
 [252.51744]
 [279.8268 ]
 [294.83606]
 [282.84384]
 [288.16156]
 [264.21182]
 [280.53278]
 [278.31842]
 [302.17337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.614192962646484
desired expected reward: 292.903076171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[332.08008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.717988014221191
desired expected reward: 294.4554138183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[300.9113 ]
 [311.47388]
 [308.60947]
 [281.84833]
 [320.0711 ]
 [308.4801 ]
 [306.39468]
 [327.2722 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.59186840057373
desired expected reward: 323.3273620605469



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[336.87582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.874910354614258
desired expected reward: 318.3973083496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[305.74207]
 [315.17685]
 [311.5982 ]
 [288.30624]
 [310.21704]
 [320.75073]
 [312.9869 ]
 [316.74426]
 [297.46298]
 [309.93967]
 [308.24567]
 [324.9385 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.814281463623047
desired expected reward: 327.4613342285156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[370.18542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -7.490911960601807
desired expected reward: 317.4476623535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[336.8131 ]
 [350.34113]
 [347.1023 ]
 [313.3074 ]
 [360.59427]
 [346.7758 ]
 [344.47766]
 [369.5024 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [ 6. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -10.111166000366211
desired expected reward: 361.267333984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 6. 11. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 6. 11. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [ 6. 11. 16.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[350.31122]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.692679405212402
desired expected reward: 358.8097839355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[322.53772]
 [333.14005]
 [330.45575]
 [302.5949 ]
 [327.78418]
 [341.0517 ]
 [330.39975]
 [335.1983 ]
 [313.46213]
 [328.47693]
 [326.48862]
 [347.79935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.004720687866211
desired expected reward: 340.3261413574219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[362.06732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.807141304016113
desired expected reward: 337.9921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[331.70297]
 [345.45312]
 [342.01306]
 [307.69315]
 [355.50577]
 [341.8234 ]
 [339.32224]
 [364.0754 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [3. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.845541954040527
desired expected reward: 352.8355712890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [3. 0. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [3. 0. 0. 3. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[349.1539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.936338424682617
desired expected reward: 353.1390075683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[321.4286 ]
 [331.92776]
 [329.4389 ]
 [309.0069 ]
 [302.63428]
 [326.65045]
 [339.90225]
 [329.1805 ]
 [348.08932]
 [334.01712]
 [313.2035 ]
 [321.8857 ]
 [327.46912]
 [309.37292]
 [325.65527]
 [346.75687]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.492568016052246
desired expected reward: 339.1709899902344



buy possibilites: [-1] 
expected returns: [[222.24591]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 38 

action type: buy - action 25.0
Learning step: -10.503931999206543
desired expected reward: 337.5853576660156






Player: 1 
cards in hand: [ 3.  3.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6. 16.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 16.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  6. 16.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.2815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.186872959136963
desired expected reward: 217.0590362548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[275.28293]
 [280.4289 ]
 [258.19818]
 [282.4019 ]
 [293.59955]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.665923118591309
desired expected reward: 281.3528747558594



buy possibilites: [-1] 
expected returns: [[290.84433]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  6. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 8.0
Learning step: -7.349298000335693
desired expected reward: 266.5166015625






Player: 1 
cards in hand: [ 8.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  3.  0.] 
cards in discard: [ 0.  3.  3.  6. 16.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  9.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  6. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  6. 16.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  8.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[250.454 ]
 [254.5062]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  6. 16.  0.  6. 11.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.933796882629395
desired expected reward: 281.9105224609375



action possibilites: [-1] 
expected returns: [[286.37756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  6. 16.  0.  6. 11.  8.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: -5.341172695159912
desired expected reward: 249.35218811035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[257.52475]
 [268.30453]
 [265.02664]
 [238.20302]
 [262.8392 ]
 [275.5483 ]
 [265.54007]
 [269.7826 ]
 [248.35028]
 [262.883  ]
 [260.67465]
 [281.70016]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  6. 16.  0.  6. 11.  8.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -7.2850022315979
desired expected reward: 279.0925598144531






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  6. 16.  0.  6. 11.  8.  3.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  6. 16.  0.  6. 11.  8.  3.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  3.  6. 16.  0.  6. 11.  8.  3.  3.  0.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [25.  0.  0.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[261.36017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -7.857429504394531
desired expected reward: 273.8427429199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[240.14075]
 [252.52678]
 [248.78844]
 [218.02538]
 [260.31662]
 [249.28362]
 [246.21017]
 [266.28262]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [25.  0.  0.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -6.76228666305542
desired expected reward: 252.24122619628906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[240.11882]
 [222.27798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6.  6.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.028271675109863
desired expected reward: 258.25433349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[215.04955]
 [222.59567]
 [195.29076]
 [222.97177]
 [239.84784]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  6.  6.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.128729343414307
desired expected reward: 236.84580993652344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  6.  6.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  6.  6.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  6.  6.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [8. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[287.07672]
 [292.84497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [8. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -5.623269081115723
desired expected reward: 234.2245635986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[267.27908]
 [279.32574]
 [275.26147]
 [244.87224]
 [273.23843]
 [285.66608]
 [276.51224]
 [280.77692]
 [256.4354 ]
 [272.84235]
 [270.36487]
 [290.07675]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [8. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.920860290527344
desired expected reward: 275.2308044433594



buy possibilites: [-1] 
expected returns: [[279.8553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [8. 3. 0. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.59686851501465
desired expected reward: 223.275390625






Player: 1 
cards in hand: [8. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3. 0.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[225.71512]
 [229.91156]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.  8.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.493094444274902
desired expected reward: 270.3621826171875



action possibilites: [-1] 
expected returns: [[211.29988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.  8.  3.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 25.0
Learning step: -6.340511322021484
desired expected reward: 223.55465698242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[178.54286]
 [190.48639]
 [187.0479 ]
 [158.10889]
 [184.4289 ]
 [198.86624]
 [187.371  ]
 [192.30235]
 [168.6899 ]
 [184.67416]
 [182.30412]
 [205.83295]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.  8.  3.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -5.81304931640625
desired expected reward: 205.48683166503906



buy possibilites: [-1] 
expected returns: [[201.78555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  0.] 
adversary cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.  8.  3.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 39 

action type: buy - action 16.0
Learning step: -2.731269121170044
desired expected reward: 181.69761657714844






Player: 1 
cards in hand: [ 3. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.  0.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.  8.  3.  0.  3.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6. 3.] 
adversary cards in discard: [16. 25.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.  0.] 
cards in discard: [ 8.  3. 16.  0.  0.  0.  0.  0. 11.  6.  6.  6.  0.  8.  3.  0.  3.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6. 3.] 
adversary cards in discard: [16. 25.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[235.70322]
 [220.39401]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 3.] 
cards in discard: [16. 25.  0.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -5.114768028259277
desired expected reward: 196.67079162597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[205.43436]
 [212.85469]
 [186.04291]
 [213.40984]
 [227.43634]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 3.] 
cards in discard: [16. 25.  0.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -6.24422025680542
desired expected reward: 213.95767211914062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[251.26268]
 [239.13066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -5.474656581878662
desired expected reward: 221.96168518066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[230.98772]
 [241.94472]
 [237.56058]
 [211.40837]
 [236.14835]
 [247.81339]
 [239.25647]
 [243.1307 ]
 [221.1122 ]
 [235.38965]
 [233.07819]
 [251.80061]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 6. 15.  3.  0.  0.] 
adversary cards in discard: [ 8. 16.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -6.637345790863037
desired expected reward: 242.9170684814453



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  0.  0.] 
cards in discard: [ 8. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  6.  3.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  0.  0.] 
cards in discard: [ 8. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  6.  3.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  3.  0.  0.] 
cards in discard: [ 8. 16.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3.  0.  6.  3.] 
adversary cards in discard: [0. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [16.  3.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[272.47183]
 [253.2718 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  6.  3.] 
cards in discard: [0. 0. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  3.  6.] 
adversary cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -6.7488861083984375
desired expected reward: 245.05169677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[251.75134]
 [232.53389]
 [276.33054]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  6.  3.] 
cards in discard: [0. 0. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  3.  6.] 
adversary cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.727624416351318
desired expected reward: 263.1832580566406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 11.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  3.  6.] 
cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6.] 
cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[255.60811]
 [262.4759 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  5.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -8.160876274108887
desired expected reward: 268.1696472167969



action possibilites: [-1] 
expected returns: [[176.2606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 19 

action type: take_action - action 25.0
Learning step: -8.070259094238281
desired expected reward: 251.65219116210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[156.10077]
 [167.22533]
 [163.43538]
 [142.94322]
 [136.29913]
 [161.54137]
 [174.02605]
 [164.3942 ]
 [184.47467]
 [168.51245]
 [146.27283]
 [155.04887]
 [161.17325]
 [142.52312]
 [158.80832]
 [179.29482]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 30. 30. 26. 30.  8.  4.  8.  9.  7.  9. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -4.078869819641113
desired expected reward: 172.18173217773438



buy possibilites: [-1] 
expected returns: [[166.23532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 67 

action type: buy - action 25.0
Learning step: -2.1334388256073
desired expected reward: 182.3412322998047






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16 25] -> size -> 15 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16 25] -> size -> 15 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 8. 16.  0.  3.  6. 15.  3.  0.  0.  0. 11.  3.  6.  3.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 8. 0. 0. 3.] 
adversary cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16 25] -> size -> 15 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [6. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[198.17482]
 [186.92676]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 3.] 
cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  8  6 16 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -3.620164155960083
desired expected reward: 162.6151580810547



action possibilites: [-1] 
expected returns: [[193.56436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 25  8 16 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 10
Learning step: -3.4650871753692627
desired expected reward: 179.94061279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[178.65648]
 [160.12064]
 [198.0361 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 25  8 16 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  4.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -4.081486701965332
desired expected reward: 189.48287963867188



buy possibilites: [-1] 
expected returns: [[186.16115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 25.  0.  3.  0.  0.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 25  8 16 25  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    1    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -284 

action type: buy - action 6.0
Learning step: -18.01740837097168
desired expected reward: 142.10324096679688






Player: 1 
cards in hand: [6. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25  8 16 25  6] -> size -> 12 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  9.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25  8 16 25  6] -> size -> 12 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  8.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 25  8 16 25  6] -> size -> 12 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[130.22559 ]
 [113.569084]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 25  8 16 25  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  8.  7.  8. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -6.698204040527344
desired expected reward: 179.46295166015625



action possibilites: [-1] 
expected returns: [[88.181435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 14 

action type: gain_card_n - action 9
Learning step: -1.4168405532836914
desired expected reward: 80.60161590576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[72.36203 ]
 [77.093834]
 [58.384506]
 [78.12317 ]
 [87.15293 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  3.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -2.3352999687194824
desired expected reward: 85.84613800048828



buy possibilites: [-1] 
expected returns: [[88.023224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -16.238704681396484
desired expected reward: 42.145816802978516






Player: 1 
cards in hand: [11.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  0.] 
cards in discard: [11.  6.  0.  6.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  2.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  8.  6.  0.] 
adversary cards in discard: [10.  6. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 26. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  8.  6.  0.] 
adversary cards in discard: [10.  6. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 26. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  8.  6.  0.] 
adversary cards in discard: [10.  6. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  8.  6.  0.] 
adversary cards in discard: [10.  6. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25.  0.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[74.73513]
 [81.66449]
 [68.55793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8.  6.  0.] 
cards in discard: [10.  6. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  6.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11  6  3] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -3.9943833351135254
desired expected reward: 84.02883911132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.684525]
 [66.04649 ]
 [49.901703]
 [68.50156 ]
 [73.20988 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8.  6.  0.] 
cards in discard: [10.  6. 16.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  6.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11  6  3] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -3.3680522441864014
desired expected reward: 68.93598937988281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  6.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0
  6  0 11  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 16. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 25. 25.] 
expected returns: [[42.752014]
 [35.904915]
 [35.747116]
 [44.186447]
 [44.186447]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  1.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1.0
Learning step: -4.007993221282959
desired expected reward: 69.20185852050781



action possibilites: [-1] 
expected returns: [[76.62827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 25.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -5 

action type: take_action - action 25.0
Learning step: -0.7282808423042297
desired expected reward: 43.32006072998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[59.705765]
 [62.753487]
 [63.4768  ]
 [70.02991 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16. 25.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -2.621846914291382
desired expected reward: 74.00642395019531



buy possibilites: [-1] 
expected returns: [[55.98207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16. 25.  0.  6.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 6. 8. 3.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -36.0 

action type: buy - action 0.0
Learning step: -3.5256917476654053
desired expected reward: 56.18007278442383






Player: 1 
cards in hand: [3. 3. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8. 3.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 25. 10. 16. 25.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 8. 3.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 25. 10. 16. 25.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[67.17367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 0. 25. 10. 16. 25.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.
  3.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -2.092557191848755
desired expected reward: 53.8895149230957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[52.306725]
 [57.66423 ]
 [54.915466]
 [59.715637]
 [56.533707]
 [53.944603]
 [60.08924 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 0. 25. 10. 16. 25.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.
  3.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.8356833457946777
desired expected reward: 64.12193298339844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.
  3.  3.  6.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 25.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.
  3.  3.  6.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 25.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [11.  6.  0.  6.  0.  0.  6.  3. 11.  0.  0.  8.  0. 15.  3.  0.  6.  6.
  3.  3.  6.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16. 25.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 16. 25.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.  8.] 
expected returns: [[ 98.60708]
 [ 86.75883]
 [101.43571]
 [ 88.4821 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 25.  6.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -1.6776657104492188
desired expected reward: 58.41156768798828



action possibilites: [-1] 
expected returns: [[62.39543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  8. 25.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: -3.2414233684539795
desired expected reward: 94.66498565673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[55.909325]
 [59.484276]
 [60.7853  ]
 [67.757744]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  8. 25.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 25. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -1.469376802444458
desired expected reward: 60.926055908203125



buy possibilites: [-1] 
expected returns: [[113.16982]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  8. 25.  0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.6150760650634766
desired expected reward: 60.09934997558594






Player: 1 
cards in hand: [ 0. 16.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  8.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 25.  0. 16.  6.  8. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  8.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 25.  0. 16.  6.  8. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[60.358032]
 [53.289093]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 25.  0. 16.  6.  8. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -4.618535041809082
desired expected reward: 108.55128479003906



action possibilites: [-1.] 
expected returns: [[50.52214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 3. 25.  0. 16.  6.  8. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.6937942504882812
desired expected reward: 50.91705322265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[44.1261  ]
 [47.938423]
 [46.29351 ]
 [49.922188]
 [47.088715]
 [45.623093]
 [51.175217]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 3. 25.  0. 16.  6.  8. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.6654197573661804
desired expected reward: 49.856719970703125






Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 0. 16.  6.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 0. 16.  6.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[45.282112]
 [48.390022]
 [48.390022]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  8.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.777051568031311
desired expected reward: 49.39816665649414



action possibilites: [-1] 
expected returns: [[52.324257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  8.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 17 

action type: take_action - action 25.0
Learning step: -0.29044875502586365
desired expected reward: 46.0644416809082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.503456]
 [52.2062  ]
 [49.137764]
 [48.40123 ]
 [56.049637]
 [50.48497 ]
 [53.1728  ]
 [39.913353]
 [47.829918]
 [46.53386 ]
 [58.761444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  8.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.6419927477836609
desired expected reward: 51.6822624206543






Player: 1 
cards in hand: [ 3.  0.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  8.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6
  0 11  6  3  6  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  3.  8. 10. 16.] 
adversary cards in discard: [25.  0. 25.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  3.  8. 10. 16.] 
adversary cards in discard: [25.  0. 25.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  3.  8. 10. 16.] 
adversary cards in discard: [25.  0. 25.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  8. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
expected returns: [[120.857635]
 [107.97109 ]
 [105.06033 ]
 [105.38805 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8. 10. 16.] 
cards in discard: [25.  0. 25.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6675035357475281
desired expected reward: 58.09393310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 99.71572]
 [120.16779]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  8. 10. 16.] 
cards in discard: [25.  0. 25.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 6. 6. 0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -3.5279788970947266
desired expected reward: 113.86810302734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[52.383224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6. 11.  0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -5.134221076965332
desired expected reward: 115.03356170654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[34.93905 ]
 [41.902977]
 [39.923866]
 [47.14435 ]
 [40.174423]
 [38.669426]
 [51.85087 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  6. 11.  0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.6884043216705322
desired expected reward: 48.27463150024414



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 11.  0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 30.  8.  0.  8.  8.  7.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  6.  3.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  6.  3.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  6.  3.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  6.  3.] 
adversary cards in discard: [0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 25.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 93.61314]
 [100.53948]
 [100.53948]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  6.  3.] 
cards in discard: [0. 3. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.  0. 11.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6443832516670227
desired expected reward: 51.206485748291016



action possibilites: [-1] 
expected returns: [[88.12351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6.  3.  0. 16.] 
cards in discard: [0. 3. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.  0. 11.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: -2.152984380722046
desired expected reward: 96.5622787475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[63.026146]
 [70.079384]
 [70.56469 ]
 [87.37307 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  6.  3.  0. 16.] 
cards in discard: [0. 3. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.  0. 11.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.850250244140625
desired expected reward: 86.27326202392578






Player: 1 
cards in hand: [6. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.  0. 11.  0.  6. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 0. 16.  6.  8.  3.  0.  0.  3.  0.  3.  3. 15.  3.  3.  8.  0.  3.  6.
  6.  6.  0.  8.  0. 11.  0.  6. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[70.91799 ]
 [59.079323]
 [60.057404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -3.2328476905822754
desired expected reward: 84.14020538330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[54.87568 ]
 [59.78238 ]
 [59.535675]
 [70.383354]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -2.029697895050049
desired expected reward: 63.2138557434082



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 16.] 
adversary cards in discard: [ 6.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 16.] 
adversary cards in discard: [ 6.  0.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[135.09828]
 [125.28193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 16.] 
cards in discard: [ 6.  0.  0. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7871004343032837
desired expected reward: 69.59625244140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[112.9551  ]
 [119.92094 ]
 [117.15838 ]
 [123.65799 ]
 [118.289925]
 [115.84111 ]
 [126.33156 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 16.] 
cards in discard: [ 6.  0.  0. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [0. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.206501007080078
desired expected reward: 130.20359802246094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0. 25.  3.  6.] 
adversary cards in discard: [ 6.  0.  0. 10.  8.  0.  0.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  6.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0. 25.  3.  6.] 
adversary cards in discard: [ 6.  0.  0. 10.  8.  0.  0.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [0. 8. 0. 3. 0. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0. 25.  3.  6.] 
adversary cards in discard: [ 6.  0.  0. 10.  8.  0.  0.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [25.  0. 25.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[62.759296]
 [66.172485]
 [66.172485]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  3.  6.] 
cards in discard: [ 6.  0.  0. 10.  8.  0.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 11.  6.] 
adversary cards in discard: [0. 8. 0. 3. 0. 8. 3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -5.090151786804199
desired expected reward: 121.24139404296875



action possibilites: [-1] 
expected returns: [[83.296974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 11.  6.] 
adversary cards in discard: [0. 8. 0. 3. 0. 8. 3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: -0.634443461894989
desired expected reward: 65.5380630493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[69.64274 ]
 [74.669205]
 [75.30343 ]
 [85.98483 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  3.  6.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  6. 11.  6.] 
adversary cards in discard: [0. 8. 0. 3. 0. 8. 3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.5851200819015503
desired expected reward: 81.71185302734375






Player: 1 
cards in hand: [ 3.  6.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 11.  6.] 
cards in discard: [0. 8. 0. 3. 0. 8. 3. 3. 6. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0. 10.  0.] 
adversary cards in discard: [25.  0. 25.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  6. 11.  6.] 
cards in discard: [0. 8. 0. 3. 0. 8. 3. 3. 6. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0. 10.  0.] 
adversary cards in discard: [25.  0. 25.  3.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[119.418594]
 [109.65053 ]
 [109.06438 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 10.  0.] 
cards in discard: [25.  0. 25.  3.  6.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6 10  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.945825457572937
desired expected reward: 84.03900909423828



action possibilites: [-1] 
expected returns: [[71.263885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 25.  3.  6.  0.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.5131465792655945
desired expected reward: 53.31896209716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[58.685783]
 [64.32311 ]
 [62.099636]
 [67.14232 ]
 [62.934574]
 [60.9317  ]
 [69.07652 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 25.  3.  6.  0.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  8.  0. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -1.3189371824264526
desired expected reward: 69.9449462890625






Player: 1 
cards in hand: [15.  0.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  0. 11.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0
 11  6  3  6  0  0  0  8  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[11.974253]
 [14.452759]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -3.4649658203125
desired expected reward: 65.6115493774414



action possibilites: [-1] 
expected returns: [[36.425457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: 1.0568288564682007
desired expected reward: 12.3117094039917





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[25.691338]
 [32.77117 ]
 [30.723194]
 [37.18373 ]
 [31.053204]
 [29.321922]
 [39.7541  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  0.  3.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0] -> size -> 34 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.25778648257255554
desired expected reward: 36.16767120361328






Player: 1 
cards in hand: [16.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.  6.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  0. 25.  6.] 
adversary cards in discard: [25.  0.  3.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  6.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 24. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  0. 25.  6.] 
adversary cards in discard: [25.  0.  3.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  6.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0.  0. 25.  6.] 
adversary cards in discard: [25.  0.  3.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [14.  0.  0. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[75.54639 ]
 [55.316708]
 [81.02431 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 25.  6.] 
cards in discard: [25.  0.  3.  0.  6.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -1.0359995365142822
desired expected reward: 38.718109130859375



action possibilites: [-1] 
expected returns: [[28.268238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.  3. 16.] 
cards in discard: [25.  0.  3.  0.  6.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: -3.146613121032715
desired expected reward: 77.50635528564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[16.97362 ]
 [19.67456 ]
 [20.63674 ]
 [25.655502]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.  3. 16.] 
cards in discard: [25.  0.  3.  0.  6.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -0.6400295495986938
desired expected reward: 27.62820816040039



buy possibilites: [-1] 
expected returns: [[51.6864]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  6.  3. 16.] 
cards in discard: [25.  0.  3.  0.  6.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
adversary owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -0.9532951712608337
desired expected reward: 16.020305633544922






Player: 1 
cards in hand: [8. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 3.] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16  6 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11
  6  3  6  0  0  0  8  0  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  3.  0.  8.  3.  3.  6.  0.  0.  3.  6.  6. 11.  6.  0. 15.
  8.  0. 11.  3. 16.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [16.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[33.9692  ]
 [26.300087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -2.641998052597046
desired expected reward: 49.044403076171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[25.185122]
 [30.319866]
 [28.180277]
 [33.45826 ]
 [29.184261]
 [27.347721]
 [35.568043]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -1.6430778503417969
desired expected reward: 30.981304168701172



buy possibilites: [-1] 
expected returns: [[81.7973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: -1.668817400932312
desired expected reward: 23.516313552856445






Player: 1 
cards in hand: [0. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 16.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [14.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 16.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 6.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0. 25.  3.  0.] 
adversary cards in discard: [ 0. 16.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [14.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[93.61562]
 [64.78716]
 [95.6749 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 25.  3.  0.] 
cards in discard: [ 0. 16.  0.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 15.  6.  0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -2.8868749141693115
desired expected reward: 78.91043090820312



action possibilites: [-1] 
expected returns: [[107.39777]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  0.  0.] 
cards in discard: [ 0. 16.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 15.  6.  0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 7 

action type: take_action - action 25.0
Learning step: -1.8326505422592163
desired expected reward: 90.14936065673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 87.75579 ]
 [ 95.38261 ]
 [ 92.11825 ]
 [ 91.344635]
 [ 99.05891 ]
 [ 93.56618 ]
 [ 96.073845]
 [ 80.867   ]
 [ 90.5837  ]
 [ 88.85892 ]
 [101.270676]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  0.  0.] 
cards in discard: [ 0. 16.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 30. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 15.  6.  0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -2.9379327297210693
desired expected reward: 104.4598388671875



buy possibilites: [-1] 
expected returns: [[113.76212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  0.  0.] 
cards in discard: [ 0. 16.  0.  6.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0. 15.  6.  0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 9.5 

action type: buy - action 1.0
Learning step: -1.7344826459884644
desired expected reward: 93.64812469482422






Player: 1 
cards in hand: [11.  0. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.  6.  0.] 
cards in discard: [10.  0.  0.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 15.  6.  0.] 
cards in discard: [10.  0.  0.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[54.81048 ]
 [58.020287]
 [44.48008 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 25.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -5.2768683433532715
desired expected reward: 108.4852523803711



action possibilites: [-1] 
expected returns: [[64.58367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 7 

action type: take_action - action 25.0
Learning step: -0.9215324521064758
desired expected reward: 53.57176971435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[49.391693]
 [55.700966]
 [54.5732  ]
 [60.904686]
 [53.986862]
 [53.354454]
 [65.659294]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -1.6051380634307861
desired expected reward: 62.97853469848633






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 25.  0.  3.] 
adversary cards in discard: [25.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  8.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 25.  0.  3.] 
adversary cards in discard: [25.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 14. 25.  0.  3.] 
adversary cards in discard: [25.  0.  3.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6. 14. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[ 99.89634]
 [ 82.27462]
 [105.33871]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 25.  0.  3.] 
cards in discard: [25.  0.  3.  6.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 6.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -1.782761812210083
desired expected reward: 63.87653350830078



action possibilites: [-1] 
expected returns: [[115.82453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  3. 16.  0.] 
cards in discard: [25.  0.  3.  6.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 6.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 6 

action type: take_action - action 25.0
Learning step: -2.3207545280456543
desired expected reward: 102.21537017822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 99.07631]
 [104.28467]
 [104.24432]
 [114.19709]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  3. 16.  0.] 
cards in discard: [25.  0.  3.  6.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 6.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -3.067544937133789
desired expected reward: 112.75698852539062






Player: 1 
cards in hand: [6. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 6.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 6.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
adversary victory points: 0
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[45.46978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 11.  6.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.4588518142700195
desired expected reward: 108.73822021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.00925 ]
 [40.77429 ]
 [38.669308]
 [27.803356]
 [37.297085]
 [45.102566]
 [39.14077 ]
 [50.918015]
 [41.731407]
 [29.50904 ]
 [33.664295]
 [37.379772]
 [27.663525]
 [36.014378]
 [48.453156]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  8. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 11.  6.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -1.9715797901153564
desired expected reward: 42.51741027832031



buy possibilites: [-1] 
expected returns: [[26.563328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  3.  8. 11.  6.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.] 
adversary owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 35 

action type: buy - action 25.0
Learning step: -0.22516117990016937
desired expected reward: 50.6928596496582






Player: 1 
cards in hand: [ 8.  3.  8. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 11.  6.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16 11  3  3  8  0  6  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0
  0  0  8  0  8  0  3 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [25.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1 25] -> size -> 19 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  3  8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8
  0  8  0  3 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [25.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1 25] -> size -> 19 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  3  8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8
  0  8  0  3 10 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  8.  0.  6.  6.] 
adversary cards in discard: [25.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1 25] -> size -> 19 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [14.  8.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[95.740616]
 [75.16813 ]
 [83.32227 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  6.  6.] 
cards in discard: [25.  3.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 25  8 16 25  6  6  0  3 14  0  0  1 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3.  6. 16.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.  8.  8.] 
adversary owned cards: [16  3  3  8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8
  0  8  0  3 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -0.14169025421142578
desired expected reward: 26.42163848876953



action possibilites: [-1] 
expected returns: [[47.204964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [25.  3.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3.  6. 16.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.  8.  8.] 
adversary owned cards: [16  3  3  8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8
  0  8  0  3 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.0163841247558594
desired expected reward: 86.55352783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[39.89148 ]
 [50.882256]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [25.  3.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  3.  6. 16.] 
adversary cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.  8.  8.] 
adversary owned cards: [16  3  3  8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8
  0  8  0  3 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 0.07444152981042862
desired expected reward: 47.27940368652344






Player: 1 
cards in hand: [ 3.  8.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  6. 16.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  3  8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8
  0  8  0  3 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25. 16.] 
adversary cards in discard: [25.  3.  1.  0.  0.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25. 16.] 
adversary cards in discard: [25.  3.  1.  0.  0.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  0.  0.  3.  0.  6. 11.  0. 15.  6.  0. 11.  0.  0.  0.  0.  3.  6.
  8.  3.  0.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25. 16.] 
adversary cards in discard: [25.  3.  1.  0.  0.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 25. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[78.29906]
 [82.58748]
 [66.61234]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25. 16.] 
cards in discard: [25.  3.  1.  0.  0.  0.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 0.5042539834976196
desired expected reward: 51.38651657104492



action possibilites: [-1] 
expected returns: [[36.979042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16. 25.  0.] 
cards in discard: [25.  3.  1.  0.  0.  0.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 48 

action type: take_action - action 25.0
Learning step: -0.7001655697822571
desired expected reward: 77.94371032714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[22.452787]
 [26.561556]
 [25.751   ]
 [30.285242]
 [25.49135 ]
 [24.994505]
 [33.46408 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16. 25.  0.] 
cards in discard: [25.  3.  1.  0.  0.  0.  8. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 1.1832245588302612
desired expected reward: 38.16226577758789






Player: 1 
cards in hand: [ 6.  8. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  3.  3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[15.755175]
 [19.08277 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 0.0763702392578125
desired expected reward: 33.540443420410156



action possibilites: [-1] 
expected returns: [[26.434042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 25.0
Learning step: 2.02020525932312
desired expected reward: 20.51141357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.219446]
 [17.413525]
 [16.777468]
 [20.149857]
 [16.585363]
 [16.231062]
 [22.588959]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  5.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 1.4831299781799316
desired expected reward: 27.917171478271484



buy possibilites: [-1] 
expected returns: [[57.46591]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  3. 16.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.] 
adversary owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11  0] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 49.0 

action type: buy - action 8.0
Learning step: 2.913713216781616
desired expected reward: 19.499107360839844






Player: 1 
cards in hand: [6. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  6 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0
  3 10 11  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 8. 25.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0  3
 10 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 8. 25.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0  3
 10 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 23. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 8. 25.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0  3
 10 11  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [ 8. 25.  0.  0.  3.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[38.497795]
 [27.12802 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 8. 25.  0.  0.  3.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 3.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 8  0 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0  3
 10 11  0  3] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -1.747314453125
desired expected reward: 55.718597412109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.043009]
 [30.171347]
 [28.75401 ]
 [28.052757]
 [32.597054]
 [29.164745]
 [30.719847]
 [22.559132]
 [27.935032]
 [27.107927]
 [34.440132]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [ 8. 25.  0.  0.  3.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 3.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.] 
adversary owned cards: [ 8  0 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0  3
 10 11  0  3] -> size -> 28 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -0.7943670153617859
desired expected reward: 36.37094497680664



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 8. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 6. 3.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  8  3  0  0  6  3  0  6  0 11  6  3  6  0  0  0  8  0  8  0  3
 10 11  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 25.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 25.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25.] 
expected returns: [[-22.428312]
 [-22.45682 ]
 [-23.438635]
 [-23.438635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 25.  1. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -2.4211013317108154
desired expected reward: 32.019046783447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-20.704927]
 [-21.682098]
 [-20.973097]
 [-21.564157]
 [-21.420612]
 [-20.676983]
 [-21.39559 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 25.  1. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: 0.5879020690917969
desired expected reward: -23.58984375



buy possibilites: [-1] 
expected returns: [[1.5282581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 25.  1. 25.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 15 

action type: buy - action 10.0
Learning step: 1.7833328247070312
desired expected reward: -18.89365577697754






Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7. 10.  9. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [16.  0.  0. 14.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [16.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[14.857787 ]
 [ 9.836007 ]
 [ 6.6425467]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 14.  0.] 
cards in discard: [10.  0.  8. 25.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: 0.04649604484438896
desired expected reward: 1.5747541189193726



action possibilites: [-1] 
expected returns: [[23.254593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [10.  0.  8. 25.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 14.0
Learning step: 1.0728079080581665
desired expected reward: 7.081214427947998





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[12.873089]
 [17.541567]
 [16.901176]
 [ 6.381094]
 [15.719441]
 [19.37225 ]
 [16.813166]
 [21.593855]
 [18.052414]
 [ 8.528214]
 [13.256187]
 [16.03396 ]
 [ 6.755061]
 [14.929894]
 [20.451176]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [10.  0.  8. 25.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 0.10109319537878036
desired expected reward: 23.35568618774414



buy possibilites: [-1] 
expected returns: [[55.673874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [10.  0.  8. 25.  1. 25. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0.] 
adversary cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29 10] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 25.0 

action type: buy - action 14.0
Learning step: 2.076251745223999
desired expected reward: 10.604458808898926






Player: 1 
cards in hand: [15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0
  3  0 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  8. 10.  3.  3.  3.  8.  6.  0.  0.  0.  8.  3. 29. 10. 11.  8.
  0.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  3.  0.] 
adversary cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[51.14715 ]
 [52.64995 ]
 [44.441673]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  3.  0.] 
cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -1.784507393836975
desired expected reward: 53.889366149902344



action possibilites: [-1] 
expected returns: [[-10.749398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0. 3.] 
cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 25.0
Learning step: -1.9743584394454956
desired expected reward: 50.67558288574219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-11.351151]
 [-11.35934 ]
 [-10.904066]
 [-10.602303]
 [-11.363294]
 [-10.852949]
 [ -9.9435  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0. 3.] 
cards in discard: [10.  0.  8. 25.  1. 25. 14. 14. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 1.153149962425232
desired expected reward: -9.596248626708984






Player: 1 
cards in hand: [10.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  4.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25.  0. 10. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [25.  0. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[-6.9296227]
 [-7.0561953]
 [-6.374276 ]
 [-7.0561953]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10. 25.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: 0.1784702092409134
desired expected reward: -9.765026092529297



action possibilites: [-1. 25. 25.] 
expected returns: [[16.974707]
 [17.562746]
 [17.562746]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: 1.6034786701202393
desired expected reward: -5.60577392578125



action possibilites: [-1. 25. 16. 14.] 
expected returns: [[43.74237 ]
 [43.93068 ]
 [32.13527 ]
 [24.808691]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3. 16. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 25.0
Learning step: 1.8751699924468994
desired expected reward: 19.437917709350586



action possibilites: [-1] 
expected returns: [[53.240692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25. 14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action 14.0
Learning step: 2.807481288909912
desired expected reward: 27.61617088317871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[43.920486]
 [48.29521 ]
 [47.24461 ]
 [46.137802]
 [51.353127]
 [47.12174 ]
 [48.82962 ]
 [40.33884 ]
 [46.3232  ]
 [45.341946]
 [53.68282 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25. 14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 29. 30. 22. 30.  8.  0.  8.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: take_action - action -1
Learning step: 1.3242501020431519
desired expected reward: 54.56494140625



buy possibilites: [-1] 
expected returns: [[21.75645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3. 16.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25. 14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 60  0  0  0  0  0  0  0 32  0] 
sum of rewards: 89 

action type: buy - action 16.0
Learning step: 2.632629871368408
desired expected reward: 48.77043914794922






Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 22. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 22. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 0.] 
adversary cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16] -> size -> 20 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[19.745535]
 [15.244239]
 [15.244239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.3264001607894897
desired expected reward: 20.430049896240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[12.547002]
 [15.776624]
 [14.88515 ]
 [17.851841]
 [14.91104 ]
 [14.187005]
 [19.407803]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.241714358329773
desired expected reward: 18.503820419311523



buy possibilites: [-1] 
expected returns: [[4.520259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0.  0. 15.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 1.0
Learning step: -0.43560630083084106
desired expected reward: 15.34102725982666






Player: 1 
cards in hand: [ 0.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  3.  1. 25.] 
adversary cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  3.  1. 25.] 
adversary cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1] -> size -> 21 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
expected returns: [[-7.873824]
 [-5.802061]
 [-8.454744]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  1. 25.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.0237997770309448
desired expected reward: 3.4964590072631836



action possibilites: [-1] 
expected returns: [[45.75158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 25.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 14.0
Learning step: 1.6695137023925781
desired expected reward: -4.132548809051514





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.202236]
 [38.60587 ]
 [36.36328 ]
 [26.5349  ]
 [35.76995 ]
 [41.42052 ]
 [37.331875]
 [46.775974]
 [39.112034]
 [27.91841 ]
 [32.054813]
 [35.30676 ]
 [25.966812]
 [34.034725]
 [43.054867]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 25.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -1.0078685283660889
desired expected reward: 44.743709564208984



buy possibilites: [-1] 
expected returns: [[10.78442]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 25.] 
cards in discard: [16. 10. 25. 14.  0. 25.  0.  3. 16.  1.  0.  8.  8.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 11.5 

action type: buy - action 10.0
Learning step: -0.9476885199546814
desired expected reward: 34.35906982421875






Player: 1 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [1. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  3.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [1. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [1. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [1. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[37.005024]
 [28.800905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [ 6.  3. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -0.4264971911907196
desired expected reward: 10.357922554016113





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.994654]
 [31.077175]
 [29.544811]
 [28.4881  ]
 [34.38349 ]
 [29.81292 ]
 [31.751667]
 [21.684319]
 [28.564615]
 [27.480045]
 [36.937363]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  7.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [ 6.  3. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.6855581998825073
desired expected reward: 34.04326248168945



buy possibilites: [-1] 
expected returns: [[26.153692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [ 6.  3. 11.  0. 29.] 
adversary cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -8.5 

action type: buy - action 11.0
Learning step: -1.5557165145874023
desired expected reward: 32.82777404785156






Player: 1 
cards in hand: [ 6.  3. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  0. 29.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.] 
cards in discard: [15.  8. 11. 10.  8.  0.  0.  3.  8.  3.  0.  8.  0.  0.  3.  0.  0. 15.
  0.  6.  8.  3.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [25. 25. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[42.143192]
 [42.575863]
 [42.575863]
 [42.575863]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  0.  0.] 
cards in discard: [11.  1.  8.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.000911831855774
desired expected reward: 25.152780532836914



action possibilites: [-1] 
expected returns: [[6.7546053]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0.  0. 14.] 
cards in discard: [11.  1.  8.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 25.0
Learning step: -1.5768145322799683
desired expected reward: 40.99905014038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-1.2010874]
 [ 2.1111696]
 [ 1.7387087]
 [ 5.3043985]
 [ 1.1010945]
 [ 1.007061 ]
 [ 9.20543  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  0.  0. 14.] 
cards in discard: [11.  1.  8.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0.14874683320522308
desired expected reward: 6.9033522605896



buy possibilites: [-1] 
expected returns: [[70.23308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  0.  0. 14.] 
cards in discard: [11.  1.  8.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: 0.49029865860939026
desired expected reward: -0.7107897996902466






Player: 1 
cards in hand: [11.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10.  1. 16. 10. 14.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [10.  1. 16. 10. 14.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10.  1. 16. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 10. 14.] 
expected returns: [[21.080498]
 [17.366564]
 [17.193924]
 [17.366564]
 [14.11126 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 16. 10. 14.] 
cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0. 10.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -3.727375030517578
desired expected reward: 66.50570678710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.802052]
 [19.736128]
 [19.90395 ]
 [23.9291  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 16. 10. 14.] 
cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0. 10.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.204882264137268
desired expected reward: 19.875635147094727



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [11.  3.  0. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 8.  3. 16.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14. 10.  1. 16. 10.
 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [11.  3.  0. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 8.  3. 16.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14. 10.  1. 16. 10.
 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0. 0.] 
cards in discard: [11.  3.  0. 10.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  3. 16.  0.  0.] 
adversary cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14. 10.  1. 16. 10.
 14.] 
adversary owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[-2.0706549]
 [-6.1509686]
 [-6.3425083]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16.  0.  0.] 
cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14. 10.  1. 16. 10.
 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 25  8 16 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0.  6.  3.  8.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -1.9235239028930664
desired expected reward: 22.00558853149414



action possibilites: [-1] 
expected returns: [[1.340781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14. 10.  1. 16. 10.
 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0.  6.  3.  8.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.12627850472927094
desired expected reward: -5.563718318939209





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.6008818]
 [ 1.2371302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  1.  8.  3.  0.  0.  0. 25. 25. 25.  0.  0.  0. 14. 10.  1. 16. 10.
 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  0.  6.  3.  8.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.26568588614463806
desired expected reward: 1.0750950574874878






Player: 1 
cards in hand: [15.  0.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  3.  8.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 25.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  3.  8.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 25.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  3.  8.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [10. 25.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [10. 25.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[15.710172]
 [ 8.773355]
 [17.494017]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -0.9485911726951599
desired expected reward: 0.2885444760322571



action possibilites: [-1. 25.] 
expected returns: [[29.977636]
 [31.000929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: 0.18450216948986053
desired expected reward: 7.332850933074951





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.750167]
 [18.495827]
 [17.53021 ]
 [10.45201 ]
 [16.662407]
 [21.146471]
 [17.45234 ]
 [24.454544]
 [18.917315]
 [11.624424]
 [14.729056]
 [16.699217]
 [10.543431]
 [15.85749 ]
 [23.507551]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  9.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -1.2318533658981323
desired expected reward: 28.745790481567383



buy possibilites: [-1] 
expected returns: [[25.52489]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  1.  0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  0.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 4.0 

action type: buy - action 29.0
Learning step: -0.17155618965625763
desired expected reward: 18.74576759338379






Player: 1 
cards in hand: [ 3.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  0.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 21. 30.  8.  0.  7.  6.  2.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 14. 10.  0.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  7.  6.  2.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 14. 10.  0.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 20. 30.  8.  0.  7.  6.  2.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 14. 10.  0.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  8. 14. 10.  0.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [25.  8. 14. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 14. 10.] 
expected returns: [[ -7.9094057]
 [ -8.170478 ]
 [-10.79481  ]
 [ -7.7057104]
 [-10.27934  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 14. 10.  0.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.  8.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.163485288619995
desired expected reward: 22.361406326293945



action possibilites: [-1. 25.  8. 14. 11.] 
expected returns: [[-8.195079 ]
 [-9.092047 ]
 [-8.128723 ]
 [-6.5962105]
 [-7.822935 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 14.  0. 11.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.  8.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 10.0
Learning step: -0.34945446252822876
desired expected reward: -10.628796577453613



action possibilites: [-1. 25.  8. 11.] 
expected returns: [[-19.970385]
 [-22.751488]
 [-24.946035]
 [-22.077883]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0. 11.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 14.0
Learning step: 0.15347953140735626
desired expected reward: -6.442731857299805



action possibilites: [-1] 
expected returns: [[64.7637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14. 11.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  60 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: gain_card_n - action 0
Learning step: 2.5624077320098877
desired expected reward: -23.54207992553711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[57.97814 ]
 [61.96332 ]
 [61.13627 ]
 [65.022896]
 [60.901825]
 [60.289856]
 [67.327324]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14. 11.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -0.4806726574897766
desired expected reward: 64.28302764892578



buy possibilites: [-1] 
expected returns: [[35.02673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  0.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14. 11.] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  3.  0.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
adversary owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  60. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -4.0 

action type: buy - action 0.0
Learning step: -2.3108060359954834
desired expected reward: 55.66733932495117






Player: 1 
cards in hand: [15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3
  0 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  0.  3. 16.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  0.  3. 16.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  0.  3. 16.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [25.  1.  0.  3. 16.] 
adversary cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [25.  1.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[ -7.3147774]
 [ -7.7656527]
 [-10.206737 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  3. 16.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1. 15.  3.] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -3.628117322921753
desired expected reward: 31.39861297607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-12.070754]
 [ -9.730246]
 [ -9.388732]
 [ -8.622493]
 [-10.00293 ]
 [ -9.502997]
 [ -7.813717]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  3. 16.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 27. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1. 15.  3.] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -1.529518961906433
desired expected reward: -8.844293594360352



buy possibilites: [-1] 
expected returns: [[-9.97256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  3. 16.] 
cards in discard: [29. 10. 25.  0.  0.  1.  0.  0.  0. 10. 14. 11. 25.  8.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6. 29.  0.  3.] 
adversary cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1. 15.  3.] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1] -> size -> 37 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 1.0
Learning step: -0.5378701686859131
desired expected reward: -10.268118858337402






Player: 1 
cards in hand: [ 0.  6. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.  3.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0
  1] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  0.  3.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  1.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0
  1] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  0.  3.] 
cards in discard: [11.  3.  0. 10.  8. 10.  8.  8.  0.  0.  0.  0. 15.  0.  6.  3.  8.  3.
  8. 11.  3.  8.  0.  0.  0.  8.  1. 15.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0
  1] -> size -> 25 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[9.082854 ]
 [2.6934078]
 [6.3035364]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3 14  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -1.0304663181304932
desired expected reward: -11.003026008605957



action possibilites: [-1] 
expected returns: [[11.40733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.8523147702217102
desired expected reward: 7.327280044555664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.7488161]
 [ 2.1029284]
 [ 1.59811  ]
 [ 6.049693 ]
 [ 0.6470361]
 [ 7.721966 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  3. 10.  8.] 
adversary cards in hand: [15.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -1.1512888669967651
desired expected reward: 10.256040573120117



buy possibilites: [-1] 
expected returns: [[13.1180105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  2. 10.  8.] 
adversary cards in hand: [15.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 10.0
Learning step: 0.46280303597450256
desired expected reward: 1.1098471879959106






Player: 1 
cards in hand: [15.  8.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  0  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0
 29 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  2. 10.  8.] 
adversary cards in hand: [16. 29.  0.  0. 10.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  2. 10.  8.] 
adversary cards in hand: [16. 29.  0.  0. 10.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  2. 10.  8.] 
adversary cards in hand: [16. 29.  0.  0. 10.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [16. 29.  0.  0. 10.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [16. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
expected returns: [[-6.30081  ]
 [-6.035673 ]
 [-6.5427427]
 [-5.4713926]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0.  0. 10.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10. 15.  8. 10. 10.] 
adversary owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -2.4857535362243652
desired expected reward: 10.632257461547852



action possibilites: [-1. 16. 29. 14.] 
expected returns: [[ 1.8761027 ]
 [-0.69717264]
 [-0.02844214]
 [-0.9764625 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0.  0. 14.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10. 15.  8. 10. 10.] 
adversary owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 10.0
Learning step: -0.4042806327342987
desired expected reward: -5.875672340393066





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-0.21842217]
 [ 0.485008  ]
 [ 2.5754611 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.  0. 14.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [10. 15.  8. 10. 10.] 
adversary owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10] -> size -> 38 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -0.7536811232566833
desired expected reward: 1.1224205493927002






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10. 15.  8. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10. 15.  8. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [10. 15.  8. 10. 10.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [25.  0. 25.  1.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [25.  0. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-7.2000055]
 [-7.648472 ]
 [-7.648472 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  1.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -1.9940464496612549
desired expected reward: 0.5814146995544434





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-11.068074 ]
 [ -9.791373 ]
 [ -9.696525 ]
 [-10.431094 ]
 [ -8.162293 ]
 [ -9.426725 ]
 [-11.542987 ]
 [ -9.885237 ]
 [-10.117888 ]
 [ -6.9251366]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25.  1.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0.] 
adversary owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -1.526245355606079
desired expected reward: -8.726244926452637



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  3  0  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29
 10  0 15  8  3  8 10 10  0  3  8  1  8 10  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  1.  8. 10.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  1.  8. 10.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  8.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  1.  8. 10.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  1.  8. 10.  0.] 
adversary cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
adversary owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[7.7285757]
 [4.8118753]
 [4.6254787]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  8. 10.  0.] 
cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25  8 25  0  3  0  0  1 25  8 10 14 16  1 10 11  0 29  0  0  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
adversary owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -1.2018181085586548
desired expected reward: -8.126946449279785



action possibilites: [-1] 
expected returns: [[-7.444333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
adversary owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.2965751886367798
desired expected reward: 7.284979343414307





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-7.712105 ]
 [-7.3123693]
 [-7.444333 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 20. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
adversary owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -0.49425196647644043
desired expected reward: -7.93858528137207



buy possibilites: [-1] 
expected returns: [[-11.108752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  8.  0.  0.  0. 10. 16. 29.  0.  0. 14. 25.  0. 25.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8.  8.  0. 10.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
adversary owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 5 

action type: buy - action 3.0
Learning step: 0.3656715452671051
desired expected reward: -6.94669771194458






Player: 1 
cards in hand: [ 3.  8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8.  0. 10.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8.  0. 29.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 15  8  3  0 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10
  0 15  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8  3 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15
  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8  3 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15
  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[3.5443509]
 [2.1842425]
 [3.1177208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  6.  0.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.] 
adversary owned cards: [15  8  3 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15
  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -0.5213345885276794
desired expected reward: -11.630086898803711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-2.1735473 ]
 [-0.8810388 ]
 [-0.66127217]
 [ 0.8931427 ]
 [-0.9101273 ]
 [ 2.51907   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 11. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  6.  0.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.] 
adversary owned cards: [15  8  3 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15
  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -1.3003311157226562
desired expected reward: 2.2440268993377686



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  6.  0.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  3 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15
  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0.  0. 10. 10.] 
adversary cards in discard: [ 1.  3.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 0. 0.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  8  3 11  6  3  6  0  0  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15
  8  3  8 10 10  0  3  8  1  8 10  1 29] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0.  0. 10. 10.] 
adversary cards in discard: [ 1.  3.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0.  0. 10. 10.] 
adversary cards in discard: [ 1.  3.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0.  0. 10. 10.] 
adversary cards in discard: [ 1.  3.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [14.  0.  0. 10. 10.] 
adversary cards in discard: [ 1.  3.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [14.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
expected returns: [[-0.17547011]
 [-2.7577753 ]
 [-1.7137278 ]
 [-1.7137278 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 10. 10.] 
cards in discard: [ 1.  3.  0. 11. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -1.2177746295928955
desired expected reward: -0.25099635124206543



action possibilites: [-1. 14. 10.] 
expected returns: [[-5.5851374]
 [-5.529641 ]
 [-5.971661 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 10.  0.] 
cards in discard: [ 1.  3.  0. 11. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -2 

action type: take_action - action 10.0
Learning step: -0.14054624736309052
desired expected reward: -1.8542702198028564



action possibilites: [-1. 10.] 
expected returns: [[-6.607231]
 [-6.327343]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 1.  3.  0. 11. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 17 

action type: take_action - action 14.0
Learning step: 0.9825847744941711
desired expected reward: -4.547054767608643



action possibilites: [-1.  8.] 
expected returns: [[ 3.4868784]
 [-2.3606787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 1.  3.  0. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 14. 10.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 37 

action type: take_action - action 10.0
Learning step: 2.21281361579895
desired expected reward: -4.114530563354492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 1.6510668e+00]
 [ 3.2328038e+00]
 [ 3.3713765e+00]
 [-4.0392876e-03]
 [ 2.4532857e+00]
 [ 5.3678241e+00]
 [ 6.3722820e+00]
 [ 3.7735457e+00]
 [ 9.6493721e-01]
 [ 2.2953615e+00]
 [ 3.1004267e+00]
 [ 4.1112113e-01]
 [ 2.8789182e+00]
 [ 7.3220272e+00]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 1.  3.  0. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 14. 10.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: 1.794018030166626
desired expected reward: 5.280880928039551






Player: 1 
cards in hand: [ 3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  1. 10.  8.] 
adversary cards in hand: [29.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  6.  8. 10.  1. 10.  8.] 
adversary cards in hand: [29.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  6.  8. 10.  1. 10.  8.] 
adversary cards in hand: [29.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [29.  0. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[24.728214]
 [22.155415]
 [25.259323]
 [25.259323]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 25.  1.] 
cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  6.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 11.  3.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6. 29. 11.  3.  8.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -0.9577146768569946
desired expected reward: 6.364299297332764



action possibilites: [-1] 
expected returns: [[-0.22492027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  1.  0.  0.] 
cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  6.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 11.  3.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6. 29. 11.  3.  8.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -1 

action type: take_action - action 25.0
Learning step: -1.3180269002914429
desired expected reward: 23.941295623779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.4065228 ]
 [-1.3067509 ]
 [-1.268293  ]
 [-3.4680967 ]
 [-1.724329  ]
 [-0.18930435]
 [ 0.10202765]
 [-1.12213   ]
 [-3.236886  ]
 [-2.3765867 ]
 [-1.5768838 ]
 [-3.4065592 ]
 [-1.9681284 ]
 [ 0.797014  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  1.  0.  0.] 
cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  6.  8. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 11.  3.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6. 29. 11.  3.  8.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -0.14765025675296783
desired expected reward: -0.3725705146789551



Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 3 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 3 

Remodel: 2 
Workshop: 1 
Chapel: 2 
Witch: 3 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  0. 25.  1.  0.  0.] 
cards in discard: [ 1.  3.  0. 11. 25. 10. 14. 10.  0.  0.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  8 25  0  3  0  0 25  8 14 16  1 10 11  0 29  0  0  1 10  3 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 19. 30.  8.  0.  7.  6.  0.  7.  6.  8. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 11.  3.] 
adversary cards in discard: [10. 15.  8. 10. 10.  1.  3.  8.  0.  0.  0. 29. 15.  0.  3.  0. 10.  8.
  3. 29.  0. 10.  8.  0.  6. 29. 11.  3.  8.] 
adversary owned cards: [15  8 11  3  6  0  8  0  8  0  3 10 11  0  3  0 29 10  0 15  8  3  8 10
 10  0  3  8  1  8 10  1 29  0 29] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5 -500    2  -20    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -494 

action type: buy - action 10.0
Learning step: -24.621156692504883
desired expected reward: -26.198041915893555



