 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[315.76257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -672 

action type: buy - action -1.0
Learning step: -48.749080657958984
desired expected reward: 254.2325439453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[300.515  ]
 [305.84882]
 [305.41733]
 [296.41547]
 [305.93005]
 [311.09305]
 [306.056  ]
 [313.49136]
 [302.04163]
 [305.62448]
 [307.51016]
 [321.84427]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.112500190734863
desired expected reward: 310.37725830078125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[358.50388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.035276412963867
desired expected reward: 313.80902099609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[335.2831 ]
 [340.5243 ]
 [340.1018 ]
 [331.2564 ]
 [345.68375]
 [340.7319 ]
 [340.3095 ]
 [358.14352]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.477766990661621
desired expected reward: 352.0528869628906



buy possibilites: [-1] 
expected returns: [[356.15906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -8.21263313293457
desired expected reward: 332.31158447265625






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[313.54086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.807021141052246
desired expected reward: 345.35205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[300.69052]
 [306.11188]
 [305.64758]
 [296.5094 ]
 [311.3999 ]
 [306.31094]
 [305.84665]
 [322.3728 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.914952278137207
desired expected reward: 306.6820373535156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 0. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[341.42944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.471113204956055
desired expected reward: 313.9017028808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[326.18683]
 [331.14932]
 [330.7506 ]
 [323.3586 ]
 [322.17105]
 [331.2207 ]
 [335.88773]
 [331.345  ]
 [341.62045]
 [338.0664 ]
 [327.7135 ]
 [332.53058]
 [330.9463 ]
 [327.58914]
 [332.6549 ]
 [346.4409 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.79313850402832
desired expected reward: 334.5414123535156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[323.81653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.07160472869873
desired expected reward: 336.36932373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[310.20367]
 [315.66348]
 [315.24658]
 [306.0235 ]
 [315.762  ]
 [321.07297]
 [315.88733]
 [323.5195 ]
 [311.79895]
 [315.4704 ]
 [317.40155]
 [332.132  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.24869441986084
desired expected reward: 317.4376220703125



buy possibilites: [-1] 
expected returns: [[283.44843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -9.270930290222168
desired expected reward: 306.199462890625






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [11.  3.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [11.  3.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [11.  3.  0.  0.  0. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.72974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.0968780517578125
desired expected reward: 276.3515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[308.07385]
 [312.6395 ]
 [312.17517]
 [305.5856 ]
 [304.51016]
 [312.64743]
 [316.97983]
 [312.77957]
 [322.3127 ]
 [319.06158]
 [309.27313]
 [313.8057 ]
 [312.31522]
 [309.14102]
 [313.93777]
 [327.0981 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.943106651306152
desired expected reward: 309.96990966796875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[264.6792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.423758506774902
desired expected reward: 316.67437744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[247.55809]
 [252.90675]
 [252.47034]
 [243.46149]
 [258.16183]
 [253.11475]
 [252.67834]
 [268.99054]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.735246181488037
desired expected reward: 260.3158264160156



buy possibilites: [-1] 
expected returns: [[277.15033]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.773001194000244
desired expected reward: 239.78506469726562






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[345.48004]
 [327.54517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.885449409484863
desired expected reward: 270.264892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[323.38275]
 [329.13748]
 [328.62015]
 [318.92892]
 [334.7243 ]
 [329.34824]
 [328.83087]
 [346.50165]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.312987327575684
desired expected reward: 333.7099609375



buy possibilites: [-1] 
expected returns: [[332.30225]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [0. 0. 3. 0. 0. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  3.  1.  0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.  3.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 1.0
Learning step: -8.680073738098145
desired expected reward: 320.4573974609375






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  1.  0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  3.  8.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  1.  0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  3.  8.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  1.  0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  3.  8.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.8837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -11.048877716064453
desired expected reward: 321.25335693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[273.44238]
 [278.76776]
 [278.34906]
 [270.56754]
 [269.35742]
 [278.85947]
 [283.5696 ]
 [278.98126]
 [288.9576 ]
 [285.75232]
 [274.9744 ]
 [280.2371 ]
 [278.56253]
 [274.85263]
 [280.36432]
 [293.0921 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 28. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.57592487335205
desired expected reward: 286.701171875



buy possibilites: [-1] 
expected returns: [[302.78732]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -333.0 

action type: buy - action 6.0
Learning step: -23.305158615112305
desired expected reward: 246.05226135253906






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [6. 0. 3. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [6. 0. 3. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [6. 0. 3. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[293.01825]
 [275.4242 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [6. 0. 3. 0. 1. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -10.82083797454834
desired expected reward: 291.96649169921875



action possibilites: [-1.] 
expected returns: [[340.49924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 0. 3. 0. 1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -22 

action type: take_action - action 10.0
Learning step: -7.296877384185791
desired expected reward: 269.8653259277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[319.5065 ]
 [324.79108]
 [324.26587]
 [315.3875 ]
 [324.81616]
 [329.8371 ]
 [324.95978]
 [332.25415]
 [320.8987 ]
 [324.43457]
 [326.30124]
 [342.24808]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 0. 3. 0. 1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.780131340026855
desired expected reward: 329.7191162109375



buy possibilites: [-1] 
expected returns: [[313.05746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 0. 3. 0. 1. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 3.0
Learning step: -9.669501304626465
desired expected reward: 314.59637451171875






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.80945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1 10] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.297846794128418
desired expected reward: 302.7596130371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[290.56668]
 [296.22684]
 [295.80826]
 [286.32703]
 [296.34976]
 [301.92245]
 [296.47174]
 [304.46503]
 [292.20413]
 [296.05316]
 [298.06302]
 [313.5345 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1 10] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.302416801452637
desired expected reward: 298.80987548828125



buy possibilites: [-1] 
expected returns: [[299.56616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1 10] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -10.88809585571289
desired expected reward: 279.6785888671875






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 8.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11  1 15  3  3  3  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  9. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0. 11.  1. 10. 11.  0.  0.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [0. 3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[374.42908]
 [359.883  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [0. 3. 0. 3. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -8.304779052734375
desired expected reward: 291.2613830566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[354.2283 ]
 [359.71927]
 [359.2329 ]
 [350.47253]
 [364.82385]
 [359.92807]
 [359.44168]
 [374.8573 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [0. 3. 0. 3. 1. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -12.149516105651855
desired expected reward: 362.1258850097656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  1.  0.  0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 6. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[328.88055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 0.  3.  0.  3.  1.  0.  0.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -12.984140396118164
desired expected reward: 361.8731384277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[282.6112 ]
 [287.84564]
 [287.44888]
 [278.6154 ]
 [287.96216]
 [293.11185]
 [288.07693]
 [295.5259 ]
 [284.1173 ]
 [287.6801 ]
 [289.49707]
 [304.14084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 0.  3.  0.  3.  1.  0.  0.  0. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  0.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.220579147338867
desired expected reward: 293.3800964355469



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [10. 15.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [10. 15.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [10. 15.  3.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[260.91467]
 [248.65967]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -11.06839656829834
desired expected reward: 293.0724792480469



action possibilites: [-1.] 
expected returns: [[253.22371]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action 10.0
Learning step: -7.257606506347656
desired expected reward: 239.84518432617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[233.5099 ]
 [238.58939]
 [229.35164]
 [239.25276]
 [255.63622]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.813794136047363
desired expected reward: 245.409912109375



buy possibilites: [-1] 
expected returns: [[263.49774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  1.  8. 11.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 8.0
Learning step: -6.233938217163086
desired expected reward: 233.01881408691406






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  8. 11.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[260.87018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0. 11.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -9.046183586120605
desired expected reward: 254.45155334472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[229.54662]
 [235.34872]
 [228.97893]
 [234.9469 ]
 [226.54688]
 [225.39201]
 [235.50401]
 [241.17952]
 [235.61339]
 [247.70465]
 [243.74278]
 [231.2497 ]
 [237.10834]
 [235.21153]
 [231.14035]
 [237.21771]
 [253.38794]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0. 11.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -8.954996109008789
desired expected reward: 245.65402221679688



buy possibilites: [-1] 
expected returns: [[187.54103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0. 11.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -30    0    0    0    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1740 

action type: buy - action 2.0
Learning step: 79.7707290649414
desired expected reward: 308.7496643066406






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.  0.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0. 11.  3.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 1. 6. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2] -> size -> 19 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0.  0.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0. 11.  3.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  7. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 1. 6. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2] -> size -> 19 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0.  0.] 
cards in discard: [10. 15.  3.  3.  0. 10.  3. 10.  0.  0.  0. 29.  0. 11.  3.  0.  1.  8.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 1. 6. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2] -> size -> 19 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[263.18045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.  1.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -5.10796594619751
desired expected reward: 182.4330596923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[248.31902]
 [252.7136 ]
 [252.34587]
 [244.84981]
 [252.77371]
 [256.73288]
 [252.87218]
 [258.66962]
 [249.56544]
 [252.5045 ]
 [253.93788]
 [265.49988]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.  1.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -8.893729209899902
desired expected reward: 251.9545440673828



buy possibilites: [-1] 
expected returns: [[211.84288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  3.  2.  1.  0.  0.  0.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 10. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 0 

action type: buy - action 14.0
Learning step: -7.7118072509765625
desired expected reward: 241.8536376953125






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 11.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2 14] -> size -> 20 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2 14] -> size -> 20 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 2. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2 14] -> size -> 20 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [8. 0. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[207.61665]
 [193.7068 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 2. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10  0  1  6  3  0  8  2 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -7.692546367645264
desired expected reward: 204.15032958984375



action possibilites: [-1] 
expected returns: [[262.9311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.9665582180023193
desired expected reward: 181.68359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[238.00352]
 [233.90672]
 [259.6219 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -8.198504447937012
desired expected reward: 254.7325897216797



buy possibilites: [-1] 
expected returns: [[295.20242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3. 10.  0.  3.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action 0.0
Learning step: -7.29522180557251
desired expected reward: 230.7082977294922






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  0.  3.] 
cards in discard: [10.  3.  8. 11.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 14.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [10.  3.  8. 11.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 14.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 14.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 14.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  1.  0. 14.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[174.92958]
 [155.55542]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 14.  0.] 
cards in discard: [0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -12.691668510437012
desired expected reward: 282.5107421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[161.17938]
 [166.30591]
 [165.96552]
 [157.42044]
 [166.45396]
 [171.39636]
 [166.55617]
 [173.51932]
 [162.70618]
 [166.21576]
 [167.98402]
 [181.08171]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 14.  0.] 
cards in discard: [0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -6.3363142013549805
desired expected reward: 164.72509765625



buy possibilites: [-1] 
expected returns: [[183.63115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 14.  0.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0] -> size -> 27 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 0 

action type: buy - action 29.0
Learning step: -4.54426383972168
desired expected reward: 168.97503662109375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  0. 10.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  0. 10.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  0. 10.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29] -> size -> 18 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[150.04828]
 [134.31487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  3.  0.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.  8.  1.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0  0] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -7.5894341468811035
desired expected reward: 176.04171752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[129.84152]
 [135.12456]
 [125.63057]
 [135.73026]
 [151.83403]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  5. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  3.  0.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.  8.  1.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0  0] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -5.907886505126953
desired expected reward: 142.548583984375



buy possibilites: [-1] 
expected returns: [[140.60338]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  3.  0.] 
adversary cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.  8.  1.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0  0] -> size -> 28 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -24 

action type: buy - action 8.0
Learning step: -4.822936534881592
desired expected reward: 130.9073028564453






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  3.  0.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.  8.  1.  0.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0
  8  8  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8] -> size -> 19 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.  8.  1.  0.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [10.  3.  8. 11.  3.  0.  8.  0. 10. 11.  3.  0.  3.  0.  0.  8.  1.  0.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8] -> size -> 19 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[155.20024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 1. 0.] 
cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.  3.  0. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -4.177628993988037
desired expected reward: 136.42575073242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[137.50233]
 [142.45184]
 [142.1913 ]
 [133.78023]
 [142.64072]
 [147.5687 ]
 [142.72285]
 [149.71582]
 [139.05367]
 [142.46233]
 [144.16006]
 [157.81126]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 1. 0.] 
cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.  3.  0. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 29. 26. 30.  8.  9. 10.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -4.987629413604736
desired expected reward: 148.45858764648438



buy possibilites: [-1] 
expected returns: [[160.26128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 1. 0.] 
cards in discard: [ 0.  8. 29.  3.  1.  0. 14.  0.  8.  3.  0. 10.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 20 

action type: buy - action 16.0
Learning step: -2.5261573791503906
desired expected reward: 140.11456298828125






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8 16] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8 16] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  8.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8 16] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8 16] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 14.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[225.30327]
 [213.96846]
 [216.33809]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10  0  1  6  3  0  8 14  0 29  8 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  8.  1. 15.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -3.7035179138183594
desired expected reward: 156.55775451660156



action possibilites: [-1] 
expected returns: [[194.502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  8.  1. 15.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 8
Learning step: -5.8652496337890625
desired expected reward: 206.96563720703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[173.31917]
 [169.99895]
 [190.69746]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  8.  1. 15.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0 11] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -5.270463466644287
desired expected reward: 189.23153686523438






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  8.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  1. 15.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  0  0  8 11 15  3  3  3  1 10  8 10 10 29  0  8  8  0
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 16. 29. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 16. 29. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 16. 29. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 16. 29. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 8.  3. 16. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 29. 10.] 
expected returns: [[179.3517 ]
 [164.223  ]
 [164.13776]
 [171.18588]
 [163.94803]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16. 29. 10.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  1 10  0  1  6  3  0  8  0 29  8 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3. 10.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -6.377228260040283
desired expected reward: 184.3202362060547



action possibilites: [-1] 
expected returns: [[242.18782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3. 10.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 11
Learning step: -2.0820751190185547
desired expected reward: 159.83575439453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[223.20216]
 [220.28355]
 [238.14449]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3. 10.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -6.554502964019775
desired expected reward: 235.63331604003906



buy possibilites: [-1] 
expected returns: [[211.19002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  3. 10.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action 0.0
Learning step: -7.5083327293396
desired expected reward: 215.69384765625






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [8. 0. 8. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [8. 0. 8. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [8. 0. 8. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 3.] 
adversary cards in discard: [8. 0. 8. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[175.50095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [8. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.298755168914795
desired expected reward: 203.89126586914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[160.34554]
 [157.73814]
 [174.04482]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 3.] 
cards in discard: [8. 0. 8. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 10. 11.  3.  0.] 
adversary cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1  0] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -5.449448585510254
desired expected reward: 166.13926696777344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 11.  3.  0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0.  3.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3 11  0  0  8 11  3  3  3 10  8 10 10 29  0  8  8  0  0 11  0
  1  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 29.  0.  0.  0.  0.  0.  0.  8.  8.  1.  0. 11.  3.  0.  3. 10. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 0.] 
adversary cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[254.43303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0
 14] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -2.6398301124572754
desired expected reward: 171.40496826171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[230.74329]
 [236.92598]
 [230.113  ]
 [236.47316]
 [227.38922]
 [226.062  ]
 [237.08417]
 [243.1298 ]
 [237.22247]
 [250.10098]
 [245.84573]
 [232.51439]
 [238.73622]
 [236.76962]
 [232.37613]
 [238.87453]
 [255.65364]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 0.] 
cards in discard: [8. 0. 8. 3. 6. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 7 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0
 14] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -6.770181179046631
desired expected reward: 244.89248657226562



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [29.  8.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.  8. 10. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 11  0  0  8 11  3  3 10  8 10 10 29  0  8  8  0  0 11  0  1  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[284.6386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -6.047861576080322
desired expected reward: 249.60577392578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[268.55658]
 [272.48575]
 [268.06992]
 [272.09354]
 [266.3917 ]
 [265.48758]
 [272.5168 ]
 [276.26105]
 [272.62958]
 [280.70798]
 [278.03134]
 [269.5607 ]
 [273.4717 ]
 [272.23734]
 [269.448  ]
 [273.58435]
 [283.84467]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -7.498719215393066
desired expected reward: 274.04888916015625



buy possibilites: [-1] 
expected returns: [[231.47235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 6 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [29.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -22.0 

action type: buy - action 0.0
Learning step: -9.319701194763184
desired expected reward: 259.23687744140625






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [0. 1. 0. 0. 1. 6.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  7.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [0. 1. 0. 0. 1. 6.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [29.  8.  0.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [0. 1. 0. 0. 1. 6.] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[229.7321]
 [217.8522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [0. 1. 0. 0. 1. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -6.146070957183838
desired expected reward: 225.32627868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[214.04207]
 [217.28502]
 [211.27768]
 [217.8296 ]
 [230.50293]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [0. 1. 0. 0. 1. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -6.055891036987305
desired expected reward: 222.207275390625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[181.91318]
 [169.0766 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  8.] 
adversary cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -7.110618591308594
desired expected reward: 223.392333984375



action possibilites: [-1] 
expected returns: [[256.51385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  8.] 
adversary cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.8797272443771362
desired expected reward: 168.1460418701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[231.69939]
 [238.25107]
 [226.33556]
 [239.0809 ]
 [260.14587]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11. 14.  0.  8.] 
adversary cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -6.5137834548950195
desired expected reward: 250.0000762939453






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [11. 11. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 14.  0.  8.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 14.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 14.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 14.] 
cards in discard: [29.  8.  0.  8. 11.  0.  0. 10.  0.  8. 25.  0.  1.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [0. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[185.56236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -9.041834831237793
desired expected reward: 251.10403442382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[172.13571]
 [175.23373]
 [174.97241]
 [169.74127]
 [175.29079]
 [178.29483]
 [175.37796]
 [179.65837]
 [172.98355]
 [175.11661]
 [176.16179]
 [184.47906]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -5.108551502227783
desired expected reward: 173.84494018554688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 1.] 
adversary cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 1.] 
adversary cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  6.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 1.] 
adversary cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 1.] 
adversary cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
adversary owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[216.49954]
 [199.11543]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 1.] 
cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 1 0 1 6 3 0 8 0 8 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  1.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -4.768683910369873
desired expected reward: 179.71038818359375



action possibilites: [-1] 
expected returns: [[220.38358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  1.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.801439046859741
desired expected reward: 188.3999481201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[205.16083]
 [209.51837]
 [201.44185]
 [210.15709]
 [224.59818]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  4.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  1.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -5.383963584899902
desired expected reward: 214.99961853027344



buy possibilites: [-1] 
expected returns: [[204.16138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [8. 0. 0. 3. 0. 1. 3. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  3.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 11.  8.  0.  1.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 25 

action type: buy - action 8.0
Learning step: -4.664224147796631
desired expected reward: 205.4928741455078






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11. 11.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  0.  1.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  3.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  1.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  1.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 8. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8] -> size -> 14 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [6. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[194.27475]
 [175.20769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -6.166881084442139
desired expected reward: 197.99449157714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[174.33371]
 [169.51996]
 [199.96771]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 29. 26. 30.  8.  9.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -5.704413890838623
desired expected reward: 188.41580200195312



buy possibilites: [-1] 
expected returns: [[167.14917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 29. 26. 30.  8.  8.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -20.41514015197754
desired expected reward: 149.1047821044922






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  8.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [6. 6. 8. 3. 0. 3.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6] -> size -> 15 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 29. 26. 30.  8.  8.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [6. 6. 8. 3. 0. 3.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6] -> size -> 15 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [6. 6. 8. 3. 0. 3.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6] -> size -> 15 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[183.82634]
 [169.60907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [6. 6. 8. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  8.  8. 14.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.  0.  0. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -5.148353099822998
desired expected reward: 162.00082397460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[161.61531]
 [165.69579]
 [165.35403]
 [158.46228]
 [169.81017]
 [165.88396]
 [165.54219]
 [178.53253]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [6. 6. 8. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  3.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  8.  8. 14.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.  0.  0. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -5.8877973556518555
desired expected reward: 173.6807403564453



buy possibilites: [-1] 
expected returns: [[198.75362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [6. 6. 8. 3. 0. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  8.  8. 14.] 
adversary cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.  0.  0. 11.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -12.0 

action type: buy - action 8.0
Learning step: -4.422240734100342
desired expected reward: 161.46170043945312






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [29. 25.  8.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  8.  8. 14.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.  0.  0. 11.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 14 11 25
  0 11 10  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.  0.  0. 11.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.] 
cards in discard: [11. 10.  0.  0.  3.  3.  0. 10. 11. 11.  8.  0.  1.  0.  0.  0. 11.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[196.79153]
 [185.5583 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11
 10  0] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -6.293834209442139
desired expected reward: 192.45977783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[186.60442]
 [190.26756]
 [189.94464]
 [184.58855]
 [183.7642 ]
 [190.32854]
 [193.86632]
 [190.43304]
 [198.0064 ]
 [195.48764]
 [187.59134]
 [191.24307]
 [190.11009]
 [187.48688]
 [191.34753]
 [201.15749]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11
 10  0] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -6.25238037109375
desired expected reward: 191.45013427734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 8.] 
adversary cards in discard: [0. 8. 0. 0. 1.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 11  3  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11
 10  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 8.] 
adversary cards in discard: [0. 8. 0. 0. 1.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 8.] 
adversary cards in discard: [0. 8. 0. 0. 1.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 8.] 
adversary cards in discard: [0. 8. 0. 0. 1.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 8. 8.] 
adversary cards in discard: [0. 8. 0. 0. 1.] 
adversary owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [8. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[181.2474 ]
 [171.01682]
 [171.01682]
 [171.01682]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 8. 8.] 
cards in discard: [0. 8. 0. 0. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 6 3 0 8 0 8 0 0 8 6 8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -6.396573543548584
desired expected reward: 194.76092529296875



action possibilites: [-1] 
expected returns: [[201.71535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [0. 8. 0. 0. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 4
Learning step: -1.689745306968689
desired expected reward: 149.8770751953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[176.37073]
 [171.95279]
 [199.3308 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 8. 0. 0. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 29. 26. 30.  8.  8.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -4.562894344329834
desired expected reward: 197.15245056152344



buy possibilites: [-1] 
expected returns: [[181.36815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 8. 0. 0. 1. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8. 29.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.] 
adversary owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -284.0 

action type: buy - action 6.0
Learning step: -18.716856002807617
desired expected reward: 153.23590087890625






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [10.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  0.  0.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 11  3  8 10 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [0. 8. 0. 0. 1. 6. 8. 0. 8.] 
adversary owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6] -> size -> 15 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [0. 8. 0. 0. 1. 6. 8. 0. 8.] 
adversary owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 0. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 6.] 
adversary cards in discard: [0. 8. 0. 0. 1. 6. 8. 0. 8.] 
adversary owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6] -> size -> 15 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [3. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.87985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [0. 8. 0. 0. 1. 6. 8. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -5.7465643882751465
desired expected reward: 175.62158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[144.44185]
 [142.22563]
 [156.10501]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [0. 8. 0. 0. 1. 6. 8. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -4.672305583953857
desired expected reward: 151.85406494140625



buy possibilites: [-1] 
expected returns: [[197.54079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 6.] 
cards in discard: [0. 8. 0. 0. 1. 6. 8. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 11.  3.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -4.4774250984191895
desired expected reward: 139.96441650390625






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 11.  3.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 16 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 16 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 16 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[167.34218]
 [151.42282]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -6.459998607635498
desired expected reward: 191.08079528808594



action possibilites: [-1] 
expected returns: [[194.27599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 0
Learning step: -1.8998634815216064
desired expected reward: 139.5216064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[171.80406]
 [176.02304]
 [168.21385]
 [176.63843]
 [190.18921]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1] -> size -> 22 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -4.8877692222595215
desired expected reward: 189.38821411132812






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[206.2647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 10.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -5.122613430023193
desired expected reward: 185.06658935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[178.83395]
 [183.267  ]
 [182.9184 ]
 [175.86292]
 [187.9719 ]
 [183.50256]
 [183.15395]
 [199.55923]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 29. 26. 30.  8.  7.  9.  5.  2.  9.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 10.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10] -> size -> 24 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -6.185150623321533
desired expected reward: 197.6747283935547



buy possibilites: [-1] 
expected returns: [[230.01355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [8. 3. 0. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0 6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  1. 11. 10.  0.] 
adversary cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0.] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10] -> size -> 24 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -315.0 

action type: buy - action 6.0
Learning step: -19.367841720581055
desired expected reward: 156.4950714111328






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11. 10.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0 6] -> size -> 16 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0 6] -> size -> 16 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0 6] -> size -> 16 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.  0.] 
cards in discard: [ 0. 10.  8.  0.  8. 29.  1. 11.  8.  8.  0.  3. 29. 10. 11.  0.  0. 11.
  0. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 8. 3. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
adversary owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0 6] -> size -> 16 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [1. 8. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[180.36293]
 [167.71864]
 [167.71864]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8. 3. 6.] 
cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 0 1 3 0 0 8 0 0 8 6 8 6 0 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -8.371006965637207
desired expected reward: 221.64254760742188



action possibilites: [-1] 
expected returns: [[207.92378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 7
Learning step: -3.1583633422851562
desired expected reward: 162.09906005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[182.6194 ]
 [186.95949]
 [178.97426]
 [187.56548]
 [203.734  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  2.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -5.855350017547607
desired expected reward: 202.0684356689453



buy possibilites: [-1] 
expected returns: [[169.12286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [8. 3. 0. 0. 6. 3. 0. 6. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 13 

action type: buy - action 8.0
Learning step: -4.923010349273682
desired expected reward: 182.64248657226562






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10 29  0  8  8  0  0 11  0  1  0 11  0 11 10  0  0  1 29 10
 10 29] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 6. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[152.85606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0. 29.] 
adversary cards in discard: [10.  8.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -5.787059307098389
desired expected reward: 163.33580017089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[130.30872]
 [134.69565]
 [134.29526]
 [127.97755]
 [127.0617 ]
 [134.76326]
 [139.00908]
 [134.88759]
 [143.999  ]
 [140.9678 ]
 [131.45598]
 [135.85358]
 [134.48717]
 [131.33168]
 [135.97787]
 [147.75737]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 0 1 3 0 0 8 0 0 8 8 6 0 6 8] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  9.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0. 29.] 
adversary cards in discard: [10.  8.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -5.255076885223389
desired expected reward: 146.70420837402344



buy possibilites: [-1] 
expected returns: [[93.7533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0. 29.] 
adversary cards in discard: [10.  8.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 35 

action type: buy - action 25.0
Learning step: -3.340500593185425
desired expected reward: 140.6584930419922






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [11.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 29.] 
cards in discard: [10.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1. 11. 29. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 10.] 
cards in discard: [10.  8.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 26. 30.  8.  6.  9.  5.  1.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.] 
cards in discard: [10.  8.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  1.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 10.] 
cards in discard: [10.  8.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  1.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 10.] 
cards in discard: [10.  8.  8.  6.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [6. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[153.68396]
 [142.79451]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [25.  0.  0.  6.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 10. 11.] 
adversary cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8] -> size -> 25 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.6323727369308472
desired expected reward: 92.12093353271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[136.75049]
 [139.80779]
 [134.2121 ]
 [151.24629]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [25.  0.  0.  6.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 10. 11.] 
adversary cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8] -> size -> 25 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -4.615354537963867
desired expected reward: 146.7568359375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10. 11.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 8.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1.  8. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 11.  0.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 8.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.  0.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 8.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 11.  0.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [8. 8. 3. 0. 8.] 
adversary cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [8. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[169.79585]
 [160.9833 ]
 [160.9833 ]
 [160.9833 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 8.] 
cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.155898094177246
desired expected reward: 147.0904083251953



action possibilites: [-1] 
expected returns: [[229.68094]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.334897756576538
desired expected reward: 151.719482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[220.77975]
 [219.12985]
 [228.34949]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 29. 26. 30.  8.  5.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -6.250268936157227
desired expected reward: 223.4306640625



buy possibilites: [-1] 
expected returns: [[138.89795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [25.  0.  0.  6.  1.  0.  6.  3.  0.  8.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 29. 26. 30.  8.  4.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11.  1.] 
adversary cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0] -> size -> 26 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -307.0 

action type: buy - action 6.0
Learning step: -23.18128776550293
desired expected reward: 195.9485321044922






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  1.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  4.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 1.] 
cards in discard: [10.  8.  8.  6.  8. 29. 11.  0.  0. 29. 10.  0. 10.  0.  8. 10. 11.  0.
  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 1. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
adversary victory points: -2
player victory points: -1 





Player: 0 
cards in hand: [0. 1. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[119.38787]
 [105.71026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14] -> size -> 28 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: -5.281747341156006
desired expected reward: 133.61619567871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[104.10493 ]
 [108.6778  ]
 [108.33386 ]
 [100.76317 ]
 [108.792145]
 [113.330284]
 [115.33777 ]
 [105.36087 ]
 [108.56771 ]
 [110.11691 ]
 [121.700096]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14] -> size -> 28 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -4.200195789337158
desired expected reward: 113.0505142211914



buy possibilites: [-1] 
expected returns: [[64.073586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8. 3.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14] -> size -> 28 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 15 

action type: buy - action 14.0
Learning step: -3.076387405395508
desired expected reward: 102.28447723388672






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  6.  6. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 17 
adversary victory points: -2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  5.  6. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 17 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8.] 
cards in discard: [29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  5.  6. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 17 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8.] 
cards in discard: [29. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 8. 6.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.] 
adversary owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 17 
adversary victory points: -2
player victory points: -1 





Player: 0 
cards in hand: [8. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[156.81537]
 [145.19647]
 [145.19647]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 6.] 
cards in discard: [14.  0.  1.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 29.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: -0.7112846374511719
desired expected reward: 63.362300872802734



action possibilites: [-1] 
expected returns: [[129.47865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [14.  0.  1.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 29.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.7649712562561035
desired expected reward: 132.7998504638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.586655]
 [118.71717 ]
 [129.66322 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [14.  0.  1.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 29.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action -1
Learning step: -3.5306396484375
desired expected reward: 125.94801330566406



buy possibilites: [-1] 
expected returns: [[115.37861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [14.  0.  1.  0.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 29.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -27.0 

action type: buy - action 0.0
Learning step: -4.783313274383545
desired expected reward: 115.8033218383789






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0. 29.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  0. 25.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.  0.  8.  0.  8.  6.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: -1 


action possibilites: [-1.  8. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29.  8.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  0. 25.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.  0.  8.  0.  8.  6.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  8.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 29. 26. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  0. 25.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.  0.  8.  0.  8.  6.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  8.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 25. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  6.  0. 25.] 
adversary cards in discard: [14.  0.  1.  0.  8.  3.  0.  8.  0.  8.  6.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[83.579216]
 [81.83164 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  0. 25.] 
cards in discard: [14.  0.  1.  0.  8.  3.  0.  8.  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 25. 30.  8.  3.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11.  1.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3] -> size -> 31 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -5.254649639129639
desired expected reward: 110.12396240234375



action possibilites: [-1] 
expected returns: [[148.57396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 25. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11.  1.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6] -> size -> 32 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action 25.0
Learning step: -1.0986683368682861
desired expected reward: 80.73297119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[132.61581]
 [136.36113]
 [129.56136]
 [149.21797]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  0. 14.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 29. 25. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 11.  1.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6] -> size -> 32 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -4.649662017822266
desired expected reward: 143.92430114746094






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 11. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11.  1.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 25. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 11.  1.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 29. 25. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 11.  1.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 29. 24. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.] 
adversary owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [6. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[99.10276]
 [91.69021]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  0  0  8  0  0  8  8  6  0  6  8 25  6 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -6.677464485168457
desired expected reward: 142.54052734375



action possibilites: [-1] 
expected returns: [[66.9611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.4958255290985107
desired expected reward: 89.55317687988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.504673]
 [58.045067]
 [67.21371 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 29. 24. 30.  8.  2.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -2.290379285812378
desired expected reward: 64.67071533203125



buy possibilites: [-1] 
expected returns: [[113.87635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10. 10.  3.  8.] 
adversary cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -318.0 

action type: buy - action 6.0
Learning step: -16.240036010742188
desired expected reward: 41.805023193359375






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.  8.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 10.  8. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  8. 14.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1.  8. 14. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 14. 10.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 14 29 29  3  6  3] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.  8. 10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [29. 29. 11.  0.  1.  0.  8.  3. 10.  8.  0.  0. 29.  8.  6.  3.  0. 29.
 11. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.  8. 10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 1. 0.] 
adversary cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [0. 8. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[124.64751]
 [120.30674]
 [120.30674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 1. 0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1
Learning step: -4.868528366088867
desired expected reward: 109.00782012939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[108.456055]
 [110.02482 ]
 [109.81889 ]
 [107.2552  ]
 [110.00491 ]
 [111.71092 ]
 [112.64994 ]
 [108.795364]
 [109.862854]
 [110.38588 ]
 [115.73923 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 1. 0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 29. 24. 30.  8.  1.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1.0
Learning step: -5.572925090789795
desired expected reward: 117.99250030517578



buy possibilites: [-1] 
expected returns: [[96.68815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 1. 0.] 
cards in discard: [25.  0.  6.  6.  0. 14.  8.  6.  8.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [12. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [29.  6.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -349.0 

action type: buy - action 6.0
Learning step: -20.637277603149414
desired expected reward: 86.61795043945312






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [29.  6.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  9.] 
adversary cards in hand: [1. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  8.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [1. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  8.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [1. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0.  8.] 
cards in discard: [15.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [1. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [1. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[83.34362]
 [75.79221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  8.  1.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0] -> size -> 34 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -5.437995433807373
desired expected reward: 91.25015258789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[79.86262 ]
 [82.53298 ]
 [82.22551 ]
 [82.52132 ]
 [85.03606 ]
 [86.2409  ]
 [80.499725]
 [82.313385]
 [83.2224  ]
 [90.30653 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  8.  1.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0] -> size -> 34 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1.0
Learning step: -4.944814682006836
desired expected reward: 83.0487289428711



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  8.  1.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [1. 8. 0. 6. 0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  1.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [1. 8. 0. 6. 0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  8.  1.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [10. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [1. 8. 0. 6. 0.] 
adversary owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [0. 8. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[132.07658]
 [122.83242]
 [122.83242]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 8.] 
cards in discard: [1. 8. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  0  0  8  8  0  6  8 25  6 14  0  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1.0
Learning step: -4.1517438888549805
desired expected reward: 86.15478515625



action possibilites: [-1] 
expected returns: [[93.21353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [1. 8. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: trash_cards_n_from_hand - action 10
Learning step: -4.8227458000183105
desired expected reward: 115.5782470703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[84.40046 ]
 [92.163956]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [1. 8. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -3.5591819286346436
desired expected reward: 89.65435028076172



buy possibilites: [-1] 
expected returns: [[98.3079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [1. 8. 0. 6. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  6. 11.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action 0.0
Learning step: -4.408095359802246
desired expected reward: 79.99236297607422






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6. 11.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 14.  6.  6.  0.] 
adversary cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
adversary owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 11. 10.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 14.  6.  6.  0.] 
adversary cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
adversary owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 11.  8.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  6
  8  0  6 29 29  3  6  3 15  0  0] -> size -> 35 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 14.  6.  6.  0.] 
adversary cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
adversary owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 14.  6.  6.  0.] 
adversary cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
adversary owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 14.  6.  6.  0.] 
adversary cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
adversary owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 14.  6.  6.  0.] 
adversary cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
adversary owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [ 8. 14.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[93.78719 ]
 [88.84062 ]
 [87.561485]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  6.  6.  0.] 
cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  8  0  8 25  6 14  0  6  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 10.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -5.317454814910889
desired expected reward: 92.99044799804688



action possibilites: [-1] 
expected returns: [[79.074715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.] 
cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 10.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.336113691329956
desired expected reward: 81.96978759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[73.34684]
 [78.6529 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.] 
cards in discard: [1. 8. 0. 6. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 10.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -3.083387851715088
desired expected reward: 75.99132537841797



buy possibilites: [-1] 
expected returns: [[79.869484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.] 
cards in discard: [1. 8. 0. 6. 0. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0. 29. 11.  3. 10.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -47.0 

action type: buy - action 0.0
Learning step: -4.220279693603516
desired expected reward: 69.1265869140625






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  3. 10.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1. 29. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  3. 10.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1. 29. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  3. 29.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0] -> size -> 35 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  5.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10. 11. 29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11] -> size -> 36 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 11. 29. 29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11] -> size -> 36 
action values: 2 
buys: 0 
player value: 2 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 11. 29. 29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11] -> size -> 36 
action values: 2 
buys: 1 
player value: 2 
card supply: [ 7. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 11. 29. 29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
action values: 2 
buys: 0 
player value: 2 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[86.89036 ]
 [84.494026]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  8.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -4.036430358886719
desired expected reward: 75.83305358886719



action possibilites: [-1] 
expected returns: [[8.579894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  8.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -16 

action type: take_action - action 25.0
Learning step: -4.552308559417725
desired expected reward: 74.35482025146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-1.1909063 ]
 [ 0.12672359]
 [ 0.0232476 ]
 [ 0.16160291]
 [ 1.8665061 ]
 [ 2.9085867 ]
 [-0.8712127 ]
 [ 0.09667104]
 [ 0.63243634]
 [ 7.1335225 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 11.  8.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -1.2309143543243408
desired expected reward: 7.348979949951172



buy possibilites: [-1] 
expected returns: [[11.232113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0. 6.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 1.  3.  0. 11.  8.] 
adversary cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 15 

action type: buy - action 15.0
Learning step: 0.9711006283760071
desired expected reward: 1.6035395860671997






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 11.  8.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [14.  8.  8.  0.  8.] 
adversary cards in discard: [15. 25.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0 15] -> size -> 14 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 11.  8.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [14.  8.  8.  0.  8.] 
adversary cards in discard: [15. 25.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0 15] -> size -> 14 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 11.  8.] 
cards in discard: [15.  0. 11. 29.  6.  0.  8.  0.  0. 29.  0.  8.  1.  0. 10. 10.  8.  3.
  0. 11. 11.  3.  8.  0.  6.  0. 10. 10. 11. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [14.  8.  8.  0.  8.] 
adversary cards in discard: [15. 25.  0.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0 15] -> size -> 14 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [14.  8.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.  8.] 
expected returns: [[135.12971]
 [124.66587]
 [126.87988]
 [126.87988]
 [126.87988]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  8.  0.  8.] 
cards in discard: [15. 25.  0.  6.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  0  8  8  0  8 25 14  0  6  6  0  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0] -> size -> 38 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: 0.4978303909301758
desired expected reward: 11.72994327545166



action possibilites: [-1] 
expected returns: [[34.305622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.] 
cards in discard: [15. 25.  0.  6.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0] -> size -> 38 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 5
Learning step: -6.066378593444824
desired expected reward: 113.69872283935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.61431 ]
 [31.757956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.] 
cards in discard: [15. 25.  0.  6.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 11. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0] -> size -> 38 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -1.954354166984558
desired expected reward: 32.35126876831055






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 3. 11. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 14.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11.  0.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 14.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  0.] 
cards in discard: [1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 14.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11.  0.] 
cards in discard: [1. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 14.  0.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 6. 14.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[71.11374 ]
 [61.574875]
 [63.570614]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  8.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  0  8 25 14  0  6  6  0  0 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 10. 29.  0.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -1.9627087116241455
desired expected reward: 29.795249938964844



action possibilites: [-1] 
expected returns: [[201.1695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 10. 29.  0.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: trash_cards_n_from_hand - action 6
Learning step: 1.3358153104782104
desired expected reward: 59.14577865600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[192.28496]
 [200.42842]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 10. 29.  0.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -5.924563407897949
desired expected reward: 195.24493408203125



buy possibilites: [-1] 
expected returns: [[118.824615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 1. 10. 29.  0.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -36.0 

action type: buy - action 0.0
Learning step: -8.740694046020508
desired expected reward: 183.5442657470703






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 1. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 29.  0.  0.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0. 25.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0. 25.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 23. 29. 24. 30.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0. 25.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 24. 29.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 15.  8.  0. 25.] 
adversary cards in discard: [ 0.  8. 14.  0.] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 0. 15.  8.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 25.] 
expected returns: [[87.14416]
 [83.2217 ]
 [82.87618]
 [85.78971]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  0. 25.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 24. 29.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11.  8.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -6.817049503326416
desired expected reward: 112.007568359375



action possibilites: [-1] 
expected returns: [[13.418943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  0.  6.  0.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 24. 29.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11.  8.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -35 

action type: take_action - action 25.0
Learning step: -5.7581400871276855
desired expected reward: 80.44318389892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 7.0355906]
 [ 8.410892 ]
 [ 8.297531 ]
 [ 9.769767 ]
 [ 8.358218 ]
 [12.534371 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8.  0.  6.  0.] 
cards in discard: [ 0.  8. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 23. 29. 24. 29.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11.  8.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -2.2533977031707764
desired expected reward: 11.165545463562012



buy possibilites: [-1] 
expected returns: [[78.63531]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8.  0.  6.  0.] 
cards in discard: [ 0.  8. 14.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 11.  8.  8.  6.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -1.882485032081604
desired expected reward: 5.153102397918701






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  8.  6.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  4.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  6. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  6. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 8.  6. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 25 14  0  6  0  0 15  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 8.  6. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[79.84681 ]
 [73.74744 ]
 [72.092186]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 25 14  0  6  0  0 15  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10. 15.  0. 29.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.029094696044922
desired expected reward: 73.60621643066406



action possibilites: [-1] 
expected returns: [[31.673456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 25  0  0 15  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10. 15.  0. 29.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 10
Learning step: -4.794105052947998
desired expected reward: 69.34104919433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.825632]
 [33.330055]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 25  0  0 15  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10. 15.  0. 29.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -2.7035317420959473
desired expected reward: 28.969924926757812



buy possibilites: [-1] 
expected returns: [[102.5749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0. 10. 15.  0. 29.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
adversary owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action 0.0
Learning step: -1.5633596181869507
desired expected reward: 20.86253547668457






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.  0. 29.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 29.  0.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8 11  3  8 10  8  8  0 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8
  0  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 3 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15. 29.] 
owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 4 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15. 29.] 
owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  3.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 15. 29.] 
owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  2.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  8.  0.  0. 25.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[63.20538]
 [55.26078]
 [60.74458]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 25.] 
cards in discard: [0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 25  0  0 15  0  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  2.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0. 11. 10. 15. 29.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.058587074279785
desired expected reward: 96.51631164550781



action possibilites: [-1] 
expected returns: [[80.93739]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 25 15  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  2.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0. 11. 10. 15. 29.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 4
Learning step: -3.435553789138794
desired expected reward: 46.69734573364258





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[71.54771]
 [78.9442 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 25 15  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 23. 29. 24. 29.  8.  0.  9.  2.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0. 11. 10. 15. 29.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -5.089406490325928
desired expected reward: 75.84798431396484



Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 2 
Gold: 1 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 0 
Chapel: 5 
Witch: 1 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.] 
cards in discard: [0. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 25 15  0  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 24. 29.  8.  0.  9.  2.  0.  8.  4.  6. 10.  3. 10.  7.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [ 1.  0. 11.  3. 29. 11.  0.  1. 10.  4. 29.  0.  0.  1. 11. 11.  0.  8.
  8.  6.  0.  0. 11. 10. 15. 29.  0.] 
adversary owned cards: [ 8 11  3  8 10  8  8 11  0  1  0 11  0 11 10  0  0  1 29 10 10 29  8  0
  6 29 29  3  6  3 15  0  0  0 11  0  0  1  0  4 11 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -40    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -555 

action type: buy - action 0.0
Learning step: -31.3273868560791
desired expected reward: 40.22032928466797



