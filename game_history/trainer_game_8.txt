 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.0875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -650 

action type: buy - action -1.0
Learning step: -33.637672424316406
desired expected reward: -10.884235382080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[309.40622]
 [309.4233 ]
 [309.40622]
 [309.40622]
 [310.38138]
 [312.27206]
 [310.84808]
 [317.47287]
 [312.23   ]
 [310.60562]
 [313.99167]
 [326.1506 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.54245662689209
desired expected reward: 323.22454833984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[353.13293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.898590087890625
desired expected reward: 317.2519836425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[333.7227 ]
 [333.73972]
 [333.7227 ]
 [333.7227 ]
 [336.58856]
 [335.16458]
 [334.92206]
 [350.46713]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.659296035766602
desired expected reward: 345.29351806640625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[355.19116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.0584716796875
desired expected reward: 340.40863037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[337.1286 ]
 [337.14566]
 [337.1286 ]
 [337.1286 ]
 [338.10373]
 [339.99445]
 [338.57043]
 [344.85886]
 [339.95236]
 [338.32794]
 [341.61887]
 [352.93405]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.714747428894043
desired expected reward: 347.7245178222656



buy possibilites: [-1] 
expected returns: [[328.844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 1.0
Learning step: -9.833292007446289
desired expected reward: 327.3123474121094






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[356.4924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.487825393676758
desired expected reward: 319.3561706542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[345.38477]
 [345.40182]
 [345.38477]
 [345.38477]
 [348.25064]
 [346.8266 ]
 [346.58414]
 [361.19025]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.010336875915527
desired expected reward: 346.9618835449219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[332.98148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -11.587198257446289
desired expected reward: 349.6030578613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[318.23535]
 [318.25238]
 [318.23535]
 [318.23535]
 [319.21048]
 [321.10117]
 [319.6772 ]
 [325.9656 ]
 [321.05914]
 [319.4347 ]
 [322.72562]
 [334.0408 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.545248985290527
desired expected reward: 326.0020446777344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[374.7867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [15. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -9.343607902526855
desired expected reward: 324.69720458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[358.57913]
 [358.59625]
 [358.57913]
 [358.57913]
 [358.57913]
 [359.55432]
 [361.44498]
 [360.021  ]
 [364.68497]
 [366.30942]
 [361.40292]
 [362.6027 ]
 [359.7785 ]
 [360.93622]
 [363.06943]
 [374.3846 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [15. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.606639862060547
desired expected reward: 364.3236999511719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [15. 29.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [15. 29.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [15. 29.  0.  3.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.5504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -12.70362377166748
desired expected reward: 361.6810302734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[320.6133 ]
 [320.63034]
 [320.6133 ]
 [320.6133 ]
 [323.47916]
 [322.05515]
 [321.81265]
 [336.41873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.092657089233398
desired expected reward: 327.3788146972656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  3 15 15  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[393.2735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -9.558594703674316
desired expected reward: 326.86016845703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[375.78146]
 [375.79855]
 [375.78146]
 [375.78146]
 [376.75662]
 [378.64734]
 [377.22336]
 [383.9144 ]
 [378.6053 ]
 [376.98087]
 [380.29346]
 [392.93616]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -12.59949779510498
desired expected reward: 381.2824401855469



buy possibilites: [-1] 
expected returns: [[350.39978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -27.5 

action type: buy - action 1.0
Learning step: -11.802734375
desired expected reward: 354.4318542480469






Player: 1 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[346.0898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -11.286831855773926
desired expected reward: 339.1129455566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[332.8282 ]
 [332.8443 ]
 [332.8282 ]
 [332.8282 ]
 [332.8282 ]
 [333.78018]
 [335.62253]
 [334.23044]
 [338.7991 ]
 [340.3911 ]
 [335.5843 ]
 [336.76425]
 [333.99234]
 [335.134  ]
 [337.21457]
 [348.2923 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.301360130310059
desired expected reward: 336.8389587402344



buy possibilites: [-1] 
expected returns: [[364.8549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3.  0.  0.] 
adversary cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -11.532172203063965
desired expected reward: 321.2959899902344






Player: 1 
cards in hand: [ 3. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  0.  0.] 
cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [16. 15.  3.  3.  0.  0. 29.  0.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[384.58316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -11.215559959411621
desired expected reward: 353.63934326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[372.8014 ]
 [372.8176 ]
 [372.8014 ]
 [372.8014 ]
 [372.8014 ]
 [373.75345]
 [375.59576]
 [374.20374]
 [378.77237]
 [380.36432]
 [375.55756]
 [376.7375 ]
 [373.96555]
 [375.10727]
 [377.18777]
 [388.26556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [0. 0. 0. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -12.16646671295166
desired expected reward: 371.2639465332031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 27. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.  3.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[372.4587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  1.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -12.606974601745605
desired expected reward: 375.6585693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[356.52267]
 [356.53882]
 [356.52267]
 [356.52267]
 [359.31702]
 [357.92496]
 [357.6868 ]
 [371.98676]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  1.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -12.04652214050293
desired expected reward: 361.56695556640625



buy possibilites: [-1] 
expected returns: [[381.01633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  1.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -343.0 

action type: buy - action 6.0
Learning step: -26.40326499938965
desired expected reward: 330.1194152832031






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  1.  0. 29.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [6. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  1.  0. 29.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [6. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.7167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [6. 0. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3. 15.  0.] 
adversary cards in discard: [16.  1.  0. 29.  0.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -13.390730857849121
desired expected reward: 367.6256103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[330.27563]
 [330.29175]
 [330.27563]
 [330.27563]
 [330.27563]
 [330.27563]
 [331.2276 ]
 [333.06992]
 [331.67795]
 [336.24658]
 [337.83853]
 [333.03177]
 [334.2117 ]
 [331.43973]
 [332.58145]
 [334.662  ]
 [345.7397 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [6. 0. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  3. 15.  0.] 
adversary cards in discard: [16.  1.  0. 29.  0.  3.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -11.859413146972656
desired expected reward: 335.25555419921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 15.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3. 15.  0.] 
cards in discard: [16.  1.  0. 29.  0.  3.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.] 
cards in discard: [16.  1.  0. 29.  0.  3.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.] 
cards in discard: [16.  1.  0. 29.  0.  3.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 27. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.] 
cards in discard: [16.  1.  0. 29.  0.  3.  0.  3.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[372.88376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16  3] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -11.52586555480957
desired expected reward: 334.21380615234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[352.60165]
 [352.6178 ]
 [352.60165]
 [352.60165]
 [352.60165]
 [353.55365]
 [355.39597]
 [354.00394]
 [358.57254]
 [360.16458]
 [355.35782]
 [356.5377 ]
 [353.76578]
 [354.9075 ]
 [356.98798]
 [368.06573]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16  3] -> size -> 18 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -13.190815925598145
desired expected reward: 360.63665771484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 29  3 15 15  3 16  0  1 16  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [0. 0. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [0. 0. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [0. 0. 0. 1. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[471.8399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [0. 0. 0. 1. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 29.  3.  3.  0.] 
adversary cards in discard: [29. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -9.961968421936035
desired expected reward: 358.103759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[453.6529 ]
 [453.67075]
 [453.6529 ]
 [453.6529 ]
 [456.77515]
 [455.2197 ]
 [454.95352]
 [470.94128]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [0. 0. 0. 1. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15. 29.  3.  3.  0.] 
adversary cards in discard: [29. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -15.241632461547852
desired expected reward: 455.483642578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.  3.  0.] 
cards in discard: [29. 16.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  3.  3.  0.] 
cards in discard: [29. 16.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  3.  3.  0.] 
cards in discard: [29. 16.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[457.61755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [29. 16.  3.  0.  3.  0. 15. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -15.37732219696045
desired expected reward: 455.5639343261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[422.4529 ]
 [422.4681 ]
 [422.4529 ]
 [422.4529 ]
 [423.37753]
 [425.1651 ]
 [423.8117 ]
 [429.8112 ]
 [425.12982]
 [423.5791 ]
 [426.7158 ]
 [437.49936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  0.  0.] 
adversary cards in discard: [29. 16.  3.  0.  3.  0. 15. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -14.528059959411621
desired expected reward: 427.3590087890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [29. 16.  3.  0.  3.  0. 15. 29.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [29. 16.  3.  0.  3.  0. 15. 29.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  0.  0.] 
cards in discard: [29. 16.  3.  0.  3.  0. 15. 29.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [6. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[462.0057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0] -> size -> 20 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -13.623260498046875
desired expected reward: 423.8760986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[444.59293]
 [444.61096]
 [444.59293]
 [444.59293]
 [445.70343]
 [447.8457 ]
 [446.22272]
 [453.41965]
 [447.80377]
 [445.94437]
 [449.7052 ]
 [462.64536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [6. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  0.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0] -> size -> 20 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -15.008288383483887
desired expected reward: 447.2897644042969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 15.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[462.13058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -14.888046264648438
desired expected reward: 447.75732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[439.74878]
 [439.76562]
 [439.74878]
 [439.74878]
 [440.78464]
 [442.782  ]
 [441.26837]
 [447.9818 ]
 [442.74313]
 [441.0082 ]
 [444.51694]
 [456.5851 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 26. 30.  8.  9.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0] -> size -> 21 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -15.117709159851074
desired expected reward: 446.84765625



buy possibilites: [-1] 
expected returns: [[403.14505]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0] -> size -> 21 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -354.0 

action type: buy - action 6.0
Learning step: -30.616674423217773
desired expected reward: 409.13214111328125






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10. 10. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 1. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[406.22415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [6. 3. 0. 1. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  3. 29. 16.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -13.751242637634277
desired expected reward: 389.393798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[389.00565]
 [389.02094]
 [389.00565]
 [389.00565]
 [389.00565]
 [389.93033]
 [391.71786]
 [390.36453]
 [394.81326]
 [396.36395]
 [391.68265]
 [392.8344 ]
 [390.1319 ]
 [391.2484 ]
 [393.2686 ]
 [404.05215]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [6. 3. 0. 1. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  3. 29. 16.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8] -> size -> 22 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -13.971814155578613
desired expected reward: 390.73980712890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  3. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29. 16.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  8.  8. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  8.  7. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  8.  7. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  8.  7. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[458.81058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  8.  7. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0. 16.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -12.086346626281738
desired expected reward: 391.96575927734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[436.25513]
 [436.272  ]
 [436.25513]
 [436.25513]
 [437.291  ]
 [439.2884 ]
 [437.7747 ]
 [444.4882 ]
 [439.24948]
 [437.51456]
 [441.02335]
 [453.09146]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1 0 6 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 26. 30.  8.  8.  7. 10.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0. 16.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -15.073065757751465
desired expected reward: 443.4272766113281



buy possibilites: [-1] 
expected returns: [[373.879]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  8.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  0. 16.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -39.5 

action type: buy - action 11.0
Learning step: -15.527140617370605
desired expected reward: 423.76123046875






Player: 1 
cards in hand: [15.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 16.  0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  8.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  7.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 26. 30.  8.  7.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [ 0.  3.  3.  0.  1. 15.  8.  3.  0.  3.  3.  0. 16.  0. 16. 29.  0. 29.
  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 26. 30.  8.  7.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[430.8812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [11.  0.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  7.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6.  8. 16. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -10.695693016052246
desired expected reward: 363.1833190917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[415.3694 ]
 [415.38748]
 [415.3694 ]
 [415.3694 ]
 [418.61453]
 [416.99512]
 [416.71722]
 [433.37814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [11.  0.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 30.  8.  7.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 6.  8. 16. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -13.658563613891602
desired expected reward: 417.3750915527344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8. 16. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 16. 16.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  7.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 16.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 16.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 16.] 
cards in discard: [6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 1. 1. 0.] 
adversary cards in discard: [11.  0.  6.  0.  0.  0.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[401.8784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 1. 0.] 
cards in discard: [11.  0.  6.  0.  0.  0.  3.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -13.3251371383667
desired expected reward: 420.0530700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[387.78467]
 [387.80215]
 [387.78467]
 [387.78467]
 [387.78467]
 [388.85004]
 [390.9193 ]
 [389.3526 ]
 [394.8542 ]
 [396.8233 ]
 [390.8748 ]
 [392.33633]
 [389.08548]
 [390.36783]
 [392.88843]
 [406.5977 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1. 0.] 
cards in discard: [11.  0.  6.  0.  0.  0.  3.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.809366226196289
desired expected reward: 390.1361083984375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  9. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  8. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[415.19257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  8. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.708163261413574
desired expected reward: 394.8895263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[400.09122]
 [400.09122]
 [400.09122]
 [401.471  ]
 [416.8389 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  8. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -12.260550498962402
desired expected reward: 403.76141357421875



buy possibilites: [-1] 
expected returns: [[412.1947]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -6 

action type: buy - action 8.0
Learning step: -11.09916877746582
desired expected reward: 390.3717956542969






Player: 1 
cards in hand: [ 0.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [8. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [8. 0. 6. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[430.00995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [8. 0. 6. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  1. 29.  3.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.  0.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -11.675738334655762
desired expected reward: 400.5189514160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[413.31604]
 [413.3369 ]
 [413.31604]
 [413.31604]
 [413.31604]
 [413.31604]
 [414.4505 ]
 [416.61435]
 [414.96588]
 [420.33075]
 [422.20428]
 [416.5737 ]
 [417.9725 ]
 [414.7002 ]
 [416.0583 ]
 [418.4878 ]
 [431.47958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [8. 0. 6. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  1. 29.  3.] 
adversary cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.  0.  0.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -12.556479454040527
desired expected reward: 415.6211853027344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  0.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1. 29.  3.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.  0.  0.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [8. 0. 6. 3. 0. 6. 0. 0. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  3.  0.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.  0.  0.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [8. 0. 6. 3. 0. 6. 0. 0. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  3.  0.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.  0.  0.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  8. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [8. 0. 6. 3. 0. 6. 0. 0. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  3.  0.] 
cards in discard: [ 6.  0. 16.  6.  8. 16.  8.  3.  3. 16.  0.  0.  0.  0.  3.  0. 15. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10. 10. 10.  8.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [8. 0. 6. 3. 0. 6. 0. 0. 0. 1. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[396.7798]
 [380.9997]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [8. 0. 6. 3. 0. 6. 0. 0. 0. 1. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10. 10. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -13.439218521118164
desired expected reward: 418.04034423828125



action possibilites: [-1] 
expected returns: [[463.5541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 8.  0.  6.  3.  0.  6.  0.  0.  0.  1.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 15 

action type: gain_card_n - action 9
Learning step: -7.857327938079834
desired expected reward: 372.8885803222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[445.09476]
 [445.09476]
 [445.09476]
 [446.8483 ]
 [464.3775 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 8.  0.  6.  3.  0.  6.  0.  0.  0.  1.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -12.588128089904785
desired expected reward: 450.9659729003906



buy possibilites: [-1] 
expected returns: [[312.1516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 8.  0.  6.  3.  0.  6.  0.  0.  0.  1.  1. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -16.43132972717285
desired expected reward: 428.6634521484375






Player: 1 
cards in hand: [16.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.39868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  0.  3.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29 10] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -8.783401489257812
desired expected reward: 303.36822509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[323.3605 ]
 [323.37805]
 [323.3605 ]
 [323.3605 ]
 [324.29785]
 [326.08945]
 [324.7257 ]
 [330.71207]
 [326.05548]
 [324.50558]
 [327.63937]
 [338.3821 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [15. 29.  0.  0.  3.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29 10] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -9.933928489685059
desired expected reward: 324.4740295410156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  0.  0.  3.] 
cards in discard: [10. 16.  0. 29.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  1.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  0.] 
cards in discard: [10. 16.  0. 29.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6
  0  8 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  1.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 16.  0. 29.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  1.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 16.  0. 29.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  1.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [10.  0.  1.  3.  0.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  0.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[433.4917 ]
 [414.59653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  3.  0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16.  1.  0.  6.  8.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -7.963028907775879
desired expected reward: 330.4190368652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[415.0133 ]
 [415.03674]
 [415.0133 ]
 [415.0133 ]
 [416.29095]
 [418.72992]
 [416.8738 ]
 [425.02286]
 [418.6838 ]
 [416.5754 ]
 [420.83832]
 [435.47055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  3.  0.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16.  1.  0.  6.  8.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -12.754298210144043
desired expected reward: 420.8308410644531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  1.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  6.  8.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 10.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  6.  8.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  7. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 10.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  6.  8.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  0.  0. 10.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[375.5706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 0.  0.  3.  0.  0. 10.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16. 15.  3.  3.  6.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.] 
adversary owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -14.031878471374512
desired expected reward: 421.43865966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[353.5464 ]
 [353.56845]
 [353.5464 ]
 [353.5464 ]
 [357.04904]
 [355.29987]
 [355.01825]
 [372.82913]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 0.  0.  3.  0.  0. 10.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16. 15.  3.  3.  6.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.] 
adversary owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.239527702331543
desired expected reward: 363.9448547363281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 15.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  3.  3.  6.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  3.  3.  6.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  8. 11.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 11.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[366.32117]
 [349.80743]
 [351.45593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  1.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.
 16. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -11.243792533874512
desired expected reward: 361.5852966308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[341.00113]
 [341.02362]
 [341.00113]
 [341.00113]
 [344.31198]
 [342.65295]
 [342.3989 ]
 [359.16476]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  1.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.
 16. 15.  3.  3.  6.] 
adversary owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -10.684150695800781
desired expected reward: 347.4405212402344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.
 16. 15.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 29  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0
  8 29 10 15  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.
 16. 15.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.
 16. 15.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 16.  0. 29.  0.  0. 15. 29. 15.  0.  3.  0.  8. 16.  1.  0.  6.  8.
 16. 15.  3.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[273.93753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 0.  8. 11.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16.  6.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -12.536371231079102
desired expected reward: 346.62835693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[262.54822]
 [262.56598]
 [262.54822]
 [262.54822]
 [263.4365 ]
 [265.11807]
 [263.8306 ]
 [269.4455 ]
 [265.0896 ]
 [263.63284]
 [266.57483]
 [276.9153 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 0.  8. 11.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 26. 30.  8.  6.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16.  6.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.195419311523438
desired expected reward: 263.88751220703125



buy possibilites: [-1] 
expected returns: [[306.2053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 0.  8. 11.  1.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [16.  6.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -325.0 

action type: buy - action 6.0
Learning step: -22.487791061401367
desired expected reward: 240.0604248046875






Player: 1 
cards in hand: [16.  6.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  8. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  6  0  6  0  8 29 10
 15  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.  6.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.  6.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 11.  1.  3.  6.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[208.88579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 0.  8. 11.  1.  3.  6.  0.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 16.] 
adversary cards in discard: [ 0. 16.  8. 15.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -12.379732131958008
desired expected reward: 293.8255615234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[197.8913 ]
 [197.90698]
 [197.8913 ]
 [197.8913 ]
 [200.17987]
 [199.03357]
 [198.85764]
 [210.98842]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [ 0.  8. 11.  1.  3.  6.  0.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 16.] 
adversary cards in discard: [ 0. 16.  8. 15.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0] -> size -> 27 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -7.518934726715088
desired expected reward: 200.5047607421875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 16.] 
cards in discard: [ 0. 16.  8. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 16.] 
cards in discard: [ 0. 16.  8. 15.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  7. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 16.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  0. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[313.72156]
 [298.0257 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 29.  3. 15.  3.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.362847805023193
desired expected reward: 205.62557983398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[294.5761 ]
 [294.59512]
 [294.5761 ]
 [294.5761 ]
 [295.5352 ]
 [297.34973]
 [295.96002]
 [302.0205 ]
 [297.31885]
 [295.7468 ]
 [298.9218 ]
 [309.91727]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 29.  3. 15.  3.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -10.505244255065918
desired expected reward: 301.4637145996094



buy possibilites: [-1] 
expected returns: [[457.57883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0. 29.  3. 15.  3.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29] -> size -> 28 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -30.5 

action type: buy - action 1.0
Learning step: -5.95923376083374
desired expected reward: 288.63592529296875






Player: 1 
cards in hand: [ 0. 29.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 15.  3.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1] -> size -> 21 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 15.  3.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1] -> size -> 21 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 15.  3.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1] -> size -> 21 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[422.31757]
 [405.61127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  0.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -15.243072509765625
desired expected reward: 442.33575439453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[403.18015]
 [403.18015]
 [403.18015]
 [405.04068]
 [423.6126 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  6. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  0.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -13.440261840820312
desired expected reward: 407.6229248046875



buy possibilites: [-1] 
expected returns: [[292.83105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 6.  8. 10.  0.  0.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 8.0
Learning step: -15.013336181640625
desired expected reward: 390.0273742675781






Player: 1 
cards in hand: [ 6.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  0.  0.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  0.  0.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.82858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  8.  3. 15. 16.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.  6.
  8. 10.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -8.565409660339355
desired expected reward: 284.2656555175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[326.20163]
 [326.22607]
 [326.20163]
 [326.20163]
 [329.87375]
 [328.0081 ]
 [327.72885]
 [346.58   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  8.  3. 15. 16.] 
adversary cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.  6.
  8. 10.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -11.522079467773438
desired expected reward: 336.3065185546875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  3. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 15. 16.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.  6.
  8. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  0  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15
  8  0  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.  6.
  8. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 15.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.  6.
  8. 10.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 15.] 
cards in discard: [ 0. 16.  8. 15.  3. 29.  1.  0.  0.  0. 16.  0.  0. 29.  3. 15.  3.  6.
  8. 10.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [1. 0. 0. 6. 8.] 
adversary cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[325.31506]
 [308.12985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 8.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -11.849991798400879
desired expected reward: 334.73004150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[302.75043]
 [302.7737 ]
 [302.75043]
 [302.75043]
 [303.94342]
 [306.19864]
 [304.4726 ]
 [312.00165]
 [306.1605 ]
 [304.20874]
 [308.15036]
 [321.65784]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 8.] 
cards in discard: [ 1.  0.  0. 10.  1.  3.  8.  6.  6.  0. 11.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [ 0.  1.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -10.938395500183105
desired expected reward: 314.3766784667969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  1.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  0  8 16  0  0  6  0  8 29 10 15  8
  0  0 29  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10. 10.  8. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 0. 23.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0 23] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[323.62363]
 [307.06137]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1  0  6  6 11  8 10  0  6  1  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 16.  0.  0.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0 23] -> size -> 31 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -10.079336166381836
desired expected reward: 300.0452880859375



action possibilites: [-1] 
expected returns: [[325.05402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 16.  0.  0.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0 23] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 9
Learning step: -9.35837173461914
desired expected reward: 320.0833740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[312.11874]
 [312.11874]
 [327.34177]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 8.  3. 16.  0.  0.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0 23] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -9.19449234008789
desired expected reward: 315.8595275878906






Player: 1 
cards in hand: [ 8.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16.  0.  0.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  0  8 16  0  0  6  0  8 29 10 15  8  0
  0 29  0  0  0  0 23] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  5. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 11.  3.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  4. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 11.  3.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  4. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  8. 11.  3.  0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[278.56082]
 [266.08676]
 [267.34732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11.  3.  0.] 
cards in discard: [8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  4. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -11.403556823730469
desired expected reward: 315.938232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[262.6974 ]
 [262.7151 ]
 [262.6974 ]
 [262.6974 ]
 [265.20963]
 [263.9491 ]
 [263.76245]
 [276.4371 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 11.  3.  0.] 
cards in discard: [8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  4. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.982211112976074
desired expected reward: 268.65179443359375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  4. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 6.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  4. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 6.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 6.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[302.44836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [ 8.  3.  1.  8. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [29.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8  8] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -8.237370491027832
desired expected reward: 268.1997375488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[288.8608 ]
 [288.88058]
 [288.8608 ]
 [288.8608 ]
 [289.82584]
 [291.64682]
 [290.24887]
 [296.4759 ]
 [291.6149 ]
 [290.04123]
 [293.22046]
 [305.0869 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 6.] 
cards in discard: [ 8.  3.  1.  8. 11.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [29.  0.  0. 15. 15.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8  8] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.550463676452637
desired expected reward: 291.9822082519531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 15. 15.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  0  8 16  0  0  6  0  8 29 10 15  8  0  0
 29  0  0  0  0 23  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 15.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  8. 10.  7.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 15.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 8.  3.  1.  8. 11.  3.  0.  3.  0.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[211.96204]
 [197.04057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [ 8.  3.  1.  8. 11.  3.  0.  3.  0.  1.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 15. 29.  8.  8.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.
 10. 15. 29.  0. 15.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -11.76384449005127
desired expected reward: 293.3230285644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[198.0192 ]
 [198.03871]
 [198.0192 ]
 [198.0192 ]
 [198.9789 ]
 [200.78682]
 [199.39885]
 [205.62225]
 [200.75577]
 [199.19258]
 [202.34998]
 [214.36156]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [ 8.  3.  1.  8. 11.  3.  0.  3.  0.  1.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0. 15. 29.  8.  8.] 
adversary cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.
 10. 15. 29.  0. 15.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.1144609451293945
desired expected reward: 204.8475799560547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 15. 29.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29.  8.  8.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.
 10. 15. 29.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 29.  8.  8.] 
cards in discard: [ 0. 23. 29. 16.  1.  0.  0.  8. 16.  8.  3.  0.  8. 10.  3.  6.  0.  0.
 10. 15. 29.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [3. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[353.3309]
 [337.8699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -4.088397979736328
desired expected reward: 210.27316284179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[336.38715]
 [336.409  ]
 [336.38715]
 [336.38715]
 [337.46667]
 [339.4988 ]
 [337.93726]
 [344.71448]
 [339.46368]
 [337.70544]
 [341.25705]
 [353.39825]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -10.972777366638184
desired expected reward: 340.634765625



buy possibilites: [-1] 
expected returns: [[325.5529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  0. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -19.5 

action type: buy - action 10.0
Learning step: -10.535332679748535
desired expected reward: 327.17010498046875






Player: 1 
cards in hand: [ 0.  0. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  3. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  3.] 
cards in discard: [8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  2. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 8. 1. 0. 0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[347.0738 ]
 [329.47272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [10.  3.  8.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  2. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29.  0.  8. 23.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.76125431060791
desired expected reward: 315.7916259765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[333.1255 ]
 [333.15033]
 [333.1255 ]
 [333.1255 ]
 [333.1255 ]
 [334.3541 ]
 [336.66916]
 [334.89114]
 [340.60416]
 [342.60464]
 [336.62863]
 [338.13266]
 [334.6281 ]
 [336.09158]
 [338.66968]
 [352.49222]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 0. 0.] 
cards in discard: [10.  3.  8.  1.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  2. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29.  0.  8. 23.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -10.786307334899902
desired expected reward: 336.2874755859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 29.  0.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  8. 23.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  2. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8. 29.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  8. 29.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  2. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  8. 29.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8] -> size -> 33 
action values: 0 
buys: 2 
player value: 2 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  2. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  8. 29.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  8. 29.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[167.1031 ]
 [154.14919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 1. 10.  8. 29.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -15.133069038391113
desired expected reward: 337.35919189453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.89818]
 [146.89818]
 [146.89818]
 [148.17006]
 [160.85284]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 10.  0.] 
cards in discard: [10.  3.  8.  1.  0.  0.  0.  8.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 1. 10.  8. 29.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
adversary owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.634920120239258
desired expected reward: 153.14727783203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 10.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8. 29.  0.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  1. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 10.  8. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  8.  0. 15.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  1. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 15.  8.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 3  3 15 15  3 16  1 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29
  0  0  0  0 23  8  8 10  8  8  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  1. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 3  3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0
  0  0  0 23  8  8 10  8  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  1. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  8.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 3  3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0
  0  0  0 23  8  8 10  8  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 0.  1. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[309.28815]
 [295.47626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 16.  3. 16.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.] 
adversary owned cards: [ 3  3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0
  0  0  0 23  8  8 10  8  8  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -2.377366781234741
desired expected reward: 158.4754638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[289.86792]
 [289.8901 ]
 [289.86792]
 [289.86792]
 [292.96216]
 [291.40643]
 [291.1794 ]
 [306.77402]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  1. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 16.  3. 16.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.] 
adversary owned cards: [ 3  3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0
  0  0  0 23  8  8 10  8  8  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.86359691619873
desired expected reward: 298.49517822265625



buy possibilites: [-1] 
expected returns: [[334.61057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  3.  3.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 3. 16.  3. 16.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.] 
adversary owned cards: [ 3  3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0
  0  0  0 23  8  8 10  8  8  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -22.0 

action type: buy - action 8.0
Learning step: -8.141585350036621
desired expected reward: 283.264892578125






Player: 1 
cards in hand: [ 3. 16.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3. 16.  0.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0
  0  0  0 23  8  8 10  8  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0  0
  0  0 23  8  8 10  8  8  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0  0
  0  0 23  8  8 10  8  8  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[426.14917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0  0
  0  0 23  8  8 10  8  8  0  1] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -7.842172145843506
desired expected reward: 326.7684020996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[409.38132]
 [409.4078 ]
 [409.38132]
 [409.38132]
 [410.67   ]
 [413.0923 ]
 [419.29782]
 [413.05096]
 [410.95712]
 [415.1861 ]
 [429.6439 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0  0
  0  0 23  8  8 10  8  8  0  1] -> size -> 34 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -12.509739875793457
desired expected reward: 413.6394348144531



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0  0
  0  0 23  8  8 10  8  8  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 15.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  0  0  6  0  8 29 10 15  8  0  0 29  0  0
  0  0 23  8  8 10  8  8  0  1] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 8.  0.  0. 16.  3.  3.  8.  0. 23.  8. 29.  0.  8. 29. 29. 10.  8.  0.
 15.  8.  1. 16.  3. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  0.  6.  1.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[220.34924]
 [202.29636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  1.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -17.319486618041992
desired expected reward: 412.32440185546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[205.94205]
 [205.96762]
 [205.94205]
 [205.94205]
 [207.18121]
 [209.5112 ]
 [215.47903]
 [209.47142]
 [207.45761]
 [211.52502]
 [225.75542]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  1.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6. 10.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -6.803880214691162
desired expected reward: 213.54534912109375



buy possibilites: [-1] 
expected returns: [[222.39758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  1.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 8. 29.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 18 

action type: buy - action 14.0
Learning step: -4.569627285003662
desired expected reward: 204.90182495117188






Player: 1 
cards in hand: [ 8. 29.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  6.  8.  8. 10.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0. 14. 10.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8 14] -> size -> 22 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 1.  6.  8.  8. 10.] 
adversary cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0. 14. 10.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8 14] -> size -> 22 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[174.83511]
 [160.35269]
 [160.35269]
 [160.13956]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  8.  8. 10.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0. 14. 10.  0.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  1  0  6 11  8 10  0  6  1  8 10  8 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  8.  0. 15.] 
adversary cards in discard: [ 8. 29.  0. 15.  6.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -8.00114917755127
desired expected reward: 214.3964385986328



action possibilites: [-1] 
expected returns: [[204.59753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0. 14. 10.  0.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  8.  0. 15.] 
adversary cards in discard: [ 8. 29.  0. 15.  6.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 12
Learning step: -3.054417848587036
desired expected reward: 156.1028289794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[190.7225 ]
 [190.7225 ]
 [208.78448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0.  1. 11.  3.  3.  0.  3.  0.  0.  0. 14. 10.  0.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [10.  0.  8.  0. 15.] 
adversary cards in discard: [ 8. 29.  0. 15.  6.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -5.359157562255859
desired expected reward: 199.23837280273438






Player: 1 
cards in hand: [10.  0.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0. 15.] 
cards in discard: [ 8. 29.  0. 15.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0  0 29  0  0  0  0 23
  8  8 10  8  8  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 14.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.] 
cards in discard: [ 8. 29.  0. 15.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 14.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.] 
cards in discard: [ 8. 29.  0. 15.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  7.] 
adversary cards in hand: [ 6. 14.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.] 
cards in discard: [ 8. 29.  0. 15.  6. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 6. 14.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[380.0287]
 [366.7295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 15.  0. 23. 16.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -2.696244955062866
desired expected reward: 206.08824157714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[363.14594]
 [363.1673 ]
 [363.14594]
 [363.14594]
 [366.1183 ]
 [364.40622]
 [379.38495]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 15.  0. 23. 16.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -11.222103118896484
desired expected reward: 367.13677978515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 15.  0. 23. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 23. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 23. 16.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0. 23. 16.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0. 23. 16.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [1. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[266.79944]
 [254.27718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [ 6. 14.  6.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 16. 16. 29.  1.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -13.754591941833496
desired expected reward: 365.6304016113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[256.28394]
 [256.30325]
 [256.28394]
 [256.28394]
 [257.15524]
 [258.7896 ]
 [263.03564]
 [258.76202]
 [257.35214]
 [260.19946]
 [270.42984]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [ 6. 14.  6.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 8. 16. 16. 29.  1.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.112380027770996
desired expected reward: 259.4549255371094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 16. 16. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 16. 29.  1.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29  8 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8
  8 10  8  8  0  1  0 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 26. 30.  8.  5.  7.  9.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  1.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 26. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  1.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 25. 30. 26. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  1.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[189.53984]
 [173.81792]
 [174.04016]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  0.] 
cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -10.566551208496094
desired expected reward: 259.86328125



action possibilites: [-1.  8.] 
expected returns: [[208.83276]
 [196.47418]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -4.257297039031982
desired expected reward: 169.5606231689453



action possibilites: [-1.] 
expected returns: [[329.13388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 5
Learning step: -2.1192710399627686
desired expected reward: 193.3763885498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[313.27036]
 [313.27036]
 [331.34735]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -8.878417015075684
desired expected reward: 320.2554626464844



buy possibilites: [-1] 
expected returns: [[288.97937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 14.  6.  0.  1.  1.  0.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [0. 8. 3. 0. 3.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
adversary owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -10.411483764648438
desired expected reward: 302.85888671875






Player: 1 
cards in hand: [0. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 3.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15 15  3 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8
 10  8  8  0  1  0 15  0 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0] -> size -> 17 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0] -> size -> 17 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[336.41162]
 [321.5241 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  6.] 
adversary cards in hand: [ 0. 29.  8.  3.  8.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.  8.  0.  0.] 
adversary owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3  0] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -7.751683712005615
desired expected reward: 281.2276916503906



action possibilites: [-1] 
expected returns: [[255.70842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 29.  8.  3.  8.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.  8.  0.  0.] 
adversary owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3  0] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: gain_card_n - action 9
Learning step: -9.193605422973633
desired expected reward: 310.7472839355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[248.02798]
 [248.04697]
 [248.02798]
 [248.02798]
 [248.89139]
 [250.50912]
 [254.63152]
 [250.4818 ]
 [249.0868 ]
 [251.9041 ]
 [261.511  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 29.  8.  3.  8.] 
adversary cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.  8.  0.  0.] 
adversary owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3  0] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -6.763999938964844
desired expected reward: 248.94442749023438






Player: 1 
cards in hand: [ 0. 29.  8.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3.  8.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 15 16 16  3 29 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8
  8  0  1  0 15  0 11  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 6.  8. 14.  1.  0.] 
adversary cards in discard: [15. 11.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8  8
  0  1  0 15  0 11  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 6.  8. 14.  1.  0.] 
adversary cards in discard: [15. 11.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [ 8. 29.  0. 15.  6. 15. 15. 10.  8.  0.  0.  8. 15.  0. 23. 16. 11.  3.
 16. 16. 29.  1.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8  8
  0  1  0 15  0 11  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 6.  8. 14.  1.  0.] 
adversary cards in discard: [15. 11.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[266.5074 ]
 [253.30957]
 [254.62411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 14.  1.  0.] 
cards in discard: [15. 11.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 8. 23. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8  8
  0  1  0 15  0 11  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -7.948955535888672
desired expected reward: 253.56202697753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[252.6938 ]
 [252.71445]
 [252.6938 ]
 [252.6938 ]
 [255.36627]
 [253.83307]
 [267.2204 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 14.  1.  0.] 
cards in discard: [15. 11.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 25. 30. 25. 30.  8.  5.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 8. 23. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8  8
  0  1  0 15  0 11  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -8.117964744567871
desired expected reward: 256.9808654785156



buy possibilites: [-1] 
expected returns: [[233.3773]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 14.  1.  0.] 
cards in discard: [15. 11.  1.  0.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 8. 23. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8  8
  0  1  0 15  0 11  3  0] -> size -> 32 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -23.683700561523438
desired expected reward: 229.01011657714844






Player: 1 
cards in hand: [ 8. 23. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [15 15 16 16  3 16  6  8 29 10 15  8  0 29  0  0  0  0 23  8  8 10  8  8
  0  1  0 15  0 11  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [15. 11.  1.  0.  0.  3.  6.  6.  8. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6] -> size -> 19 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  0  8  8 10  8  8  0  1  0
 15  0 11  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [15. 11.  1.  0.  0.  3.  6.  6.  8. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6] -> size -> 19 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  0  8  8 10  8  8  0  1  0
 15  0 11  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [15. 11.  1.  0.  0.  3.  6.  6.  8. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6] -> size -> 19 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[182.63182]
 [169.54112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [15. 11.  1.  0.  0.  3.  6.  6.  8. 14.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  0  8  8 10  8  8  0  1  0
 15  0 11  3  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -8.928645133972168
desired expected reward: 224.4486541748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[170.40497]
 [170.40497]
 [170.40497]
 [184.6104 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [15. 11.  1.  0.  0.  3.  6.  6.  8. 14.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  0  8  8 10  8  8  0  1  0
 15  0 11  3  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -6.390165328979492
desired expected reward: 176.2416534423828



buy possibilites: [-1] 
expected returns: [[170.90999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [15. 11.  1.  0.  0.  3.  6.  6.  8. 14.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0. 16.  0.  8.  0.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  0  8  8 10  8  8  0  1  0
 15  0 11  3  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -56.0 

action type: buy - action 0.0
Learning step: -7.197353363037109
desired expected reward: 157.65921020507812






Player: 1 
cards in hand: [ 0. 16.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  8.  0.] 
cards in discard: [ 8. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  0  8  8 10  8  8  0  1  0
 15  0 11  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 30.  8.  4.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 8. 10.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15
  0 11  3  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 8. 10.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15
  0 11  3  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 8. 10.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15
  0 11  3  0  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [8. 6. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [8. 6. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[282.02798]
 [266.59085]
 [266.59085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [15.  6.  3. 15.  8.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15
  0 11  3  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -3.154161214828491
desired expected reward: 167.75582885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[262.8503 ]
 [262.8503 ]
 [279.85263]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [15.  6.  3. 15.  8.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.] 
adversary owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15
  0 11  3  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -8.62240982055664
desired expected reward: 271.3697814941406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [15.  6.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3. 15.  8.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15 15 16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15
  0 11  3  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  1.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15  0 11
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  1.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15  0 11
  3  0  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  1.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15  0 11
  3  0  6  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 3.  6. 10.  1.  0.] 
adversary cards in discard: [8. 6. 3. 0. 8.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3.  6. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[250.60707]
 [236.60066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  1.  0.] 
cards in discard: [8. 6. 3. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [11.  8.  8.  0. 15.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.] 
adversary owned cards: [16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15  0 11
  3  0  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -9.249815940856934
desired expected reward: 270.60284423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[235.81845]
 [235.84131]
 [235.81845]
 [235.81845]
 [238.63184]
 [237.02922]
 [251.03563]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  1.  0.] 
cards in discard: [8. 6. 3. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [11.  8.  8.  0. 15.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.] 
adversary owned cards: [16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15  0 11
  3  0  6  0  0] -> size -> 29 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.764523506164551
desired expected reward: 241.8639678955078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  0. 15.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  3 16  6  8 29 15  8 29  0  0  0  8  8 10  8  8  0  1  0 15  0 11
  3  0  6  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 6. 15.  0. 14.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 6. 15.  0. 14.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 6. 15.  0. 14.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[260.133  ]
 [249.73892]
 [248.20424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0. 14.  0.] 
cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 16. 16. 29.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.] 
adversary owned cards: [16 16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6
  0  0] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -7.60897970199585
desired expected reward: 243.42666625976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[246.15483]
 [246.15483]
 [246.15483]
 [260.85318]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0. 14.  0.] 
cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  0. 16. 16. 29.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.] 
adversary owned cards: [16 16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6
  0  0] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.983178615570068
desired expected reward: 250.74020385742188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 16. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 16. 29.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 1.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[233.65208]
 [218.51204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  0.] 
cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  1. 15. 29.  3.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1.0
Learning step: -9.16528606414795
desired expected reward: 251.68789672851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[206.93056]
 [206.95682]
 [206.93056]
 [206.93056]
 [206.93056]
 [208.06465]
 [210.1736 ]
 [213.70515]
 [215.52441]
 [210.14668]
 [211.51099]
 [208.32745]
 [209.66481]
 [211.99281]
 [224.4669 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  0.] 
cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6. 10.  5.] 
adversary cards in hand: [ 0.  1. 15. 29.  3.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -8.078798294067383
desired expected reward: 225.5732879638672



buy possibilites: [-1] 
expected returns: [[229.68262]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  0.] 
cards in discard: [ 8.  6.  3.  0.  8.  3.  6. 10.  1.  0.  6. 15.  0. 14.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  1. 15. 29.  3.] 
adversary cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 24 

action type: buy - action 22.0
Learning step: -4.115382671356201
desired expected reward: 205.5494384765625






Player: 1 
cards in hand: [ 0.  1. 15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15. 29.  3.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 8.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 8.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 8.] 
cards in discard: [ 8. 10.  6.  0. 16.  0.  8.  0.  0.  8.  6.  3.  8. 15.  3.  0. 16.  0.
  0. 29. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 5. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [1. 6. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [1. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[286.99588]
 [273.18036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [15.  0. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -6.455604553222656
desired expected reward: 223.22702026367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[268.90433]
 [268.92722]
 [268.90433]
 [268.90433]
 [271.7177 ]
 [270.11508]
 [284.12155]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 25. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [15.  0. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -9.263874053955078
desired expected reward: 275.24029541015625



buy possibilites: [-1] 
expected returns: [[255.2187]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 8. 0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [15.  0. 15.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -8 

action type: buy - action 1.0
Learning step: -8.1039400100708
desired expected reward: 260.8232727050781






Player: 1 
cards in hand: [15.  0. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  8.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 15.  0.  0. 14.] 
adversary cards in discard: [1. 1. 6. 6. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1] -> size -> 22 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  8.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 15.  0.  0. 14.] 
adversary cards in discard: [1. 1. 6. 6. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1] -> size -> 22 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  8.  0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 24. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 15.  0.  0. 14.] 
adversary cards in discard: [1. 1. 6. 6. 8. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1] -> size -> 22 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[298.54367]
 [287.71954]
 [286.1169 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  0. 14.] 
cards in discard: [1. 1. 6. 6. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 1. 16. 29.  3. 29.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -7.447092533111572
desired expected reward: 247.7716064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[282.48135]
 [282.48135]
 [282.48135]
 [297.69855]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  0. 14.] 
cards in discard: [1. 1. 6. 6. 8. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 24. 30.  8.  3.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 1. 16. 29.  3. 29.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -9.60107135772705
desired expected reward: 287.9785461425781



buy possibilites: [-1] 
expected returns: [[257.93503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  0. 14.] 
cards in discard: [1. 1. 6. 6. 8. 0. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 1. 16. 29.  3. 29.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -337.0 

action type: buy - action 6.0
Learning step: -24.941226959228516
desired expected reward: 257.5401306152344






Player: 1 
cards in hand: [ 1. 16. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 29.  3. 29.] 
cards in discard: [ 0. 15.  0. 15.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  0.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  6.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 8. 0. 0. 1.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[220.7593 ]
 [207.26411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 1.] 
cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0 29] -> size -> 30 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -9.850796699523926
desired expected reward: 248.084228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[203.89388]
 [203.91527]
 [203.89388]
 [203.89388]
 [204.79124]
 [206.46455]
 [210.68849]
 [206.44409]
 [205.00566]
 [207.903  ]
 [217.74385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 1.] 
cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.] 
adversary owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0 29] -> size -> 30 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -8.104247093200684
desired expected reward: 212.65505981445312



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  0. 10.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15  8 29  0  0  8  8 10  8  8  0  1  0 15  0  3  0  6  0
  0  3  0  0  0 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0. 11. 22.  0.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0. 11. 22.  0.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 3.  0. 11. 22.  0.] 
adversary cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.  3.  8.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
expected returns: [[152.93596]
 [140.86879]
 [140.43466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 22.  0.] 
cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.  3.  8.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29] -> size -> 27 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -9.382463455200195
desired expected reward: 208.36141967773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[135.9964 ]
 [135.9964 ]
 [135.9964 ]
 [150.56871]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 22.  0.] 
cards in discard: [ 1.  1.  6.  6.  8.  0.  6.  6. 15.  0.  0. 14.  3.  8.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29] -> size -> 27 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -6.224210739135742
desired expected reward: 146.7117462158203



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 22.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 22.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 22.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0. 22.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[206.74986]
 [196.4435 ]
 [195.51796]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6. 16.  0.  8.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.  3.
  0.  0.  3.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0] -> size -> 28 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -4.838745594024658
desired expected reward: 145.72996520996094



action possibilites: [-1] 
expected returns: [[254.00511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6. 16.  0.  8.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.  3.
  0.  0.  3.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0] -> size -> 28 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: LIBRARY: skip_action_card - action 1
Learning step: -4.8106913566589355
desired expected reward: 188.7054443359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[243.41212]
 [243.43698]
 [243.41212]
 [243.41212]
 [243.41212]
 [244.47476]
 [246.45255]
 [249.74942]
 [251.51639]
 [246.42882]
 [247.6968 ]
 [244.72743]
 [245.97171]
 [248.15395]
 [260.20395]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0.  6. 16.  0.  8.] 
adversary cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.  3.
  0.  0.  3.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0] -> size -> 28 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -7.8366379737854
desired expected reward: 246.16847229003906






Player: 1 
cards in hand: [ 0.  6. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  0.  8.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.  3.
  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 8. 15.  1.  6.  3.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  0.  8.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.  3.
  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 24. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 8. 15.  1.  6.  3.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  0.  8.] 
cards in discard: [ 0. 15.  0. 15.  8.  0. 16.  0. 29. 29. 29.  1.  3.  6.  8.  0.  0.  3.
  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 8. 15.  1.  6.  3.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  1.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[214.72896]
 [200.18947]
 [203.34135]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  1.  6.  3.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 29. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -10.619898796081543
desired expected reward: 249.58404541015625



action possibilites: [-1] 
expected returns: [[210.94482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 3.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 29. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action 15.0
Learning step: -6.770809173583984
desired expected reward: 196.57054138183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[197.11751]
 [197.11751]
 [197.11751]
 [213.14355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6. 3.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 6. 29. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1
Learning step: -7.228213787078857
desired expected reward: 203.71661376953125






Player: 1 
cards in hand: [ 6. 29. 15. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 15. 15.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [14.  0.  3.  0.  6.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 15. 15.  8.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [14.  0.  3.  0.  6.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
adversary victory points: -2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [14.  0.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[129.33449]
 [118.17562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  6.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [29.  8.  3.  6.  0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1.0
Learning step: -10.155966758728027
desired expected reward: 202.9875946044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[117.35221]
 [117.35221]
 [117.35221]
 [131.24321]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  6.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 23. 30.  8.  2.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [29.  8.  3.  6.  0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.973575115203857
desired expected reward: 123.36091613769531



buy possibilites: [-1] 
expected returns: [[209.63892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  6.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [29.  8.  3.  6.  0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -358.0 

action type: buy - action 6.0
Learning step: -19.05073356628418
desired expected reward: 98.30147552490234






Player: 1 
cards in hand: [29.  8.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  6.  0.] 
cards in discard: [ 6. 29. 15. 15.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [11.  1.  1.  6.  6.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6. 14.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6] -> size -> 24 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  6.  0.] 
cards in discard: [ 6. 29. 15. 15.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [11.  1.  1.  6.  6.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6. 14.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6] -> size -> 24 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  6.  0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [11.  1.  1.  6.  6.] 
adversary cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6. 14.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6] -> size -> 24 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [11.  1.  1.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[211.89288]
 [197.26328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.  6.  6.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6. 14.  0.  3.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 29.  0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0] -> size -> 30 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -8.6914644241333
desired expected reward: 200.94744873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[195.30132]
 [195.32791]
 [195.30132]
 [195.30132]
 [196.44821]
 [198.58524]
 [204.06837]
 [198.55913]
 [196.7245 ]
 [200.44345]
 [213.25485]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.  6.  6.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6. 14.  0.  3.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  5.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 29.  0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0] -> size -> 30 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -8.84637451171875
desired expected reward: 203.04653930664062



buy possibilites: [-1] 
expected returns: [[317.36032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.  6.  6.] 
cards in discard: [22.  0.  0.  0. 10.  0.  8.  0. 15.  8.  1.  6.  3.  6. 14.  0.  3.  0.
  6. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 0. 16.  8. 29.  0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0] -> size -> 30 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -26 

action type: buy - action 29.0
Learning step: -3.7187180519104004
desired expected reward: 187.4677734375






Player: 1 
cards in hand: [ 0. 16.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8. 29.  0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 29.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8. 29.  0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 24. 30. 23. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 29.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8. 29.  0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 3. 29.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[196.24556]
 [188.23012]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -14.9242525100708
desired expected reward: 302.4360656738281



action possibilites: [-1.] 
expected returns: [[305.55804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: discard_n_cards - action 1
Learning step: -4.603427886962891
desired expected reward: 176.96624755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[288.79453]
 [288.82144]
 [288.79453]
 [288.79453]
 [292.1249 ]
 [290.23773]
 [306.73563]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -10.931227684020996
desired expected reward: 294.6268310546875



buy possibilites: [-1] 
expected returns: [[267.99567]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [1. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -30 

action type: buy - action 1.0
Learning step: -9.91117000579834
desired expected reward: 278.9102783203125






Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 1. 10.  0. 22. 14.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1] -> size -> 26 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  5.] 
adversary cards in hand: [ 1. 10.  0. 22. 14.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1] -> size -> 26 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  4.] 
adversary cards in hand: [ 1. 10.  0. 22. 14.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1] -> size -> 26 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  0. 22. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22. 14.] 
expected returns: [[155.32948]
 [143.2909 ]
 [144.24928]
 [144.61348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 22. 14.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  0.  8. 16.  3.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.
  0.  1.  0.  3.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3 15] -> size -> 32 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1
Learning step: -13.394037246704102
desired expected reward: 254.60162353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[143.41957]
 [143.4393 ]
 [143.41957]
 [143.41957]
 [145.80997]
 [144.455  ]
 [156.2905 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 22. 14.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  6.  9.  4.] 
adversary cards in hand: [ 0.  0.  8. 16.  3.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.
  0.  1.  0.  3.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3 15] -> size -> 32 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -7.761044502258301
desired expected reward: 147.5684356689453



buy possibilites: [-1] 
expected returns: [[132.21263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 22. 14.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  0.  8. 16.  3.] 
adversary cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.
  0.  1.  0.  3.  0.] 
adversary owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3 15] -> size -> 32 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -50 

action type: buy - action 10.0
Learning step: -6.747966289520264
desired expected reward: 137.70703125






Player: 1 
cards in hand: [ 0.  0.  8. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 16.  3.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.
  0.  1.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0
  0  0 29  0  3  0  3 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  8.  0. 10.  4.  9.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  0. 11.  8.  6.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10] -> size -> 27 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.
  0.  1.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  9.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  0. 11.  8.  6.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10] -> size -> 27 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 6. 29. 15. 15.  8.  0. 29.  8.  3.  6.  0.  3.  0. 16.  8. 29.  0. 15.
  0.  1.  0.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  9.  9.  5.  9.  4.] 
adversary cards in hand: [ 0.  0. 11.  8.  6.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10] -> size -> 27 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[85.651115]
 [75.14485 ]
 [73.949   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  6.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  9.  9.  5.  9.  4.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -7.66151762008667
desired expected reward: 124.55111694335938



action possibilites: [-1] 
expected returns: [[62.040108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  4.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -22 

action type: gain_card_n - action 7
Learning step: -3.388387680053711
desired expected reward: 70.29740905761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[54.52146]
 [54.52146]
 [54.52146]
 [63.98031]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  4.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: take_action - action -1
Learning step: -3.637230396270752
desired expected reward: 58.40287780761719






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  4.] 
adversary cards in hand: [ 8.  0. 15.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14. 11.  0.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  4.] 
adversary cards in hand: [ 8.  0. 15.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14. 11.  0.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [ 8.  0. 15.  1.  0.] 
adversary cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14. 11.  0.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 15.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[132.45268 ]
 [118.50651 ]
 [121.525986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  1.  0.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14. 11.  0.  0.  8.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15] -> size -> 33 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1.0
Learning step: -3.206228017807007
desired expected reward: 60.77408218383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[113.80305 ]
 [113.82603 ]
 [113.80305 ]
 [113.80305 ]
 [114.799934]
 [116.657166]
 [121.34652 ]
 [116.635254]
 [115.039955]
 [118.25245 ]
 [129.17917 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  1.  0.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14. 11.  0.  0.  8.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 23. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15] -> size -> 33 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -6.744348049163818
desired expected reward: 125.70833587646484



buy possibilites: [-1] 
expected returns: [[88.98191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 15.  1.  0.] 
cards in discard: [ 1.  1. 29.  3.  0.  6.  0. 10.  1. 10.  0. 22. 14. 14. 11.  0.  0.  8.
  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 22. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [0. 8. 6. 1. 0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15] -> size -> 33 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5.    0.   -3.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -53.5 

action type: buy - action 1.0
Learning step: -6.149991512298584
desired expected reward: 107.67603302001953






Player: 1 
cards in hand: [0. 8. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 1. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1] -> size -> 29 
adversary victory points: -3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 22. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1] -> size -> 29 
adversary victory points: -3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 1. 0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 1. 22. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [6. 6. 6. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1] -> size -> 29 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[143.45566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [29.  8.  3. 15. 15.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -4.12134313583374
desired expected reward: 84.86056518554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[132.36664]
 [132.36664]
 [143.2718 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  1.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [29.  8.  3. 15. 15.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -6.925804138183594
desired expected reward: 136.52984619140625



buy possibilites: [-1] 
expected returns: [[189.32382]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 6. 3.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [29.  8.  3. 15. 15.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -369 

action type: buy - action 6.0
Learning step: -20.80854606628418
desired expected reward: 111.55809020996094






Player: 1 
cards in hand: [29.  8.  3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 15. 15.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [6. 6. 6. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 15.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [6. 6. 6. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3. 15.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [6. 6. 6. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[135.9412 ]
 [129.56914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [6. 6. 6. 6. 6. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [29.  0.  6. 11.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0. 15. 29.  8.  3. 15.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -9.89109992980957
desired expected reward: 179.43272399902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[126.93294 ]
 [126.95208 ]
 [126.93294 ]
 [127.748726]
 [129.26324 ]
 [133.07413 ]
 [129.2474  ]
 [127.947174]
 [130.56346 ]
 [139.44618 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [6. 6. 6. 6. 6. 3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [29.  0.  6. 11.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0. 15. 29.  8.  3. 15.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -7.211090087890625
desired expected reward: 128.7301025390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6. 11.  0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0. 15. 29.  8.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [ 0. 11. 22. 15. 10.] 
adversary cards in discard: [ 6.  6.  6.  6.  6.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6. 11.  0.] 
cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0. 15. 29.  8.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [ 0. 11. 22. 15. 10.] 
adversary cards in discard: [ 6.  6.  6.  6.  6.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
adversary victory points: -4
player victory points: 2 


Player 1 won the game! 



Player 0 bought cards:
Copper: 4 
Silver: 6 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 1 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 2 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 11. 22. 15. 10.] 
cards in discard: [ 6.  6.  6.  6.  6.  3.  0.  0.  0. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  6 11  0  6  1  8 10  8 14  0 15  6  0 22  1  6  6
 29  1 10 14  1  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 22. 30.  8.  0.  7.  7.  0. 10.  4.  8.  9.  5.  9.  3.] 
adversary cards in hand: [29.  0.  6. 11.  0.] 
adversary cards in discard: [15.  0.  3.  0.  0.  0.  0.  0.  8.  6.  1.  0. 15. 29.  8.  3. 15.  0.] 
adversary owned cards: [16 16  6 29 15 29  0  8  8  8  8  0  1  0 15  0  3  0  6  0  0  3  0  0
  0 29  0  3  0  3 15 11 15  0  0] -> size -> 35 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5 -500   -4  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -569 

action type: buy - action -1.0
Learning step: -35.42230987548828
desired expected reward: 104.02387237548828



