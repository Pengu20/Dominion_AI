 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.478409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.767191886901855
desired expected reward: 4.805865287780762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.371904]
 [22.715767]
 [22.700743]
 [22.247023]
 [23.346249]
 [23.01741 ]
 [23.002386]
 [23.737257]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6214689016342163
desired expected reward: 23.16562271118164



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.530176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6019428968429565
desired expected reward: 23.135311126708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.28054 ]
 [23.624403]
 [23.609377]
 [23.155659]
 [23.428019]
 [24.254883]
 [23.926046]
 [24.30753 ]
 [23.801163]
 [23.911018]
 [24.145025]
 [24.64589 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6413370966911316
desired expected reward: 24.137203216552734



buy possibilites: [-1] 
expected returns: [[25.52413]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.4643271863460541
desired expected reward: 23.446691513061523






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.11059]
 [24.37572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6526432037353516
desired expected reward: 24.87148666381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.080084]
 [24.423944]
 [24.40892 ]
 [23.955198]
 [25.054424]
 [24.725586]
 [24.710566]
 [25.445433]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6503978371620178
desired expected reward: 24.698854446411133



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.740507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6301432847976685
desired expected reward: 24.815288543701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.859472]
 [26.203331]
 [26.188307]
 [25.734587]
 [26.833813]
 [26.50497 ]
 [26.489948]
 [27.22482 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.680435836315155
desired expected reward: 26.292871475219727



buy possibilites: [-1] 
expected returns: [[28.14445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  1. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.10918178409337997
desired expected reward: 26.380767822265625






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  1. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  1. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  1. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.92745 ]
 [26.192581]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7120739221572876
desired expected reward: 27.432374954223633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.695131]
 [26.038992]
 [26.023966]
 [25.570246]
 [26.669474]
 [26.340635]
 [26.32561 ]
 [27.060478]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6882365942001343
desired expected reward: 26.487573623657227



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[27.200285]
 [26.465414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 0.  0.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6775429248809814
desired expected reward: 26.3829345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.223036]
 [26.551872]
 [26.098152]
 [26.86854 ]
 [27.588385]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 0.  0.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6890924572944641
desired expected reward: 26.678321838378906



buy possibilites: [-1] 
expected returns: [[26.725098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 0.  0.  3. 10.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  1.  0.  3.] 
adversary cards in discard: [3. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.65233039855957
desired expected reward: 16.445819854736328






Player: 1 
cards in hand: [ 3. 11.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  0.  3.] 
cards in discard: [3. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3.] 
cards in discard: [3. 0. 0. 3. 3. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.021147]
 [30.286276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6269553303718567
desired expected reward: 26.098142623901367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.890842]
 [30.234707]
 [30.219683]
 [29.765963]
 [30.865185]
 [30.53635 ]
 [30.521326]
 [31.256197]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7657187581062317
desired expected reward: 30.461334228515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.298376]
 [25.596735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [ 6. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.76413494348526
desired expected reward: 28.871828079223633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.059118]
 [25.374739]
 [24.937132]
 [25.68066 ]
 [26.366898]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [ 6. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6745401620864868
desired expected reward: 25.7912540435791



buy possibilites: [-1] 
expected returns: [[27.427168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [ 6. 10.  0.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.3924345374107361
desired expected reward: 25.288225173950195






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  3.  0. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  3.  0. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  3.  0. 29.  0.  0. 23.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.29358]
 [27.59194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10 23] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6769222617149353
desired expected reward: 26.750246047973633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.092365]
 [27.407986]
 [26.970379]
 [27.713911]
 [28.400143]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10 23] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7130449414253235
desired expected reward: 27.74787712097168



buy possibilites: [-1] 
expected returns: [[29.004185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.  0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  3.] 
adversary cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10 23] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.427695631980896
desired expected reward: 26.980289459228516






Player: 1 
cards in hand: [11.  8.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  3.] 
cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 29  3  3  8  0 10 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  3.  0. 29.  0.  0. 23.  0.  0.  1.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 8.] 
adversary cards in discard: [ 3. 10.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.495243]
 [25.809008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7434324026107788
desired expected reward: 28.260751724243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.601534]
 [25.93256 ]
 [25.91715 ]
 [25.479548]
 [26.538694]
 [26.223078]
 [26.207674]
 [26.909313]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [ 3. 10.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6730270981788635
desired expected reward: 25.953195571899414



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  1.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  7. 10. 10.] 
adversary cards in hand: [ 6.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  3.  3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[27.6279  ]
 [26.926258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6683453321456909
desired expected reward: 26.240966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.362442]
 [26.67806 ]
 [26.240456]
 [26.983984]
 [27.670218]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  9. 10.  9.  8. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7008267641067505
desired expected reward: 27.09735107421875



buy possibilites: [-1] 
expected returns: [[29.123566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9.  8. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 10.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.631416320800781
desired expected reward: 16.609039306640625






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9.  8. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9.  8. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 10.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6] -> size -> 16 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.379898]
 [24.678257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 23.  0. 29.] 
adversary cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7583579421043396
desired expected reward: 28.36520767211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.467531]
 [24.78315 ]
 [24.345543]
 [25.089073]
 [25.775307]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 23.  0. 29.] 
adversary cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.653337836265564
desired expected reward: 24.898656845092773



buy possibilites: [-1] 
expected returns: [[26.510693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  3. 10.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 23.  0. 29.] 
adversary cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.3751322031021118
desired expected reward: 24.408018112182617






Player: 1 
cards in hand: [ 3.  0. 23.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  0. 29.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  0.  0.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
action values: 1 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8] -> size -> 21 
action values: 0 
buys: 2 
player value: 5 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  9.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 26. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10.  1.  0.  3.  3.  8.  0.  3.  0.  0.  0. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[28.916117]
 [28.229881]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6436469554901123
desired expected reward: 25.867046356201172



action possibilites: [-1] 
expected returns: [[27.192905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.08084644377231598
desired expected reward: 27.13155174255371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.028442]
 [26.340448]
 [25.907537]
 [26.642345]
 [27.318342]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08626029640436172
desired expected reward: 27.106645584106445



buy possibilites: [-1] 
expected returns: [[26.386177]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6.  6.  3. 10.  0.  0.  3.  3.  0.  0.  3. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.17684131860733032
desired expected reward: 26.517292022705078






Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.614025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6187561750411987
desired expected reward: 25.76742172241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.766872]
 [30.094072]
 [30.078882]
 [29.645966]
 [30.692785]
 [30.380775]
 [30.365583]
 [31.056774]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7529639005661011
desired expected reward: 29.992666244506836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 10. 10.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 10. 10.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[27.199148]
 [26.523151]
 [26.50796 ]
 [26.50796 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10. 10.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7989023327827454
desired expected reward: 30.257871627807617



action possibilites: [-1.  8. 10.] 
expected returns: [[27.971659]
 [27.295666]
 [27.280468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 10.  3.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.05974262207746506
desired expected reward: 26.594154357910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.47371 ]
 [26.352802]
 [27.763607]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8. 10.  3.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  3. 10.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10519380122423172
desired expected reward: 27.866464614868164






Player: 1 
cards in hand: [ 0.  0.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 10.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.  0.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.  0.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 23. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.  0.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [6. 3. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 10.  0.  3.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [6. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.183578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  0. 10.  0.  3.  8. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0. 23.  8.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.665033757686615
desired expected reward: 27.098573684692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.032566]
 [28.91166 ]
 [30.322464]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 3.] 
cards in discard: [ 3.  0.  0.  3.  0. 10.  0.  3.  8. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0. 23.  8.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 24 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7473887205123901
desired expected reward: 29.526365280151367



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0. 23.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 23.  8.  0.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 11.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0. 29.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 24 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3] -> size -> 22 
action values: 0 
buys: 2 
player value: 1 
card supply: [28. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.] 
cards in discard: [ 3.  8.  0.  0.  0.  3. 10.  0.  0.  3.  3. 10.  0.  0.  1.  3.  3.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.53286]
 [29.84167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7406718730926514
desired expected reward: 29.5817928314209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.603157]
 [29.915163]
 [29.48225 ]
 [30.217058]
 [30.893055]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 22. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7526673674583435
desired expected reward: 29.904956817626953



buy possibilites: [-1] 
expected returns: [[30.647713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 21. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.48565393686294556
desired expected reward: 29.42951011657715






Player: 1 
cards in hand: [1. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 21. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 21. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 0.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.97506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 21. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7744064331054688
desired expected reward: 29.873306274414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.627811]
 [26.939817]
 [26.506907]
 [27.241716]
 [27.917711]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 21. 30.  8.  8. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7071081399917603
desired expected reward: 27.390506744384766



buy possibilites: [-1] 
expected returns: [[26.299723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3. 10.  0.  0.] 
adversary cards in discard: [1. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.659846305847168
desired expected reward: 16.847057342529297






Player: 1 
cards in hand: [29.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.  0.  0.] 
cards in discard: [1. 3. 0. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 23.] 
cards in discard: [1. 3. 0. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 23. 10.] 
cards in discard: [1. 3. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 23. 10.] 
cards in discard: [1. 3. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 23. 10.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  3.  6.] 
adversary cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[24.866144]
 [24.209995]
 [24.195196]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  3.  6.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6811460256576538
desired expected reward: 25.618576049804688



action possibilites: [-1.  8.] 
expected returns: [[28.167313]
 [27.511158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.01581069827079773
desired expected reward: 24.255483627319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.969395]
 [27.274033]
 [26.850988]
 [27.568378]
 [28.224527]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [ 3.  3.  0. 10.  3.  0.  6.  3.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 3.] 
adversary cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10577716678380966
desired expected reward: 28.061534881591797






Player: 1 
cards in hand: [3. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 3.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
adversary victory points: 4
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.331772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7083197832107544
desired expected reward: 27.516206741333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.050255]
 [25.93185 ]
 [27.305387]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6946994066238403
desired expected reward: 26.773488998413086



buy possibilites: [-1] 
expected returns: [[26.51746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 11.] 
adversary cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6530742645263672
desired expected reward: 25.397178649902344






Player: 1 
cards in hand: [ 3.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 11.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.  3.  0.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [0. 3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.  3.  0.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [0. 3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.] 
cards in discard: [ 1.  3.  0.  0.  3.  0. 29. 10.  3.  0.  0. 23. 10.  3.  0.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [0. 3. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[24.256649]
 [23.600498]
 [23.585701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [0. 3. 0. 3. 6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6933000087738037
desired expected reward: 25.824159622192383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.237196]
 [23.541836]
 [23.118792]
 [23.83618 ]
 [24.492329]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [0. 3. 0. 3. 6. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 21. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6312018632888794
desired expected reward: 23.743995666503906



buy possibilites: [-1] 
expected returns: [[25.361507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [0. 3. 0. 3. 6. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.34995922446250916
desired expected reward: 23.191877365112305






Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3.  3.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3] -> size -> 21 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 20. 30.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3.  3.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3] -> size -> 21 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 3.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3.  3.  0.  3.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3] -> size -> 21 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.15841]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 0.  3.  0.  3.  6.  3.  3.  0.  3.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8.  0.] 
adversary cards in discard: [4. 1. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4] -> size -> 25 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6256257891654968
desired expected reward: 24.735881805419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.025017]
 [26.329655]
 [25.906612]
 [26.623999]
 [27.28015 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 0.  3.  0.  3.  6.  3.  3.  0.  3.  0.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8.  0.] 
adversary cards in discard: [4. 1. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4] -> size -> 25 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6855863928794861
desired expected reward: 26.478168487548828



buy possibilites: [-1] 
expected returns: [[26.63227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 3.] 
cards in discard: [ 0.  3.  0.  3.  6.  3.  3.  0.  3.  0.  8. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8.  0.] 
adversary cards in discard: [4. 1. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4] -> size -> 25 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6511116623878479
desired expected reward: 25.373905181884766






Player: 1 
cards in hand: [ 0.  8. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8.  0.] 
cards in discard: [4. 1. 3. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.766207]
 [26.095257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.669509768486023
desired expected reward: 25.96276092529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.769966]
 [25.651562]
 [27.0251  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  6. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6801003813743591
desired expected reward: 26.203357696533203



buy possibilites: [-1] 
expected returns: [[27.87796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  6. 10.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23. 10.  3.  0.  0.] 
adversary cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.630380392074585
desired expected reward: 25.139585494995117






Player: 1 
cards in hand: [23. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  3.  0.  0.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 9 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0.  3.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  0.  3.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  0.  3.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 6.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.365988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7300840616226196
desired expected reward: 27.147876739501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.82687 ]
 [22.709883]
 [24.058405]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6208246946334839
desired expected reward: 23.252967834472656



buy possibilites: [-1] 
expected returns: [[24.79993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 6.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5744068622589111
desired expected reward: 22.252464294433594






Player: 1 
cards in hand: [ 0.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 9 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 20. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 29.] 
cards in discard: [ 4.  1.  3.  0.  0.  0. 10.  0. 11.  0.  8.  8.  0.  0. 10. 23.  3.  0.
  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 10 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.228193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 10.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3] -> size -> 29 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6606019139289856
desired expected reward: 24.139328002929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.177662]
 [21.49209 ]
 [21.477844]
 [21.060677]
 [22.067272]
 [21.76709 ]
 [21.75284 ]
 [22.409197]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [29. 10.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3] -> size -> 29 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5879215598106384
desired expected reward: 21.64027214050293



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29. 10.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 10 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  8.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.  3.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  7.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 10 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.571358]
 [24.929249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  7.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11] -> size -> 30 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.556473433971405
desired expected reward: 21.85272216796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.428524]
 [24.728704]
 [24.311537]
 [25.01795 ]
 [25.660059]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 19. 29.  8.  7. 10.  7.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11] -> size -> 30 
adversary victory points: 10
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6546880006790161
desired expected reward: 24.916669845581055



buy possibilites: [-1] 
expected returns: [[22.697569]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [ 0.  6.  0.  3.  6. 10.  0.  3.  3.  0.  3.  6.  0.  0.  3.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11] -> size -> 30 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.4135366976261139
desired expected reward: 24.315170288085938






Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  9. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 10 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.13715 ]
 [25.480793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0. 11.  8.  3.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29] -> size -> 31 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5587818026542664
desired expected reward: 22.13878631591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.018394]
 [25.318579]
 [24.90141 ]
 [25.607822]
 [26.249931]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [23.  0. 11.  8.  3.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29] -> size -> 31 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6667878031730652
desired expected reward: 25.514352798461914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 11.  8.  3.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  8.  3.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  8.  3.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 10 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.083786]
 [22.427431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6978748440742493
desired expected reward: 25.55205726623535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.940155]
 [22.240337]
 [21.82317 ]
 [22.529583]
 [23.17169 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  7. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6061887145042419
desired expected reward: 22.477598190307617



buy possibilites: [-1] 
expected returns: [[25.06192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.3227372467517853
desired expected reward: 22.206844329833984






Player: 1 
cards in hand: [3. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
adversary victory points: 6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
adversary victory points: 6
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
adversary victory points: 6
player victory points: 10 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.89693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  4.  0. 10.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.  0.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0] -> size -> 33 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6509398221969604
desired expected reward: 24.410980224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.752728]
 [23.052908]
 [22.63574 ]
 [23.342152]
 [23.984262]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  4.  0. 10.] 
adversary cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.  0.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0] -> size -> 33 
adversary victory points: 10
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6220510601997375
desired expected reward: 23.274879455566406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  4.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  4.  0. 10.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.  0.  3.  8.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
adversary victory points: 6
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  4.  0. 10.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.  0.  3.  8.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 18. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
adversary victory points: 6
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  4.  0. 10.] 
cards in discard: [11. 29. 10.  1.  3.  0.  3. 29. 10.  0.  0.  0.  0. 15. 11. 23.  0.  8.
  3.  0.  3.  8.  3.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
adversary victory points: 6
player victory points: 11 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.663975]
 [23.021864]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0
  3  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0  3] -> size -> 34 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6237529516220093
desired expected reward: 23.36050796508789



action possibilites: [-1] 
expected returns: [[24.035788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0  3] -> size -> 34 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.05961696431040764
desired expected reward: 21.484909057617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.93761 ]
 [23.229097]
 [22.823828]
 [23.510923]
 [24.129032]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [15. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0  3] -> size -> 34 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.024463405832648277
desired expected reward: 24.011323928833008






Player: 1 
cards in hand: [15. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0
  4 10  0  0  3 11 29 15  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.  8.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.  8.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 29. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.  8.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 6. 6. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.  8.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.96886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 0.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.  8.  3.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1] -> size -> 34 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6221979260444641
desired expected reward: 23.506834030151367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.83994 ]
 [22.726154]
 [24.031363]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 0.] 
cards in discard: [ 6.  0.  3.  0. 10.  8.  3.  3.  0. 10.  0.  3.  0.  0.  3.  3.  8.  3.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 15. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1] -> size -> 34 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.623727023601532
desired expected reward: 23.34513282775879



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1. 15. 10.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1. 15. 10.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.592964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  4. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  3.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10] -> size -> 35 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5917146801948547
desired expected reward: 23.439645767211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.527098]
 [25.832693]
 [25.81858 ]
 [25.41331 ]
 [26.391893]
 [26.100409]
 [26.086296]
 [26.718515]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  4. 10.  9.] 
adversary cards in hand: [29.  3.  0.  3.  3.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10] -> size -> 35 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6733967661857605
desired expected reward: 25.919567108154297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  3.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  8. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
adversary victory points: 6
player victory points: 11 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.932571]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 3.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [29.  0. 23.  0. 10.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6897634863853455
desired expected reward: 26.02875328063965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.791193]
 [23.67741 ]
 [24.982616]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 3.] 
cards in discard: [3. 0. 0. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 17. 29.  8.  7. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [29.  0. 23.  0. 10.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
adversary victory points: 11
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6426502466201782
desired expected reward: 24.289920806884766



buy possibilites: [-1] 
expected returns: [[24.758522]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 3.] 
cards in discard: [3. 0. 0. 0. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [29.  0. 23.  0. 10.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.600357055664062
desired expected reward: 14.07705307006836






Player: 1 
cards in hand: [29.  0. 23.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 23.  0. 10.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6] -> size -> 26 
adversary victory points: 5
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 23.  0. 10.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6] -> size -> 26 
adversary victory points: 5
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.353762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6475411653518677
desired expected reward: 24.110980987548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.3018  ]
 [22.607397]
 [22.593287]
 [22.188015]
 [23.1666  ]
 [22.875114]
 [22.860998]
 [23.493223]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6100863218307495
desired expected reward: 22.743675231933594



buy possibilites: [-1] 
expected returns: [[22.256691]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  3.  0.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
adversary victory points: 11
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.585358738899231
desired expected reward: 21.716440200805664






Player: 1 
cards in hand: [ 8. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3.  0.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 29  3  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4
 10  0  0  3 11 29 15  0  3  1 10 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 10.  8.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 10.  8.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 10.  8.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 10.  0. 10.  8.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[19.752048]
 [19.119827]
 [19.119827]
 [19.13394 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 10.  8.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  8.  3.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6142575740814209
desired expected reward: 21.642433166503906



action possibilites: [-1. 10.  8.] 
expected returns: [[23.04366 ]
 [22.411438]
 [22.425549]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.  3.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  8.  3.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.11486268788576126
desired expected reward: 19.234689712524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.893955]
 [21.780172]
 [23.08538 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.  3.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 17. 29.  8.  6. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  8.  3.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.00590389221906662
desired expected reward: 23.037757873535156



buy possibilites: [-1] 
expected returns: [[19.257088]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.  3.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0. 3. 6. 6. 3. 0. 0. 0. 3. 3. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  8.  3.] 
adversary cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.993136405944824
desired expected reward: 12.787035942077637






Player: 1 
cards in hand: [ 0. 10. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  8.  3.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0  6] -> size -> 28 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  8.  3.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0  6] -> size -> 28 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  8.  3.] 
cards in discard: [ 1. 15. 10.  0.  0. 10.  3.  0.  3.  0.  0. 29. 29.  3.  0.  3.  3.  1.
 29.  0. 23.  0. 10.  0.  8. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0  6] -> size -> 28 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[22.156723]
 [21.54366 ]
 [21.557251]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49846217036247253
desired expected reward: 18.758625030517578



action possibilites: [-1.  8.] 
expected returns: [[22.158413]
 [21.558939]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 10 10  6  8  3  6  3  3  3  6  0  3  0  0  0  3
  8  6  0  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.033835772424936295
desired expected reward: 21.577495574951172



action possibilites: [-1.] 
expected returns: [[21.927837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.6266270875930786
desired expected reward: 22.413801193237305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.972815]
 [20.861336]
 [22.131649]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6177455186843872
desired expected reward: 22.545583724975586






Player: 1 
cards in hand: [0. 3. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 0.] 
adversary cards in discard: [10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
adversary victory points: 5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  6. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 0.] 
adversary cards in discard: [10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
adversary victory points: 5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 6. 0.] 
adversary cards in discard: [10.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
adversary victory points: 5
player victory points: 9 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.421616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [10.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 29. 10.] 
adversary cards in discard: [8. 0. 3. 0. 0. 4.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5575224757194519
desired expected reward: 21.574127197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.442097]
 [23.726477]
 [23.33062 ]
 [24.00146 ]
 [24.600933]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [10.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 17. 29.  8.  5. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 29. 10.] 
adversary cards in discard: [8. 0. 3. 0. 0. 4.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
adversary victory points: 9
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6308958530426025
desired expected reward: 23.790719985961914



buy possibilites: [-1] 
expected returns: [[21.708012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0.] 
cards in discard: [10.  8.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 29. 10.] 
adversary cards in discard: [8. 0. 3. 0. 0. 4.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.621984481811523
desired expected reward: 13.708635330200195






Player: 1 
cards in hand: [ 8. 10.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 29. 10.] 
cards in discard: [8. 0. 3. 0. 0. 4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 29. 10.] 
cards in discard: [8. 0. 3. 0. 0. 4.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[22.524748]
 [21.911682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [11.  3.  0.  1. 29.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5673053860664368
desired expected reward: 21.14070701599121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.510494]
 [21.80846 ]
 [21.794868]
 [21.399014]
 [22.354233]
 [22.06985 ]
 [22.05626 ]
 [22.669327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [11.  3.  0.  1. 29.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5936911702156067
desired expected reward: 21.931055068969727



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  1. 29.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 29.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 29.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  5. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 29.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  4. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.679266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  4. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  1.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.602447509765625
desired expected reward: 22.066879272460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.518286]
 [20.802662]
 [20.406807]
 [21.077644]
 [21.677118]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  4. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  1.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5793253779411316
desired expected reward: 21.09994125366211



buy possibilites: [-1] 
expected returns: [[22.619728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  0.  1.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8] -> size -> 38 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.30482217669487
desired expected reward: 20.7728214263916






Player: 1 
cards in hand: [ 3. 29.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  1.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6  8] -> size -> 27 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  1.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  7.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6  8] -> size -> 27 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  1.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 8.] 
adversary cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6  8] -> size -> 27 
adversary victory points: 4
player victory points: 9 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.15038 ]
 [21.550907]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 8.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 10 10  8  3  6  3  3  3  6  0  3  0  0  0  3  8  6  0
  6  6  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 39 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.598530650138855
desired expected reward: 22.021198272705078



action possibilites: [-1] 
expected returns: [[17.981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 39 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.019877241924405098
desired expected reward: 20.823213577270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.088896]
 [16.978342]
 [18.227423]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 17. 29.  8.  4. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 39 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09527263790369034
desired expected reward: 18.07627296447754



buy possibilites: [-1] 
expected returns: [[18.714182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10.  8.  3.  6.  0.  3.  6.  6.  0.  0. 10.  0.  3.  0.  8.  6.  3.  0.
  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0. 15.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.8628511428833
desired expected reward: 8.115492820739746






Player: 1 
cards in hand: [ 3.  0. 10.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 15.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0
  3 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [0. 3. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.161512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4577295482158661
desired expected reward: 18.256452560424805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.155317]
 [23.044767]
 [24.293844]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6264452934265137
desired expected reward: 23.535066604614258



buy possibilites: [-1] 
expected returns: [[21.443144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 3.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6195064783096313
desired expected reward: 22.535810470581055






Player: 1 
cards in hand: [ 0.  0. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23.  0.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.  0.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  6.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.  0.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 6.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [6. 8. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.915846]
 [23.32777 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 6. 6.] 
cards in discard: [0. 0. 3. 6. 3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11.  3.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.  0.  0. 23.  0.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11] -> size -> 40 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5446478128433228
desired expected reward: 20.898496627807617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.803988]
 [22.693434]
 [23.942514]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 6. 6.] 
cards in discard: [0. 0. 3. 6. 3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11.  3.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.  0.  0. 23.  0.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11] -> size -> 40 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6227642297744751
desired expected reward: 23.293081283569336



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  8.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.  0.  0. 23.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.  0.  0. 23.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.  0.  0. 23.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  4.  8. 10.  0. 29. 10.  0.  8. 11.  3.  0.  1. 29.
 11.  3. 29.  3.  0.  1.  0. 15.  3. 10.  0. 11.  0.  0. 23.  0.  0. 14.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.115095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0] -> size -> 42 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6465669274330139
desired expected reward: 23.295948028564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.1316  ]
 [20.424768]
 [20.412058]
 [20.021051]
 [20.962511]
 [20.682056]
 [20.669346]
 [21.270132]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 23.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0] -> size -> 42 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5659833550453186
desired expected reward: 20.54911231994629



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  8. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 23.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 23.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 23.  0.] 
cards in discard: [10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[18.288658]
 [17.687874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 15.  4.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10] -> size -> 43 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5985962748527527
desired expected reward: 20.671531677246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.202595]
 [17.48305 ]
 [17.092045]
 [17.75305 ]
 [18.341124]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [0. 0. 3. 6. 3. 3. 6. 8. 3. 6. 6. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 15.  4.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.] 
adversary owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10] -> size -> 43 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5125187039375305
desired expected reward: 17.776142120361328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  8. 15.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 15.  4.] 
cards in discard: [10.  0.  0.  8. 23.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3
 11 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  4.] 
cards in discard: [10.  0.  0.  8. 23.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  4.] 
cards in discard: [10.  0.  0.  8. 23.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  4.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [10.  6.  8.  0.  8.] 
adversary cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [10.  6.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[19.764153]
 [19.16337 ]
 [19.176079]
 [19.176079]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.  0.  8.] 
cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6
  8  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  1. 10.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49644166231155396
desired expected reward: 17.844682693481445



action possibilites: [-1] 
expected returns: [[18.145197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  8.] 
cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  1. 10.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.07288467139005661
desired expected reward: 18.99421501159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.140215]
 [17.029665]
 [18.278746]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8.] 
cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  3. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  1. 10.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09088560193777084
desired expected reward: 18.236082077026367



buy possibilites: [-1] 
expected returns: [[18.56791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  8.] 
cards in discard: [ 0.  0.  3.  6.  3.  3.  6.  8.  3.  6.  6.  3.  3.  0.  0.  0.  0.  3.
  0. 10.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  1. 10.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.856759071350098
desired expected reward: 8.172905921936035






Player: 1 
cards in hand: [ 0.  3. 29.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1. 10.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  1.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  1.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  1.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  8.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.268034]
 [18.695263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 11.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14] -> size -> 44 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5071285367012024
desired expected reward: 18.060781478881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.186672]
 [18.078   ]
 [19.296808]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 11.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14] -> size -> 44 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.531945526599884
desired expected reward: 18.736085891723633



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 11.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  8.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 3. 3.] 
adversary cards in discard: [3. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 3. 3.] 
adversary cards in discard: [3. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  3. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 3. 3.] 
adversary cards in discard: [3. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 6. 3. 3. 3.] 
adversary cards in discard: [3. 6. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.173414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3. 3.] 
cards in discard: [3. 6. 3. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5275834202766418
desired expected reward: 18.76922607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.12857 ]
 [18.019896]
 [19.238707]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 3.] 
cards in discard: [3. 6. 3. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  2. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5297170281410217
desired expected reward: 18.64369773864746



buy possibilites: [-1] 
expected returns: [[23.020065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3. 3.] 
cards in discard: [3. 6. 3. 8. 0. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 29.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.448885917663574
desired expected reward: 8.571009635925293






Player: 1 
cards in hand: [ 0.  8.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 29.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 29.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.70346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6652156114578247
desired expected reward: 22.354848861694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.702492]
 [15.988774]
 [15.977001]
 [15.593816]
 [16.514366]
 [16.239857]
 [16.228083]
 [16.812628]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [29.  0.  0. 11.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48028746247291565
desired expected reward: 16.223173141479492



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 10.] 
adversary cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3. 3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 10.] 
adversary cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3. 3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 10.] 
adversary cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3. 3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  3.  8.  0. 10.] 
adversary cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3. 3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[18.357224]
 [17.78445 ]
 [17.78445 ]
 [17.772676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8.  0. 10.] 
cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3. 3. 0. 0. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8.  0.  3. 14.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4652611017227173
desired expected reward: 16.34736442565918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.23299 ]
 [17.124317]
 [18.343128]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8.  0. 10.] 
cards in discard: [3. 6. 3. 8. 0. 6. 3. 6. 3. 3. 3. 3. 0. 0. 6. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8.  0.  3. 14.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5146348476409912
desired expected reward: 17.842586517333984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  8.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3. 14.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  7.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 14.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 14.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[17.992208]
 [17.407665]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  0. 10.] 
cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29. 11.  8.  0.  3. 14.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5138307213783264
desired expected reward: 17.82929801940918



action possibilites: [-1.] 
expected returns: [[15.566271]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29. 11.  8.  0.  3. 14.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.09121587872505188
desired expected reward: 17.49888038635254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.663241]
 [14.949528]
 [14.937753]
 [14.554569]
 [15.47512 ]
 [15.200607]
 [15.188835]
 [15.773377]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  2. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29. 11.  8.  0.  3. 14.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.14291615784168243
desired expected reward: 15.709186553955078



buy possibilites: [-1] 
expected returns: [[18.24649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 0.] 
cards in discard: [ 3.  6.  3.  8.  0.  6.  3.  6.  3.  3.  3.  3.  0.  0.  6.  0.  8.  3.
  8.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29. 11.  8.  0.  3. 14.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.2455698847770691
desired expected reward: 15.446179389953613






Player: 1 
cards in hand: [10.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11.  0.] 
cards in discard: [10.  0.  0.  8. 23.  0.  0. 15. 10.  8.  4. 14. 10.  0.  3. 29.  1.  0.
 14.  8. 11.  0.  3.  0. 10.  0.  8.  3. 29.  0.  0. 29.  0.  0. 11.  0.
  1. 29. 11.  8.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8] -> size -> 29 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8] -> size -> 29 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 6.  6.  3. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8] -> size -> 29 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.50312]
 [20.91858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4740670323371887
desired expected reward: 17.772422790527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.487064]
 [20.378391]
 [21.597202]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 10.  6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5748440623283386
desired expected reward: 20.92827606201172



buy possibilites: [-1] 
expected returns: [[18.261961]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 10.  6.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.] 
adversary owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.5639002919197083
desired expected reward: 19.92316436767578






Player: 1 
cards in hand: [ 8. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 29  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11
 29 15  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10.  3.  3. 11.  0.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  3.  3. 11.  0.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[16.343307]
 [15.772743]
 [15.783897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8.  0.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14. 10. 29.  3.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5294180512428284
desired expected reward: 17.732542037963867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.374923]
 [15.643987]
 [15.268327]
 [15.900791]
 [16.4602  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  8.  0.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14. 10. 29.  3.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4736037850379944
desired expected reward: 15.86970329284668



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 29.  3.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10. 29.  3.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10. 29.  3.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 6. 6. 8. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [6. 6. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[13.965023]
 [13.405612]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 3.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 10 10  8  3  3  3  3  6  0  3  0  0  0  3  8  6  0  6  6  8
  6  0  6  6  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49952274560928345
desired expected reward: 15.960676193237305



action possibilites: [-1] 
expected returns: [[18.244362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.25172698497772217
desired expected reward: 13.246354103088379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.273848]
 [17.167252]
 [18.359127]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  1. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08906392753124237
desired expected reward: 18.333425521850586



buy possibilites: [-1] 
expected returns: [[16.82594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
adversary owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.888345718383789
desired expected reward: 8.278905868530273






Player: 1 
cards in hand: [ 0.  8.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8  0 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15
  0  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6] -> size -> 28 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.200791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 11.  1.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0.] 
adversary owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.49516987800598145
desired expected reward: 16.330768585205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.362559]
 [14.642776]
 [14.63162 ]
 [15.157489]
 [14.888426]
 [14.877272]
 [15.447837]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  5.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 11.  1.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0.] 
adversary owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44877371191978455
desired expected reward: 14.752017974853516



buy possibilites: [-1] 
expected returns: [[14.682921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 11.  1.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0.] 
adversary owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.08944601565599442
desired expected reward: 15.24693489074707






Player: 1 
cards in hand: [ 0.  0. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  1.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 7. 28. 30. 17. 29.  8.  0. 10.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.036128]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [23.  8.  0. 11. 29.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.] 
adversary owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4326082766056061
desired expected reward: 14.250312805175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.023467]
 [14.29253 ]
 [14.549335]
 [15.108745]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [23.  8.  0. 11. 29.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.] 
adversary owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44760990142822266
desired expected reward: 14.588518142700195



buy possibilites: [-1] 
expected returns: [[13.298736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 0.  6.  6.  3. 10.  6.  3.  0. 10.  8.  0.  6.  8.  6. 11.  6.  3.  0.
  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [23.  8.  0. 11. 29.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.] 
adversary owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4310672879219055
desired expected reward: 13.592399597167969






Player: 1 
cards in hand: [23.  8.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 11. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0. 11. 29.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23  0 10  8 11  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0
  3  1 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 29.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 29.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[14.962054]
 [14.39149 ]
 [14.402644]
 [14.402644]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8. 15.  8.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.39540818333625793
desired expected reward: 12.903326988220215



action possibilites: [-1.  8.  8.] 
expected returns: [[16.507467]
 [15.948058]
 [15.948058]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6
  6  8  0  6 11  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8. 15.  8.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.18845102190971375
desired expected reward: 14.579940795898438



action possibilites: [-1.  8.] 
expected returns: [[16.198685 ]
 [15.6512575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8. 15.  8.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.7723564505577087
desired expected reward: 15.620038032531738





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.33822 ]
 [16.402699]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8. 15.  8.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7317970395088196
desired expected reward: 16.93048095703125



buy possibilites: [-1] 
expected returns: [[14.763118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [11.  8. 15.  8.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.7448661923408508
desired expected reward: 16.083084106445312






Player: 1 
cards in hand: [11.  8. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  8.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15.  8.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15.  8.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  6.  0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[13.930951]
 [13.647965]
 [13.372524]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  6.  0.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  0.  4.  0. 10.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44897449016571045
desired expected reward: 14.314143180847168



action possibilites: [-1. 11.] 
expected returns: [[13.813661]
 [13.530677]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  3.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  1. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  0.  4.  0. 10.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.19267916679382324
desired expected reward: 13.565204620361328



action possibilites: [-1.] 
expected returns: [[16.740643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  0.  4.  0. 10.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 39 

action type: gain_card_n - action 5
Learning step: 0.9578717350959778
desired expected reward: 13.888040542602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.710456]
 [16.774935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  0.  4.  0. 10.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7194466590881348
desired expected reward: 17.4600887298584






Player: 1 
cards in hand: [14.  0.  4.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  4.  0. 10.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8] -> size -> 31 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  4.  0. 10.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8] -> size -> 31 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.078206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5054268836975098
desired expected reward: 16.269508361816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.033643]
 [13.298085]
 [14.098124]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.42953652143478394
desired expected reward: 13.648669242858887



buy possibilites: [-1] 
expected returns: [[12.551824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 6.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.40921512246131897
desired expected reward: 12.624427795410156






Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3.  3. 11.  0.  3.  8.  3.  0.  0. 14. 10. 29.  3.  0.  8.  0. 10.
  0. 11. 16. 29.  0.  0.  1.  1.  8. 23. 29.  0. 11.  8. 15.  8.  0. 14.
  0.  4.  0. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.358002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 4
Learning step: -0.7429020404815674
desired expected reward: 22.64579963684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 9.2788315]
 [ 9.554275 ]
 [ 9.543274 ]
 [10.0603285]
 [ 9.784885 ]
 [10.343313 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.35702821612358093
desired expected reward: 10.00097370147705



buy possibilites: [-1] 
expected returns: [[12.5266485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 47 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: 0.234901562333107
desired expected reward: 9.789175987243652






Player: 1 
cards in hand: [ 0.  8.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3  8 10 23 10  8  3  3  3  0  0  0  4 10  0  0  3 11 29 15  0  3  1
 10 29  0  0  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1] -> size -> 33 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1] -> size -> 33 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 6.] 
adversary cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.  0.  0.  0.] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1] -> size -> 33 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.7729025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 14. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.41268396377563477
desired expected reward: 12.113964080810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.940987]
 [11.012975]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 14. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3685593605041504
desired expected reward: 10.6212158203125



buy possibilites: [-1] 
expected returns: [[10.1237755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 6.] 
cards in discard: [ 0. 10.  8.  8.  3.  0.  8. 10. 11.  3.  6.  0.  3.  0.  3.  0.  6.  0.
  6.  8.  3.  1.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 14. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.34192991256713867
desired expected reward: 9.599056243896484






Player: 1 
cards in hand: [ 0. 11. 29. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 14. 10.] 
cards in discard: [8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29. 14. 10.] 
cards in discard: [8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1  0] -> size -> 34 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.693229]
 [14.142321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10. 10.  8.  3.  0.] 
adversary cards in discard: [ 8.  0. 11. 29. 14. 10.] 
adversary owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3017481565475464
desired expected reward: 9.822027206420898





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.689788]
 [14.761776]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10. 10.  8.  3.  0.] 
adversary cards in discard: [ 8.  0. 11. 29. 14. 10.] 
adversary owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4403005540370941
desired expected reward: 14.252927780151367



Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 3. 0. 8. 6.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 10 10  8  3  3  3  3  0  3  0  0  0  3  8  0  6  6  8  6  0  6  6
  8  0  6 11  0  0  8  0  1  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 27. 30. 17. 29.  8.  0.  9.  4.  0. 10.  6.  7.  9.  3. 10.  9.] 
adversary cards in hand: [10. 10.  8.  3.  0.] 
adversary cards in discard: [ 8.  0. 11. 29. 14. 10.] 
adversary owned cards: [ 3  8 23 10  8  3  3  3  0  4 10  0  0  3 11 29 15  0  3  1 10 29  0  0
  8  0  8 11  0 11 14  0 10  0 14 14  8  0 29  0 16  0  0] -> size -> 43 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action 0.0
Learning step: -15.56069278717041
desired expected reward: -1.8709049224853516



