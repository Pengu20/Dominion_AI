 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.7656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -40    0    0   20    0    0    0    0  -25    0    0
    9    0] 
sum of rewards: -541 

action type: buy - action 11.0
Learning step: -26.236967086791992
desired expected reward: -42.49763488769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[296.41083]
 [309.19635]
 [303.40894]
 [270.5074 ]
 [316.37833]
 [305.03934]
 [302.15866]
 [321.92117]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.413467407226562
desired expected reward: 314.0146484375



buy possibilites: [-1] 
expected returns: [[287.17838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -7.846419811248779
desired expected reward: 294.312255859375






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[299.42764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.700838565826416
desired expected reward: 279.4775390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[280.9144 ]
 [295.71194]
 [287.84863]
 [255.44997]
 [287.38492]
 [301.2248 ]
 [291.2407 ]
 [292.04965]
 [266.2779 ]
 [285.49356]
 [278.98166]
 [304.2035 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.655484199523926
desired expected reward: 291.7036437988281



buy possibilites: [-1] 
expected returns: [[297.01862]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -7.159514904022217
desired expected reward: 280.68914794921875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[282.19412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -8.103163719177246
desired expected reward: 288.91546630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[261.14774]
 [270.60086]
 [264.72498]
 [241.39044]
 [265.25864]
 [274.3606 ]
 [268.31702]
 [269.0858 ]
 [250.64622]
 [264.19116]
 [260.14584]
 [276.60397]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.58245325088501
desired expected reward: 272.3183288574219



buy possibilites: [-1] 
expected returns: [[284.8719]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 8.0
Learning step: -6.456233501434326
desired expected reward: 261.86077880859375






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  0.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.23868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.220523834228516
desired expected reward: 277.6513671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.63864]
 [288.75925]
 [281.7565 ]
 [244.29584]
 [296.01343]
 [283.56558]
 [279.46658]
 [300.73624]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -7.794277191162109
desired expected reward: 284.3421936035156



buy possibilites: [-1] 
expected returns: [[279.54105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 27 

action type: buy - action 11.0
Learning step: -7.160998821258545
desired expected reward: 288.8524169921875






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14. 15.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[270.65897]
 [247.95169]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 15.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -7.641179084777832
desired expected reward: 271.8998718261719



action possibilites: [-1.] 
expected returns: [[273.62555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 15.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 30 

action type: take_action - action 10.0
Learning step: -4.7839250564575195
desired expected reward: 244.0260772705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[246.07018]
 [252.72467]
 [219.17923]
 [254.77885]
 [268.56512]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 15.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -6.604764461517334
desired expected reward: 267.0207824707031



buy possibilites: [-1] 
expected returns: [[257.0067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 15.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -282.0 

action type: buy - action 6.0
Learning step: -19.27631187438965
desired expected reward: 199.90293884277344






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 15.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 15.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 15.  3.  0. 14.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  8.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11  6] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[277.80115]
 [271.8923 ]
 [260.10858]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  8.] 
cards in discard: [ 6. 10.  0.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.854243755340576
desired expected reward: 250.1524658203125



action possibilites: [-1] 
expected returns: [[293.182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6. 10.  0.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  8  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: trash_cards_n_from_hand - action 12
Learning step: -5.456306457519531
desired expected reward: 242.60171508789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[266.28757]
 [235.00626]
 [293.7779 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 10.  0.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  8  6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.28858470916748
desired expected reward: 284.8934326171875



buy possibilites: [-1] 
expected returns: [[303.81247]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 10.  0.  3.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  8  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action 0.0
Learning step: -7.628594875335693
desired expected reward: 258.6589050292969






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  8  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  8  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  8  6  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[255.19525]
 [241.42572]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  8  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -10.25106143951416
desired expected reward: 293.5614013671875



action possibilites: [-1] 
expected returns: [[242.0369]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  3  8  6  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 6
Learning step: -5.269868850708008
desired expected reward: 205.0441131591797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[209.01524]
 [184.88335]
 [231.64099]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  3  8  6  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.564066410064697
desired expected reward: 234.4728240966797



buy possibilites: [-1] 
expected returns: [[225.87082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 10  3  8  6  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  3.  8.  0.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action 0.0
Learning step: -7.068669319152832
desired expected reward: 201.9465789794922






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  8.  0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  8.  0.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[238.78476]
 [220.69977]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  0.] 
cards in discard: [0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.341075897216797
desired expected reward: 218.5297393798828



action possibilites: [-1.] 
expected returns: [[245.99959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 10  3  8  6  0  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action 10.0
Learning step: -5.615579128265381
desired expected reward: 213.39581298828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[217.27393]
 [230.76707]
 [224.70769]
 [189.06871]
 [237.5672 ]
 [226.47778]
 [223.17429]
 [242.04393]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 10  3  8  6  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -7.426266670227051
desired expected reward: 238.5733184814453



buy possibilites: [-1] 
expected returns: [[188.93063]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 8. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  1.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -2.0 

action type: buy - action 8.0
Learning step: -7.172949314117432
desired expected reward: 219.30482482910156






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[207.33571]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 10.  0.] 
adversary cards in discard: [15.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -5.996730327606201
desired expected reward: 182.93389892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[185.71242]
 [191.46457]
 [164.63469]
 [192.8925 ]
 [204.81497]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 10.  0.] 
adversary cards in discard: [15.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.271251678466797
desired expected reward: 199.3865966796875



buy possibilites: [-1] 
expected returns: [[196.40387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  0. 10.  0.] 
adversary cards in discard: [15.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -5 

action type: buy - action 3.0
Learning step: -5.165395259857178
desired expected reward: 186.2991943359375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 10.  0.] 
cards in discard: [15.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  8.  8.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [15.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 6. 8. 8.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [15.  8.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 6. 8. 8.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[204.19446]
 [187.43008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [3. 0. 3. 3. 0. 6. 8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8.  1.  0. 14.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: discard_down_to_3_cards - action 0
Learning step: -3.9585206508636475
desired expected reward: 149.69313049316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[182.30191]
 [188.98051]
 [156.1896 ]
 [191.42314]
 [203.30464]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [3. 0. 3. 3. 0. 6. 8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8.  1.  0. 14.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -6.5582427978515625
desired expected reward: 195.35877990722656



buy possibilites: [-1] 
expected returns: [[191.84525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [3. 0. 3. 3. 0. 6. 8. 8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [15.  8.  1.  0. 14.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 6 

action type: buy - action 3.0
Learning step: -4.832508087158203
desired expected reward: 184.1480255126953






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  8.  1.  0. 14.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  8.  1.  0. 14.  3.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  8.  1.  0. 14.  3.  0. 10.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[179.21191]
 [166.15855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -5.790215969085693
desired expected reward: 186.05502319335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[155.55383]
 [161.28696]
 [135.3688 ]
 [162.3135 ]
 [175.82889]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -5.476474285125732
desired expected reward: 173.8946533203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 15.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 15.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 15.  1.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[186.86389]
 [178.74643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [0. 8. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  0.] 
adversary cards in discard: [29. 10.  0.  1.  3. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -4.80963659286499
desired expected reward: 171.0192413330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.2229 ]
 [147.42418]
 [187.1951 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [0. 8. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  0.] 
adversary cards in discard: [29. 10.  0.  1.  3. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -5.529096603393555
desired expected reward: 179.67201232910156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14.  0.] 
cards in discard: [29. 10.  0.  1.  3. 15.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [29. 10.  0.  1.  3. 15.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [29. 10.  0.  1.  3. 15.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 27. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [29. 10.  0.  1.  3. 15.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[177.88333]
 [161.28564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 3
Learning step: -5.496913433074951
desired expected reward: 169.07733154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[151.53876]
 [157.4829 ]
 [126.32643]
 [160.04901]
 [171.38464]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -6.018903732299805
desired expected reward: 172.0902862548828



buy possibilites: [-1] 
expected returns: [[171.05649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -5.828166961669922
desired expected reward: 145.71058654785156






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  7. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 8. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[175.01341]
 [159.51973]
 [159.51973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [ 3.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 14.  0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -5.523496150970459
desired expected reward: 165.53298950195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.70425]
 [124.71109]
 [175.91301]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [ 3.  0.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  1.  3. 14.  0.] 
adversary cards in discard: [8. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -5.697616100311279
desired expected reward: 165.10890197753906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 14.  0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  8.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 6.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [8. 3. 3. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 6.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [8. 3. 6.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[169.02725]
 [155.37784]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6.] 
cards in discard: [10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 10  3  8  6  0  0  8  3  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0.  0. 29.  8.] 
adversary cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8 15] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 6
Learning step: -5.137784004211426
desired expected reward: 158.15036010742188



action possibilites: [-1] 
expected returns: [[156.41]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0.  0. 29.  8.] 
adversary cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8 15] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.194858551025391
desired expected reward: 147.08682250976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.47592 ]
 [111.387665]
 [157.5509  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0.  0. 29.  8.] 
adversary cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8 15] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -4.891923427581787
desired expected reward: 151.51808166503906






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  8.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1 29  3  8 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [10.  3.  8.  6.] 
adversary owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [10.  3.  8.  6.] 
adversary owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [10.  3.  8.  6.] 
adversary owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  3.  0. 15. 14.  0.  1.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [10.  3.  8.  6.] 
adversary owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[125.72563]
 [116.07727]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [10.  3.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  3  8  6  0  0  8  3  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -6.789559841156006
desired expected reward: 150.7613525390625



action possibilites: [-1] 
expected returns: [[134.36938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10.  3.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  6  0  0  8  3  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: trash_cards_n_from_hand - action 4
Learning step: -2.5402300357818604
desired expected reward: 95.7305908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.776474]
 [ 89.23592 ]
 [133.54398 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  3.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  6  0  0  8  3  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1
Learning step: -4.808435440063477
desired expected reward: 129.56094360351562



buy possibilites: [-1] 
expected returns: [[146.54619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10.  3.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 15. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -4.491534233093262
desired expected reward: 108.2849349975586






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 15. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[181.76653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  1.  3.  0.] 
adversary cards in discard: [ 0.  8.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.8946990966796875
desired expected reward: 141.6514892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[160.75885]
 [171.28938]
 [165.53564]
 [139.16171]
 [175.56998]
 [168.0788 ]
 [164.06068]
 [177.72826]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  8. 10.  8.] 
adversary cards in hand: [15.  3.  1.  3.  0.] 
adversary cards in discard: [ 0.  8.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -6.978929042816162
desired expected reward: 174.47042846679688



buy possibilites: [-1] 
expected returns: [[148.566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15.  3.  1.  3.  0.] 
adversary cards in discard: [ 0.  8.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -15 

action type: buy - action 10.0
Learning step: -5.610300064086914
desired expected reward: 158.4503936767578






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [15.  3.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  3.  0.] 
cards in discard: [ 0.  8.  0. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  8. 10.  8.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  3.  0.] 
cards in discard: [ 0.  8.  0. 15. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  9.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  8. 10.  8.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  3.  0.] 
cards in discard: [ 0.  8.  0. 15. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  8. 10.  8.] 
adversary cards in discard: [10.  0.  3.  0.  0.  3.] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 3.  6.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[138.13919]
 [122.91084]
 [120.33969]
 [122.91084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8. 10.  8.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  3.  8.] 
adversary cards in discard: [ 0.  8.  0. 15. 10. 11. 15.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -6.254459381103516
desired expected reward: 142.31153869628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.85377]
 [ 90.44976]
 [136.43767]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  8. 10.  8.] 
cards in discard: [10.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  3.  8.] 
adversary cards in discard: [ 0.  8.  0. 15. 10. 11. 15.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.870060920715332
desired expected reward: 130.4194793701172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3.  8.] 
cards in discard: [ 0.  8.  0. 15. 10. 11. 15.  3.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.] 
cards in discard: [ 0.  8.  0. 15. 10. 11. 15.  3.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.] 
cards in discard: [ 0.  8.  0. 15. 10. 11. 15.  3.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  6. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.] 
cards in discard: [ 0.  8.  0. 15. 10. 11. 15.  3.  1.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.90535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -5.2839741706848145
desired expected reward: 131.15367126464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.27036 ]
 [105.729485]
 [ 80.668915]
 [107.43386 ]
 [118.89182 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -4.782086372375488
desired expected reward: 114.68051147460938



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  5. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  8.  0.] 
adversary cards in discard: [6. 3. 0. 3. 0.] 
adversary owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 10.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[143.63809]
 [130.03127]
 [135.21399]
 [135.21399]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8.  0.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  6  0  0  8  3  3  0  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  8.  3.] 
adversary cards in discard: [ 8. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -4.072752475738525
desired expected reward: 114.81906127929688



action possibilites: [-1] 
expected returns: [[110.95521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  8.  3.] 
adversary cards in discard: [ 8. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -33 

action type: trash_cards_n_from_hand - action 12
Learning step: -4.434034824371338
desired expected reward: 101.17650604248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 92.17835 ]
 [ 67.764565]
 [109.07285 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  8.  3.] 
adversary cards in discard: [ 8. 15.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -5.141360759735107
desired expected reward: 105.81385040283203






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  8.  3.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 3.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 25. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[134.61714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 15.  1.  1.] 
adversary cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -63 

action type: discard_down_to_3_cards - action 4
Learning step: -3.4718704223632812
desired expected reward: 63.919593811035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.31441]
 [102.17442]
 [133.34944]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 15.  1.  1.] 
adversary cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0 -30   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -7.224427700042725
desired expected reward: 128.22903442382812



buy possibilites: [-1] 
expected returns: [[112.37894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0. 15.  1.  1.] 
adversary cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -63.0 

action type: buy - action 0.0
Learning step: -6.637195110321045
desired expected reward: 113.6772232055664






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10.  0. 15.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  1.  1.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  1. 11.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  9. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 28. 30. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 8. 15.  0.  3.  3.  0.  3. 14.  3.  8.  8.  3. 14.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15. 11.] 
owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[135.38284]
 [126.86416]
 [126.86416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -4.3714280128479
desired expected reward: 108.00750732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.09878 ]
 [102.889595]
 [133.48741 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -5.661932468414307
desired expected reward: 128.63426208496094



buy possibilites: [-1] 
expected returns: [[101.3304]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 15.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -63.0 

action type: buy - action 0.0
Learning step: -6.875004768371582
desired expected reward: 113.22377014160156






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 6. 8.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 6. 8.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 6. 8.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [0. 3. 0. 8. 6. 8.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[74.210846]
 [62.766804]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [0. 3. 0. 8. 6. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -5.165510654449463
desired expected reward: 96.16488647460938



action possibilites: [-1.] 
expected returns: [[127.30755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -0.9191295504570007
desired expected reward: 61.75185775756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[105.6316  ]
 [112.01021 ]
 [ 82.158165]
 [113.297745]
 [126.166725]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -4.552079200744629
desired expected reward: 122.7554702758789



buy possibilites: [-1] 
expected returns: [[110.13315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3. 10.  8.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.] 
adversary owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -4.95358419418335
desired expected reward: 100.67802429199219






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  8.  3.] 
cards in discard: [10. 15.  8.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 3. 8.] 
cards in discard: [10. 15.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 15  0 14  1  8 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [10. 15.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [10. 15.  8.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [10. 15.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 8. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [8. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[126.66088]
 [112.86993]
 [112.86993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  8.] 
adversary cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.] 
adversary owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -4.013017177581787
desired expected reward: 106.12013244628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.93949]
 [113.40479]
 [ 84.8578 ]
 [113.9369 ]
 [128.2117 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6. 0. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 29. 24. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  8.] 
adversary cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.] 
adversary owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -4.96441650390625
desired expected reward: 121.3347396850586



buy possibilites: [-1] 
expected returns: [[126.69845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6. 0. 0.] 
cards in discard: [ 0. 10.  0.  3.  0.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  1.  3.  3.  8.] 
adversary cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.] 
adversary owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10  0] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 3.0
Learning step: -2.6553378105163574
desired expected reward: 103.4657211303711






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [11.  1.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3.  8.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  0 14  1 10  1  3  8 15  3  0 11  8  8  3 14  2 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 29. 23. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[100.80436]
 [ 92.2409 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14. 15.  2.  0.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1.] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -3.775968551635742
desired expected reward: 122.92247772216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 84.77289]
 [ 64.03265]
 [100.74314]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 29. 23. 30.  8.  9. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14. 15.  2.  0.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1.] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -2.684798002243042
desired expected reward: 97.1455078125



buy possibilites: [-1] 
expected returns: [[84.33936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [14. 15.  2.  0.  3.] 
adversary cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1.] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -303.0 

action type: buy - action 6.0
Learning step: -16.453994750976562
desired expected reward: 47.578636169433594






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [14. 15.  2.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  2.  0.  3.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [6. 0. 8. 3. 6. 3.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  2.  0.  3.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  2.  0.  3.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  2.  0.  3.] 
cards in discard: [10. 15.  8.  0.  0.  0. 10.  8.  1.  3.  8.  1. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.] 
adversary owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 14 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[68.08085 ]
 [61.195244]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: discard_down_to_3_cards - action 2
Learning step: -0.3902547061443329
desired expected reward: 34.9167366027832



action possibilites: [-1] 
expected returns: [[105.072174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.6664264798164368
desired expected reward: 65.944580078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 89.49876]
 [ 69.10786]
 [103.57603]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -2.954892158508301
desired expected reward: 102.11727905273438



buy possibilites: [-1] 
expected returns: [[90.141716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  8.  3.  6.  3.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  8.  1. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -3.6467487812042236
desired expected reward: 85.85199737548828






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  8.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  1. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14  1 10  1  8 15  3  0  8  8  3 14  2 10  0 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[126.26682]
 [116.4869 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3  0  0 10  0  0  0  3  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 14.  0.  1.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -2.0422542095184326
desired expected reward: 88.0994644165039



action possibilites: [-1] 
expected returns: [[111.305725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 14.  0.  1.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.8875995874404907
desired expected reward: 101.95196533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 92.03083]
 [ 73.93228]
 [108.53361]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 29. 23. 30.  8.  8. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 14.  0.  1.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -2.67250919342041
desired expected reward: 108.63321685791016



buy possibilites: [-1] 
expected returns: [[96.70897]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 14.  0.  1.] 
adversary cards in discard: [ 8.  0. 14.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 6.0
Learning step: -16.270662307739258
desired expected reward: 57.66162109375






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  0.  1.] 
cards in discard: [ 8.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [10.  8.  0.  3.  3.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.  0.  1.] 
cards in discard: [ 8.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  8.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [10.  8.  0.  3.  3.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.  0.  1.] 
cards in discard: [ 8.  0. 14. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [10.  8.  0.  3.  3.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [10.  8.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[56.179848]
 [43.58153 ]
 [46.06016 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  3.  3.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  8.  2.  0.  0.] 
adversary cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -4.500356197357178
desired expected reward: 92.20861053466797



action possibilites: [-1.  8.] 
expected returns: [[40.468163]
 [29.763744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  8.  2.  0.  0.] 
adversary cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: -0.9001712799072266
desired expected reward: 38.119407653808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.593113]
 [ 9.898998]
 [39.89863 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  8.  2.  0.  0.] 
adversary cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -1.185289978981018
desired expected reward: 39.28287124633789



buy possibilites: [-1] 
expected returns: [[83.40293]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 3. 6.] 
cards in discard: [6. 8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [14.  8.  2.  0.  0.] 
adversary cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -0.603089451789856
desired expected reward: 23.99001693725586






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [14.  8.  2.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  2.  0.  0.] 
cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 2. 0. 0.] 
cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 2. 0. 0.] 
cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 2. 0. 0.] 
cards in discard: [ 8.  0. 14. 11.  8.  3. 14.  0.  1. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.310585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14. 10. 15. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_down_to_3_cards - action 4
Learning step: 0.40339842438697815
desired expected reward: 23.427722930908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 85.987495]
 [ 91.87676 ]
 [ 63.205765]
 [ 93.56804 ]
 [104.001144]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14. 10. 15. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -3.864960193634033
desired expected reward: 98.56236267089844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [14. 10. 15. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 15. 10. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 15. 10. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 8. 6. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 3. 8.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10. 15.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [6. 0. 3. 0. 0. 3. 8.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[110.409065]
 [ 98.36645 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [6. 0. 3. 0. 0. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  8.  2.  0.] 
adversary cards in discard: [14. 10. 15. 10. 15.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_down_to_3_cards - action 1
Learning step: 1.72222101688385
desired expected reward: -1.2825747728347778





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 90.93725]
 [ 67.61231]
 [110.59935]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [6. 0. 3. 0. 0. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 29. 23. 30.  8.  7. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  8.  2.  0.] 
adversary cards in discard: [14. 10. 15. 10. 15.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -4.1248979568481445
desired expected reward: 104.58027648925781



buy possibilites: [-1] 
expected returns: [[81.50187]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [6. 0. 3. 0. 0. 3. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  0.  8.  2.  0.] 
adversary cards in discard: [14. 10. 15. 10. 15.] 
adversary owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -17.846824645996094
desired expected reward: 49.76551055908203






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [14.  0.  8.  2.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  2.  0.] 
cards in discard: [14. 10. 15. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  0 14 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0.] 
cards in discard: [14. 10. 15. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [14. 10. 15. 10. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [14. 10. 15. 10. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[54.70346 ]
 [45.204193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  3. 11.  8.  0.] 
adversary cards in discard: [14. 10. 15. 10. 15.  0.  8.  2.  0.] 
adversary owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -4.252309322357178
desired expected reward: 77.24955749511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.16176 ]
 [42.43203 ]
 [27.80162 ]
 [43.663322]
 [51.782413]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [14.  3. 11.  8.  0.] 
adversary cards in discard: [14. 10. 15. 10. 15.  0.  8.  2.  0.] 
adversary owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -3.0689055919647217
desired expected reward: 51.177249908447266



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [14.  3. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.  8.  0.] 
cards in discard: [14. 10. 15. 10. 15.  0.  8.  2.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 23. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [ 0.  6.  0.  3. 10.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0.] 
cards in discard: [14. 10. 15. 10. 15.  0.  8.  2.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [ 0.  6.  0.  3. 10.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  0.] 
cards in discard: [14. 10. 15. 10. 15.  0.  8.  2.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 29. 22. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [ 0.  6.  0.  3. 10.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [3. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.66196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [ 0.  6.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 2.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0  3] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -2.6053218841552734
desired expected reward: 49.17707824707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.04506 ]
 [70.80257 ]
 [54.0162  ]
 [74.269745]
 [79.53222 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [ 0.  6.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 28. 29. 22. 30.  8.  6. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 2.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0  3] -> size -> 19 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.1795125007629395
desired expected reward: 75.10041046142578



buy possibilites: [-1] 
expected returns: [[80.42422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [ 0.  6.  0.  3. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 2.  0. 14.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0  3] -> size -> 19 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -347.0 

action type: buy - action 6.0
Learning step: -18.24126625061035
desired expected reward: 35.77494812011719






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 2.  0. 14.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  0. 14.  8.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  0 10  1  8 15  0  8  8  3 14  2 10  0 14 11 14  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6  6] -> size -> 16 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6  6] -> size -> 16 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [6. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6  6] -> size -> 16 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [6. 8. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[59.64441 ]
 [51.978916]
 [51.978916]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 6. 0.] 
cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  8  3  3 10  0  0  0  3  6  0  6  0  6  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [15.  3.  3.  8.  8.] 
adversary cards in discard: [ 8. 14.] 
adversary owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -5.184442043304443
desired expected reward: 75.23977661132812



action possibilites: [-1] 
expected returns: [[50.720573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [15.  3.  3.  8.  8.] 
adversary cards in discard: [ 8. 14.] 
adversary owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 11
Learning step: -1.6044567823410034
desired expected reward: 48.30893325805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.997498]
 [12.727448]
 [50.44967 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 29. 22. 30.  8.  5. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [15.  3.  3.  8.  8.] 
adversary cards in discard: [ 8. 14.] 
adversary owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -1.9937870502471924
desired expected reward: 48.72678756713867



buy possibilites: [-1] 
expected returns: [[62.286354]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  0.  3. 10.  6.  3.  3.  0.  6.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [15.  3.  3.  8.  8.] 
adversary cards in discard: [ 8. 14.] 
adversary owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -316.0 

action type: buy - action 6.0
Learning step: -15.034929275512695
desired expected reward: -2.307493209838867






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  8.  8.] 
cards in discard: [ 8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 10  8 15  0  8  8  3 14 10  0 14 11 14  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [ 8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 8. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 8. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[50.888298]
 [42.160217]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [ 8. 14.  0.  8.  3.  8.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -3.3796088695526123
desired expected reward: 58.90674591064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.442726]
 [25.97468 ]
 [51.161873]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  3. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [ 8. 14.  0.  8.  3.  8.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -2.8963429927825928
desired expected reward: 47.145904541015625



buy possibilites: [-1] 
expected returns: [[60.448868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  3. 10.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 14. 14.] 
adversary cards in discard: [ 8. 14.  0.  8.  3.  8.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -56.0 

action type: buy - action 0.0
Learning step: -3.4620368480682373
desired expected reward: 36.98069381713867






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 14. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14. 14.] 
cards in discard: [ 8. 14.  0.  8.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3. 10.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 8. 14.  0.  8.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3. 10.  0.  0.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 8. 14.  0.  8.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  6. 10.  8.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3. 10.  0.  0.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 8. 14.  0.  8.  3.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6.  3. 10.  0.  0.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[69.03911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [ 0.  3.  0.  6.  3. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14. 10. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: discard_down_to_3_cards - action 1
Learning step: -1.7070995569229126
desired expected reward: 37.54046630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.978256]
 [35.220955]
 [67.646126]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [ 0.  3.  0.  6.  3. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14. 10. 11. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10] -> size -> 16 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -3.5491225719451904
desired expected reward: 65.57437896728516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [14. 10. 11. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11. 10. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 11. 10. 15.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 15.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 15.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10. 15.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[49.396572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0. 14. 10. 11. 10. 15.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0] -> size -> 17 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: discard_down_to_3_cards - action 1
Learning step: 0.2589041292667389
desired expected reward: -9.315969467163086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.01037 ]
 [37.34849 ]
 [22.14394 ]
 [39.125248]
 [44.050407]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 0. 14. 10. 11. 10. 15.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0] -> size -> 17 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -2.8837828636169434
desired expected reward: 45.12334442138672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [ 0. 14. 10. 11. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [6. 8. 0. 0. 6.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [ 0. 14. 10. 11. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  4. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [6. 8. 0. 0. 6.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [ 0. 14. 10. 11. 10. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  3. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [6. 8. 0. 0. 6.] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[41.565742]
 [35.039536]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [6. 8. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  3. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 10.] 
adversary cards in discard: [ 0. 14. 10. 11. 10. 15.  8.  0.  8.  8.  3.  0.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1.0
Learning step: -2.6472318172454834
desired expected reward: 41.403167724609375



action possibilites: [-1.] 
expected returns: [[70.41834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [6. 8. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  3. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 10.] 
adversary cards in discard: [ 0. 14. 10. 11. 10. 15.  8.  0.  8.  8.  3.  0.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: -0.35400134325027466
desired expected reward: 33.41427993774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.565395]
 [62.27693 ]
 [56.086582]
 [29.697538]
 [57.04422 ]
 [64.87965 ]
 [59.612198]
 [59.706413]
 [38.004234]
 [54.455357]
 [48.685013]
 [65.576805]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [6. 8. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  3. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 10.] 
adversary cards in discard: [ 0. 14. 10. 11. 10. 15.  8.  0.  8.  8.  3.  0.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: -2.5817673206329346
desired expected reward: 67.83657836914062



buy possibilites: [-1] 
expected returns: [[39.12983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [6. 8. 0. 0. 6. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  0. 10.] 
adversary cards in discard: [ 0. 14. 10. 11. 10. 15.  8.  0.  8.  8.  3.  0.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -4.0 

action type: buy - action 8.0
Learning step: -1.9230998754501343
desired expected reward: 50.14732360839844






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0. 10.] 
cards in discard: [ 0. 14. 10. 11. 10. 15.  8.  0.  8.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  0. 10.] 
cards in discard: [ 0. 14. 10. 11. 10. 15.  8.  0.  8.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8. 6. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0  8] -> size -> 16 
adversary victory points: -1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 6. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[41.542812]
 [33.82814 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 10  0  0  0  3  0  6  0  6  6  6  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -2.399576187133789
desired expected reward: 36.730255126953125



action possibilites: [-1] 
expected returns: [[62.003845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.1659088134765625
desired expected reward: 33.05399703979492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.90474]
 [34.36227]
 [60.16236]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  4. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -2.8497798442840576
desired expected reward: 59.1540641784668



buy possibilites: [-1] 
expected returns: [[28.769293]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -328 

action type: buy - action 6.0
Learning step: -17.470806121826172
desired expected reward: 16.891464233398438






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [6. 8. 6. 3. 3.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.] 
adversary cards in discard: [6. 8. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  9.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.] 
adversary cards in discard: [6. 8. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  8.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  0.] 
adversary cards in discard: [6. 8. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [ 6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[46.32248 ]
 [34.460964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.] 
cards in discard: [6. 8. 6. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: discard_down_to_3_cards - action 1
Learning step: -1.5298935174942017
desired expected reward: -0.48724305629730225





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.57328 ]
 [-6.014348]
 [45.729164]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [6. 8. 6. 3. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -4.094574928283691
desired expected reward: 41.50501251220703



buy possibilites: [-1] 
expected returns: [[53.26373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.] 
cards in discard: [6. 8. 6. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -78.0 

action type: buy - action 0.0
Learning step: -4.330230236053467
desired expected reward: 28.243053436279297






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [29. 14.  0. 10.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6  0] -> size -> 17 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [29. 14.  0. 10.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  2. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6  0] -> size -> 17 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [29. 14.  0. 10.  0.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.] 
adversary owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6  0] -> size -> 17 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[47.491913]
 [39.11141 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  0  0  3  0  6  0  6  6  6  0  8  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  8. 15. 10. 11.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29  8] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -4.102658748626709
desired expected reward: 49.16107177734375



action possibilites: [-1] 
expected returns: [[47.22131]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  8. 15. 10. 11.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29  8] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: trash_cards_n_from_hand - action 6
Learning step: -0.996117115020752
desired expected reward: 23.17581558227539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.807518]
 [26.12425 ]
 [49.2034  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  8. 15. 10. 11.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29  8] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1
Learning step: -2.339580535888672
desired expected reward: 44.88172912597656



buy possibilites: [-1] 
expected returns: [[38.571438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  8.  6.  3.  3.  0.  0.  0.  6. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  8. 15. 10. 11.] 
adversary cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
adversary owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29  8] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action 0.0
Learning step: -3.372518539428711
desired expected reward: 34.43500518798828






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [14.  8. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15. 10. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 15. 10. 11.] 
cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 15  0  8  8 14 10  0 14 11 14  0  3  0 10  0  8 29  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [29. 14.  0. 10.  0.  8.  8.  0.  0.  3.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 6. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [ 6. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[46.78717 ]
 [38.635864]
 [42.363914]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  0.  8.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -2.790285110473633
desired expected reward: 35.781150817871094



action possibilites: [-1.  8.] 
expected returns: [[46.313065]
 [41.370872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  0.  8.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -16 

action type: take_action - action 10.0
Learning step: -1.6574369668960571
desired expected reward: 35.3189811706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.08175 ]
 [39.176003]
 [25.47529 ]
 [39.947533]
 [44.96231 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 29. 22. 30.  8.  3. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  0.  8.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -2.310499906539917
desired expected reward: 44.00254821777344



buy possibilites: [-1] 
expected returns: [[1.0106437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 28. 29. 22. 30.  8.  2. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14.  0.  8.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -328.0 

action type: buy - action 6.0
Learning step: -17.651023864746094
desired expected reward: 7.824256896972656






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [14.  0.  8.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  8. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  2. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [ 6. 10.  6.  8.  3.  0.  0.] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6] -> size -> 16 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  8. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 29. 22. 30.  8.  2. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 3. 6.] 
adversary cards in discard: [ 6. 10.  6.  8.  3.  0.  0.] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6] -> size -> 16 
adversary victory points: -3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.9498653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 6. 10.  6.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  2. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [14.  0.  8.  8. 14.] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.2784738540649414
desired expected reward: -1.2678301334381104





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.0691485]
 [2.6002831]
 [8.658535 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 6. 10.  6.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 29. 22. 30.  8.  2. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [14.  0.  8.  8. 14.] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.660297393798828
desired expected reward: 4.986739158630371



buy possibilites: [-1] 
expected returns: [[-13.243925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 6. 10.  6.  8.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [14.  0.  8.  8. 14.] 
adversary owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -359.0 

action type: buy - action 6.0
Learning step: -18.37800407409668
desired expected reward: -15.777724266052246






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [14.  0.  8.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  8 14 10  0 14 14  0  3  0 10  0  8 29  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [14.  0.  8.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.] 
cards in discard: [14.  0.  8.  8. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
adversary victory points: -4
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[28.832289]
 [21.852552]
 [24.66804 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10. 14.  0.  0.  8.] 
adversary cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -1.7118362188339233
desired expected reward: -14.955760955810547



action possibilites: [-1.  8.] 
expected returns: [[44.61422 ]
 [39.746696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10. 14.  0.  0.  8.] 
adversary cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action 10.0
Learning step: -2.0973823070526123
desired expected reward: 19.928768157958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.63698 ]
 [44.546547]
 [41.93483 ]
 [32.24472 ]
 [47.009514]
 [42.83963 ]
 [41.362587]
 [48.724594]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 28. 29. 22. 30.  8.  1. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10. 14.  0.  0.  8.] 
adversary cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -39 

action type: take_action - action -1.0
Learning step: -3.2163760662078857
desired expected reward: 41.39783477783203



buy possibilites: [-1] 
expected returns: [[8.181787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10. 14.  0.  0.  8.] 
adversary cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -350.0 

action type: buy - action 6.0
Learning step: -18.928146362304688
desired expected reward: 13.316574096679688






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [10. 14.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  0.  8.] 
cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 3. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6  6] -> size -> 18 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  8.] 
cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 3. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6  6] -> size -> 18 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  0.  8.] 
cards in discard: [14.  0.  8.  8. 14.  8.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 3. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6  6] -> size -> 18 
adversary victory points: -5
player victory points: 1 





Player: 0 
cards in hand: [0. 8. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 1.7582769]
 [-3.6578617]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 6.] 
cards in discard: [ 6. 10.  0.  0.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  0  3  0  0  6  6  6  0  8  6  0  0  6  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1
Learning step: -3.937403917312622
desired expected reward: 4.244382858276367



action possibilites: [-1] 
expected returns: [[9.649908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6. 10.  0.  0.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.0081708431243896
desired expected reward: -4.502296447753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 3.9767027]
 [11.014911 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6. 10.  0.  0.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [29.  8.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.7068052291870117
desired expected reward: 7.943102836608887






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [29.  8.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  1. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [8. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 6. 6. 6.] 
adversary cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [6. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-4.071204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 6.] 
cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -2.92887282371521
desired expected reward: 8.086040496826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.81207  ]
 [  1.3648014]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 6.] 
cards in discard: [ 6. 10.  0.  0.  8.  0.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 3. 14.  8.  0.  0.] 
adversary cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.6247220039367676
desired expected reward: -1.6525919437408447



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8.  0.  0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  3.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  7.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.1967885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14. 14. 10.  0.  8.] 
adversary cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: discard_down_to_3_cards - action 2
Learning step: -1.6435946226119995
desired expected reward: -15.535435676574707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.09898  ]
 [ 1.8870919]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14. 14. 10.  0.  8.] 
adversary cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.525512218475342
desired expected reward: 0.22174668312072754



buy possibilites: [-1] 
expected returns: [[7.150777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [14. 14. 10.  0.  8.] 
adversary cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.] 
adversary owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action 0.0
Learning step: -3.6841583251953125
desired expected reward: -4.783138275146484






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [14. 14. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14. 10.  0.  8.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 10 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  0.] 
cards in discard: [ 8.  8. 10. 29.  0.  8.  0.  8. 11. 14.  3.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [6. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[8.070476 ]
 [7.1841154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 0.] 
cards in discard: [10.  0.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 8. 14.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.6126534938812256
desired expected reward: 4.53812313079834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.6094847]
 [9.497411 ]
 [9.254804 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6. 0.] 
cards in discard: [10.  0.  0.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 8. 14.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.538788318634033
desired expected reward: 4.2196221351623535



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8. 14.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  8.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.  8.  6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.145247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  8. 29.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.] 
adversary owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: discard_down_to_3_cards - action 5
Learning step: -1.5613932609558105
desired expected reward: -10.964044570922852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 7.083763]
 [ 9.637116]
 [15.322467]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  8. 29.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.] 
adversary owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.969228744506836
desired expected reward: 13.407402038574219



buy possibilites: [-1] 
expected returns: [[12.782523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  6.  6.  6.  8.  0.  6.  0.  8.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  8. 29.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.] 
adversary owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 20 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -78.0 

action type: buy - action 0.0
Learning step: -3.9665801525115967
desired expected reward: 3.1171562671661377






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8. 29.] 
cards in discard: [29. 14.  8.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 14 14  0  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.] 
cards in discard: [29. 14.  8.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.] 
cards in discard: [29. 14.  8.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [10.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [10.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-66.13099]
 [-85.79154]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
adversary owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -4.644984245300293
desired expected reward: 8.13753890991211



action possibilites: [-1.] 
expected returns: [[4.3678007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
adversary owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action 10.0
Learning step: 2.802504301071167
desired expected reward: -79.28207397460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-6.1259813]
 [-2.335739 ]
 [ 1.7231143]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
adversary owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1.0
Learning step: -1.6609951257705688
desired expected reward: 2.70680570602417



buy possibilites: [-1] 
expected returns: [[32.35081]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 14.  8.] 
adversary cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
adversary owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -58.0 

action type: buy - action 0.0
Learning step: -1.865808129310608
desired expected reward: -7.991781711578369






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 14.  8.] 
cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 14  3  0 10  0  8 29  8  0  0  8 11  0 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [29. 14.  8.  0.  8.  0.  8.  8. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 0. 0. 6. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  3.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [6. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.637688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -3.3186233043670654
desired expected reward: 29.032188415527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[22.771946]
 [27.244637]
 [24.905067]
 [29.54227 ]
 [24.64622 ]
 [32.214806]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -3.337531805038452
desired expected reward: 27.725452423095703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  3.  6.  0.  0.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0.  0.  3.  6.  0.  0.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[20.141073]
 [10.613941]
 [10.613941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  3.  6.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  8.] 
adversary cards in discard: [ 0.  0. 11.  8.  3.] 
adversary owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -3.5138566493988037
desired expected reward: 24.905973434448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 9.682381]
 [14.029772]
 [23.58827 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 8. 0.] 
cards in discard: [ 0. 10.  3.  6.  0.  0.  3.  6.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  8.] 
adversary cards in discard: [ 0.  0. 11.  8.  3.] 
adversary owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -3.002608299255371
desired expected reward: 16.457313537597656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  8.] 
cards in discard: [ 0.  0. 11.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  0. 11.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 0.  0. 11.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [0. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[  1.2955103]
 [-13.055248 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  8.] 
adversary cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -3.6491096019744873
desired expected reward: 19.939189910888672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-12.184674 ]
 [ -6.4641266]
 [  1.3395491]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  8.] 
adversary cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.6901564598083496
desired expected reward: 0.8008074760437012



buy possibilites: [-1] 
expected returns: [[-36.177475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  8.  8.] 
adversary cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -78.0 

action type: buy - action 0.0
Learning step: -4.104759216308594
desired expected reward: -16.289432525634766






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  8.] 
cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 10.  0.] 
adversary cards in discard: [0. 0. 8. 0. 3. 6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  5. 10.  8.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 8.] 
cards in discard: [ 0.  0. 11.  8.  3.  8.  0.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.0660305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[   -5     0    -3   -40     0     0     0   -90     0     0     0     0
     0 -1500    13     0] 
sum of rewards: -1625 

action type: discard_down_to_3_cards - action 3
Learning step: -80.74608612060547
desired expected reward: -90.50112915039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.1923847]
 [ 3.785437 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.4017739295959473
desired expected reward: -1.6833548545837402



buy possibilites: [-1] 
expected returns: [[5.80122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -78.0 

action type: buy - action 0.0
Learning step: -3.709853410720825
desired expected reward: -4.90223503112793






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  7.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
adversary victory points: -3
player victory points: 1 





Player: 0 
cards in hand: [6. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.1911774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  8. 10.] 
adversary cards in discard: [ 8. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.499058485031128
desired expected reward: 3.302161455154419





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[0.1385541]
 [3.8825254]
 [7.34717  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 29. 22. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  8. 10.] 
adversary cards in discard: [ 8. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.732076406478882
desired expected reward: 5.756919860839844



buy possibilites: [-1] 
expected returns: [[58.85898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [ 0.  0.  8.  0.  3.  6. 10.  0.  0.  6.  6.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 8. 11.  3.  8. 10.] 
adversary cards in discard: [ 8. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -29 

action type: buy - action 3.0
Learning step: -0.3198002576828003
desired expected reward: 3.562746524810791






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  8. 10.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1.  8. 11.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  8.  8.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  8.  8.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29] -> size -> 19 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 3. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  8.  8.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 





Player: 0 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-14.156193]
 [-23.896624]
 [-23.896624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0. 10.  8. 11.  3.  8.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -5.313797950744629
desired expected reward: 53.54518127441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-23.669436]
 [-20.63914 ]
 [-18.086092]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0. 10.  8. 11.  3.  8.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -1.4532746076583862
desired expected reward: -18.638553619384766



buy possibilites: [-1] 
expected returns: [[12.708907]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0. 10.  8. 11.  3.  8.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0] -> size -> 20 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -67.0 

action type: buy - action 0.0
Learning step: -1.8805782794952393
desired expected reward: -25.550006866455078






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0. 10.  8. 11.  3.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0] -> size -> 22 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0. 10.  8. 11.  3.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 28. 29. 21. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0] -> size -> 22 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [ 8. 29. 29. 29.  0.  0.  0.  0. 10.  8. 11.  3.  8.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 28. 29. 20. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0] -> size -> 22 
adversary victory points: -2
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-10.17858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [0. 8. 3. 0. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 29. 20. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -3.1816961765289307
desired expected reward: 9.52721118927002





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-17.780468]
 [-18.95055 ]
 [-16.30653 ]
 [-18.4944  ]
 [-17.146278]
 [-18.150646]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [0. 8. 3. 0. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 28. 29. 20. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -2.330204725265503
desired expected reward: -10.678377151489258



buy possibilites: [-1] 
expected returns: [[6.754039]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [0. 8. 3. 0. 0. 8. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 28. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -34.0 

action type: buy - action 3.0
Learning step: -0.7327083945274353
desired expected reward: -17.039222717285156






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 28. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.23922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0. 29.] 
adversary cards in discard: [8. 0. 8. 3. 8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -1.0430176258087158
desired expected reward: 5.711021423339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[37.37149 ]
 [42.255062]
 [40.47072 ]
 [45.193733]
 [39.65748 ]
 [46.943176]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 28. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0. 29.] 
adversary cards in discard: [8. 0. 8. 3. 8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -3.278120756149292
desired expected reward: 45.374515533447266



buy possibilites: [-1] 
expected returns: [[-3.1801727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [14.  0.  0.  0. 29.] 
adversary cards in discard: [8. 0. 8. 3. 8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -18 

action type: buy - action 1.0
Learning step: -3.0843074321746826
desired expected reward: 39.17076110839844






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 29.] 
cards in discard: [8. 0. 8. 3. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  6.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0. 1. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8.  0.  8.  3.  8. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  6.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0. 1. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8.  0.  8.  3.  8. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 10.  6.  0.  6.] 
adversary cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0. 1. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 10.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.810686]
 [13.302711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  6.] 
cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0. 1. 0. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  3.  8. 14.  0. 29.  0.  0.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -1.2619612216949463
desired expected reward: -4.442133903503418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[12.868121]
 [15.412103]
 [17.19149 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  6.] 
cards in discard: [0. 8. 3. 0. 0. 8. 3. 0. 0. 6. 6. 0. 1. 0. 0. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  3.  8. 14.  0. 29.  0.  0.  8.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -2.445429563522339
desired expected reward: 17.365243911743164



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 11.] 
cards in discard: [ 8.  0.  8.  3.  8. 14.  0. 29.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 27. 29. 19. 30.  8.  0. 10.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 8.  0.  8.  3.  8. 14.  0. 29.  0.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 27. 29. 19. 30.  8.  0.  9.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [ 8.  0.  8.  3.  8. 14.  0. 29.  0.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 27. 29. 19. 30.  8.  0.  9.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
adversary victory points: -1
player victory points: 2 


Player 1 won the game! 



Player 0 bought cards:
Copper: 18 
Silver: 1 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 1 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 10  3  0  0  6  0  8  6  0  0  6  6  6  0  0  0  0  0  3  0  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 29. 19. 30.  8.  0.  9.  6.  0. 10.  6.  6. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0.] 
adversary cards in discard: [ 8.  0.  8.  3.  8. 14.  0. 29.  0.  0.  8. 16.  0.] 
adversary owned cards: [ 8  8  8 14  3  0  0  8 29  8  0  0  8 11  0 29  0 10 29  0  3 16  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -30    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -536 

action type: buy - action -1.0
Learning step: -27.659574508666992
desired expected reward: -10.468088150024414



