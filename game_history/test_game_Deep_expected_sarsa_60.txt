 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[78.63088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -360        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000365 

action type: buy - action -1
Learning step: -120011.0078125
desired expected reward: -120100.84375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 63.203884]
 [ 86.22632 ]
 [ 72.66561 ]
 [ 34.844215]
 [ 78.83699 ]
 [ 89.2446  ]
 [ 79.591   ]
 [100.36905 ]
 [ 49.2125  ]
 [ 66.03826 ]
 [ 70.579124]
 [ 77.86316 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.1061782836914



buy possibilites: [-1] 
expected returns: [[80.45532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.36905670166016






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[90.13686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.455322265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 76.4451  ]
 [ 97.89518 ]
 [ 85.36879 ]
 [ 47.231167]
 [100.69065 ]
 [ 91.76696 ]
 [ 79.24056 ]
 [ 90.20205 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.64527893066406



buy possibilites: [-1] 
expected returns: [[72.45431]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 100.69065856933594






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[53.414165]
 [63.909634]
 [73.83702 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.45430755615234



action possibilites: [-1. 11.] 
expected returns: [[63.026012]
 [74.00638 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 74.08563232421875



action possibilites: [-1] 
expected returns: [[66.35869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.29368591308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[50.956207]
 [72.99075 ]
 [60.120564]
 [25.020653]
 [65.97571 ]
 [75.85769 ]
 [66.69344 ]
 [86.03122 ]
 [36.877483]
 [53.82326 ]
 [58.142635]
 [65.065094]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.35868835449219



buy possibilites: [-1] 
expected returns: [[70.15993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.03121948242188






Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[49.709934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.15992736816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[41.89209 ]
 [60.937237]
 [49.279903]
 [17.436016]
 [54.35134 ]
 [63.636242]
 [55.01075 ]
 [73.37898 ]
 [29.92982 ]
 [44.206375]
 [47.690414]
 [53.50694 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.24100875854492



buy possibilites: [-1] 
expected returns: [[75.85515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [25.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.37898254394531






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [25.  1.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [25.  1.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [25.  1.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.76629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.85514831542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[66.69699 ]
 [87.3712  ]
 [75.29998 ]
 [38.00749 ]
 [80.780624]
 [90.06603 ]
 [81.46304 ]
 [99.60322 ]
 [52.77518 ]
 [69.391815]
 [73.449554]
 [79.97886 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.40132904052734



buy possibilites: [-1] 
expected returns: [[80.718216]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 99.60321807861328






Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[139.44548]
 [162.04976]
 [162.04976]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.71821594238281



action possibilites: [-1. 29. 29.] 
expected returns: [[126.57878]
 [145.06746]
 [145.06746]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 161.71533203125



action possibilites: [-1. 29.] 
expected returns: [[150.3339 ]
 [169.10452]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  3.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 145.0674591064453



action possibilites: [-1. 11.] 
expected returns: [[214.70805]
 [224.68456]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 11.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 169.10450744628906



action possibilites: [-1] 
expected returns: [[222.77495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 236.5951690673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[215.48427]
 [232.82658]
 [222.70236]
 [202.02359]
 [192.2711 ]
 [227.30344]
 [235.09413]
 [227.8754 ]
 [260.47223]
 [243.40025]
 [204.20714]
 [220.5867 ]
 [217.75142]
 [203.65807]
 [221.15863]
 [226.64438]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  9.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 222.7749481201172



buy possibilites: [-1] 
expected returns: [[209.93242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  0.  3. 10. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  8.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [15.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 260.47222900390625






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [15.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  8.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [15.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10.  8.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [15.  0.  0.  1.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9.  8.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 10.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[76.6587 ]
 [85.57046]
 [68.77902]
 [68.77902]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9.  8.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 209.9324188232422



action possibilites: [-1] 
expected returns: [[84.62983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.1917724609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.63346 ]
 [48.336956]
 [86.585144]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.62982940673828






Player: 1 
cards in hand: [ 1. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29.  0.] 
adversary cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[111.89061]
 [130.32872]
 [130.32872]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  0.] 
cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  8.] 
adversary cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -365 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.58514404296875



action possibilites: [-1. 29.] 
expected returns: [[150.60751]
 [169.59486]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  8.] 
adversary cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 127.97897338867188



action possibilites: [-1. 25.] 
expected returns: [[196.2823 ]
 [235.26114]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 25.] 
cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9.  9.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  8.] 
adversary cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 169.59486389160156



action possibilites: [-1] 
expected returns: [[184.77461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0.  3. 29.] 
cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  8.] 
adversary cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 235.2611541748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[175.99051]
 [196.72437]
 [164.11667]
 [184.4558 ]
 [159.78735]
 [148.52837]
 [189.85077]
 [199.55226]
 [190.53261]
 [226.98929]
 [209.56548]
 [162.35873]
 [181.97255]
 [178.64699]
 [161.71141]
 [182.64265]
 [189.07483]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0.  3. 29.] 
cards in discard: [10. 11. 10.  3. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  8.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  8.] 
adversary cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 184.7746124267578



buy possibilites: [-1] 
expected returns: [[227.08871]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0.  3. 29.] 
cards in discard: [10. 11. 10.  3. 10.  0.  6. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  3.  3.  0.  8.] 
adversary cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 57.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 226.9893035888672






Player: 1 
cards in hand: [15.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.  8.] 
cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3 15  8 16  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [16. 25.  1.  0.  0.  0.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 86.10025]
 [103.02318]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 227.08871459960938



action possibilites: [-1.] 
expected returns: [[113.70827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.37200927734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[106.997765]
 [122.21472 ]
 [113.34013 ]
 [ 85.90491 ]
 [117.35054 ]
 [124.21213 ]
 [117.86976 ]
 [131.22124 ]
 [ 96.77689 ]
 [108.99516 ]
 [111.99386 ]
 [116.87201 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.70826721191406



buy possibilites: [-1] 
expected returns: [[135.76443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 131.22125244140625






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  3. 29.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  3. 29.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 10.  0.  3. 29.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25. 10.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[167.84294]
 [200.87068]
 [158.10245]
 [185.69957]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0.  3. 29.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  8.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 25.  1.] 
adversary cards in discard: [3. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.76443481445312



action possibilites: [-1] 
expected returns: [[149.09604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29.  0. 10.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 25.  1.] 
adversary cards in discard: [3. 0. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 197.0574188232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[139.96451 ]
 [146.37381 ]
 [119.566284]
 [150.96964 ]
 [149.85995 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0. 10.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  9.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 25.  1.] 
adversary cards in discard: [3. 0. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.09603881835938



buy possibilites: [-1] 
expected returns: [[159.7195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0. 10.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  8.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 25.  1.] 
adversary cards in discard: [3. 0. 0. 3. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 150.96963500976562






Player: 1 
cards in hand: [ 6.  3.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 25.  1.] 
cards in discard: [3. 0. 0. 3. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  8.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 11.  3. 29. 29.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  6.  8. 25. 10.  0.  3. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 25.  1.] 
cards in discard: [3. 0. 0. 3. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  8.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 11.  3. 29. 29.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  6.  8. 25. 10.  0.  3. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8] -> size -> 23 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25. 11.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 29.] 
expected returns: [[104.766396]
 [137.94183 ]
 [112.88692 ]
 [121.27355 ]
 [121.27355 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  3. 29. 29.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.  8. 25. 10.  0.  3. 29.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  7.  9.  9.  8.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.71949768066406



action possibilites: [-1] 
expected returns: [[66.48103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29. 29.  0.  0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.  8. 25. 10.  0.  3. 29.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  8.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.6935272216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.245316]
 [63.41444 ]
 [33.132896]
 [68.724945]
 [67.38352 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29. 29.  0.  0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.  8. 25. 10.  0.  3. 29.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  8.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.48103332519531



buy possibilites: [-1] 
expected returns: [[66.43086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29. 29.  0.  0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  6.  8. 25. 10.  0.  3. 29.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  7.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 16.] 
adversary cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 68.72492980957031






Player: 1 
cards in hand: [ 0.  0.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  8. 16.] 
cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  7.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  3. 29. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  8. 16.] 
cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  7.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  3. 29. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  8. 16.] 
cards in discard: [ 3.  0.  0.  3.  0.  3.  6.  6.  3.  0. 25.  1.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  3. 29. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [25.  3. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 10.] 
expected returns: [[67.77326 ]
 [95.9831  ]
 [82.99267 ]
 [95.9831  ]
 [60.293118]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29. 25. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  6.  9.  9.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.43086242675781



action possibilites: [-1] 
expected returns: [[101.900764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.11747741699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 94.712036]
 [ 74.50528 ]
 [104.3312  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 25. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.90076446533203






Player: 1 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0. 29.] 
adversary cards in discard: [25.  3. 29. 25. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  9.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0. 29.] 
adversary cards in discard: [25.  3. 29. 25. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [ 6. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  8.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  6.  0. 29.] 
adversary cards in discard: [25.  3. 29. 25. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29.  3.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[126.63374]
 [142.53757]
 [142.53757]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  0. 29.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  8.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 104.33120727539062



action possibilites: [-1. 29. 11.] 
expected returns: [[106.69911]
 [120.83943]
 [113.9509 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 29. 11.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  8.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 140.22486877441406



action possibilites: [-1. 11. 10.] 
expected returns: [[134.68196]
 [143.63469]
 [125.13875]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 11. 10.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  8.  6.  7.  5. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 120.83943176269531



action possibilites: [-1] 
expected returns: [[129.15044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 10.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  8.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 154.49037170410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[117.67173 ]
 [135.93634 ]
 [125.14606 ]
 [ 93.72429 ]
 [138.36235 ]
 [130.65672 ]
 [119.984055]
 [129.40965 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 10.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  8.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.1504364013672



buy possibilites: [-1] 
expected returns: [[105.58822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 10.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  3.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.36236572265625






Player: 1 
cards in hand: [ 3.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 16.  3.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10 11] -> size -> 26 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[121.270805]
 [136.97401 ]
 [122.358444]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  0.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.58821868896484



action possibilites: [-1.  8.] 
expected returns: [[80.239105]
 [81.3055  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 136.97401428222656



action possibilites: [-1] 
expected returns: [[53.590755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 86.3638916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[44.97912 ]
 [56.732838]
 [49.75048 ]
 [29.67872 ]
 [58.298916]
 [53.321827]
 [46.464523]
 [52.475697]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  7.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.590755462646484



buy possibilites: [-1] 
expected returns: [[42.082043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25.  3. 29. 25. 10. 29.  0. 10. 11. 29. 29. 11.  3.  6.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 6.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 58.29890823364258






Player: 1 
cards in hand: [3. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 6.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11
 11] -> size -> 25 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 6.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11
 11] -> size -> 25 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 6.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11
 11] -> size -> 25 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29. 10.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[59.145412]
 [73.394226]
 [51.490013]
 [60.13728 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 6. 6. 0.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.0820426940918



action possibilites: [-1. 10.  8.  8.] 
expected returns: [[76.98236]
 [69.90665]
 [77.88741]
 [77.88741]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8  8 10 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 6. 6. 0.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.9733657836914



action possibilites: [-1] 
expected returns: [[15.967985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 6. 6. 0.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 91.14874267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.957796]
 [-6.515235]
 [19.16021 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 6. 6. 0.] 
adversary cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.967985153198242






Player: 1 
cards in hand: [1. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 6. 0.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6. 11. 29. 29.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 6. 0.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  6.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6. 11. 29. 29.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 6. 0.] 
cards in discard: [ 6. 11.  0. 25.  0.  0.  0.  0.  3.  0.  0. 16.  3.  0.  3.  3.  0.  8.
  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6. 11. 29. 29.] 
adversary cards in discard: [29.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  6. 11. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 29.] 
expected returns: [[63.69173 ]
 [70.918594]
 [70.918594]
 [77.81517 ]
 [77.81517 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11. 29. 29.] 
cards in discard: [29.  8. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.16023063659668



action possibilites: [-1. 11. 11. 29. 11.] 
expected returns: [[80.271454]
 [87.43328 ]
 [87.43328 ]
 [94.26944 ]
 [87.43328 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11. 29. 11.] 
cards in discard: [29.  8. 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.37911987304688



action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[108.24138]
 [115.83126]
 [115.83126]
 [115.83126]
 [100.52104]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11. 11. 10.] 
cards in discard: [29.  8. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  6.  7.  5. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 94.26942443847656



action possibilites: [-1] 
expected returns: [[109.23944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 11. 10.] 
cards in discard: [29.  8. 10.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  6.  7.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 125.8431396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[100.30607 ]
 [106.55132 ]
 [ 79.541664]
 [111.0132  ]
 [110.03425 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 11. 10.] 
cards in discard: [29.  8. 10.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  6.  7.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 109.23944091796875



buy possibilites: [-1] 
expected returns: [[117.3436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 11. 10.] 
cards in discard: [29.  8. 10.  3. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  5.  7.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 101 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 111.01318359375






Player: 1 
cards in hand: [11.  1.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  5.  9.  5.  5.  7.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  5.  5.  7.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  5.  5.  7.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8.] 
cards in discard: [ 6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  5.  5.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 25. 25.] 
adversary cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[53.659622]
 [46.64622 ]
 [77.452354]
 [77.452354]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 25. 25.] 
cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  4.  9.  5.  5.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  6. 25.  0.  3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.34359741210938



action possibilites: [-1] 
expected returns: [[36.240177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 25. 29.  0.] 
cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  5.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  6. 25.  0.  3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.4523696899414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.900183]
 [34.60259 ]
 [18.686092]
 [37.24482 ]
 [36.64922 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 25. 29.  0.] 
cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  5.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  6. 25.  0.  3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.240177154541016



buy possibilites: [-1] 
expected returns: [[56.70731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 25. 29.  0.] 
cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  6. 25.  0.  3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.24481964111328






Player: 1 
cards in hand: [11.  6. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 25.  0.  3.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.  8. 25.  0.  3. 10.
 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 25.  0.  3.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.  8. 25.  0.  3. 10.
 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8] -> size -> 26 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[50.82383 ]
 [59.925503]
 [46.001377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  0.] 
cards in discard: [29.  8. 10.  3. 10.  8. 29. 29. 11.  6. 11. 11. 10.  8. 25.  0.  3. 10.
 25. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16.  0.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.70730972290039



action possibilites: [-1. 10. 29.] 
expected returns: [[19.714365]
 [13.623217]
 [30.824827]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16.  0.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.92551040649414



action possibilites: [-1. 10. 11.] 
expected returns: [[33.2972  ]
 [26.980448]
 [39.16409 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16.  0.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.824811935424805



action possibilites: [-1] 
expected returns: [[22.317614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16.  0.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 46.33950424194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.42716   ]
 [28.639563  ]
 [21.302534  ]
 [ 0.91787815]
 [24.411713  ]
 [30.404467  ]
 [24.831915  ]
 [36.594273  ]
 [ 8.818016  ]
 [17.965967  ]
 [20.272995  ]
 [24.031578  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16.  0.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.31761360168457



buy possibilites: [-1] 
expected returns: [[88.72463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 16.  0.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 273 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.5942497253418






Player: 1 
cards in hand: [ 6.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16.  0.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11
  0  0 11  6 14  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  3.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 25. 25. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  3.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 25. 25. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  3.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 25. 25. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10. 10. 25. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 25. 10.] 
expected returns: [[64.6477 ]
 [57.05179]
 [57.05179]
 [90.7095 ]
 [90.7095 ]
 [57.05179]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25. 25. 10.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  3.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.7246322631836



action possibilites: [-1] 
expected returns: [[75.76312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25. 10. 29.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.70951080322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.48536 ]
 [50.738613]
 [76.166626]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 25. 10. 29.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.76312255859375






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29.  3.  8.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29.  3.  8.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29.  3.  8.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11.  8. 29.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.  8.] 
expected returns: [[ 89.93986]
 [ 97.28396]
 [ 90.93905]
 [104.30445]
 [ 90.93905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29.  3.  8.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.1666259765625



action possibilites: [-1. 11.  8.  8.] 
expected returns: [[72.39911 ]
 [79.404236]
 [73.350044]
 [73.350044]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  8.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.30447387695312



action possibilites: [-1] 
expected returns: [[67.00717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.35594177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[57.53529 ]
 [64.14068 ]
 [35.828686]
 [68.8641  ]
 [67.807724]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  4.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.00717163085938



buy possibilites: [-1] 
expected returns: [[64.66018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 6.] 
adversary cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 111 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 68.86412048339844






Player: 1 
cards in hand: [0. 8. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 6.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11. 10. 29.  6.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 6.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11. 10. 29.  6.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 6.] 
cards in discard: [ 6. 14. 11.  1.  0.  0.  8.  6. 11.  6. 25.  0.  3.  3. 16.  6.  0.  0.
  6.  3.  0.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11. 10. 29.  6.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8] -> size -> 30 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 29.] 
expected returns: [[29.144316]
 [29.920248]
 [34.724277]
 [23.194899]
 [39.87915 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 29.  6.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.6601791381836



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[37.35526 ]
 [38.035236]
 [42.91116 ]
 [31.742735]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  6.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.879154205322266



action possibilites: [-1] 
expected returns: [[29.68231]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.13346481323242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.90838  ]
 [ 3.0811734]
 [29.36413  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3. 10.  0. 25. 10. 10. 25. 10. 29.  0. 10.  8.
 29. 11.  8.  3.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.682310104370117






Player: 1 
cards in hand: [ 8.  3. 25.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  3.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [29. 25.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 25.  3.  6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [29. 25.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 25.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8. 10. 10.] 
expected returns: [[ -5.937064 ]
 [  4.3811593]
 [ 13.172165 ]
 [ -5.212387 ]
 [-11.605327 ]
 [-11.605327 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  6.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.364118576049805



action possibilites: [-1] 
expected returns: [[18.272423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  6.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.172163009643555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.819723]
 [-5.019685]
 [18.819342]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 10. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  6.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.272422790527344






Player: 1 
cards in hand: [ 0.  6. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  6.] 
cards in discard: [ 8.  3. 25.  3.  6.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  4.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 10. 29.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  8. 10. 29.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  8. 10. 29.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  8. 10. 29.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  8. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 29.] 
expected returns: [[69.89679 ]
 [84.03293 ]
 [70.872696]
 [62.481068]
 [84.03293 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 10. 29.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.8193302154541



action possibilites: [-1.  8. 10. 29. 10.] 
expected returns: [[71.93404]
 [72.8897 ]
 [64.55897]
 [85.98299]
 [64.55897]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 29. 10.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.032958984375



action possibilites: [-1.  8. 10. 10. 25.] 
expected returns: [[67.92732 ]
 [68.85409 ]
 [60.845493]
 [60.845493]
 [93.467766]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 25.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8] -> size -> 36 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.98298645019531



action possibilites: [-1] 
expected returns: [[65.13757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 10.  3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  5.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.4677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[57.5793  ]
 [70.14339 ]
 [62.806225]
 [71.82183 ]
 [66.55638 ]
 [59.21922 ]
 [65.720985]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 10. 10.  3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  5.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.1375732421875



buy possibilites: [-1] 
expected returns: [[78.82154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 10. 10.  3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 71.82182312011719






Player: 1 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  8. 10.  0. 11.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11] -> size -> 32 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 6.  8. 10.  0. 11.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11] -> size -> 32 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[50.43793 ]
 [51.353916]
 [43.33727 ]
 [57.08192 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  0. 11.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.82154083251953



action possibilites: [-1] 
expected returns: [[60.254665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  0.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.1048812866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.190533]
 [60.643856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  0.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 8.  3.  0. 11.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.25466537475586






Player: 1 
cards in hand: [ 8.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 29. 29.  0.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.  3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [10.  3. 29. 29.  0.] 
adversary cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  3. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[38.210804]
 [31.650122]
 [50.345493]
 [50.345493]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 29.  0.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.643856048583984



action possibilites: [-1. 29. 11.] 
expected returns: [[32.93473]
 [41.674  ]
 [37.41077]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.76357650756836



action possibilites: [-1. 11.] 
expected returns: [[27.368074]
 [32.287945]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.19660568237305



action possibilites: [-1] 
expected returns: [[34.523518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0. 10.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.21144104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[27.520456]
 [38.28091 ]
 [31.81362 ]
 [39.756577]
 [35.077503]
 [28.874693]
 [34.321335]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0. 10.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  4.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.52351760864258



buy possibilites: [-1] 
expected returns: [[22.760813]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25. 29.  8. 10. 10. 11.  0. 11. 29. 29. 25.  0.  8. 10. 10. 10.  3. 15.
 11.  6.  8. 10.  0. 10.  3. 15. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 6.  0.  0. 16.  3.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.756595611572266






Player: 1 
cards in hand: [ 6.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16.  3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  6  0  3  6  6  8  6 11  0
  0 11  6 14  6  3  6  3  0  6 15  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 3.  8. 10.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 29.] 
expected returns: [[20.716078]
 [21.418394]
 [15.037359]
 [21.418394]
 [31.970896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [14.  3.  6.  6.  0.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.760812759399414



action possibilites: [-1. 10.  8. 29.] 
expected returns: [[36.577705]
 [31.357767]
 [37.240246]
 [47.033695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 29.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [14.  3.  6.  6.  0.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.683820724487305



action possibilites: [-1. 10.] 
expected returns: [[40.539608]
 [34.399647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [8. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [14.  3.  6.  6.  0.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.42704391479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[32.343113]
 [44.149845]
 [37.26786 ]
 [45.705814]
 [40.781082]
 [33.899086]
 [40.039055]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [8. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  3.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [14.  3.  6.  6.  0.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.53960037231445



buy possibilites: [-1] 
expected returns: [[46.21081]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 8.  8. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [14.  3.  6.  6.  0.] 
adversary cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.705814361572266






Player: 1 
cards in hand: [14.  3.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  6.  0.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  6.  0.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  6.  0.] 
cards in discard: [ 8.  3. 25.  3.  6.  6. 15.  8. 11.  0.  6.  0.  6.  6.  0.  0.  6.  0.
  3.  8.  3.  0. 11.  3.  3. 16.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [29. 10. 10. 11. 11.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11] -> size -> 36 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11. 11.] 
expected returns: [[85.77256 ]
 [96.31984 ]
 [80.13639 ]
 [80.13639 ]
 [91.160324]
 [91.160324]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 11. 11.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.210811614990234



action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[77.50729]
 [72.42208]
 [72.42208]
 [82.1538 ]
 [82.1538 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [ 3. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 89.68576049804688



action possibilites: [-1] 
expected returns: [[97.876144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.44538879394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[91.22205]
 [98.20567]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0] -> size -> 38 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.87614440917969






Player: 1 
cards in hand: [ 3. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 29. 25. 29. 15.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 29. 25. 29. 15.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 29. 25. 29. 15.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [ 3. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 29. 25. 29. 15.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 15.] 
expected returns: [[32.156097]
 [45.672466]
 [58.843662]
 [45.672466]
 [27.820086]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29. 15.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0.  6.  6. 16.  6.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.2056655883789



action possibilites: [-1] 
expected returns: [[43.44599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 15. 10. 11.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0.  6.  6. 16.  6.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.84364700317383





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.37654 ]
 [42.681103]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 15. 10. 11.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0.  6.  6. 16.  6.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29] -> size -> 40 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.44599151611328






Player: 1 
cards in hand: [ 0.  6.  6. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 16.  6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 6. 11. 10.  0. 10.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 16.  6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 6. 11. 10.  0. 10.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 16.  6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 6. 11. 10.  0. 10.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6. 11. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[63.462048]
 [69.55257 ]
 [56.949314]
 [56.949314]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.  0. 10.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 0. 25.  6.  8.  3.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 41 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.68110656738281



action possibilites: [-1] 
expected returns: [[89.846214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 10.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 25.  6.  8.  3.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 41 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.90289306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[79.749756]
 [89.11898 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 10.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 25.  6.  8.  3.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 41 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.8462142944336






Player: 1 
cards in hand: [ 0. 25.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6.  8.  3.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0
 11  6 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 10.  8.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 10.  8.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 10.  8.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 8. 15. 25. 10.  8.] 
adversary cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 25. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 25. 10.  8.] 
expected returns: [[17.907621]
 [18.372412]
 [15.360918]
 [33.609364]
 [13.794651]
 [18.372412]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 25. 10.  8.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.11898803710938



action possibilites: [-1] 
expected returns: [[15.0114975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.  8. 10. 29.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.6093864440918





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.202759]
 [15.011496]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 10.  8. 10. 29.] 
cards in discard: [ 8.  8. 11. 29. 29.  3. 10.  0.  3. 15. 29. 11. 10. 10. 11. 25.  0. 29.
 29. 15. 10. 11. 15. 11.  6. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0] -> size -> 40 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.011497497558594






Player: 1 
cards in hand: [ 6.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 11.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  2.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [11.  3. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[28.229856]
 [34.05707 ]
 [34.05707 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0.  0.  6.  8. 15.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 42 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.011497497558594



action possibilites: [-1] 
expected returns: [[14.741438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  8. 15.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 42 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.09688949584961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 7.750788]
 [14.822811]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [15.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0.  0.  6.  8. 15.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 42 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.741437911987305






Player: 1 
cards in hand: [ 0.  0.  6.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  8. 15.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6
 14  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15.  6. 25. 11.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15.  6. 25. 11.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 15.  6. 25. 11.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 15.  6. 25. 11.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 15.  6. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 25. 11.] 
expected returns: [[61.046062]
 [74.325966]
 [56.64128 ]
 [85.662   ]
 [67.62651 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  6. 25. 11.] 
cards in discard: [15. 11.  3. 11.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 14.  0.  3.  8.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.822809219360352



action possibilites: [-1] 
expected returns: [[98.69241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  6. 11. 29. 15.] 
cards in discard: [15. 11.  3. 11.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 14.  0.  3.  8.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.66200256347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[91.61865]
 [98.9706 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  6. 11. 29. 15.] 
cards in discard: [15. 11.  3. 11.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 14.  0.  3.  8.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.69241333007812






Player: 1 
cards in hand: [ 3. 14.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  3.  8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  3. 15.  0.  0.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  3. 15.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  2.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  3. 15.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10.  3. 15.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[91.66313]
 [85.2023 ]
 [87.60859]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 15.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 6. 0. 3. 6.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8. 11. 14.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -71.12966918945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[83.545395]
 [91.58141 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 15.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 6. 0. 3. 6.] 
adversary cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8. 11. 14.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.66314697265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8. 11. 14.  3.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29.  8. 15.  0. 10.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 6.] 
cards in discard: [ 3. 29. 11.  3.  0.  0.  1.  0.  0.  6.  6. 16.  6.  0.  8. 25.  6.  8.
  0. 11.  6.  0.  3.  0. 10. 15.  0.  6.  8. 11. 14.  3.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29.  8. 15.  0. 10.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  8. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15. 10.] 
expected returns: [[24.054018]
 [35.479893]
 [24.90051 ]
 [20.237253]
 [17.987255]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 15.  0. 10.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.58143615722656



action possibilites: [-1. 15. 10. 10.] 
expected returns: [[13.388128 ]
 [ 9.654631 ]
 [ 7.5622287]
 [ 7.5622287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.339353561401367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 6.129768 ]
 [10.5606365]
 [13.939604 ]
 [13.115656 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  1.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.388134002685547



buy possibilites: [-1] 
expected returns: [[30.897467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10. 10.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [16. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 41 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 13.939615249633789






Player: 1 
cards in hand: [16. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6 11  0  0 11  6 14
  6  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 30.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 29. 10. 11.  8.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [4.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 29. 10. 11.  8.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [4.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 29. 10. 11.  8.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [4. 0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [29. 29. 10. 11.  8.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29. 29. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 11.  8.] 
expected returns: [[16.569216]
 [26.043661]
 [26.043661]
 [11.416159]
 [21.422966]
 [17.254185]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10. 11.  8.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.8974666595459



action possibilites: [-1. 29. 11. 11.] 
expected returns: [[38.860867]
 [48.568966]
 [43.829144]
 [43.829144]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.108240127563477



action possibilites: [-1.  8.] 
expected returns: [[45.901524]
 [46.453953]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.47787857055664



action possibilites: [-1] 
expected returns: [[35.576057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 46.4539680480957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[30.199484]
 [33.643894]
 [35.576054]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 8. 6. 6. 0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.57605743408203






Player: 1 
cards in hand: [3. 8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 6. 0.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6
  3  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 25. 10. 11. 10.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 25. 10. 11. 10.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 25. 10. 11. 10.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 25. 10. 11. 10.] 
adversary cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 25. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 11. 10.] 
expected returns: [[ 7.8724275]
 [ 4.07756  ]
 [21.30127  ]
 [ 4.07756  ]
 [11.40357  ]
 [ 4.07756  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 11. 10.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11. 25. 10.  8.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 35.57605743408203



action possibilites: [-1] 
expected returns: [[4.568626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10. 29.  8.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11. 25. 10.  8.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.3012752532959





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-0.34397602]
 [ 4.568628  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 10. 29.  8.] 
cards in discard: [15. 11.  3. 11.  3.  0. 25. 29. 15.  6. 11. 29. 15.  0.  0. 10.  3. 15.
  8.  8. 29. 15.  0. 10. 10. 10.  8. 11. 11. 29. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11. 25. 10.  8.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.5686259269714355






Player: 1 
cards in hand: [ 3. 11. 25. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25. 10.  8.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [11.  8.  6. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10.  8.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [11.  8.  6. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 10.  8.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [11.  8.  6. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11.  8.  6. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10. 10.] 
expected returns: [[ 6.5348716]
 [12.0647335]
 [ 7.2691827]
 [ 0.7408395]
 [ 0.7408395]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  6. 10. 10.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0. 14. 15.  8.  0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.5686259269714355



action possibilites: [-1] 
expected returns: [[25.016409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10. 10.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0. 14. 15.  8.  0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 10.53449821472168





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.656843]
 [25.424236]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10. 10.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0. 14. 15.  8.  0.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.016408920288086






Player: 1 
cards in hand: [ 0. 14. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 15.  8.  0.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3
  6  3  0  6 15  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15. 25. 15.  0.  0.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15. 25. 15.  0.  0.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15. 25. 15.  0.  0.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15. 25. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 15.] 
expected returns: [[59.895   ]
 [55.619953]
 [81.63495 ]
 [55.619953]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 15.  0.  0.] 
cards in discard: [ 1. 11.  8.  6. 10. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 6. 0. 0. 6.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.424238204956055



action possibilites: [-1] 
expected returns: [[69.17208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  0.  8. 10.] 
cards in discard: [ 1. 11.  8.  6. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 6. 0. 0. 6.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 81.63497161865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[61.525684]
 [66.880066]
 [69.96771 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.  0.  8. 10.] 
cards in discard: [ 1. 11.  8.  6. 10. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [3. 6. 0. 0. 6.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.17208099365234






Player: 1 
cards in hand: [3. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 6.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  3. 29. 11. 29.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 6.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  3. 29. 11. 29.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[29.79093 ]
 [42.914364]
 [36.51161 ]
 [42.914364]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11. 29.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 69.96772766113281



action possibilites: [-1. 29.  8.] 
expected returns: [[50.661545]
 [62.736668]
 [51.51515 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 44.6071891784668



action possibilites: [-1. 11.] 
expected returns: [[68.186066]
 [73.49055 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.161163330078125



action possibilites: [-1] 
expected returns: [[53.669865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 71.97560119628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[46.799644]
 [51.46986 ]
 [54.065838]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.669864654541016






Player: 1 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 10.  3. 29. 10.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 10.  3. 29. 10.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [10. 10.  3. 29. 10.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 10.] 
expected returns: [[41.69396 ]
 [35.71029 ]
 [35.71029 ]
 [53.077324]
 [35.71029 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 29. 10.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [8. 3. 6. 1. 6.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.06584548950195



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[36.719017]
 [31.5482  ]
 [31.5482  ]
 [31.5482  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [8. 3. 6. 1. 6.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.83726119995117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.224752]
 [36.708977]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [8. 3. 6. 1. 6.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 44 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 36.719024658203125






Player: 1 
cards in hand: [8. 3. 6. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 1. 6.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  6  6  8  6  0  0 11  6 14  6  3  6
  3  0  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11.  8. 15. 15.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11.  8. 15. 15.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11.  8. 15. 15.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 3. 11.  8. 15. 15.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  8. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 15.] 
expected returns: [[14.74394  ]
 [19.471128 ]
 [15.418678 ]
 [11.6561775]
 [11.6561775]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8. 15. 15.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.708988189697266



action possibilites: [-1] 
expected returns: [[11.842302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15. 15.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -128 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 18.192907333374023





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 6.0581927]
 [11.8423   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 15. 15.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.842302322387695






Player: 1 
cards in hand: [ 0.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.  0.  8.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [11. 29. 10. 10. 11.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1. 11.  3.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 4.  0. 16.  0.  0.  3.  0.  8.  3.  6.  6.  1. 11.  3. 25. 10.  8.  8.
 14.  0.  3.  6.  0.  0.  6.  0.  0.  0.  0. 11.  3.  0.  8.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [11. 29. 10. 10. 11.] 
adversary cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1. 11.  3.  8. 15. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 29. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 10. 11.] 
expected returns: [[ 2.812078 ]
 [ 7.3567214]
 [11.688831 ]
 [-2.0330687]
 [-2.0330687]
 [ 7.3567214]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 10. 11.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1. 11.  3.  8. 15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.842302322387695



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[18.227522]
 [13.882347]
 [22.268362]
 [26.135328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1. 11.  3.  8. 15. 15. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.1213812828063965



action possibilites: [-1. 15.] 
expected returns: [[41.09959]
 [38.40872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1. 11.  3.  8. 15. 15. 11. 10. 10.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.16192054748535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[35.64799]
 [39.14529]
 [41.09959]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 1. 11.  8.  6. 10. 10. 25. 15. 15.  0.  0.  8. 10.  3. 11.  0.  8.  1.
 29. 29. 11.  3.  0. 29. 10. 10. 10.  1. 11.  3.  8. 15. 15. 11. 10. 10.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 1 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 41.09957504272461






Player: 1 
cards in hand: [0. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 1.  8.  8. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 1.  8.  8. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 6.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 1.  8.  8. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  8. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 25.] 
expected returns: [[10.567442]
 [11.296484]
 [11.296484]
 [21.658289]
 [31.136889]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8. 29. 25.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [8. 0. 8. 1. 4.] 
adversary cards in discard: [0. 0. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0  0] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.09957504272461



action possibilites: [-1] 
expected returns: [[32.60447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8. 29. 15. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [8. 0. 8. 1. 4.] 
adversary cards in discard: [0. 0. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0  0] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.13688850402832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[25.596205]
 [29.779676]
 [32.137127]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8. 29. 15. 11.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [8. 0. 8. 1. 4.] 
adversary cards in discard: [0. 0. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0  0] -> size -> 44 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.604469299316406






Player: 1 
cards in hand: [8. 0. 8. 1. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 1. 4.] 
cards in discard: [0. 0. 3. 0. 6. 6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  1 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0
  6  8  6  3  0  3 29  0  0  8  0 10 11  4  0  0  1  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15.  8.  8. 11. 10.] 
adversary cards in discard: [25.  1.  8.  8. 29. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [0. 0. 3. 0. 6. 6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15.  8.  8. 11. 10.] 
adversary cards in discard: [25.  1.  8.  8. 29. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0. 0. 3. 0. 6. 6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [15.  8.  8. 11. 10.] 
adversary cards in discard: [25.  1.  8.  8. 29. 15. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [15.  8.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8. 11. 10.] 
expected returns: [[46.51761 ]
 [42.126793]
 [47.41872 ]
 [47.41872 ]
 [52.71296 ]
 [39.42377 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8. 11. 10.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [0. 0. 3. 0. 6. 6. 8. 8.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.13712692260742



action possibilites: [-1] 
expected returns: [[49.500637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8. 10.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [0. 0. 3. 0. 6. 6. 8. 8.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 51.04755783081055





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[40.720108]
 [49.519627]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8. 10.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 6. 10.  6.  3. 11.] 
adversary cards in discard: [0. 0. 3. 0. 6. 6. 8. 8.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.50063705444336






Player: 1 
cards in hand: [ 6. 10.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  3. 11.] 
cards in discard: [0. 0. 3. 0. 6. 6. 8. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 6.  1. 29.  8. 10.] 
adversary cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 44 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  3. 11.] 
cards in discard: [0. 0. 3. 0. 6. 6. 8. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 6.  1. 29.  8. 10.] 
adversary cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 44 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6.  1. 29.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[21.897568]
 [33.88862 ]
 [22.636202]
 [16.192286]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1. 29.  8. 10.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0. 16. 25. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  6.  6.  8.  8.  6. 10.  6.  3. 11.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.519622802734375



action possibilites: [-1.  8. 10.] 
expected returns: [[39.81014 ]
 [40.69344 ]
 [32.925884]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.  6.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 10 29 29 29 10 25 10  6 25 29  8 10 11 11 10
  8  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0. 16. 25. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  6.  6.  8.  8.  6. 10.  6.  3. 11.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.12608528137207



action possibilites: [-1] 
expected returns: [[43.25076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.  6.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 29 29 10 25 10  6 25 29  8 10 11 11 10  8
  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0. 16. 25. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  6.  6.  8.  8.  6. 10.  6.  3. 11.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 44.64524841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[34.68115 ]
 [46.251797]
 [39.364754]
 [47.80692 ]
 [36.152397]
 [42.09947 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.  6.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 29 29 10 25 10  6 25 29  8 10 11 11 10  8
  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  1.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0. 16. 25. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  6.  6.  8.  8.  6. 10.  6.  3. 11.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.25075912475586



Game is draw!



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 6 
Witch: 2 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1.] 
cards in discard: [25.  1.  8.  8. 29. 15. 11.  1. 11. 15.  8.  8. 10.  6.  1. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11 29 29 29 10 25 10  6 25 29  8 10 11 11 10  8
  8 10 29 10  8 10 11 15 15 11 11 15 15 15  8  1  1  1  1 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 24. 29.  8.  0.  9.  0.  0.  7.  3.  9. 10.  1. 10.  3.] 
adversary cards in hand: [ 0.  0. 16. 25. 11.] 
adversary cards in discard: [ 0.  0.  3.  0.  6.  6.  8.  8.  6. 10.  6.  3. 11.] 
adversary owned cards: [ 0  3  3  0 25  3  8 16  0  3  8  6  0  0 11  6 14  6  3  6  3  0  6  8
  6  3  0  3 29  0  0  8  0 10 11  0  0  1  0  0  0] -> size -> 41 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -28 

action type: buy - action 11.0
Learning step: -3.0322771072387695
desired expected reward: 44.77465057373047



