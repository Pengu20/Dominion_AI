 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.400648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -16.07754135131836
desired expected reward: 14.840461730957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.20082 ]
 [22.278122]
 [22.20082 ]
 [22.288225]
 [22.62833 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5944257974624634
desired expected reward: 22.053146362304688



buy possibilites: [-1] 
expected returns: [[23.413166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.33250537514686584
desired expected reward: 21.945613861083984






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.338297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6051169037818909
desired expected reward: 22.808048248291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.71502 ]
 [23.79777 ]
 [23.792318]
 [23.72006 ]
 [23.71502 ]
 [23.768225]
 [23.8941  ]
 [23.802423]
 [23.967129]
 [23.983795]
 [23.813635]
 [23.876564]
 [23.796972]
 [23.779434]
 [23.91076 ]
 [24.142525]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.605534553527832
desired expected reward: 22.94475555419922



buy possibilites: [-1] 
expected returns: [[27.550299]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  3.  0. 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 23.0
Learning step: 0.9229812622070312
desired expected reward: 24.799543380737305






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.73774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7146198749542236
desired expected reward: 26.835678100585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.43487 ]
 [24.517616]
 [24.512167]
 [24.43487 ]
 [24.613947]
 [24.522272]
 [24.51682 ]
 [24.862375]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6398078203201294
desired expected reward: 24.302005767822266



buy possibilites: [-1] 
expected returns: [[27.747885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.05706561729311943
desired expected reward: 24.556882858276367






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 23.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 23.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 23.  0.  3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[27.536016]
 [27.270052]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  0.  3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6927011609077454
desired expected reward: 27.05518341064453



action possibilites: [-1.] 
expected returns: [[28.154573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
action values: 1 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: -0.07740519940853119
desired expected reward: 27.35686683654785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.474272]
 [27.55702 ]
 [27.551569]
 [27.474272]
 [27.527475]
 [27.653349]
 [27.561674]
 [27.743044]
 [27.572887]
 [27.556227]
 [27.67001 ]
 [27.90178 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
action values: 0 
buys: 2 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10417298972606659
desired expected reward: 28.050399780273438






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.345306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 16.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11 29] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.69789719581604
desired expected reward: 27.203880310058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.23356 ]
 [27.316307]
 [27.31086 ]
 [27.23356 ]
 [27.41264 ]
 [27.320961]
 [27.315514]
 [27.661066]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 16.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11 29] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.688327431678772
desired expected reward: 26.85034942626953



buy possibilites: [-1] 
expected returns: [[30.144224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 16.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11 29] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.11295101046562195
desired expected reward: 27.202560424804688






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 16.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9. 10. 10.] 
adversary cards in hand: [23.  0. 11.  3.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [23.  0. 11.  3.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [23.  0. 11.  3.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 22.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [23.  0. 11.  3.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [23.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
expected returns: [[29.335188]
 [29.069221]
 [29.08676 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 11.  3.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7456437349319458
desired expected reward: 29.39858055114746



action possibilites: [-1. 11.] 
expected returns: [[28.720562]
 [28.475761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
action values: 1 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: -0.12624338269233704
desired expected reward: 29.143342971801758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.340187]
 [28.421803]
 [28.416332]
 [28.340187]
 [28.51692 ]
 [28.426208]
 [28.420738]
 [28.76172 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [10.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10] -> size -> 14 
action values: 0 
buys: 2 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.11219094693660736
desired expected reward: 28.60837173461914



buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.624521]
 [28.624521]
 [29.046055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [10.  0.  0.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: buy - action 11.0
Learning step: 0.16711537539958954
desired expected reward: 28.684036254882812






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11] -> size -> 15 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.318237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7222900390625
desired expected reward: 28.32376480102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.786915]
 [27.868534]
 [27.863066]
 [27.786915]
 [27.96365 ]
 [27.872938]
 [27.867468]
 [28.208452]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7109306454658508
desired expected reward: 27.77397918701172



buy possibilites: [-1] 
expected returns: [[31.48222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [ 0. 16.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.11549273878335953
desired expected reward: 27.753042221069336






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 16 29 22  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3. 11. 10.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3. 11. 10.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3. 11. 10.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [11.  3. 11. 10.  0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1] -> size -> 16 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [11.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[28.889423]
 [28.644623]
 [28.644623]
 [28.54844 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 10.  0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  9.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 22. 29.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  0.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7910565733909607
desired expected reward: 30.691164016723633



action possibilites: [-1] 
expected returns: [[32.01254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 22. 29.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  0.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.18313796818256378
desired expected reward: 29.282926559448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.423115]
 [31.423115]
 [31.844646]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8. 10.  9.  7. 10. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 22. 29.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  0.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1783679574728012
desired expected reward: 31.834171295166016



buy possibilites: [-1] 
expected returns: [[34.443058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 22. 29.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  0.  0. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.131041526794434
desired expected reward: 22.292068481445312






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 22. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 22. 29.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  0.  0. 16.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 23.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 10.  6. 11.  3. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 23.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 10.  6. 11.  3. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 22.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 23.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 10.  6. 11.  3. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 22.  0.] 
cards in discard: [15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 23.] 
adversary cards in discard: [ 1.  3.  0.  3.  0.  0. 10.  6. 11.  3. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[24.894154]
 [24.63216 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 23.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 10.  6. 11.  3. 11. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9202896952629089
desired expected reward: 33.522769927978516



action possibilites: [-1.] 
expected returns: [[30.719296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: 0.025834178552031517
desired expected reward: 24.91645050048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.102411]
 [30.184021]
 [30.178553]
 [30.102411]
 [30.154963]
 [30.27914 ]
 [30.18843 ]
 [30.368002]
 [30.199238]
 [30.182962]
 [30.29542 ]
 [30.523943]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6] -> size -> 18 
action values: 0 
buys: 2 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8.  9.  9.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.15354691445827484
desired expected reward: 30.56574821472168



buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.42543 ]
 [33.42543 ]
 [33.846966]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 16.0
Learning step: 0.37838366627693176
desired expected reward: 30.533344268798828



buy possibilites: [-1] 
expected returns: [[30.611168]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [16.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 16.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.23134562373161316
desired expected reward: 33.19408416748047






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 16.] 
cards in discard: [15. 29.  3.  0.  0. 22.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [15. 29.  3.  0.  0. 22.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [15. 29.  3.  0.  0. 22.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0] -> size -> 20 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.34723]
 [31.00625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  6.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7380836606025696
desired expected reward: 29.873085021972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.662231]
 [30.736853]
 [30.662231]
 [30.746147]
 [31.072178]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  6.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7. 10. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7588275074958801
desired expected reward: 30.327735900878906



buy possibilites: [-1] 
expected returns: [[29.718342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.  6.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [15. 29.  3.  0.  0. 22.  0.  0. 16.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.5203418731689453
desired expected reward: 30.225807189941406






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [15. 29.  3.  0.  0. 22.  0.  0. 16.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [15. 29.  3.  0.  0. 22.  0.  0. 16.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9. 10.  9.  8.  9.  9.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [15. 29.  3.  0.  0. 22.  0.  0. 16.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0.  3.  0. 10.] 
adversary cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8] -> size -> 21 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[31.255718]
 [31.018559]
 [30.92427 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 10.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.713687539100647
desired expected reward: 29.004653930664062



action possibilites: [-1] 
expected returns: [[28.294662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.28721317648887634
desired expected reward: 31.61656951904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.038582]
 [28.113207]
 [28.038582]
 [28.122505]
 [28.448528]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.10261882841587067
desired expected reward: 28.19204330444336



buy possibilites: [-1] 
expected returns: [[29.305416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [16.  0. 23.  0.  0.  3.  0.  3.  8.  0.  0.  3. 10.  6. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.15431064367294312
desired expected reward: 28.267518997192383






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [14.  8.  3.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 26. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [14.  8.  3.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3] -> size -> 23 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [14.  8.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
expected returns: [[27.559877]
 [27.244041]
 [27.233849]
 [27.32272 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  1. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.739264965057373
desired expected reward: 28.566150665283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.246117]
 [27.320742]
 [27.246117]
 [27.330036]
 [27.656067]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  1. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.695652425289154
desired expected reward: 27.08943748474121



buy possibilites: [-1] 
expected returns: [[31.100018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  1. 11.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.40307217836380005
desired expected reward: 26.917673110961914






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11. 23.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  9.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11. 23.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0. 11. 23.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
expected returns: [[33.937668]
 [33.70051 ]
 [33.683826]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 23.  0.  3.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 22.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.725436270236969
desired expected reward: 30.37458038330078



action possibilites: [-1. 11.] 
expected returns: [[31.10445 ]
 [30.867292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  6.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 22.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: -0.24232405424118042
desired expected reward: 33.688499450683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.61102 ]
 [30.69106 ]
 [30.685642]
 [30.61102 ]
 [30.78381 ]
 [30.694939]
 [30.68952 ]
 [31.02097 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  6.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3] -> size -> 24 
action values: 0 
buys: 2 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 22.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.15991206467151642
desired expected reward: 30.944538116455078



buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.732586]
 [32.81263 ]
 [32.807213]
 [32.732586]
 [32.90538 ]
 [32.81651 ]
 [32.811096]
 [33.14254 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  6.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 22.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.12283269315958023
desired expected reward: 30.48818588256836



buy possibilites: [-1] 
expected returns: [[32.43331]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  6.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 10. 22.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.34621694684028625
desired expected reward: 33.157310485839844






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 22.  3.] 
cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1. 22. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  3. 15.] 
cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.] 
cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.] 
cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  7.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.] 
cards in discard: [ 3.  0. 16.  0.  0. 29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.758831]
 [30.427383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8014236688613892
desired expected reward: 31.631887435913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.233002]
 [30.31158 ]
 [30.305962]
 [30.233002]
 [30.402012]
 [30.31517 ]
 [30.309551]
 [30.630865]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 25. 30.  8.  9.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.750484824180603
desired expected reward: 29.905776977539062



buy possibilites: [-1] 
expected returns: [[31.023586]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 25. 30.  8.  9.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.7312424778938293
desired expected reward: 29.50176239013672






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [29. 11. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  9.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0. 10.  0.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0. 10.  0.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  3.  3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0. 10.  0.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[30.857224]
 [30.509953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0. 10.  0.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7581652402877808
desired expected reward: 30.26542091369629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.46407 ]
 [30.542648]
 [30.537025]
 [30.46407 ]
 [30.633078]
 [30.546236]
 [30.540619]
 [30.861929]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0. 10.  0.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7540874481201172
desired expected reward: 30.10313606262207



buy possibilites: [-1] 
expected returns: [[32.853065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [ 3. 14.  8.  3.  1. 11.  0. 10. 23.  0. 11.  0.  3.  6.  0. 10.  0.  0.
  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 15.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.1813221275806427
desired expected reward: 30.3613224029541






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 15.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1] -> size -> 28 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 15.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1] -> size -> 28 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 15.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1] -> size -> 28 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.901217]
 [31.579906]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7994133830070496
desired expected reward: 32.053653717041016



action possibilites: [-1. 11.] 
expected returns: [[31.826164]
 [31.59731 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  8.  8.  6.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.17151305079460144
desired expected reward: 31.652706146240234



action possibilites: [-1.] 
expected returns: [[30.625706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 5
Learning step: 0.6960206627845764
desired expected reward: 32.21432876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.152142]
 [30.225101]
 [30.152142]
 [30.234308]
 [30.550003]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 25. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0] -> size -> 22 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.44959086179733276
desired expected reward: 31.07529640197754






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [23.  0.  0.  3.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [23.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[36.455868]
 [36.210102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  3.  0.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10. 22.  0.  0.  0.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.  0.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6847456693649292
desired expected reward: 29.86525535583496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.15236 ]
 [36.230934]
 [36.225315]
 [36.15236 ]
 [36.321365]
 [36.234524]
 [36.2289  ]
 [36.550213]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.  3.  0.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10. 22.  0.  0.  0.] 
adversary cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.  0.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3] -> size -> 23 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8623197674751282
desired expected reward: 35.59354782104492



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10. 22.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 22.  0.  0.  0.] 
cards in discard: [ 6. 11. 29. 29.  3.  3.  0.  0.  3.  3.  0. 15.  0.  3. 16.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.  0.  0.] 
cards in discard: [15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0. 10. 11.  0.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 1.  0. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[32.33297 ]
 [32.011658]
 [32.10412 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 11.  0.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [11. 29.  3.  3.  0.] 
adversary cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15] -> size -> 24 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.9085507392883301
desired expected reward: 35.641666412353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.07069 ]
 [32.149265]
 [32.143642]
 [32.07069 ]
 [32.121273]
 [32.239697]
 [32.152855]
 [32.324444]
 [32.161892]
 [32.147232]
 [32.254356]
 [32.468544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10. 11.  0.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [11. 29.  3.  3.  0.] 
adversary cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15] -> size -> 24 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7813919186592102
desired expected reward: 31.551578521728516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [11. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  3.  0.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  3. 14.  1.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  3.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  3. 14.  1.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  3.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  9. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  3. 14.  1.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  3.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  8.  3. 14.  1.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 6.  8.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[28.971014]
 [28.65532 ]
 [28.664364]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  3. 14.  1.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [15.  3. 29.  0.  0.] 
adversary cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8216033577919006
desired expected reward: 31.646944046020508



action possibilites: [-1] 
expected returns: [[30.498835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 1.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [15.  3. 29.] 
adversary cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.08784381300210953
desired expected reward: 28.576520919799805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.262228]
 [30.339033]
 [30.333021]
 [30.262228]
 [30.311129]
 [30.426586]
 [30.342337]
 [30.508528]
 [30.349913]
 [30.33633 ]
 [30.440168]
 [30.64498 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 1.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 24. 30.  8.  8.  8.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [15.  3. 29.] 
adversary cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.14542104303836823
desired expected reward: 30.353412628173828



buy possibilites: [-1] 
expected returns: [[29.58483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 1.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  7.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [15.  3. 29.] 
adversary cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 16.0
Learning step: 0.8113069534301758
desired expected reward: 31.122432708740234






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [15.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  7.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.
 14.  6.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16] -> size -> 30 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 29.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 24. 30.  8.  8.  7.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.
 14.  6.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16] -> size -> 30 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 29.] 
cards in discard: [15. 22. 10.  0.  0.  0.  3.  0.  0.  8. 29. 11.  3.  3.  0.  3.  0.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.
 14.  6.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16] -> size -> 30 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[31.856148]
 [31.522295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.
 14.  6.  8.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [10.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8  0] -> size -> 26 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7044575214385986
desired expected reward: 28.88037109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.677122]
 [31.747913]
 [31.677122]
 [31.757227]
 [32.05987 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.
 14.  6.  8.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  8. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [10.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8  0] -> size -> 26 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7713742852210999
desired expected reward: 31.08477210998535



buy possibilites: [-1] 
expected returns: [[29.432993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [11. 10. 11.  0.  0.  3.  3. 23.  0.  0.  3.  0.  1.  0. 10. 11.  0. 16.
 14.  6.  8.  3.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  7. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [10.  0.  3.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8  0] -> size -> 26 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.5536704063415527
desired expected reward: 31.203556060791016






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  6. 16.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  7. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 16.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15
  8  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  7. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[35.0596 ]
 [34.75095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6653793454170227
desired expected reward: 28.767614364624023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.885403]
 [34.96221 ]
 [34.956203]
 [34.885403]
 [34.934303]
 [35.049763]
 [34.965515]
 [35.131706]
 [34.973087]
 [34.959507]
 [35.063343]
 [35.268158]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  5.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8359319567680359
desired expected reward: 34.29804229736328



buy possibilites: [-1] 
expected returns: [[37.447674]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.6732922792434692
desired expected reward: 34.376468658447266






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  3.  1. 11.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11] -> size -> 32 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 24. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  3.  1. 11.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11] -> size -> 32 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  3.  1. 11.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11] -> size -> 32 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[38.130795]
 [37.9124  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  1. 11.] 
cards in discard: [11.  0.  0.  0.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.873974084854126
desired expected reward: 36.573699951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.905964]
 [37.976765]
 [37.905964]
 [37.986076]
 [38.288715]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  1. 11.] 
cards in discard: [11.  0.  0.  0.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 23. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8942108750343323
desired expected reward: 37.2365837097168



buy possibilites: [-1] 
expected returns: [[35.972996]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  1. 11.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8  3] -> size -> 27 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.6715864539146423
desired expected reward: 37.305179595947266






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8
  0  8  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  1. 10.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  1. 10.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  1. 10.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [ 0.  1. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[35.382557]
 [35.07391 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  0.  0.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 11.  8.  3. 22.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8589693903923035
desired expected reward: 35.1140251159668



action possibilites: [-1.] 
expected returns: [[32.890827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 11.  8.  3. 22.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.2568635940551758
desired expected reward: 34.817047119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.85413 ]
 [32.930935]
 [32.924927]
 [32.85738 ]
 [32.85413 ]
 [32.903027]
 [33.018486]
 [32.93424 ]
 [33.086845]
 [33.10043 ]
 [32.941814]
 [33.000862]
 [32.92823 ]
 [32.910603]
 [33.032074]
 [33.23688 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  9.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 11.  8.  3. 22.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.18998199701309204
desired expected reward: 32.700843811035156



buy possibilites: [-1] 
expected returns: [[35.63722]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 11.  8.  3. 22.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 14.0
Learning step: 0.07593635469675064
desired expected reward: 33.01774978637695






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3. 22.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 16 29 22  0  3  0  0 15  0 10 29 11  6  0  0  3 15  8  0
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 16.  0. 23.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 16.  0. 23.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 16.  0. 23.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 16.  0. 23.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
adversary victory points: 6
player victory points: 5 





Player: 0 
cards in hand: [16.  0. 16.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 23.] 
expected returns: [[38.192867]
 [37.859013]
 [37.859013]
 [37.956844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  0. 23.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.] 
adversary owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8199893236160278
desired expected reward: 34.817230224609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.687347]
 [37.755188]
 [37.687347]
 [37.76488 ]
 [38.052593]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0. 23.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  6. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.] 
adversary owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8881218433380127
desired expected reward: 36.960670471191406



buy possibilites: [-1] 
expected returns: [[35.271656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 16.  0. 23.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 29.  0. 15.  0.] 
adversary cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.] 
adversary owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.6725940108299255
desired expected reward: 37.092288970947266






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 15.  0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  8.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  8.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 22. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  8.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [ 8. 10. 16.  0.  6.  3.  3.  0.  3.  0.  3. 29. 15.  3.  0.  0.  0.  8.
  3. 22.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  8.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
adversary victory points: 6
player victory points: 6 





Player: 0 
cards in hand: [11.  0.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[33.541996]
 [33.335117]
 [33.254284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  6.  3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8573435544967651
desired expected reward: 34.41431427001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.31303]
 [33.31303]
 [33.67828]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  6.  3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  8.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.804683268070221
desired expected reward: 32.73731231689453



buy possibilites: [-1] 
expected returns: [[36.25166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  6.  3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  7.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3] -> size -> 25 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -9.798748016357422
desired expected reward: 23.5142822265625






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  7.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [11. 14.  8. 10.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6] -> size -> 36 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  7.  7.  4.  5. 10.  8.  8.  9.  6.  9.  8.] 
adversary cards in hand: [11. 14.  8. 10.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6] -> size -> 36 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  7.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [11. 14.  8. 10.  3.] 
adversary cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6] -> size -> 36 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [11. 14.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8. 10.] 
expected returns: [[33.06266 ]
 [32.85578 ]
 [32.78094 ]
 [32.774944]
 [32.768425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  8. 10.  3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6. 11.  0.  8.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  7.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 29. 10.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8921903371810913
desired expected reward: 35.35947036743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.697414]
 [32.697414]
 [33.062664]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  8. 10.  3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6. 11.  0.  8.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  7.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 29. 10.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7967672944068909
desired expected reward: 32.26589584350586



buy possibilites: [-1] 
expected returns: [[32.41319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  8. 10.  3.] 
cards in discard: [11.  0.  0.  0.  0. 10.  3.  3.  3.  3.  1. 11. 14. 10.  0.  1.  0.  0.
  3.  8. 16.  0. 16.  0. 23.  6. 11.  0.  8.  6.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 29. 10.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -307 

action type: buy - action 6.0
Learning step: -9.850584030151367
desired expected reward: 22.846826553344727






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 29. 10.] 
cards in discard: [10.  3.  0.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  3. 29. 10.] 
cards in discard: [10.  3.  0.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[33.038914]
 [32.83203 ]
 [32.74468 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10.] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7768901586532593
desired expected reward: 31.63629913330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.829163]
 [32.903526]
 [32.897003]
 [32.829163]
 [32.98753 ]
 [32.9067  ]
 [32.900173]
 [33.194412]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [15.  0.  3.  3.  0.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10.] 
adversary owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7948390245437622
desired expected reward: 32.244075775146484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [15.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  0.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  0  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0
  3 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 6. 14.  3.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 6. 14.  3.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 21. 30.  8.  6.  7.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 6. 14.  3.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 6. 14.  3.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 6. 14.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[35.92987]
 [35.64815]
 [35.64216]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  3.  3.  8.] 
cards in discard: [ 0. 11. 10.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 23 11 10 11  1 10  6 16  0  8 14  3  3
  0 10  0  1 11 16  8 11  3 14  8  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10 16] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7701631188392639
desired expected reward: 32.42424774169922



action possibilites: [-1] 
expected returns: [[37.049564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 11. 10.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10 16] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 10
Learning step: -0.22616489231586456
desired expected reward: 35.28001022338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[36.891457]
 [36.891457]
 [37.25671 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 11. 10.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  6.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10 16] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.2723368704319
desired expected reward: 36.77722930908203



buy possibilites: [-1] 
expected returns: [[35.251934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 11. 10.  0.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  3. 29.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
adversary owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10 16] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -9.286598205566406
desired expected reward: 27.604862213134766






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3. 29.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  3  0  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3
 10 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [0. 1. 0. 8. 6.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  3  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [0. 1. 0. 8. 6.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  3  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  5. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [0. 1. 0. 8. 6.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3 16 29 22  3  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10
 16  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [0. 1. 0. 8. 6.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [0. 1. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[32.06958 ]
 [31.781866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 6.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 16.  8. 22.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.  8. 15.
  3.  3. 29.] 
adversary owned cards: [ 3  3  3 16 29 22  3  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10
 16  8] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.872035801410675
desired expected reward: 34.37989807128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[31.449064]
 [31.522532]
 [31.516151]
 [31.449064]
 [31.495562]
 [31.605064]
 [31.525862]
 [31.682156]
 [31.531593]
 [31.519485]
 [31.617168]
 [31.805481]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8. 6.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 16.  8. 22.] 
adversary cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.  8. 15.
  3.  3. 29.] 
adversary owned cards: [ 3  3  3 16 29 22  3  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10
 16  8] -> size -> 26 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7689775824546814
desired expected reward: 30.926773071289062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8. 22.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.  8. 15.
  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  3  0 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10
 16  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 22.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.  8. 15.
  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 22.] 
cards in discard: [10.  3.  0.  0.  6.  0.  8.  3.  3. 29. 10. 16. 15.  3.  3.  0.  8. 15.
  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 1.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.416126]
 [30.130129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [22.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7859962582588196
desired expected reward: 31.019485473632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.296116]
 [30.369587]
 [30.36321 ]
 [30.296116]
 [30.45212 ]
 [30.372917]
 [30.36654 ]
 [30.652538]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  5.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [22.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7427857518196106
desired expected reward: 29.673337936401367



buy possibilites: [-1] 
expected returns: [[33.15414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [22.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.71076488494873
desired expected reward: 20.58535385131836






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [22.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 16.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6] -> size -> 35 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 16.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6] -> size -> 35 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0. 16.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6] -> size -> 35 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[32.168648]
 [31.968231]
 [31.858725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 16.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 3. 16.  3. 29. 10.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8082823157310486
desired expected reward: 32.34585952758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.09201 ]
 [32.165478]
 [32.1591  ]
 [32.09201 ]
 [32.248013]
 [32.16881 ]
 [32.162434]
 [32.448425]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 16.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  5.  9.  8.] 
adversary cards in hand: [ 3. 16.  3. 29. 10.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7765045166015625
desired expected reward: 31.392139434814453



buy possibilites: [-1] 
expected returns: [[34.5555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 16.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3. 16.  3. 29. 10.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 18  0] 
sum of rewards: 12 

action type: buy - action 10.0
Learning step: -0.2420402467250824
desired expected reward: 31.920392990112305






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3. 29. 10.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 23.  6. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1. 16. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3. 10.  8.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3  3 16 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 23.  6. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 23.  6. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 23.  6. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11. 23.  6. 11. 14.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [11. 23.  6. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23. 11. 14.] 
expected returns: [[29.123074]
 [28.922655]
 [28.904459]
 [28.922655]
 [28.84918 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 23.  6. 11. 14.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.882373571395874
desired expected reward: 33.673126220703125



action possibilites: [-1. 11. 11. 14.] 
expected returns: [[29.610214]
 [29.409798]
 [29.409798]
 [29.336323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11. 14.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 23.0
Learning step: -0.10764335095882416
desired expected reward: 28.79681396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.35965 ]
 [29.35965 ]
 [29.716066]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 11. 14.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10] -> size -> 36 
action values: 1 
buys: 2 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  4.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.12828369438648224
desired expected reward: 29.481929779052734



buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.759577]
 [30.759577]
 [31.11599 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 11. 14.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  3.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -287 

action type: buy - action 6.0
Learning step: -9.166067123413086
desired expected reward: 20.19358253479004



buy possibilites: [-1] 
expected returns: [[30.079876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 11. 14.  3.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  2.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
adversary owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -288.0 

action type: buy - action 6.0
Learning step: -9.2469482421875
desired expected reward: 21.51262664794922






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 29.  0.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  3. 10.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0. 15.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  3. 10.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 15.  3.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 3 29 22  3 15  0 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  2.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  3. 10.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 4 
card supply: [18. 28. 30. 21. 30.  8.  2.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  3. 10.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 4 
card supply: [18. 28. 30. 21. 30.  8.  2.  6.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  3. 10.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [22.  3.  0.  0. 15.  6.  0.  3.  0. 29.  8. 10. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [16.  3. 10.  3.  8.] 
adversary cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [16.  3. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
expected returns: [[29.537663]
 [29.227741]
 [29.251667]
 [29.258045]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 10.  3.  8.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [29. 16.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0 16] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7440894246101379
desired expected reward: 29.335786819458008



action possibilites: [-1. 16.  8.] 
expected returns: [[29.10699 ]
 [28.797071]
 [28.827374]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  8.  0.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 23 11 10 11  1 10 16  0  8  3  3  0 10  0  1
 11 16  8 11  3 14  8  6  6  6  6 10  6  6] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [29. 16.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0 16] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.1235773041844368
desired expected reward: 29.128089904785156



action possibilites: [-1.] 
expected returns: [[23.177937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [29. 16.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0 16] -> size -> 23 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.43634605407714844
desired expected reward: 29.34929847717285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.914558]
 [22.914558]
 [23.266527]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11. 10.  0.  0.  6.  8.  0.  1.  0.  8.  6.  6.  1.  0.  3. 10.  3.
 10.  0.  0. 11.  0. 16.  6.  6. 23. 11.  6. 11. 14.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [29. 16.  0.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0 16] -> size -> 23 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5969893932342529
desired expected reward: 23.774925231933594






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [29. 16.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  8.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 22  3 15 10 29  6  0  0  3 15  8  0  8  3  0  3 10 16  8  0 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 6. 10.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 6. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[26.788826]
 [26.508244]
 [26.508244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 8.  0. 10.  3. 16.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3 22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16] -> size -> 20 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5671791434288025
desired expected reward: 22.69934844970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.60598 ]
 [26.673653]
 [26.60598 ]
 [26.683208]
 [26.957952]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 8.  0. 10.  3. 16.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 3 22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16] -> size -> 20 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6758859753608704
desired expected reward: 26.218204498291016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3. 16.] 
cards in discard: [8. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  4.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  0.  6.  3.  3.] 
adversary cards in discard: [ 6. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.] 
cards in discard: [ 8.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  0.  6.  3.  3.] 
adversary cards in discard: [ 6. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.] 
cards in discard: [ 8.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [11.  0.  6.  3.  3.] 
adversary cards in discard: [ 6. 10.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[31.759764]
 [31.563484]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  3.  3.] 
cards in discard: [ 6. 10.  0. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  5.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6260853409767151
desired expected reward: 26.331865310668945



action possibilites: [-1] 
expected returns: [[30.032536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  2.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 30 

action type: gain_card_n - action 4
Learning step: 0.2729944586753845
desired expected reward: 31.684566497802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.79968 ]
 [29.79968 ]
 [30.151653]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  2.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1363547444343567
desired expected reward: 29.896181106567383



buy possibilites: [-1] 
expected returns: [[29.781452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6 16  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  1.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -287.0 

action type: buy - action 6.0
Learning step: -9.1912841796875
desired expected reward: 20.608394622802734






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 8.  0. 11. 16.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  1.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6 16  6] -> size -> 37 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 8.  0. 11. 16.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 21. 30.  8.  1.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6 16  6] -> size -> 37 
adversary victory points: -4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[29.538967]
 [29.264227]
 [29.264227]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 23 11 10 11  1 10  0  8  3  3  0 10  0  1 11 16  8
 11  3 14  8  6  6  6  6 10  6  6 16  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  1.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 15.  0. 15. 10.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7348229289054871
desired expected reward: 29.046628952026367



action possibilites: [-1] 
expected returns: [[30.436668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  1.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 15.  0. 15. 10.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: -0.10485299676656723
desired expected reward: 29.043081283569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.338768]
 [30.338768]
 [30.690739]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  1.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 15.  0. 15. 10.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1428183764219284
desired expected reward: 30.29384994506836



buy possibilites: [-1] 
expected returns: [[28.76129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [22. 15.  0. 15. 10.] 
adversary cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.158169746398926
desired expected reward: 21.180599212646484






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [22. 15.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15. 15. 10.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  0. 15. 10.] 
cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 1. 10.  3. 11.  6.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15. 10.  6.  3.] 
cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 1. 10.  3. 11.  6.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15. 10.  6.  3.] 
cards in discard: [ 8.  0. 11. 16.  8.  0. 10.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 1. 10.  3. 11.  6.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 





Player: 0 
cards in hand: [ 1. 10.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[28.88499 ]
 [28.604408]
 [28.688713]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3. 11.  6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7108814716339111
desired expected reward: 28.05040740966797



action possibilites: [-1] 
expected returns: [[24.173574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 23 

action type: gain_card_n - action 1
Learning step: 0.09118262678384781
desired expected reward: 28.697715759277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[23.951494]
 [24.021791]
 [24.030787]
 [24.307667]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  3.  6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0.  0. 10. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.021906452253460884
desired expected reward: 24.151668548583984






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 15. 16.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 16.  0.  6. 10.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6  1] -> size -> 36 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 15. 16.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 16.  0.  6. 10.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6  1] -> size -> 36 
adversary victory points: -5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 16.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[25.089123]
 [24.781603]
 [24.80715 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  6. 10.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 10 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14
  8  6  6  6  6 10  6  6 16  6  6  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6174447536468506
desired expected reward: 23.69021987915039



action possibilites: [-1] 
expected returns: [[26.16966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0 16  0] 
sum of rewards: 30 

action type: gain_card_n - action 13
Learning step: 0.37683477997779846
desired expected reward: 26.97505760192871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[26.20564 ]
 [26.275938]
 [26.28493 ]
 [26.561811]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 15.  3.  3.  6.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05812053382396698
desired expected reward: 26.111539840698242






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  3.  6.] 
cards in discard: [ 0.  0. 10. 15. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [14.  0. 23. 11.  0.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  6.] 
cards in discard: [ 0.  0. 10. 15. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [14.  0. 23. 11.  0.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
adversary victory points: -5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  3.  6.] 
cards in discard: [ 0.  0. 10. 15. 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [14.  0. 23. 11.  0.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
adversary victory points: -5
player victory points: 3 





Player: 0 
cards in hand: [14.  0. 23. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 11.] 
expected returns: [[26.52036]
 [26.25103]
 [26.3051 ]
 [26.3231 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 23. 11.  0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.  8. 22.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6698224544525146
desired expected reward: 25.89198875427246



action possibilites: [-1] 
expected returns: [[26.36792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 11.  0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.06066776067018509
desired expected reward: 26.19036293029785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.905195]
 [25.980585]
 [25.975494]
 [25.953848]
 [26.064106]
 [25.98449 ]
 [26.139814]
 [25.992037]
 [25.979393]
 [26.076752]
 [26.261366]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 11.  0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  7.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06724965572357178
desired expected reward: 26.300670623779297



buy possibilites: [-1] 
expected returns: [[27.691938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23. 11.  0.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0 32  0] 
sum of rewards: 45 

action type: buy - action 15.0
Learning step: 0.8584628105163574
desired expected reward: 26.935213088989258






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 6.  8.  1. 11.  6.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6. 15. 14.  0. 23. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15] -> size -> 37 
adversary victory points: -5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.] 
cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 6.  8.  1. 11.  6.] 
adversary cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6. 15. 14.  0. 23. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15] -> size -> 37 
adversary victory points: -5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  8.  1. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[24.742281]
 [24.4654  ]
 [24.54502 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  1. 11.  6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6. 15. 14.  0. 23. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 11.  3. 29.  0.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.  0. 10.  8.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7222917675971985
desired expected reward: 26.969646453857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.38611 ]
 [24.456404]
 [24.4654  ]
 [24.742281]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1. 11.  6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6. 15. 14.  0. 23. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 21. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 11.  3. 29.  0.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.  0. 10.  8.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6344042420387268
desired expected reward: 24.10787582397461



buy possibilites: [-1] 
expected returns: [[23.907564]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  1. 11.  6.] 
cards in discard: [ 6. 10.  0. 10.  0. 16.  6. 11.  0.  6.  3.  3.  6.  8.  0.  1. 11.  1.
 10.  3.  6. 15. 16.  0.  0.  6. 15. 14.  0. 23. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 11.  3. 29.  0.] 
adversary cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.  0. 10.  8.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 0 

action type: buy - action 3.0
Learning step: -0.4826626777648926
desired expected reward: 23.97374153137207






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 29.  0.] 
cards in discard: [ 0.  0. 10. 15. 16.  0.  0. 15.  3.  3.  6.  8. 22.  0. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 16.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  8.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.] 
cards in discard: [ 0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.] 
cards in discard: [ 0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.] 
cards in discard: [ 0. 14.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[30.673128]
 [30.391155]
 [30.48851 ]
 [30.396246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  8.  6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0 14  0] -> size -> 23 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5467203855514526
desired expected reward: 23.360843658447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.379509]
 [30.735682]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.  8.  6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.] 
adversary owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0 14  0] -> size -> 23 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7489650249481201
desired expected reward: 29.924161911010742



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  0  0  3 15  0  8  3  0  3 10  8  0 16 11  0 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6. 11.  3.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6. 11.  3.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6. 11.  3.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6. 11.  3.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
adversary victory points: -4
player victory points: 3 





Player: 0 
cards in hand: [ 6. 11.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[30.210215]
 [30.012955]
 [30.012955]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  6. 11.] 
cards in discard: [ 3. 10. 15.  8.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  4.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15. 22. 10.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.] 
adversary owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7559678554534912
desired expected reward: 29.979713439941406



action possibilites: [-1] 
expected returns: [[26.158293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6. 11.] 
cards in discard: [ 3. 10. 15.  8.  6. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15. 22. 10.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.] 
adversary owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 3
Learning step: 0.20111210644245148
desired expected reward: 29.65277862548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.81828 ]
 [26.175406]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6. 11.] 
cards in discard: [ 3. 10. 15.  8.  6. 16.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 3. 10. 15. 22. 10.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.] 
adversary owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06140699237585068
desired expected reward: 26.096885681152344






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 15. 22. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 22. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 22. 10.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 0. 11.  8. 23.  0.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16] -> size -> 39 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15. 22. 10.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 0. 11.  8. 23.  0.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16] -> size -> 39 
adversary victory points: -4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  8. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 23.] 
expected returns: [[29.433268]
 [29.237076]
 [29.156797]
 [29.219034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 23.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 8. 15.  6.  0.  0.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.  3. 10. 15. 22. 10.] 
adversary owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6276552081108093
desired expected reward: 25.547746658325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[29.269144]
 [29.341232]
 [29.3498  ]
 [29.626274]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 23.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 8. 15.  6.  0.  0.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.  3. 10. 15. 22. 10.] 
adversary owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7238513827323914
desired expected reward: 28.70941925048828



buy possibilites: [-1] 
expected returns: [[29.277391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8. 23.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 8. 15.  6.  0.  0.] 
adversary cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.  3. 10. 15. 22. 10.] 
adversary owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: -0.8706617951393127
desired expected reward: 28.39848518371582






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  6.  0.  0.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.  3. 10. 15. 22. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  6  3 15  8  3  0  3 10  8  0 16 11  0 14  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6.  1.  6.  3. 16.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0] -> size -> 40 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.  3. 10. 15. 22. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6.  1.  6.  3. 16.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0] -> size -> 40 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 0. 14.  0. 29. 11.  3.  3. 16.  0.  8.  3.  3. 10. 15. 22. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [ 6.  1.  6.  3. 16.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0] -> size -> 40 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [ 6.  1.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[28.285074]
 [27.977343]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  6.  3. 16.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  3  0 10  0  1 11 16  8 11  3 14  8
  6  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  4. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7326209545135498
desired expected reward: 28.544771194458008



action possibilites: [-1] 
expected returns: [[24.509302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0  4  0] 
sum of rewards: 14 

action type: gain_card_n - action 5
Learning step: -0.08104362338781357
desired expected reward: 25.198667526245117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.539137]
 [24.611223]
 [24.619791]
 [24.896265]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 20. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.025797443464398384
desired expected reward: 24.483505249023438



buy possibilites: [-1] 
expected returns: [[25.055555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 17 

action type: buy - action 3.0
Learning step: 0.03474660962820053
desired expected reward: 24.64596939086914






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  6.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  6.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  4.  9.  6.] 
adversary cards in hand: [10. 10.  6.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  3.  9.  6.] 
adversary cards in hand: [10. 10.  6.  6. 11.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[25.682873]
 [25.40176 ]
 [25.40176 ]
 [25.486681]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.  6. 11.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  8. 16. 22.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6335891485214233
desired expected reward: 24.421966552734375



action possibilites: [-1. 10. 11.] 
expected returns: [[26.50633 ]
 [26.225218]
 [26.310139]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6. 11.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  8.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  8. 16. 22.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.035072822123765945
desired expected reward: 25.366687774658203



action possibilites: [-1. 10.] 
expected returns: [[24.411196]
 [24.132893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  8. 16. 22.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -7  0  0 16  0] 
sum of rewards: 44 

action type: gain_card_n - action 6
Learning step: 0.7928365468978882
desired expected reward: 26.942508697509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.979347]
 [24.334715]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  8. 16. 22.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5716860890388489
desired expected reward: 24.982881546020508



buy possibilites: [-1] 
expected returns: [[26.577875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  0.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 8. 15.  8. 16. 22.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0. -8.  0.  0.  0.  0.] 
sum of rewards: 27.0 

action type: buy - action 0.0
Learning step: 0.3696872293949127
desired expected reward: 24.349037170410156






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  8. 16. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 16. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8. 16. 22.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  1. 16.  0.  6.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8. 16.  3. 29.  3.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  1. 16.  0.  6.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  8. 16.  3. 29.  3.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  1. 16.  0.  6.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  8. 16.  3. 29.  3.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  1. 16.  0.  6.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [ 3.  1. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[30.328043]
 [30.022032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 16.  0.  6.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  3. 11. 15.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6301770210266113
desired expected reward: 25.94769859313965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[29.972672]
 [30.050116]
 [30.045893]
 [30.13452 ]
 [30.053963]
 [30.04974 ]
 [30.32804 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 16.  0.  6.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  3. 11. 15.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7433903813362122
desired expected reward: 29.58465003967285



buy possibilites: [-1] 
expected returns: [[30.577955]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 16.  0.  6.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14.  3. 11. 15.] 
adversary cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -9.  0.  0.  0.  0.] 
sum of rewards: -14.0 

action type: buy - action 0.0
Learning step: -0.9981115460395813
desired expected reward: 28.974557876586914






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  3. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 11. 15.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 16 11  0 14  0  0 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 14. 15.  1.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 11.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 14. 15.  1.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 11.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 14. 15.  1.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 11.] 
cards in discard: [10. 10. 10.  0.  0.  0.  3.  0. 22.  8. 15.  8. 16.  3. 29.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0. 14. 15.  1.] 
adversary cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 14. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[27.201796]
 [26.937162]
 [27.021948]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 15.  1.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [10.  3. 14. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7829643487930298
desired expected reward: 29.79499053955078



action possibilites: [-1] 
expected returns: [[23.28205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  1.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 14.  0.] 
adversary cards in discard: [10. 16.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.11365339159965515
desired expected reward: 26.823509216308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.926682]
 [23.004126]
 [22.926682]
 [22.9999  ]
 [22.934519]
 [22.97604 ]
 [23.08853 ]
 [23.007973]
 [23.14945 ]
 [23.163124]
 [23.017418]
 [23.070269]
 [23.003748]
 [22.985485]
 [23.102201]
 [23.28205 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  1.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 27. 30. 19. 30.  8.  0.  3.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 14.  0.] 
adversary cards in discard: [10. 16.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.006034183315932751
desired expected reward: 23.27601432800293



buy possibilites: [-1] 
expected returns: [[22.626348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  1.] 
cards in discard: [ 3. 10. 15.  8.  6. 16. 11.  6.  3.  6. 11.  0.  0. 11.  8. 23.  0.  8.
  3. 16.  6.  1.  6. 29.  0. 10. 11. 10.  6.  6.  0.  0.  3.  1. 16.  0.
  6. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 27. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 14.  0.] 
adversary cards in discard: [10. 16.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -10.   0.   0.
   8.   0.] 
sum of rewards: 13.0 

action type: buy - action 16.0
Learning step: -0.061704594641923904
desired expected reward: 22.914337158203125






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.] 
cards in discard: [10. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 27. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [16.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [16.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 16.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [16.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.93292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [16.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3. 22. 11.] 
adversary cards in discard: [10. 16.  1. 14.  3.  0.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0   -10
     0 -2400   131     0] 
sum of rewards: -2284 

action type: discard_down_to_3_cards - action 0
Learning step: -68.88668823242188
desired expected reward: -46.88706970214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.614561]
 [27.96993 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [16.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3. 22. 11.] 
adversary cards in discard: [10. 16.  1. 14.  3.  0.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6957958936691284
desired expected reward: 27.237125396728516



buy possibilites: [-1] 
expected returns: [[25.42054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [16.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  0.  3. 22. 11.] 
adversary cards in discard: [10. 16.  1. 14.  3.  0.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -11.   0.   0.
   0.   0.] 
sum of rewards: -16.0 

action type: buy - action 0.0
Learning step: -1.0415211915969849
desired expected reward: 26.573040008544922






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 22. 11.] 
cards in discard: [10. 16.  1. 14.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  6.  0. 10.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  3.  0.  8.] 
cards in discard: [10. 16.  1. 14.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  6.  0. 10.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.  0.  8.] 
cards in discard: [10. 16.  1. 14.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  3.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  6.  0. 10.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  3.  0.  8.] 
cards in discard: [10. 16.  1. 14.  3.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [22.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [11.  0.  6.  0. 10.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[29.395842]
 [29.20232 ]
 [29.117537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0. 10.] 
cards in discard: [16.  0.  0.  6.  3.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [15. 10.  8. 15. 10.] 
adversary cards in discard: [10. 16.  1. 14.  3.  0. 11. 22.  0.  0.  3. 11.  3.  0.  8.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6052809953689575
desired expected reward: 24.815258026123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[29.1047  ]
 [29.177921]
 [29.185991]
 [29.460068]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0. 10.] 
cards in discard: [16.  0.  0.  6.  3.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 19. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [15. 10.  8. 15. 10.] 
adversary cards in discard: [10. 16.  1. 14.  3.  0. 11. 22.  0.  0.  3. 11.  3.  0.  8.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7244588136672974
desired expected reward: 28.671382904052734



buy possibilites: [-1] 
expected returns: [[30.708128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0. 10.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [15. 10.  8. 15. 10.] 
adversary cards in discard: [10. 16.  1. 14.  3.  0. 11. 22.  0.  0.  3. 11.  3.  0.  8.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -12   0   0   8   0] 
sum of rewards: -9 

action type: buy - action 3.0
Learning step: -0.8174717426300049
desired expected reward: 28.360448837280273






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [15. 10.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8. 15. 10.] 
cards in discard: [10. 16.  1. 14.  3.  0. 11. 22.  0.  0.  3. 11.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 47 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 15. 10.] 
cards in discard: [10. 16.  1. 14.  3.  0. 11. 22.  0.  0.  3. 11.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 47 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 15. 10.] 
cards in discard: [10. 16.  1. 14.  3.  0. 11. 22.  0.  0.  3. 11.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [23.  8.  0.  0.  3.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 47 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [23.  8.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[24.042414]
 [23.834497]
 [23.77258 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  0.  0.  3.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  3  0 10  0  1 11 16  8 11  3 14  8  6
  6  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 16.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8201361894607544
desired expected reward: 29.887990951538086



action possibilites: [-1] 
expected returns: [[21.860497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 16.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.030270365998148918
desired expected reward: 23.629915237426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[21.874273]
 [21.9479  ]
 [21.955448]
 [22.225285]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 16.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.02566429041326046
desired expected reward: 21.886159896850586






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11  0 14  0  0 10  0  0  1 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [14. 16.  1. 29.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 17. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [14. 16.  1. 29.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 17. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [14. 16.  1. 29.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [14. 16.  1. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 29.] 
expected returns: [[21.149237]
 [20.889574]
 [20.847246]
 [21.03277 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  1. 29.  6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 17. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [10.  1.  3. 10. 11.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5961155295372009
desired expected reward: 21.629167556762695



action possibilites: [-1] 
expected returns: [[28.021296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1. 29.  6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 17. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 10. 11.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.11753642559051514
desired expected reward: 21.007108688354492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.545898]
 [27.623295]
 [27.61953 ]
 [27.59492 ]
 [27.707216]
 [27.627079]
 [27.780445]
 [27.637249]
 [27.623312]
 [27.721153]
 [27.896914]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1. 29.  6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 26. 30. 17. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 10. 11.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09962201863527298
desired expected reward: 27.921672821044922



buy possibilites: [-1] 
expected returns: [[25.043459]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1. 29.  6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 10. 11.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -12.   0.   0.
   2.   0.] 
sum of rewards: 5.0 

action type: buy - action 3.0
Learning step: -0.41562962532043457
desired expected reward: 27.203901290893555






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3] -> size -> 47 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 11 14  0  0 10  0  0  1 11  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3] -> size -> 47 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3] -> size -> 47 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 11.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3] -> size -> 47 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [ 6.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.887392]
 [27.697695]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.  0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  7.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 22. 10.  3. 14.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6092828512191772
desired expected reward: 24.434175491333008



action possibilites: [-1] 
expected returns: [[29.52168]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 22. 10.  3. 14.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -13   0   0  16   0] 
sum of rewards: 18 

action type: gain_card_n - action 7
Learning step: 0.021259402856230736
desired expected reward: 27.645200729370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[29.170668]
 [29.244299]
 [29.251844]
 [29.52168 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  3. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 22. 10.  3. 14.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.12755905091762543
desired expected reward: 29.394121170043945



buy possibilites: [-1] 
expected returns: [[27.859568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 22. 10.  3. 14.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -14   0   0   8   0] 
sum of rewards: 9 

action type: buy - action 8.0
Learning step: -0.31502991914749146
desired expected reward: 28.936817169189453






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 3. 22. 10.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22. 10.  3. 14.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16. 15. 11. 10.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22. 10.  3.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [11. 10.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22. 10.  3.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [11. 10.  0.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[26.7617  ]
 [26.572004]
 [26.4881  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0   -14
     0 -2400   142     0] 
sum of rewards: -2277 

action type: discard_down_to_3_cards - action 7
Learning step: -68.6270980834961
desired expected reward: -48.733741760253906



action possibilites: [-1. 11.] 
expected returns: [[26.532522]
 [26.34542 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.06201925128698349
desired expected reward: 26.42608070373535





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.185122]
 [26.532522]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  0. 15. 11.  0.] 
adversary cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.06884313374757767
desired expected reward: 26.463674545288086






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [15.  0. 15. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15. 11.  0.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  2.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  8.  1. 10.  8.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  0.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  1.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  8.  1. 10.  8.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  1.  2.  2. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  8.  1. 10.  8.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  0.] 
cards in discard: [ 3. 16.  0.  3. 29.  1. 10. 10.  8.  3. 14.  3. 22. 10.  3. 16.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [15.  8.  1. 10.  8.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
adversary victory points: -3
player victory points: 5 





Player: 0 
cards in hand: [15.  8.  1. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.  8.] 
expected returns: [[25.32376 ]
 [25.150776]
 [25.057241]
 [25.053753]
 [25.057241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  1. 10.  8.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10.  1.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6817157864570618
desired expected reward: 25.85080337524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.97636 ]
 [25.049759]
 [25.057241]
 [25.323757]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  1. 10.  8.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10.  1.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6456778645515442
desired expected reward: 24.67807960510254



buy possibilites: [-1] 
expected returns: [[25.869825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  1. 10.  8.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10.  1.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -15.   0.   0.
   0.   0.] 
sum of rewards: -20.0 

action type: buy - action 0.0
Learning step: -1.077657699584961
desired expected reward: 23.898704528808594






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10.  1.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  6.  0. 16.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8  0] -> size -> 50 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  6.  0. 16.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8  0] -> size -> 50 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 16. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  6.  0. 16.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8  0] -> size -> 50 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 0. 3.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 15. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 6.  6.  0. 16.  6.] 
adversary cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8  0] -> size -> 50 
adversary victory points: -3
player victory points: 6 





Player: 0 
cards in hand: [ 6.  6.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[24.443686]
 [24.145037]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 16.  6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14
  8  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 15. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  0. 15.  0. 10.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8
  3] -> size -> 25 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6706903576850891
desired expected reward: 25.199134826660156



action possibilites: [-1] 
expected returns: [[26.19155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  0. 15.  0. 10.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8
  3] -> size -> 25 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -15   0   0   4   0] 
sum of rewards: 4 

action type: gain_card_n - action 1
Learning step: -0.4542163908481598
desired expected reward: 27.85337257385254





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.844152]
 [26.19155 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [16.  0.  0.  6.  3.  0.  3. 11.  0.  6.  0. 10.  8. 23.  0.  0.  3. 14.
 16.  1. 29.  6. 14.  8. 11.  6.  0.  3.  0. 16. 15. 10. 11.  0.  3.  0.
 15.  8.  1. 10.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  0. 15.  0. 10.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8
  3] -> size -> 25 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06219428777694702
desired expected reward: 26.12935447692871






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0. 10.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0  0 10  0  0  1 11  3 16  8
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0 10  0  0  1 11  3 16  8  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0 10  0  0  1 11  3 16  8  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  2.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0 10  0  0  1 11  3 16  8  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  0.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [16.  0.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[27.064188]
 [26.76554 ]
 [26.877089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  6. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16. 14. 29. 22.  8.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0 10  0  0  1 11  3 16  8  3
 11] -> size -> 25 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6529325842857361
desired expected reward: 25.538616180419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[26.964813]
 [27.041702]
 [27.03821 ]
 [27.12511 ]
 [27.045692]
 [27.042204]
 [27.312208]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1.  6. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16. 14. 29. 22.  8.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0 10  0  0  1 11  3 16  8  3
 11] -> size -> 25 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6770859956741333
desired expected reward: 26.387102127075195



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [16. 14. 29. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 29. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14. 29. 22.  8.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8 16 14  0 10  0  0  1 11  3 16  8  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  6. 16.  6.  8.] 
adversary cards in discard: [16.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 22.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  6. 16.  6.  8.] 
adversary cards in discard: [16.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 22.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  6. 16.  6.  8.] 
adversary cards in discard: [16.  0.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6. 16.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[28.285198]
 [27.986547]
 [28.01868 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  6.  8.] 
cards in discard: [16.  0.  1.  6. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  8. 10. 11.  0.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6739541888237
desired expected reward: 26.638256072998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.926321]
 [28.273718]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  6.  8.] 
cards in discard: [16.  0.  1.  6. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  8. 10. 11.  0.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.703140914440155
desired expected reward: 27.582056045532227



buy possibilites: [-1] 
expected returns: [[25.807398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  6.  8.] 
cards in discard: [16.  0.  1.  6. 11.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [16.  8. 10. 11.  0.] 
adversary cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22.] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: -21.0 

action type: buy - action 0.0
Learning step: -1.1968119144439697
desired expected reward: 26.729509353637695






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [16.  8. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 10. 11.  0.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [0. 6. 3. 0. 8.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1. 16.  8. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 11.  0.  3.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1 11  3 16  8  3 11] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  1.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [0. 6. 3. 0. 8.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
adversary victory points: -1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [0. 6. 3. 0. 8.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [ 3. 10.  1.  3.  8.  0.  3. 11. 15.  3.  0. 10.  8. 29. 22. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [0. 6. 3. 0. 8.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
adversary victory points: -1
player victory points: 6 





Player: 0 
cards in hand: [0. 6. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.739712]
 [18.473194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 8.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10. 11.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.728574275970459
desired expected reward: 25.07882308959961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.32688 ]
 [18.400276]
 [18.40776 ]
 [18.674276]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 8.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 14. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10. 11.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5179759860038757
desired expected reward: 18.22173309326172



buy possibilites: [-1] 
expected returns: [[21.944693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 8.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [10. 11.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -17   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 3.0
Learning step: -0.7299017310142517
desired expected reward: 17.280797958374023






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [10. 11.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3. 15.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 15 10 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14. 10.  3.  3.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14. 10.  3.  3.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14. 10.  3.  3.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 14. 10.  3.  3.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0. 14. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[19.392237]
 [19.139502]
 [19.125305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 10.  3.  3.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  0.  3. 10. 10.] 
adversary cards in discard: [ 0.  8. 11.  3.] 
adversary owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6061773300170898
desired expected reward: 21.338516235351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.04785 ]
 [19.392237]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 10.  3.  3.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 3.  0.  3. 10. 10.] 
adversary cards in discard: [ 0.  8. 11.  3.] 
adversary owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5295950174331665
desired expected reward: 18.862642288208008



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [ 0.  8. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 1. 15.  8.  6.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10. 10.] 
cards in discard: [ 0.  8. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 1. 15.  8.  6.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
adversary victory points: 0
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 15.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[22.725737]
 [22.555063]
 [22.462051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  8.  6.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [29. 15. 16.  3. 22.] 
adversary cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10.] 
adversary owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.49436306953430176
desired expected reward: 18.897872924804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[22.38135 ]
 [22.457777]
 [22.454529]
 [22.462051]
 [22.458807]
 [22.725739]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  8.  6.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 26. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [29. 15. 16.  3. 22.] 
adversary cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10.] 
adversary owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5951316356658936
desired expected reward: 22.130603790283203



buy possibilites: [-1] 
expected returns: [[25.401623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  8.  6.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [29. 15. 16.  3. 22.] 
adversary cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10.] 
adversary owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -18   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 1.0
Learning step: -0.5570161938667297
desired expected reward: 21.900758743286133






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [29. 15. 16.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 16. 22.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 16.  3. 22.] 
cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [22  3 29  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  9.  3.  9.  6.] 
adversary cards in hand: [ 0.  3.  6. 11. 23.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1] -> size -> 53 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 22.] 
cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 0.  3.  6. 11. 23.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1] -> size -> 53 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 22.] 
cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 0.  3.  6. 11. 23.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1] -> size -> 53 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3.  6. 11. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
expected returns: [[24.102459]
 [23.917587]
 [23.899551]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11. 23.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 8.  8.  1. 11.  0.] 
adversary cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23. 16. 15.  3. 22.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6600586175918579
desired expected reward: 24.74156379699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.758072]
 [24.102459]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11. 23.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 8.  8.  1. 11.  0.] 
adversary cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23. 16. 15.  3. 22.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6214444041252136
desired expected reward: 23.481014251708984



buy possibilites: [-1] 
expected returns: [[21.736023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11. 23.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 8.  8.  1. 11.  0.] 
adversary cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23. 16. 15.  3. 22.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -19.   0.   0.
   0.   0.] 
sum of rewards: -24.0 

action type: buy - action 0.0
Learning step: -1.2045140266418457
desired expected reward: 22.553560256958008






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1. 11.  0.] 
cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23. 16. 15.  3. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [14.  0.  3.  8. 15.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0] -> size -> 54 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  1. 11.  0.] 
cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23. 16. 15.  3. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 25. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [14.  0.  3.  8. 15.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0] -> size -> 54 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  1. 11.  0.] 
cards in discard: [ 0.  8. 11.  3.  3.  0.  3. 10. 10. 23. 16. 15.  3. 22.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [14.  0.  3.  8. 15.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0] -> size -> 54 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [14.  0.  3.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.] 
expected returns: [[23.393166]
 [23.14043 ]
 [23.12948 ]
 [23.222492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  8. 15.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 1. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5578953623771667
desired expected reward: 21.17812728881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.048779]
 [23.393166]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  8. 15.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 1. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6076130867004395
desired expected reward: 22.785552978515625



buy possibilites: [-1] 
expected returns: [[21.508556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  8. 15.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 1. 10.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -20.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -1.2156234979629517
desired expected reward: 21.83315658569336






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  9.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 0.  3. 16.  0.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[23.440187]
 [23.144268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 8. 10. 23.  8. 15.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.550377607345581
desired expected reward: 20.958179473876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[23.0958  ]
 [23.172226]
 [23.168978]
 [23.1765  ]
 [23.173256]
 [23.44019 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 8. 10. 23.  8. 15.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.609063446521759
desired expected reward: 22.83112144470215



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 23.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 23.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 23.  8. 15.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [16. 29.  0. 11.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 23.  8. 15.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [16. 29.  0. 11.  0.] 
adversary cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
adversary victory points: 0
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16. 29.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 11.] 
expected returns: [[19.571142]
 [19.275225]
 [19.457817]
 [19.386272]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0. 11.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 16.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6489561796188354
desired expected reward: 22.791229248046875



action possibilites: [-1. 16. 11.] 
expected returns: [[19.52209 ]
 [19.230303]
 [19.339994]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 23 11 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6
  6 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8
  0  3  0  3  1  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 13. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 16.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.10356313735246658
desired expected reward: 18.439960479736328



action possibilites: [-1] 
expected returns: [[18.531008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 16.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -20   0   0   4   0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.17045001685619354
desired expected reward: 19.97463607788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[18.191298]
 [18.263647]
 [18.271212]
 [18.531008]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 16.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6868248581886292
desired expected reward: 19.217832565307617



buy possibilites: [-1] 
expected returns: [[18.126116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  0.  1.  6. 11.  0.  0.  6. 16.  6.  8.  3.  0.  6.  3.  0.  8.  0.
 14. 10.  3.  3.  1.  1. 15.  8.  6.  0.  0.  0.  3.  6. 11. 23.  0. 14.
  0.  3.  8. 15.  0.  3. 16.  0.  0.  0. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3. 11.  3.  3. 16.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0. -21.   0.   0.
   0.   0.] 
sum of rewards: 14.0 

action type: buy - action 0.0
Learning step: 0.06458530575037003
desired expected reward: 18.255882263183594






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3. 16.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3.  1.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3. 16.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 3.  1.  6. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  1.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[21.812723]
 [21.549837]
 [21.630625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6. 10. 11.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [22.  3. 11.  0.  0.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.  3. 11.  3.  3. 16.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.46599581837654114
desired expected reward: 17.660120010375977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[21.484058]
 [21.556408]
 [21.563974]
 [21.82377 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  6. 10. 11.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [22.  3. 11.  0.  0.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.  3. 11.  3.  3. 16.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5770525336265564
desired expected reward: 21.23567008972168



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [22.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3. 11.  0.  0.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.  3. 11.  3.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  3.  8.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  1.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.  3. 11.  3.  3. 16. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  2.  8.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  1.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.  0.] 
cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.  3. 11.  3.  3. 16. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  1. 10.  7.  6.  8.  2.  8.  6.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  1.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
adversary victory points: 1
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 3 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 3 
Workshop: 3 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 1 
Village: 3 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 3.  1.  6. 10. 11.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 23 11  1 10  0  0 10  0  1 11 16  8 11  3 14  8  6  6  6
 10  6  6 16  6  6  1 15 15  3 16  0  8  3 29  0  0 16  0  3  3 14  8  0
  3  0  3  1  0  0  3  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 12. 30.  8.  0.  1.  0.  0. 10.  7.  6.  8.  2.  8.  6.] 
adversary cards in hand: [22.  3.  0.  0.] 
adversary cards in discard: [22. 10.  1.  0.  3.  3.  1.  8. 10. 23.  8. 15.  3. 11.  3.  3. 16. 10.
  8.] 
adversary owned cards: [22  3  3 15  8  3  3 10  8  0 10  0  0  1  3 16  8  3 11 11  0 23  1 22
 10  8] -> size -> 26 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.804713249206543
desired expected reward: 6.019057273864746



