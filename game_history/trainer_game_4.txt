 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[332.80847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -605 

action type: buy - action -1
Learning step: -30.567005157470703
desired expected reward: -24.226943969726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[319.7091 ]
 [321.029  ]
 [321.9154 ]
 [321.29575]
 [321.22372]
 [323.81866]
 [321.43732]
 [325.497  ]
 [323.199  ]
 [322.32376]
 [324.69385]
 [332.00592]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.035794258117676
desired expected reward: 325.29541015625



buy possibilites: [-1] 
expected returns: [[335.98877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 1.0
Learning step: -8.866703987121582
desired expected reward: 312.1623229980469






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.32224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.029115676879883
desired expected reward: 325.95965576171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[341.4244 ]
 [342.7443 ]
 [343.63074]
 [343.01108]
 [345.53397]
 [343.15265]
 [344.03906]
 [353.72122]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.773992538452148
desired expected reward: 339.0181579589844



buy possibilites: [-1] 
expected returns: [[329.95123]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -4 

action type: buy - action 11.0
Learning step: -10.05279541015625
desired expected reward: 335.4811706542969






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[330.06055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.10120677947998
desired expected reward: 319.85003662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[319.12634]
 [320.44626]
 [321.3327 ]
 [320.713  ]
 [320.64096]
 [323.23593]
 [320.85455]
 [324.91428]
 [322.61624]
 [321.74103]
 [324.1111 ]
 [331.42316]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.440913200378418
desired expected reward: 322.73040771484375



buy possibilites: [-1] 
expected returns: [[303.55002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 10 

action type: buy - action 29.0
Learning step: -8.915837287902832
desired expected reward: 315.9984130859375






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  3.  0.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.151]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -9.035075187683105
desired expected reward: 294.51495361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[312.96246]
 [314.2824 ]
 [315.16885]
 [314.54913]
 [314.47705]
 [317.07202]
 [314.6907 ]
 [318.7504 ]
 [316.4523 ]
 [315.57712]
 [317.94727]
 [325.2593 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.015313148498535
desired expected reward: 311.8702697753906



buy possibilites: [-1] 
expected returns: [[318.0372]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 10 

action type: buy - action 29.0
Learning step: -8.281682014465332
desired expected reward: 310.46868896484375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0.  3.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[325.98297]
 [317.79575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [10.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.205647468566895
desired expected reward: 307.83154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[311.22043]
 [312.5404 ]
 [313.42682]
 [312.80713]
 [312.73505]
 [315.33005]
 [312.94867]
 [317.00836]
 [314.71033]
 [313.8351 ]
 [316.20526]
 [323.51727]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [10.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -10.81766414642334
desired expected reward: 316.3310546875



buy possibilites: [-1] 
expected returns: [[319.27936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [10.  3. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -27.5 

action type: buy - action 11.0
Learning step: -9.957714080810547
desired expected reward: 305.3722839355469






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [10.  3. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [11.  0.  3.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [10.  3. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [11.  0.  3.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [10.  3. 11.  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 29.  0.] 
adversary cards in discard: [11.  0.  3.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[338.98718]
 [332.47827]
 [332.47827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  0.] 
cards in discard: [11.  0.  3.  1. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -10.018757820129395
desired expected reward: 309.2605895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[323.94684]
 [326.1532 ]
 [325.53354]
 [325.6751 ]
 [336.24368]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 29.  0.] 
cards in discard: [11.  0.  3.  1. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.091788291931152
desired expected reward: 327.2958679199219



buy possibilites: [-1] 
expected returns: [[368.98282]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 29.  0.] 
cards in discard: [11.  0.  3.  1. 11.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0] -> size -> 17 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -343.0 

action type: buy - action 6.0
Learning step: -24.87423324584961
desired expected reward: 295.6526794433594






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  9. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0.] 
cards in discard: [3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[289.57468]
 [283.08768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -14.650856018066406
desired expected reward: 354.33197021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[276.8844 ]
 [278.19324]
 [279.07285]
 [278.45532]
 [280.97397]
 [278.60507]
 [279.48468]
 [289.13876]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 10.  0.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -10.730401992797852
desired expected reward: 278.1361389160156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [ 3.  8. 11.  0.  3.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 10.  0.] 
cards in discard: [ 3.  8. 11.  0.  3.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[289.23044]
 [281.0656 ]
 [282.74344]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  0.] 
cards in discard: [29.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  8.  0.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -10.684212684631348
desired expected reward: 278.4545593261719



action possibilites: [-1] 
expected returns: [[278.0004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.] 
cards in discard: [29.  3.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  8.  0.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -24 

action type: gain_card_n - action 1
Learning step: -8.842387199401855
desired expected reward: 269.10552978515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[268.15524]
 [269.4641 ]
 [270.34375]
 [269.7262 ]
 [272.24484]
 [269.87595]
 [270.75552]
 [280.40967]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.] 
cards in discard: [29.  3.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8. 11.  0.  3.  8.  0.  3.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -9.383498191833496
desired expected reward: 268.6169128417969






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  8. 11.  0.  3.  8.  0.  3.  3.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 11.  3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1] -> size -> 17 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  8. 11.  0.  3.  8.  0.  3.  3.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 11.  3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1] -> size -> 17 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  8. 11.  0.  3.  8.  0.  3.  3.  0. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  6. 11.  3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1] -> size -> 17 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 1.  0.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[246.71153]
 [238.54672]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 11.  3.] 
cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -11.228266716003418
desired expected reward: 269.181396484375



action possibilites: [-1] 
expected returns: [[234.26355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -29 

action type: gain_card_n - action 6
Learning step: -7.88385009765625
desired expected reward: 226.2117462158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[226.66171]
 [227.97055]
 [228.85017]
 [228.23262]
 [230.75127]
 [228.38239]
 [229.26198]
 [238.91609]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  7. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -8.130261421203613
desired expected reward: 226.13328552246094



buy possibilites: [-1] 
expected returns: [[211.49162]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [29.  3.  0.  0.  0.  1. 11. 29.  0.  0.  0.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -31.0 

action type: buy - action 8.0
Learning step: -8.21055793762207
desired expected reward: 220.17181396484375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8] -> size -> 19 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8] -> size -> 19 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8] -> size -> 19 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 1.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[262.83334]
 [256.34634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -7.369889736175537
desired expected reward: 204.12173461914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[253.81624]
 [255.1251 ]
 [256.0047 ]
 [255.38718]
 [255.32146]
 [257.90585]
 [255.5369 ]
 [259.58365]
 [257.2883 ]
 [256.4165 ]
 [258.7776 ]
 [266.07065]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -9.926600456237793
desired expected reward: 252.5579833984375



buy possibilites: [-1] 
expected returns: [[247.44957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 29.  3.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -48.5 

action type: buy - action 1.0
Learning step: -9.613638877868652
desired expected reward: 245.51144409179688






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  3.] 
adversary cards in discard: [ 1.  1.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  3.] 
adversary cards in discard: [ 1.  1.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  0.  3.] 
adversary cards in discard: [ 1.  1.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 8.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[247.20891]
 [236.67517]
 [239.04405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  3.] 
cards in discard: [ 1.  1.  0.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0. 10.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -9.573307991027832
desired expected reward: 237.8762664794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.7596 ]
 [226.88339]
 [226.27553]
 [226.43767]
 [236.74493]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.  3.] 
cards in discard: [ 1.  1.  0.  0. 29.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0. 10.  3.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -9.165345191955566
desired expected reward: 224.98486328125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 10.  3.  0.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8 11 10  3  0  3  8  1 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  6.  8.  0.] 
adversary cards in discard: [ 1.  1.  0.  0. 29.  3.  8.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  0.  0.  0.  3.  0. 10.  3.  0.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  6.  8.  0.] 
adversary cards in discard: [ 1.  1.  0.  0. 29.  3.  8.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.  0.  0.  3.  0. 10.  3.  0.  0. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  1.  6.  8.  0.] 
adversary cards in discard: [ 1.  1.  0.  0. 29.  3.  8.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [29.  1.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[180.99216]
 [174.64758]
 [170.6849 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  6.  8.  0.] 
cards in discard: [ 1.  1.  0.  0. 29.  3.  8.  0. 11.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -9.04616928100586
desired expected reward: 227.69876098632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[171.0746 ]
 [172.34572]
 [173.19841]
 [172.59055]
 [175.06363]
 [172.75266]
 [173.60538]
 [183.05994]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  6.  8.  0.] 
cards in discard: [ 1.  1.  0.  0. 29.  3.  8.  0. 11.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -6.123561859130859
desired expected reward: 172.9304656982422



buy possibilites: [-1] 
expected returns: [[262.33047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  6.  8.  0.] 
cards in discard: [ 1.  1.  0.  0. 29.  3.  8.  0. 11.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 10.0
Learning step: -3.0278332233428955
desired expected reward: 170.57754516601562






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 26. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [11. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[305.77948]
 [297.78314]
 [297.78314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [3. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -7.997661113739014
desired expected reward: 254.3328094482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[290.51837]
 [292.64218]
 [292.0343 ]
 [292.19647]
 [302.50372]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  6. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [3. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -10.207221984863281
desired expected reward: 294.3719787597656



buy possibilites: [-1] 
expected returns: [[311.2487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.  0.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [3. 8. 1. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 8.0
Learning step: -8.85672664642334
desired expected reward: 283.3397216796875






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [3. 8. 1. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [3. 8. 1. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 1. 8.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 8. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[335.56912]
 [325.26184]
 [325.26184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 8.] 
cards in discard: [ 8. 11. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [ 3.  8.  1.  3.  3.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -9.792976379394531
desired expected reward: 301.4557189941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[320.841  ]
 [322.11212]
 [322.9648 ]
 [322.35693]
 [322.308  ]
 [324.83002]
 [322.5191 ]
 [326.48178]
 [324.22217]
 [323.3718 ]
 [325.6804 ]
 [332.8264 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 8.] 
cards in discard: [ 8. 11. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10.  0.  0.  0.] 
adversary cards in discard: [ 3.  8.  1.  3.  3.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -11.026239395141602
desired expected reward: 323.54937744140625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [29. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0.  0.] 
cards in discard: [ 3.  8.  1.  3.  3.  0.  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0.  0.] 
cards in discard: [ 3.  8.  1.  3.  3.  0.  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0.  0.] 
cards in discard: [ 3.  8.  1.  3.  3.  0.  3. 11.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [1. 3. 3. 1. 0.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [1. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[255.3573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 1. 0.] 
cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  1. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -12.585990905761719
desired expected reward: 320.2403564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[244.40475]
 [245.67587]
 [246.52858]
 [245.06802]
 [245.92068]
 [245.87169]
 [248.39374]
 [246.08284]
 [249.19518]
 [250.04549]
 [247.7859 ]
 [249.033  ]
 [246.93553]
 [247.57477]
 [249.24413]
 [256.3901 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 1. 0.] 
cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  1. 11.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.69599437713623
desired expected reward: 244.8740692138672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 8.  1. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29. 10. 29.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.  1.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8. 0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29. 10. 29.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.  1.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  5. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29. 10. 29.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.  1.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 0.] 
cards in discard: [1. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29. 10. 29.] 
adversary cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.  1.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 0.  6. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[230.04407]
 [223.6995 ]
 [220.58951]
 [223.6995 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 10. 29.] 
cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.  1.  3.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -9.40436840057373
desired expected reward: 246.98573303222656



action possibilites: [-1. 10. 29.] 
expected returns: [[286.09586]
 [276.64133]
 [279.75128]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 29.  0.] 
cards in discard: [ 8. 11. 11.  3.  0.  0.  0.  8.  0.  1.  8.  1.  3.  3.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -12 

action type: take_action - action 29.0
Learning step: -5.37885856628418
desired expected reward: 217.2784423828125



action possibilites: [-1. 29.] 
expected returns: [[241.4999 ]
 [235.15532]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  40   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -8.0484037399292
desired expected reward: 268.5928955078125



action possibilites: [-1.] 
expected returns: [[281.71725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 2 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  60   0   0   0   0   0   0   0   0   2] 
sum of rewards: 29 

action type: take_action - action 29.0
Learning step: -3.9691269397735596
desired expected reward: 231.18617248535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[270.4719 ]
 [271.74298]
 [271.13745]
 [272.5957 ]
 [271.1351 ]
 [271.9878 ]
 [271.93884]
 [274.4609 ]
 [272.14993]
 [275.26227]
 [276.11258]
 [273.853  ]
 [275.10013]
 [273.00266]
 [273.64188]
 [275.31122]
 [282.4572 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  3.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -6.519341945648193
desired expected reward: 275.1979064941406






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  3.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[258.28183]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -9.458510398864746
desired expected reward: 262.14642333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[248.67464]
 [250.73802]
 [250.1369 ]
 [250.30891]
 [260.36646]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 25. 30.  8.  9. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.749223709106445
desired expected reward: 247.7724151611328



buy possibilites: [-1] 
expected returns: [[181.54253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3. 10.] 
adversary cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -344.0 

action type: buy - action 6.0
Learning step: -25.62213706970215
desired expected reward: 224.51475524902344






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 10.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  4. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 1.  8. 11.  8.  1.  8.  0. 10. 29.  0.  0.  3.  3.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  1.] 
adversary cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 8. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[218.93855]
 [208.88103]
 [211.13445]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  1.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -6.461769104003906
desired expected reward: 175.08074951171875



action possibilites: [-1] 
expected returns: [[241.0382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 2
Learning step: -6.104520320892334
desired expected reward: 200.4530792236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[229.76532]
 [231.00175]
 [231.8287 ]
 [231.22755]
 [233.653  ]
 [231.39961]
 [232.22653]
 [241.45709]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -7.955496311187744
desired expected reward: 233.08270263671875



buy possibilites: [-1] 
expected returns: [[234.24959]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.] 
cards in discard: [29. 10. 29.  0.  6.  0.  0.  1.  6.  0.  3.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -54.0 

action type: buy - action 0.0
Learning step: -8.917651176452637
desired expected reward: 220.84768676757812






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 10.  8.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  8.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
expected returns: [[264.35202]
 [254.29446]
 [254.29446]
 [256.54788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  8. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -8.083412170410156
desired expected reward: 226.16616821289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[254.42386]
 [255.6603 ]
 [256.48727]
 [255.88611]
 [258.31158]
 [256.0582 ]
 [256.8851 ]
 [266.11566]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  8. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  3. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -9.547146797180176
desired expected reward: 254.42041015625



buy possibilites: [-1] 
expected returns: [[218.06607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  8. 11.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -42.0 

action type: buy - action 8.0
Learning step: -9.996421813964844
desired expected reward: 246.06173706054688






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  3.  3.  0. 11.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8] -> size -> 24 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[207.2051 ]
 [199.40102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  0. 11.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -8.52026653289795
desired expected reward: 209.54580688476562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[197.68385]
 [199.14607]
 [209.37563]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  0. 11.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 25. 30.  8.  8. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.925856113433838
desired expected reward: 198.50286865234375



buy possibilites: [-1] 
expected returns: [[207.93437]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  0. 11.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  8.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -23.02878189086914
desired expected reward: 176.11729431152344






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  8.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 11 10  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [0. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[275.44504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 11.  1. 10.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.972210884094238
desired expected reward: 200.962158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[273.46082]
 [274.69727]
 [274.09772]
 [275.5242 ]
 [274.0961 ]
 [274.92307]
 [274.88675]
 [277.34854]
 [275.0951 ]
 [278.13754]
 [278.9629 ]
 [276.74734]
 [277.96548]
 [275.92206]
 [276.53903]
 [278.17383]
 [285.15262]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 11.  1. 10.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -10.190668106079102
desired expected reward: 264.2319030761719



buy possibilites: [-1] 
expected returns: [[244.33124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 11.  1. 10.] 
adversary cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -50.5 

action type: buy - action 11.0
Learning step: -10.292242050170898
desired expected reward: 255.00164794921875






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  1. 10.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 29.  3.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  1.  3.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 29.  3.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  1.  3.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 29.  3.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  1.  3.] 
cards in discard: [ 0.  0.  8.  3. 10.  8.  3.  3.  0.  0. 29.  0.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  6. 29.  3.] 
adversary cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 8.  0.  6. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[233.70578]
 [223.88548]
 [227.6651 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 29.  3.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.  0.  1.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -9.791658401489258
desired expected reward: 234.53958129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[220.8429 ]
 [222.25089]
 [232.25781]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6. 29.  3.] 
cards in discard: [ 8.  0.  8.  1.  8. 11.  6.  6.  3.  3.  0. 11. 11.  0.  1.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -9.322230339050293
desired expected reward: 224.383544921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  3.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29.] 
expected returns: [[218.4678 ]
 [208.64748]
 [209.44812]
 [212.42712]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  3.] 
adversary cards in discard: [10.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -9.560684204101562
desired expected reward: 222.69712829589844



action possibilites: [-1.  8. 10.] 
expected returns: [[207.5213 ]
 [197.70099]
 [198.50163]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 29 29 11  6  1  8  8  1 10  8  6  0  8
  6 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  3.] 
adversary cards in discard: [10.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: -7.76770544052124
desired expected reward: 203.9879150390625



action possibilites: [-1] 
expected returns: [[209.38116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  3.] 
adversary cards in discard: [10.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 11
Learning step: -5.936591148376465
desired expected reward: 192.01675415039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[198.86244]
 [200.86784]
 [200.27046]
 [200.45709]
 [210.2774 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  3.] 
adversary cards in discard: [10.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -6.616185665130615
desired expected reward: 202.76498413085938



buy possibilites: [-1] 
expected returns: [[219.3833]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  0.  3.  3.] 
adversary cards in discard: [10.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: -7.256999492645264
desired expected reward: 191.60545349121094






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  3.] 
cards in discard: [10.  8.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11.  1.] 
adversary cards in discard: [ 0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0] -> size -> 24 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  3.] 
cards in discard: [10.  8.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11.  1.] 
adversary cards in discard: [ 0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0] -> size -> 24 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  0. 11. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[212.40839]
 [204.78633]
 [204.78633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 11.  1.] 
cards in discard: [ 0. 29.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 3. 3. 8. 1.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -9.066776275634766
desired expected reward: 210.3165283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[198.39584]
 [199.60062]
 [200.40126]
 [199.80388]
 [202.18874]
 [199.9905 ]
 [200.7911 ]
 [209.81079]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 11.  1.] 
cards in discard: [ 0. 29.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 25. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 3. 3. 8. 1.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -8.679412841796875
desired expected reward: 201.6591796875



buy possibilites: [-1] 
expected returns: [[127.21723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11. 11.  1.] 
cards in discard: [ 0. 29.  8.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [1. 3. 3. 8. 1.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -42.0 

action type: buy - action 3.0
Learning step: -9.25767707824707
desired expected reward: 191.1436004638672






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 8. 1.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0
  3] -> size -> 25 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 8. 1.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0
  3] -> size -> 25 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 8. 1.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0
  3] -> size -> 25 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[176.35602]
 [168.73395]
 [166.54706]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.  0.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 11 29 29 11  1  8  8  1  8  6  0  8  6 11  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -4.707078456878662
desired expected reward: 122.5101547241211



action possibilites: [-1] 
expected returns: [[209.44316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.6738200187683105
desired expected reward: 159.052001953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.77011]
 [202.97487]
 [203.7755 ]
 [203.17812]
 [205.56297]
 [203.36472]
 [204.16537]
 [213.18506]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  6.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -7.008720397949219
desired expected reward: 202.4344482421875



buy possibilites: [-1] 
expected returns: [[170.8838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 11.0
Learning step: -6.043321132659912
desired expected reward: 185.72080993652344






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10.  8.  0.  8.  3. 10. 10.  0.  3.  3.  0.  1.  3.  3.  8.  1. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[161.14578]
 [155.27786]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  1.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -7.16473388671875
desired expected reward: 163.7190704345703



action possibilites: [-1.] 
expected returns: [[175.29436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 1.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -22 

action type: take_action - action 29.0
Learning step: -4.919770240783691
desired expected reward: 150.35809326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[172.30156]
 [173.4629 ]
 [172.87553]
 [174.23332]
 [172.87666]
 [173.64711]
 [173.64479]
 [175.97192]
 [173.8437 ]
 [176.7412 ]
 [177.51279]
 [175.3857 ]
 [176.54462]
 [174.61414]
 [175.18678]
 [176.7435 ]
 [183.38069]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 1.] 
cards in discard: [ 0. 29.  8.  0.  3.  6.  0. 11. 11.  1. 11.  8.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.96729040145874
desired expected reward: 169.3270721435547






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 24. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  8.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 6. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[177.01392]
 [167.47691]
 [167.47691]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  8  1  8  6  0  8  6 11  0  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: -8.032254219055176
desired expected reward: 175.34844970703125



action possibilites: [-1] 
expected returns: [[187.42618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: trash_cards_n_from_hand - action 5
Learning step: -5.265775203704834
desired expected reward: 161.39151000976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[176.65738]
 [178.00293]
 [187.73651]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  7. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1
Learning step: -6.406773567199707
desired expected reward: 181.0194091796875



buy possibilites: [-1] 
expected returns: [[185.58487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  6. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -21.424488067626953
desired expected reward: 156.5784454345703






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [1. 0. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 8.] 
cards in discard: [ 3. 10.  8.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  6. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  1.] 
adversary cards in discard: [6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 24 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 8.] 
cards in discard: [ 3. 10.  8.  0.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 30. 23. 30.  8.  6. 10.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  1.] 
adversary cards in discard: [6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 24 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 8.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  6.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 11.  1.] 
adversary cards in discard: [6. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 24 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 8.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[204.0043 ]
 [194.4673 ]
 [196.59552]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 11.  1.] 
cards in discard: [6. 8. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  6.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10. 29. 10.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -7.498726844787598
desired expected reward: 178.0861358642578



action possibilites: [-1] 
expected returns: [[158.75845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [6. 8. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  6.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10. 29. 10.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: trash_cards_n_from_hand - action 9
Learning step: -7.798886775970459
desired expected reward: 185.62014770507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[148.45853]
 [149.78633]
 [159.49258]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [6. 8. 0. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  6.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10. 29. 10.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: -6.15849494934082
desired expected reward: 152.59996032714844



buy possibilites: [-1] 
expected returns: [[112.96506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [6. 8. 0. 3. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10. 29. 10.  3.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -345 

action type: buy - action 6.0
Learning step: -22.197601318359375
desired expected reward: 127.58871459960938






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [14. 10. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 29. 10.  3.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 14. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29. 10.  3.  3.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  3.  3.  0.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1.  6.  0.  0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 29. 14.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 14. 10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 2 
buys: 0 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 14. 10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 23. 30.  8.  5.  9.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 29. 14. 10.] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [1. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[147.23816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0.] 
cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8. 16. 10. 29. 14. 10.  3.
  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: discard_down_to_3_cards - action 1
Learning step: -6.4597320556640625
desired expected reward: 123.4918212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[127.11702]
 [128.2442 ]
 [128.99191]
 [128.41063]
 [130.6928 ]
 [128.61664]
 [129.36436]
 [137.94255]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8. 16. 10. 29. 14. 10.  3.
  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -7.1166839599609375
desired expected reward: 129.7585906982422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8. 16. 10. 29. 14. 10.  3.
  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  1.  0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 3. 10.  8.  0.  8.  0. 16.  1.  0.  1.  3.  8. 16. 10. 29. 14. 10.  3.
  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  1.  0.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  8.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[148.18968]
 [142.44844]
 [138.8638 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  1.  0.] 
cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -6.892158031463623
desired expected reward: 131.05039978027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[138.18207]
 [139.30925]
 [140.05696]
 [139.4757 ]
 [139.4899 ]
 [141.75786]
 [139.6817 ]
 [143.26637]
 [141.17657]
 [140.42941]
 [142.50499]
 [149.0076 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  8.  1.  0.] 
cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -7.430168151855469
desired expected reward: 140.759521484375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3
 16 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 11.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 11.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  2. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 11.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16 16
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0. 11.] 
adversary cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[177.91763]
 [172.17639]
 [170.66788]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0. 11.] 
cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.  0. 29.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0. 11.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16 16
  8] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -6.265604496002197
desired expected reward: 142.7419891357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.68584]
 [167.97946]
 [177.51135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0. 11.] 
cards in discard: [ 6.  8.  0.  3.  6.  8. 11. 11.  0.  1.  6.  0.  0. 29.  8.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  8.  0. 11.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16 16
  8] -> size -> 25 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.759016513824463
desired expected reward: 170.1586151123047



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  0. 11.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16 16
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[173.36047]
 [164.03458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 10.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -7.8122878074646
desired expected reward: 169.69906616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[163.45592]
 [165.33083]
 [164.74956]
 [164.95555]
 [174.28146]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 10.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.5882248878479
desired expected reward: 165.16297912597656



buy possibilites: [-1] 
expected returns: [[131.21191]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  1.  3. 10.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -9.470528602600098
desired expected reward: 153.9853973388672






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 10.  3.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8.  3.  6. 29.] 
adversary cards in discard: [0. 0. 0. 3. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 10.  3.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8.  3.  6. 29.] 
adversary cards in discard: [0. 0. 0. 3. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  8.  3.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[135.39954]
 [128.14978]
 [126.07364]
 [129.6583 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  6. 29.] 
cards in discard: [0. 0. 0. 3. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.372262001037598
desired expected reward: 124.83965301513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[124.66794]
 [125.96155]
 [135.49347]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.  6. 29.] 
cards in discard: [0. 0. 0. 3. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  8. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.] 
adversary owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -6.533923625946045
desired expected reward: 127.97380065917969



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  8. 10.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 11  3  0  3  8  1 29  3 10  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 1.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 1.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 1.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 6. 0. 1.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[154.67093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 1.] 
cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 16.  3.  1. 14.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.  0.  8.  3. 10.] 
adversary owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -6.066035747528076
desired expected reward: 129.4274139404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[143.66043]
 [144.77542]
 [145.52315]
 [144.94185]
 [144.95605]
 [147.22401]
 [145.14786]
 [148.73253]
 [146.64273]
 [145.89557]
 [147.97116]
 [154.47379]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 1.] 
cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29. 16.  3.  1. 14.] 
adversary cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.  0.  8.  3. 10.] 
adversary owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.083539009094238
desired expected reward: 146.6336669921875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [29. 16.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  3.  1. 14.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.  0.  8.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1. 11.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  3.  1. 14.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.  0.  8.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 23. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1. 11.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 16.  3.  1. 14.] 
cards in discard: [ 8.  8.  0.  0.  8.  0.  0. 11.  0.  1.  3. 10.  3.  0.  8.  3. 10.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [11.  1. 11.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [11.  1. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[90.529884]
 [83.48097 ]
 [83.48097 ]
 [81.4854  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  0.  8.] 
cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 29 11  1  8  1  8  0  8  6 11  0  3 11  6  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -9.02811336517334
desired expected reward: 145.44564819335938



action possibilites: [-1] 
expected returns: [[141.46379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 8
Learning step: -3.0547373294830322
desired expected reward: 76.6987075805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[133.66342]
 [135.44084]
 [134.88979]
 [135.08488]
 [144.03244]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  1. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -6.199458122253418
desired expected reward: 135.2643280029297



buy possibilites: [-1] 
expected returns: [[154.95056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  0.  0.  3.  3.  8. 11.  8.  3.  6. 29.  6.  0.  6.  0.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -37 

action type: buy - action 8.0
Learning step: -4.546199798583984
desired expected reward: 119.10554504394531






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  8.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  8.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  3  0  3  8  1 29  3  1  8 10  8  0  0 10  0 14  3 16  8  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  6.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[98.91547]
 [93.51021]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -8.342782974243164
desired expected reward: 146.60777282714844



action possibilites: [-1.] 
expected returns: [[158.646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_n_cards - action 1
Learning step: -2.609262466430664
desired expected reward: 85.96668243408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[149.57306]
 [150.65471]
 [151.36934]
 [150.79616]
 [150.82866]
 [153.0158 ]
 [154.47539]
 [152.44264]
 [151.72911]
 [153.72935]
 [160.02016]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0.  1.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -6.198953151702881
desired expected reward: 152.44703674316406






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [29.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  1.] 
cards in discard: [8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  1.] 
cards in discard: [8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  1.] 
cards in discard: [ 8.  3. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 8. 8. 1. 3.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [6. 8. 8. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[170.3767 ]
 [161.37102]
 [161.37102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 1. 3.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  1. 10. 16.  0.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -7.056880474090576
desired expected reward: 152.9632568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[160.28749]
 [162.08377]
 [161.51062]
 [170.7346 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 1. 3.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  1. 10. 16.  0.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -7.440086364746094
desired expected reward: 160.95635986328125



buy possibilites: [-1] 
expected returns: [[150.54115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 1. 3.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  1. 10. 16.  0.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -85.0 

action type: buy - action 0.0
Learning step: -8.877199172973633
desired expected reward: 151.41029357910156






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10. 16.  0.] 
cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 11.  8.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10. 16.  0.] 
cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 11.  8.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[80.53543 ]
 [75.5423  ]
 [74.249725]
 [72.4939  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 11.  8.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29 29  1  8  1  8  0  8  6  0  3 11  6  6  0  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  8. 11.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -8.569605827331543
desired expected reward: 141.97154235839844



action possibilites: [-1] 
expected returns: [[129.4478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  8. 11.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 4
Learning step: -2.250537395477295
desired expected reward: 66.01171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.10581]
 [122.31367]
 [131.4749 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  5.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  8. 11.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -5.366991996765137
desired expected reward: 124.080810546875



buy possibilites: [-1] 
expected returns: [[140.10521]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14.  8.  3.  8. 11.] 
adversary cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
adversary owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -346 

action type: buy - action 6.0
Learning step: -20.263317108154297
desired expected reward: 102.05035400390625






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [14.  8.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  8. 11.] 
cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  3  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.  8. 29. 11.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 11.] 
cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.  8. 29. 11.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 11.] 
cards in discard: [ 8.  3. 14. 29.  0.  3.  0.  1.  3.  1. 10. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 8. 0. 0.] 
adversary cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.  8. 29. 11.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[194.60474]
 [185.59904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.  8. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.513017177581787
desired expected reward: 134.59219360351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[187.1046 ]
 [188.90086]
 [188.32773]
 [197.55171]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.  8. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.163187980651855
desired expected reward: 185.76296997070312



buy possibilites: [-1] 
expected returns: [[136.70584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 0.] 
cards in discard: [ 3. 29.  0.  0.  6.  0.  0.  6.  8.  8.  1.  3.  6.  8. 29. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -10.312861442565918
desired expected reward: 176.79173278808594






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29.  6.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29.  6.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  6.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[75.50546]
 [70.61928]
 [67.59671]
 [70.61928]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -8.02769660949707
desired expected reward: 128.6781463623047



action possibilites: [-1.  8. 29.] 
expected returns: [[96.54535]
 [88.39079]
 [91.52243]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 29.  6.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  6  0  3 11  6  6  0  8  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: discard_n_cards - action 3
Learning step: -3.024050712585449
desired expected reward: 63.515316009521484



action possibilites: [-1] 
expected returns: [[108.870964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: trash_cards_n_from_hand - action 3
Learning step: -1.5723059177398682
desired expected reward: 84.8657455444336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[101.41577]
 [102.5054 ]
 [110.87079]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  1.  8.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -2.742743730545044
desired expected reward: 106.12821960449219






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 14.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14.  1.  8.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 29.  8. 29.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 14.  1.  8.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 29.  8. 29.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 14.  1.  8.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 29.  8. 29.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.476213]
 [17.43939 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [ 0. 29.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  3. 11.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -6.7989420890808105
desired expected reward: 104.07183837890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.993338]
 [16.956259]
 [16.637697]
 [21.931208]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [ 0. 29.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  4.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  3. 11.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -2.3290348052978516
desired expected reward: 18.841306686401367



buy possibilites: [-1] 
expected returns: [[72.13249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  6.] 
cards in discard: [ 0. 29.  8. 29.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  3. 11.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.] 
adversary owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -16.458904266357422
desired expected reward: 0.17879104614257812






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  3. 11.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0  3  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[101.91406]
 [ 93.98489]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3. 29.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
adversary owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -3.141329526901245
desired expected reward: 68.99116516113281



action possibilites: [-1] 
expected returns: [[88.66906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3. 29.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
adversary owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.3333935737609863
desired expected reward: 88.23554992675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[81.7392 ]
 [83.36789]
 [82.83219]
 [91.44466]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 22. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3. 29.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
adversary owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -3.2301337718963623
desired expected reward: 85.43892669677734



buy possibilites: [-1] 
expected returns: [[105.97414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3. 29.  0. 10.] 
adversary cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
adversary owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 4 

action type: buy - action 3.0
Learning step: -1.5839766263961792
desired expected reward: 81.7839126586914






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [16.  3. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 29.  0. 10.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 16. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 29.  0. 14.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 1. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 29.  0.] 
cards in discard: [ 0.  3.  0.  0.  0.  0.  3.  8. 14.  1.  8.  0.  8.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 21. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14. 29.] 
owned cards: [11  0  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 21. 30.  8.  3.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [3. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14. 29. 16.] 
owned cards: [11  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [3. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14. 29. 16.] 
owned cards: [11  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 14. 29. 16.] 
owned cards: [11  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0  6 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 8.] 
adversary cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[95.04122 ]
 [87.105705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8.] 
cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  0.] 
adversary cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.] 
adversary owned cards: [11  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0  6 10] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: discard_down_to_3_cards - action 0
Learning step: -4.84170389175415
desired expected reward: 119.23320770263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.33958]
 [80.3704 ]
 [88.38891]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [ 0. 29.  8. 29.  6.  3. 11.  0.  0.  6.  3.  8.  0.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8. 14.  8.  0.] 
adversary cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.] 
adversary owned cards: [11  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0  6 10] -> size -> 22 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -3.230855703353882
desired expected reward: 85.36471557617188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8.  0.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  1 29  3  1  8  8  0  0 10  0 14  3 16  8  0  3 14  0  0  6 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  3. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 8.  3. 29.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[107.553154]
 [ 99.252464]
 [102.422066]
 [ 99.252464]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  6.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29 29  8  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 8. 0.] 
adversary cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.  8. 14.] 
adversary owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -2.8069493770599365
desired expected reward: 85.58194732666016



action possibilites: [-1] 
expected returns: [[166.23845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 8. 0.] 
adversary cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.  8. 14.] 
adversary owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 20 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 11
Learning step: -1.4461239576339722
desired expected reward: 97.28365325927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.53604]
 [158.66972]
 [167.4901 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 1. 0. 8. 0.] 
adversary cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.  8. 14.] 
adversary owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 20 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: -4.892204284667969
desired expected reward: 161.34625244140625






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8. 0.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  1 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  6. 10. 10. 14. 29. 16.  3.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 6. 3. 0.] 
adversary cards in discard: [8. 6.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [6. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[154.12079]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 19 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -6.177770137786865
desired expected reward: 161.31236267089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[143.79565]
 [145.49217]
 [144.92934]
 [153.74974]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 0.] 
cards in discard: [8. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 19 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -5.556746959686279
desired expected reward: 147.6315460205078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  1. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10. 10.] 
adversary cards in hand: [0. 8. 3. 1. 8.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 1. 8.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 25. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 1. 8.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1.] 
cards in discard: [15.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 1. 8.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[156.4242 ]
 [147.83708]
 [147.83708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 1. 8.] 
cards in discard: [8. 6. 6. 0. 6. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 10. 14.  0. 29.] 
adversary cards in discard: [15.  1. 11.  8.  0.  3.  1.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1.0
Learning step: -5.522275447845459
desired expected reward: 148.22744750976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[147.08258]
 [148.10735]
 [148.77911]
 [148.21626]
 [150.3529 ]
 [149.12132]
 [157.03665]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 1. 8.] 
cards in discard: [8. 6. 6. 0. 6. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 10. 14.  0. 29.] 
adversary cards in discard: [15.  1. 11.  8.  0.  3.  1.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -5.620936870574951
desired expected reward: 150.18344116210938



buy possibilites: [-1] 
expected returns: [[199.2977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 1. 8.] 
cards in discard: [8. 6. 6. 0. 6. 3. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 10. 14.  0. 29.] 
adversary cards in discard: [15.  1. 11.  8.  0.  3.  1.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -5.619931221008301
desired expected reward: 141.462646484375






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 6. 10. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 14.  0. 29.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 14. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0. 29.  8.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0. 29.  8.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0. 29.  8.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[150.53395]
 [143.8502 ]
 [145.24379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -7.913486003875732
desired expected reward: 191.38421630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[141.49074]
 [143.18727]
 [142.62444]
 [151.44482]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -5.425675392150879
desired expected reward: 144.10397338867188



buy possibilites: [-1] 
expected returns: [[100.99924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [8. 6. 6. 0. 6. 3. 0. 0. 0. 8. 3. 1. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -55.0 

action type: buy - action 0.0
Learning step: -7.552055358886719
desired expected reward: 133.93869018554688






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [15.  1. 11.  8.  0.  3.  1.  0. 10.  6. 14.  0. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [6. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[128.63722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 15. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: buy - action -1
Learning step: -3.4306206703186035
desired expected reward: 97.56861877441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[117.92729 ]
 [119.60247 ]
 [119.04673 ]
 [127.756294]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 21. 30.  8.  2.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 15. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: -4.8571577072143555
desired expected reward: 122.66911315917969



buy possibilites: [-1] 
expected returns: [[108.63932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 6. 15. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -336.0 

action type: buy - action 6.0
Learning step: -20.15928077697754
desired expected reward: 98.887451171875






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 6. 15. 10. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 10. 14. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  8.  0.  0.] 
adversary cards in discard: [6. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 10. 14. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  8.  0.  0.] 
adversary cards in discard: [6. 6. 3. 3. 0. 0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6] -> size -> 21 
adversary victory points: -1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[126.00442 ]
 [121.021904]
 [119.710335]
 [117.91743 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  8.  0.  0.] 
cards in discard: [6. 6. 3. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -4.507495403289795
desired expected reward: 104.13182830810547



action possibilites: [-1. 11.  8.] 
expected returns: [[139.8647 ]
 [133.40355]
 [131.56314]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.] 
cards in discard: [6. 6. 3. 3. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: discard_n_cards - action 2
Learning step: -3.512582540512085
desired expected reward: 112.124267578125



action possibilites: [-1] 
expected returns: [[174.02654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 20 

action type: gain_card_n - action 9
Learning step: -1.7251663208007812
desired expected reward: 131.090087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[167.50522]
 [168.49503]
 [169.14   ]
 [168.58394]
 [170.66481]
 [169.46936]
 [177.12599]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  5.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: -4.626283168792725
desired expected reward: 169.40025329589844



buy possibilites: [-1] 
expected returns: [[98.4675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  40   0   0   0   0   0   0   0  18   0] 
sum of rewards: 22 

action type: buy - action 11.0
Learning step: -5.217723369598389
desired expected reward: 165.44711303710938






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [ 6. 15. 10. 14. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15. 11. 29. 11.  8.  0.  0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [ 6. 15. 10. 14. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15. 11. 29. 11.  8.  0.  0.] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
adversary victory points: -1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[65.056755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15. 11. 29. 11.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [14.  8.  0.  0.  0.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -5.2595977783203125
desired expected reward: 93.20790100097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[59.448494]
 [60.875385]
 [60.39003 ]
 [67.930405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [ 6.  6.  3.  3.  0.  0.  0. 15. 11. 29. 11.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [14.  8.  0.  0.  0.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -3.615494966506958
desired expected reward: 61.441261291503906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [14.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  0.  0.  0.] 
cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0.  0.  0.] 
cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  4.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  0.  0.  0.] 
cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [8. 0. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [8. 0. 8. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[124.35462]
 [116.38229]
 [116.38229]
 [116.38229]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 29  1  8  0  8  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11. 14.  8.  0.  0.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -2.507492780685425
desired expected reward: 65.42291259765625



action possibilites: [-1] 
expected returns: [[160.94148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11. 14.  8.  0.  0.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 10
Learning step: -2.907646894454956
desired expected reward: 111.66896057128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[152.31932]
 [153.39809]
 [161.94011]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 1.] 
adversary cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11. 14.  8.  0.  0.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11] -> size -> 24 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -5.299012184143066
desired expected reward: 155.64247131347656






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11. 14.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11. 14.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0. 10.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 1.] 
cards in discard: [ 6. 15. 10. 14. 16.  0.  1.  3.  3.  3. 11. 14.  8.  0.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  6.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 19 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  3.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[109.69184 ]
 [103.480446]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  6.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0.  9.  7.  8. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -7.487941265106201
desired expected reward: 154.45217895507812



action possibilites: [-1] 
expected returns: [[108.41603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  8. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 0 

action type: gain_card_n - action 9
Learning step: -2.5495126247406006
desired expected reward: 99.9056396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.27184 ]
 [101.254395]
 [109.15738 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 8. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 21. 30.  8.  1.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  8. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -3.8531181812286377
desired expected reward: 104.56291198730469



buy possibilites: [-1] 
expected returns: [[163.67595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 8. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 21. 30.  8.  1.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  8. 11. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25] -> size -> 25 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -46.0 

action type: buy - action 0.0
Learning step: -3.630882978439331
desired expected reward: 96.64095306396484






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11. 10. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 21. 30.  8.  1.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  0. 15.] 
adversary cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 29.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  0. 15.] 
adversary cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10. 29.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0. 29.  0. 15.] 
adversary cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[100.20546 ]
 [ 95.54422 ]
 [ 94.903595]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 15.] 
cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [14. 14.  6. 25.  0.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -7.3020782470703125
desired expected reward: 156.37387084960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 91.439964]
 [ 92.326065]
 [ 92.90106 ]
 [ 94.27113 ]
 [ 93.19524 ]
 [100.15127 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0. 15.] 
cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [14. 14.  6. 25.  0.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6] -> size -> 26 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -4.107522487640381
desired expected reward: 95.18354034423828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [14. 14.  6. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  6. 25.  0.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  6.] 
adversary cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  6. 25.  0.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  6.] 
adversary cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  6. 25.  0.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 11.  6.] 
adversary cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[119.046265]
 [112.74144 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  6.] 
cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  4. 10.  7.] 
adversary cards in hand: [16. 15.  8.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1.0
Learning step: -3.6787948608398438
desired expected reward: 96.47246551513672



action possibilites: [-1] 
expected returns: [[90.58221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  8.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 3 

action type: gain_card_n - action 7
Learning step: -3.405524492263794
desired expected reward: 108.46695709228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[82.89838 ]
 [83.83599 ]
 [84.44437 ]
 [85.894264]
 [84.75578 ]
 [92.03877 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  8.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -2.8591949939727783
desired expected reward: 87.72301483154297



buy possibilites: [-1] 
expected returns: [[87.424835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 8. 15.  0. 11.  0.  3.  6.  3.  0.  0. 29.  0. 15. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  8.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.] 
adversary owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6  0] -> size -> 27 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -36.0 

action type: buy - action 0.0
Learning step: -3.9778594970703125
desired expected reward: 78.9205093383789






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [16. 15.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  8.  0. 11.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10  0 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11
 25  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 11.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 11.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8. 11.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [11.  0.  6.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
adversary victory points: -1
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[105.86519]
 [ 99.9745 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -3.361591100692749
desired expected reward: 84.06324768066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.94467]
 [106.69923]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  3.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -4.204183101654053
desired expected reward: 100.51187896728516



buy possibilites: [-1] 
expected returns: [[104.79389]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  3.  6.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0] -> size -> 28 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -56.0 

action type: buy - action 0.0
Learning step: -5.3393707275390625
desired expected reward: 92.60530090332031






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  8.  0.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 24. 30. 21. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  8.  0.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  0. 29.  8.  0.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [ 6.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[105.790665]
 [101.12869 ]
 [ 98.257675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  8.  0.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.
  3.  0.  3.  0.  1. 10.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -4.723586559295654
desired expected reward: 100.07030487060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 99.04305]
 [100.50963]
 [107.78952]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 29.  8.  0.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.
  3.  0.  3.  0.  1. 10.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3] -> size -> 29 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.748615264892578
desired expected reward: 101.04205322265625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.
  3.  0.  3.  0.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.
  3.  0.  3.  0.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  8.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [ 6. 11.  0.  8. 10. 29.  0. 14. 14.  6. 25.  0.  0.  0. 16. 15.  8. 11.
  3.  0.  3.  0.  1. 10. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.174706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14. 11. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -5.565545558929443
desired expected reward: 102.2239761352539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[62.52338 ]
 [63.397846]
 [63.965324]
 [65.33734 ]
 [64.25786 ]
 [71.22745 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  3. 10.  7.] 
adversary cards in hand: [14. 11. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -3.902576208114624
desired expected reward: 68.27213287353516



buy possibilites: [-1] 
expected returns: [[65.74613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [14. 11. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -18 

action type: buy - action 10.0
Learning step: -2.38338303565979
desired expected reward: 56.870033264160156






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [14. 11. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 15.  0.  6. 15.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0. 10.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10.  6. 15.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0. 10.  0.  0.  3.  0.  3.  0.
 15.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10.  6. 15.] 
adversary cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0. 10.  0.  0.  3.  0.  3.  0.
 15.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 2 





Player: 0 
cards in hand: [10.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[26.614117]
 [21.345903]
 [22.558014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 15.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0. 10.  0.  0.  3.  0.  3.  0.
 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 16.  6.] 
adversary cards in discard: [14. 11. 10.  0. 25.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: discard_down_to_3_cards - action 7
Learning step: -1.7059675455093384
desired expected reward: 7.408263683319092





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.839157]
 [27.459099]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 15.] 
cards in discard: [ 0. 11.  0.  6.  3.  6.  6.  0. 29.  8.  0. 10.  0.  0.  3.  0.  3.  0.
 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  0.  1. 16.  6.] 
adversary cards in discard: [14. 11. 10.  0. 25.] 
adversary owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -2.565136671066284
desired expected reward: 24.04897689819336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 16.  6.] 
cards in discard: [14. 11. 10.  0. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  1  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25
  6  0  0  0  3 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [14. 11. 10.  0. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [14. 11. 10.  0. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30. 20. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[129.54088]
 [123.39651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 14.  0. 16.  0.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -0.8348703384399414
desired expected reward: 26.624229431152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[119.3116  ]
 [120.248924]
 [120.85393 ]
 [122.30917 ]
 [121.16711 ]
 [128.45355 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 14.  0. 16.  0.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -5.925429821014404
desired expected reward: 122.36749267578125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0. 16.  0.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 16.  0.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0. 16.  0.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[72.77158 ]
 [67.412674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [ 0.  6.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 29. 15.  0.  0.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -7.127623081207275
desired expected reward: 121.325927734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[66.5825 ]
 [67.92785]
 [74.55584]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [ 0.  6.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 30. 19. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 29. 15.  0.  0.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -4.337919235229492
desired expected reward: 68.43366241455078



buy possibilites: [-1] 
expected returns: [[98.70991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 29. 15.  0.  0.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -27 

action type: buy - action 3.0
Learning step: -2.5254199504852295
desired expected reward: 65.40242767333984






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 3. 29. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 15.  0.  0.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10  3] -> size -> 26 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10  3] -> size -> 26 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 5. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10  3] -> size -> 26 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10  3] -> size -> 26 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[82.418755]
 [74.926216]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  3. 11.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0. 29.  3. 15.  8.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -4.890223026275635
desired expected reward: 93.81968688964844



action possibilites: [-1] 
expected returns: [[74.15228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  3. 11.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0. 29.  3. 15.  8.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0] -> size -> 33 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.2470359802246094
desired expected reward: 69.06221008300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[66.45637]
 [67.8386 ]
 [74.7094 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3.  6.  8.  3. 11.] 
adversary cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0. 29.  3. 15.  8.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0] -> size -> 33 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -3.4062485694885254
desired expected reward: 70.74603271484375






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8.  3. 11.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0. 29.  3. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0. 29.  3. 15.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [14. 11. 10.  0. 25.  0.  3. 16.  0.  0.  6.  0.  3. 14.  0. 16.  0.  0.
  0.  0. 29.  3. 15.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6. 29. 15.  6.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 6. 29. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[65.43523 ]
 [61.193092]
 [60.597664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 15.  6.  0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  1.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -4.610963821411133
desired expected reward: 70.09844207763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[57.349472]
 [65.32282 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 15.  6.  0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 6.  1.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -4.164943218231201
desired expected reward: 61.27028274536133



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 6.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 23. 30. 18. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 30. 17. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [10. 10.  0. 15.  0.] 
adversary cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [10. 10.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 15.] 
expected returns: [[90.772415]
 [84.01135 ]
 [84.01135 ]
 [85.61313 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 15.  0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 17. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 14.  3. 11.  0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -4.097501277923584
desired expected reward: 61.22531509399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[74.617645]
 [75.95118 ]
 [82.72587 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 15.  0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 17. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 14.  3. 11.  0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -5.238524913787842
desired expected reward: 79.1920394897461



buy possibilites: [-1] 
expected returns: [[79.85523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 15.  0.] 
cards in discard: [ 0.  6.  0.  0. 11.  3.  0. 11.  0.  3.  3.  8.  0.  6.  0.  6. 29. 15.
  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 3. 14.  3. 11.  0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -37 

action type: buy - action 3.0
Learning step: -3.850816488265991
desired expected reward: 72.1003646850586






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3. 11.  0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  3.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [14.] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[140.39084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [3. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 16.  0. 16. 10.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3 11] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_down_to_3_cards - action 3
Learning step: 0.4235630929470062
desired expected reward: 10.128177642822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[132.68694]
 [134.17491]
 [141.55983]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [3. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 16.  0. 16. 10.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3 11] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.170010566711426
desired expected reward: 134.2208251953125



buy possibilites: [-1] 
expected returns: [[157.43665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [3. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 16.  0. 16. 10.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0.] 
adversary owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3 11] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -6.842022895812988
desired expected reward: 125.84490966796875






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 16. 10.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3 16  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6
  0  0  0  3 16  0  3  0  0  1  3 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8. 10.  2. 10.  7.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [6. 3. 3. 6. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[92.391396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [3. 3. 0. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.] 
adversary owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -8.043025970458984
desired expected reward: 149.39361572265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[84.30805]
 [92.59146]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [3. 3. 0. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.] 
adversary owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -4.851655006408691
desired expected reward: 87.53974151611328



buy possibilites: [-1] 
expected returns: [[112.87763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [3. 3. 0. 0. 0. 6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.] 
adversary owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -5.425656318664551
desired expected reward: 78.88239288330078






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11. 29. 15.  6.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6. 0. 6. 3. 3. 6. 0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 23. 30. 16. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11. 29. 15.  6.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6. 0. 6. 3. 3. 6. 0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 15. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [11. 29. 15.  6.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 6. 0. 6. 3. 3. 6. 0.] 
adversary owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [11. 29. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[70.661224]
 [65.148056]
 [66.29269 ]
 [65.67779 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15.  6.  0.] 
cards in discard: [3. 3. 0. 0. 0. 6. 0. 6. 3. 3. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 15. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11. 15. 29.  0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.  3.  8.  0.  8.  0.  0.] 
adversary owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.862679958343506
desired expected reward: 106.01495361328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[62.358837]
 [70.54004 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 15.  6.  0.] 
cards in discard: [3. 3. 0. 0. 0. 6. 0. 6. 3. 3. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 15. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11. 15. 29.  0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.  3.  8.  0.  8.  0.  0.] 
adversary owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.760497093200684
desired expected reward: 65.9007339477539



Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 2 
Gold: 0 
Estate: 4 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 0 
Workshop: 5 
Chapel: 4 
Witch: 0 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 29. 15.  6.  0.] 
cards in discard: [3. 3. 0. 0. 0. 6. 0. 6. 3. 3. 6. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  3 11  6  0  8  0  6  0  6  3  0  0  6 15 11 15  0 10  0  0 10
  3  3  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30. 15. 30.  8.  0.  7.  2.  0.  9.  7.  8.  9.  2. 10.  7.] 
adversary cards in hand: [ 6. 11. 15. 29.  0.] 
adversary cards in discard: [ 3. 10.  6.  1.  0.  0.  3. 11. 14.  3.  3. 11.  0. 23.  0. 16.  0.  0.
 10.  3.  8.  0.  8.  0.  0.] 
adversary owned cards: [11 29  3  8 10 14  3  8  0  3 14  0  0  6 10  0 15  1  0  0 11 25  6  0
  0  0  3 16  0  3  0  0  1  3 11 23  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -50    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -585 

action type: buy - action 0.0
Learning step: -32.367942810058594
desired expected reward: 29.990894317626953



