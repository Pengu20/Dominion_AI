 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[290.34592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -30    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -532 

action type: buy - action -1.0
Learning step: -28.216684341430664
desired expected reward: 4.117002487182617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.66415]
 [284.3403 ]
 [278.27094]
 [235.98323]
 [292.87723]
 [278.1947 ]
 [274.90314]
 [297.78394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.390522956848145
desired expected reward: 283.9823303222656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 3. 4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 4] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.26575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 4] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -8.984343528747559
desired expected reward: 288.79962158203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[308.51953]
 [324.1653 ]
 [316.70236]
 [278.32306]
 [314.9717 ]
 [330.7843 ]
 [319.26663]
 [320.90448]
 [292.89948]
 [313.7799 ]
 [308.5323 ]
 [332.94897]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 4] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.122426986694336
desired expected reward: 322.4266662597656



buy possibilites: [-1] 
expected returns: [[314.3988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 4] -> size -> 12 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -27.5 

action type: buy - action 1.0
Learning step: -10.509291648864746
desired expected reward: 313.656005859375






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 4] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 4] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 4 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[276.11798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 4. 3. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 4 1] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -11.092880249023438
desired expected reward: 303.305908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[257.70773]
 [272.7036 ]
 [265.7291 ]
 [228.44528]
 [264.10425]
 [279.2003 ]
 [268.1574 ]
 [269.72815]
 [242.69818]
 [262.85303]
 [257.55167]
 [281.0335 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 4. 3. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 4 1] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -9.434999465942383
desired expected reward: 267.3232116699219



buy possibilites: [-1] 
expected returns: [[280.6761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 4. 3. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 4 1] -> size -> 13 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -62.0 

action type: buy - action 0.0
Learning step: -9.67017650604248
desired expected reward: 248.03758239746094






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 4. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 3. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 4 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 4 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3. 0.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.15738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1
Learning step: -8.046905517578125
desired expected reward: 272.6291809082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[321.7164 ]
 [333.97437]
 [327.94974]
 [297.0545 ]
 [326.84705]
 [339.3988 ]
 [330.40076]
 [331.73944]
 [309.09192]
 [326.05563]
 [321.83942]
 [341.23932]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 30. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -11.051946640014648
desired expected reward: 326.1435546875



buy possibilites: [-1] 
expected returns: [[317.4788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 1. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11] -> size -> 14 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -19.0 

action type: buy - action 3.0
Learning step: -10.204216003417969
desired expected reward: 317.74554443359375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3] -> size -> 13 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 29. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3] -> size -> 13 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3] -> size -> 13 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.0322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [3. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3] -> size -> 15 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -11.19266414642334
desired expected reward: 306.2861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[245.0451 ]
 [260.9914 ]
 [237.21698]
 [254.22545]
 [226.1364 ]
 [215.38286]
 [251.57405]
 [268.34177]
 [255.22832]
 [280.2311 ]
 [257.03674]
 [229.9199 ]
 [240.23697]
 [250.60092]
 [223.53648]
 [245.38892]
 [271.81744]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [3. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3] -> size -> 15 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -9.652098655700684
desired expected reward: 267.29351806640625



buy possibilites: [-1] 
expected returns: [[270.7984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [3. 0. 0. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3] -> size -> 15 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    4.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -26.5 

action type: buy - action 1.0
Learning step: -8.28160572052002
desired expected reward: 252.7097930908203






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [3. 0. 0. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [3. 0. 0. 1. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [3. 0. 0. 1. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [1. 1. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[288.1384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 1. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0] -> size -> 16 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -8.667658805847168
desired expected reward: 262.1307373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[262.73886]
 [279.03305]
 [272.12375]
 [235.0457 ]
 [286.26865]
 [273.42667]
 [268.55786]
 [289.0072 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1. 1. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0] -> size -> 16 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -9.634037971496582
desired expected reward: 275.7998352050781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
adversary victory points: 4
player victory points: 8 





Player: 0 
cards in hand: [0. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[258.3537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 3. 4. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1.0
Learning step: -10.73747444152832
desired expected reward: 278.2697448730469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[218.23088]
 [232.9617 ]
 [226.19748]
 [189.22392]
 [224.37334]
 [239.36894]
 [228.2312 ]
 [229.59363]
 [203.10197]
 [223.37268]
 [218.1819 ]
 [241.28438]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 3 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 3. 4. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -8.831583023071289
desired expected reward: 229.00572204589844



buy possibilites: [-1] 
expected returns: [[196.90945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 3. 4. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3] -> size -> 17 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -9 

action type: buy - action 14.0
Learning step: -6.174637794494629
desired expected reward: 196.9273681640625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 3. 4. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 3. 4. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  3.  4.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [14.  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14] -> size -> 15 
adversary victory points: 4
player victory points: 8 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[144.33783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  0.  1.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  4.  0. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29] -> size -> 18 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -8.688394546508789
desired expected reward: 188.22105407714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[119.387215]
 [140.27974 ]
 [131.74406 ]
 [ 96.45652 ]
 [128.0559  ]
 [150.26717 ]
 [133.12495 ]
 [135.21603 ]
 [106.409195]
 [127.65591 ]
 [120.400566]
 [154.0664  ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  0.  1.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 29.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  4.  0. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29] -> size -> 18 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -6.150544166564941
desired expected reward: 136.38629150390625



buy possibilites: [-1] 
expected returns: [[150.8121]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.  0.  1.  3.  0.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3.  4.  0. 29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29] -> size -> 18 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -9 

action type: buy - action 16.0
Learning step: -3.4595208168029785
desired expected reward: 124.59634399414062






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  4.  0. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16] -> size -> 16 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  4.  0. 29.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16] -> size -> 16 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  4.  0. 29.  0.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16] -> size -> 16 
adversary victory points: 4
player victory points: 8 





Player: 0 
cards in hand: [16.  1.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[177.43875]
 [165.22461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -5.738159656524658
desired expected reward: 145.07394409179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[160.05795]
 [171.86584]
 [165.8797 ]
 [138.31541]
 [164.87451]
 [176.56401]
 [168.25937]
 [169.27382]
 [147.7978 ]
 [163.68303]
 [159.57262]
 [177.21884]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -7.0948967933654785
desired expected reward: 168.8501739501953



buy possibilites: [-1] 
expected returns: [[189.42708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -71.0 

action type: buy - action 0.0
Learning step: -7.29079008102417
desired expected reward: 152.76718139648438






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 11.  0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 9 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[225.93044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 16.  1.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3] -> size -> 20 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: -6.9300079345703125
desired expected reward: 182.4970703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.2202 ]
 [216.60884]
 [210.4228 ]
 [171.831  ]
 [224.05962]
 [211.20148]
 [207.18172]
 [227.20265]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 16.  1.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3] -> size -> 20 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: -9.071449279785156
desired expected reward: 217.21060180664062



buy possibilites: [-1] 
expected returns: [[210.55498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 0. 16.  1.  3.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 29. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3] -> size -> 20 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -49.0 

action type: buy - action 8.0
Learning step: -8.27258586883545
desired expected reward: 202.9288787841797






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 4. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [ 3. 29.  3.  0. 29. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.  8.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [ 3. 29.  3.  0. 29. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.  8.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [ 3. 29.  3.  0. 29. 11.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [ 0. 16.  1.  3.  0.  0.  8.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 9 





Player: 0 
cards in hand: [14.  3.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[215.903  ]
 [182.97064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  1.  0.] 
cards in discard: [ 0. 16.  1.  3.  0.  0.  8.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 29. 11.  0. 29.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29] -> size -> 21 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: -8.569327354431152
desired expected reward: 201.98565673828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.53284]
 [207.31491]
 [202.61066]
 [171.4785 ]
 [199.82346]
 [213.36378]
 [202.39523]
 [203.57039]
 [182.6931 ]
 [199.35017]
 [194.91493]
 [215.70213]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  1.  0.] 
cards in discard: [ 0. 16.  1.  3.  0.  0.  8.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 3. 29.  3.  0. 29. 11.  0. 29.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29] -> size -> 21 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1.0
Learning step: -8.625287055969238
desired expected reward: 204.16773986816406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 3. 29.  3.  0. 29. 11.  0. 29.  0.  4.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 3. 29.  3.  0. 29. 11.  0. 29.  0.  4.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 3. 29.  3.  0. 29. 11.  0. 29.  0.  4.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 0.  0.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[146.30692]
 [139.97105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 16.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1.0
Learning step: -10.494402885437012
desired expected reward: 205.20774841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[138.16403 ]
 [145.78535 ]
 [141.57147 ]
 [126.74845 ]
 [120.719246]
 [141.3209  ]
 [149.74739 ]
 [144.663   ]
 [157.52419 ]
 [145.29991 ]
 [128.68907 ]
 [134.03925 ]
 [141.25117 ]
 [124.35519 ]
 [138.47636 ]
 [150.58418 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 16.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -7.430990695953369
desired expected reward: 144.78028869628906



buy possibilites: [-1] 
expected returns: [[180.95801]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 16.  0.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: -11 

action type: buy - action 25.0
Learning step: -4.203190326690674
desired expected reward: 153.32098388671875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [29.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 4.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 4.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 4.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[200.70459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  1. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -7.73800802230835
desired expected reward: 173.22000122070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[177.37187]
 [191.66142]
 [186.6554 ]
 [150.72997]
 [198.13905]
 [185.93248]
 [182.62267]
 [200.38237]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  1. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  9.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -8.509867668151855
desired expected reward: 185.2631378173828



buy possibilites: [-1] 
expected returns: [[159.61003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25.  0.  0.  1. 16.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -59.0 

action type: buy - action 8.0
Learning step: -8.65539836883545
desired expected reward: 177.27708435058594






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  3.  1.  8.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  3.  1.  8.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  3.  1.  8.] 
adversary cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [14.  0.  3.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[118.09595]
 [ 86.96709]
 [108.13805]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  1.  8.] 
cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -8.647581100463867
desired expected reward: 150.9624481201172



action possibilites: [-1] 
expected returns: [[157.76857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 8.] 
cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action 14.0
Learning step: -2.802654981613159
desired expected reward: 83.24629974365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[137.18282]
 [149.93881]
 [145.27425]
 [122.23411]
 [114.79903]
 [142.40518]
 [155.22238]
 [144.53122]
 [164.07626]
 [145.54459]
 [125.38211]
 [134.0209 ]
 [141.22005]
 [121.21735]
 [136.9824 ]
 [157.14542]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 8.] 
cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  8.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1
Learning step: -6.66574239730835
desired expected reward: 151.1028289794922



buy possibilites: [-1] 
expected returns: [[82.39131]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 8.] 
cards in discard: [25.  0.  0.  1. 16.  0.  8.  0.  0.  0.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -39.0 

action type: buy - action 8.0
Learning step: -7.322757244110107
desired expected reward: 137.20846557617188






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  9.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8] -> size -> 21 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[168.92445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11. 11.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -3.3837170600891113
desired expected reward: 79.0075912475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[136.73917]
 [150.28265]
 [145.26424]
 [108.79721]
 [142.75519]
 [156.82999]
 [145.66064]
 [146.92964]
 [122.63475]
 [142.55089]
 [137.53743]
 [160.15628]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11. 11.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -8.184499740600586
desired expected reward: 160.07546997070312



buy possibilites: [-1] 
expected returns: [[112.87394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11. 11.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    4.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -56.5 

action type: buy - action 1.0
Learning step: -7.799469947814941
desired expected reward: 142.4832000732422






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  3.] 
cards in discard: [ 1. 29.  3.  3.  0.  1.  4. 29.  0.  0.  3.  3.  0.  0. 11. 11.  0.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  7.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  3. 16.  0.  3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [14.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[159.05878]
 [132.59251]
 [147.4307 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 16.  0.  3.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 11.  3.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8] -> size -> 25 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -5.372457027435303
desired expected reward: 107.50148010253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.1372  ]
 [127.640854]
 [162.47658 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 16.  0.  3.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 11.  3.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8] -> size -> 25 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -7.553830146789551
desired expected reward: 149.74264526367188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 11.  3.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  8.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  1.  8.] 
adversary cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  7.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  1.  8.] 
adversary cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1.  3.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  7.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  1.  8.] 
adversary cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 0.  0. 25.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[ 98.463165]
 [105.92662 ]
 [ 89.48389 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  1.  8.] 
cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8. 10.  9.  7.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11] -> size -> 26 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1.0
Learning step: -8.92816162109375
desired expected reward: 153.54843139648438



action possibilites: [-1] 
expected returns: [[198.85431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 3. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8.  9.  9.  7.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -40 

action type: take_action - action 25.0
Learning step: -2.8221089839935303
desired expected reward: 103.10450744628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[173.004  ]
 [187.78401]
 [181.75568]
 [154.77946]
 [146.0056 ]
 [179.15115]
 [192.58585]
 [182.07047]
 [201.98706]
 [182.99551]
 [157.12167]
 [167.96689]
 [177.28064]
 [152.29353]
 [171.95978]
 [192.40973]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 3. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 25. 30. 25. 29.  8.  9.  9.  7.  6.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1
Learning step: -7.913037300109863
desired expected reward: 190.94126892089844



buy possibilites: [-1] 
expected returns: [[196.22209]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8. 3. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  0. 14.  3. 16.  0.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8.  9.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0. 29.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 9 

action type: buy - action 25.0
Learning step: -5.031955242156982
desired expected reward: 196.95513916015625






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 29.  8.  9.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  1.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25] -> size -> 23 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 25. 29.  8.  9.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  1.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25] -> size -> 23 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 24. 29.  8.  9.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [25.  1.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25] -> size -> 23 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [25.  1.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.  8.] 
expected returns: [[ 94.41099 ]
 [100.85484 ]
 [ 85.132996]
 [ 85.132996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 24. 29.  8.  9.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [4. 1. 0. 0. 3.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.  0. 11.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3] -> size -> 28 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1
Learning step: -10.826704978942871
desired expected reward: 185.3953857421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.307175]
 [89.73155 ]
 [86.023674]
 [64.037384]
 [94.267975]
 [85.979744]
 [83.443375]
 [95.3609  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 24. 29.  8.  9.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [4. 1. 0. 0. 3.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.  0. 11.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3] -> size -> 28 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: -5.656772136688232
desired expected reward: 85.77420043945312



buy possibilites: [-1] 
expected returns: [[114.57072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  8.  8.  0.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 24. 29.  8.  8.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [4. 1. 0. 0. 3.] 
adversary cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.  0. 11.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3] -> size -> 28 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -372.0 

action type: buy - action 6.0
Learning step: -19.224027633666992
desired expected reward: 44.81336212158203






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [4. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 1. 0. 0. 3.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.  0. 11.  0.
  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 24. 29.  8.  8.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  0.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6] -> size -> 24 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 0. 0. 3.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.  0. 11.  0.
  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 24. 29.  8.  8.  9.  7.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  0.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6] -> size -> 24 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 1. 0. 0. 3.] 
cards in discard: [ 8. 29.  3.  3.  0.  3.  3. 11. 11.  0. 29.  1.  3.  6.  3.  0. 11.  0.
  0. 29. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 24. 29.  8.  8.  9.  6.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  3.  0.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6] -> size -> 24 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [ 3. 25.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[84.83777 ]
 [92.803856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  0.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 24. 29.  8.  8.  9.  6.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11] -> size -> 29 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -7.309266567230225
desired expected reward: 107.2614517211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[70.39637 ]
 [75.986404]
 [52.27556 ]
 [76.36186 ]
 [83.68241 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  3.  0.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 24. 29.  8.  8.  9.  6.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11] -> size -> 29 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: take_action - action -1.0
Learning step: -6.16536283493042
desired expected reward: 78.67241668701172



buy possibilites: [-1] 
expected returns: [[150.9249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  3.  0.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 24. 29.  8.  8.  9.  6.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11] -> size -> 29 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -102.0 

action type: buy - action 0.0
Learning step: -5.224009037017822
desired expected reward: 65.17237091064453






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  8.  9.  6.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  0. 16.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 25. 30. 24. 29.  8.  8.  9.  6.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  0. 16.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 24. 29.  8.  8.  9.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  0. 16.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0] -> size -> 25 
adversary victory points: 3
player victory points: 10 





Player: 0 
cards in hand: [ 0. 14.  1.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[62.711323]
 [56.222343]
 [61.4866  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  0. 16.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  8.  9.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 29.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11] -> size -> 30 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: buy - action -1
Learning step: -9.779664993286133
desired expected reward: 141.14523315429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[60.30663 ]
 [63.629955]
 [61.06033 ]
 [53.6277  ]
 [61.599247]
 [64.28044 ]
 [62.774998]
 [62.89287 ]
 [56.261593]
 [60.568428]
 [59.37027 ]
 [63.171444]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0. 16.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 24. 29.  8.  8.  9.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 29.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11] -> size -> 30 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -72 

action type: take_action - action -1.0
Learning step: -5.3494720458984375
desired expected reward: 57.36186599731445



buy possibilites: [-1] 
expected returns: [[80.3517]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  0. 16.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 25. 30. 24. 29.  8.  7.  9.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 29.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11] -> size -> 30 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -383.0 

action type: buy - action 6.0
Learning step: -20.023473739624023
desired expected reward: 33.60424041748047






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  6.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  3. 29.] 
cards in discard: [11.  1.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  9.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  3. 11.] 
cards in discard: [11.  1.  0.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 24. 29.  8.  7.  9.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  5.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
adversary victory points: 2
player victory points: 10 





Player: 0 
cards in hand: [3. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[81.889755]
 [76.571   ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  4.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11] -> size -> 32 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -6.371013164520264
desired expected reward: 73.9806900024414



action possibilites: [-1] 
expected returns: [[162.65149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  4.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11] -> size -> 32 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.921641826629639
desired expected reward: 81.7043685913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[147.95331]
 [130.43771]
 [163.30328]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 25.  1.  8.  8.  0.  0.  3. 25.  0.  3.  0.  6.  0. 14.  1.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  4.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11] -> size -> 32 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -8.985934257507324
desired expected reward: 153.66555786132812






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  3.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  4.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.  4.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.  4.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 8. 14.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[82.79396 ]
 [74.71042 ]
 [63.671383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3. 11.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -11.773602485656738
desired expected reward: 151.52967834472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[62.347652]
 [69.657776]
 [66.468666]
 [49.514603]
 [65.3963  ]
 [73.30119 ]
 [67.00704 ]
 [67.510254]
 [55.4154  ]
 [64.631805]
 [61.974926]
 [74.65869 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  3. 11.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -7.724192142486572
desired expected reward: 71.9575424194336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3. 11.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6.  1.  6. 16.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3. 11.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6.  1.  6. 16.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  6.  1.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[58.001507]
 [51.08668 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1.  6. 16.] 
cards in discard: [ 8. 14.  0.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0. 29.  3.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -7.737636566162109
desired expected reward: 66.92105102539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[43.98288 ]
 [48.761707]
 [27.443304]
 [50.488518]
 [54.644466]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1.  6. 16.] 
cards in discard: [ 8. 14.  0.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  0. 29.  3.] 
adversary cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -6.736728191375732
desired expected reward: 44.27734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [11.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29.  3.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  6.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [11.  1.  0.  3.  0.  0. 16. 11. 29. 11.  1.  0.  6.  3.  0. 11.  3.  0.
  3.  4.  3.  0. 29.  3. 11. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  5.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 0.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[74.017166]
 [81.75468 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  0.] 
cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  5.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8] -> size -> 35 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -6.2095866203308105
desired expected reward: 48.434879302978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[59.709072]
 [71.131195]
 [67.08721 ]
 [37.24462 ]
 [74.87239 ]
 [66.645584]
 [63.24328 ]
 [74.9557  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 25.  0.] 
cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  5.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8] -> size -> 35 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -7.44740629196167
desired expected reward: 66.56978607177734



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  5.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 25.  8.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  5.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 25.  8.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  5.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 25.  8.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.  0.  0.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  4.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0.  0. 25.  8.] 
adversary cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 1.  0.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[64.96747 ]
 [73.978195]
 [60.782692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 25.  8.] 
cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  4.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1.0
Learning step: -7.4611663818359375
desired expected reward: 67.49454498291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.91641 ]
 [64.26832 ]
 [59.853764]
 [40.45637 ]
 [59.391747]
 [66.31433 ]
 [61.43981 ]
 [61.71157 ]
 [46.685623]
 [57.518196]
 [54.306107]
 [65.35866 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25.  8.] 
cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  4.  8.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -7.153954982757568
desired expected reward: 57.81352233886719



buy possibilites: [-1] 
expected returns: [[67.9459]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 25.  8.] 
cards in discard: [ 8. 14.  0.  1.  0.  3.  6.  1.  6. 16.  0.  0.  3. 25.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 11. 11.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
   32    0] 
sum of rewards: -73 

action type: buy - action 29.0
Learning step: -5.206796169281006
desired expected reward: 56.50477600097656






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 11.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 3.  0. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[28.21481 ]
 [22.199043]
 [21.83073 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  3. 29.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -8.08387565612793
desired expected reward: 59.862022399902344



action possibilites: [-1.  8.  8.] 
expected returns: [[52.31071 ]
 [47.358227]
 [47.358227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  3. 29.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: -4.240005970001221
desired expected reward: 17.959030151367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[44.797817]
 [50.372505]
 [48.22128 ]
 [35.116444]
 [52.503536]
 [48.064873]
 [46.47727 ]
 [52.99279 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  3. 29.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -5.771239757537842
desired expected reward: 46.539466857910156



buy possibilites: [-1] 
expected returns: [[66.544235]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  3. 29.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -6.492646217346191
desired expected reward: 38.30517578125






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 29.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 16.  3.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0] -> size -> 24 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 29.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  0. 16.  3.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0] -> size -> 24 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 29.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 16.  3.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0] -> size -> 24 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 1.  0. 16.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[86.68859]
 [77.15994]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  3.  1.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 24. 29.  8.  7.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  4.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -6.7090349197387695
desired expected reward: 59.835201263427734



action possibilites: [-1] 
expected returns: [[35.04242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 24. 29.  8.  6.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  4.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -396 

action type: gain_card_n - action 2
Learning step: -18.658063888549805
desired expected reward: -25.72768783569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.390547]
 [31.32856 ]
 [28.703674]
 [10.019979]
 [26.701544]
 [34.634613]
 [27.80966 ]
 [28.259155]
 [15.757769]
 [26.032274]
 [23.143759]
 [35.83933 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 30. 24. 29.  8.  6.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  4.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -96 

action type: take_action - action -1
Learning step: -5.916282653808594
desired expected reward: 29.126136779785156



buy possibilites: [-1] 
expected returns: [[35.62319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 10.  3.  4.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -83.0 

action type: buy - action 3.0
Learning step: -4.611788749694824
desired expected reward: 24.09189224243164






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  3.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  4.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  8. 14.  6.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 4. 0. 0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  8. 14.  6.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 4. 0. 0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  8. 14.  6.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 4. 0. 0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  8. 14.  6.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [25.  0.  8. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 14.] 
expected returns: [[ 3.6930656]
 [ 5.290956 ]
 [ 1.4088221]
 [-1.5203857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8. 14.  6.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 11.  6.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29] -> size -> 40 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -6.96520471572876
desired expected reward: 28.657987594604492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.9997802]
 [-2.0289724]
 [ 4.158712 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8. 14.  6.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 23. 29.  8.  6.  8.  4.  4.  8.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 11.  6.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29] -> size -> 40 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -5.394911289215088
desired expected reward: -1.7018475532531738



buy possibilites: [-1] 
expected returns: [[-13.923912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  8. 14.  6.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 23. 29.  8.  5.  8.  4.  4.  8.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 11. 11.  6.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29] -> size -> 40 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -110.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -416.0 

action type: buy - action 6.0
Learning step: -21.011838912963867
desired expected reward: -23.040815353393555






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 11.  6.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 23. 29.  8.  5.  8.  4.  4.  8.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 23. 29.  8.  5.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 23. 29.  8.  5.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 23. 29.  8.  5.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 10 





Player: 0 
cards in hand: [ 6.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[41.339375]
 [44.02054 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 25.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 23. 29.  8.  5.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0] -> size -> 42 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: buy - action -1
Learning step: -4.136504650115967
desired expected reward: -18.06041717529297



action possibilites: [-1] 
expected returns: [[95.32991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 1. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6] -> size -> 43 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    3] 
sum of rewards: -93 

action type: take_action - action 25.0
Learning step: -4.706104278564453
desired expected reward: 39.3144416809082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[83.32279 ]
 [88.46004 ]
 [81.18244 ]
 [85.83736 ]
 [78.06506 ]
 [75.17559 ]
 [85.05675 ]
 [91.06057 ]
 [85.97006 ]
 [95.05924 ]
 [86.24372 ]
 [79.16455 ]
 [81.927155]
 [84.9707  ]
 [77.29299 ]
 [83.40874 ]
 [92.04773 ]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 24. 30. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6] -> size -> 43 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -96 

action type: take_action - action -1
Learning step: -7.612393379211426
desired expected reward: 87.71751403808594



buy possibilites: [-1] 
expected returns: [[54.033073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  8.  8.  6.  3. 16.  1.  3.  1.  6. 25.  0.  8. 14.
  6.  2.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.  3.  0.] 
adversary cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6] -> size -> 43 
adversary victory points: 10
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -110    0    0   20    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1676 

action type: buy - action 2.0
Learning step: 80.95662689208984
desired expected reward: 162.13906860351562






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  6. 14.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 29. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  6. 14.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  3.  0.] 
cards in discard: [ 8. 29.  0. 16.  8.  0.  0.  1.  0. 11.  3.  3. 11.  0. 10.  3.  1.  3.
 29.  0. 29. 10.  1.  3.  4.  0.  0. 10.  0. 11.  8.  0. 11.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 29. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  6. 14.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [25.  6. 14.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.  8.] 
expected returns: [[18.788393]
 [27.250349]
 [-1.992718]
 [11.283594]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 14.  1.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 23. 29.  8.  4.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 10.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0] -> size -> 44 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -7.620351314544678
desired expected reward: 46.412723541259766



action possibilites: [-1] 
expected returns: [[78.01677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  1.  8.  1.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 23. 29.  8.  3.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 10.  0. 29. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    2] 
sum of rewards: -84 

action type: take_action - action 25.0
Learning step: -3.807140827178955
desired expected reward: 23.443220138549805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[69.44165 ]
 [75.751305]
 [73.16792 ]
 [57.96618 ]
 [72.01854 ]
 [78.40276 ]
 [73.147   ]
 [73.287445]
 [62.701813]
 [71.04865 ]
 [68.63832 ]
 [78.58075 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  1.  8.  1.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 29. 23. 29.  8.  3.  8.  4.  4.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 10.  0. 29. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -6.560650825500488
desired expected reward: 71.45611572265625



buy possibilites: [-1] 
expected returns: [[19.005358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  1.  8.  1.  3.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 23. 29.  8.  3.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 10.  0. 29. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6] -> size -> 45 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
   32    0] 
sum of rewards: -54 

action type: buy - action 29.0
Learning step: -5.9367523193359375
desired expected reward: 67.35070037841797






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 29. 11.] 
cards in discard: [6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 23. 29.  8.  3.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 29.] 
cards in discard: [6. 1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 23. 29.  8.  3.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 29.] 
cards in discard: [6. 1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 29. 23. 29.  8.  3.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 29.] 
cards in discard: [6. 1. 0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 29. 23. 29.  8.  3.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  6.  6.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0. 25.  1.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[91.31618]
 [97.51238]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  6.  6.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 23. 29.  8.  3.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  1.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0] -> size -> 47 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -3.609767198562622
desired expected reward: 15.395590782165527



action possibilites: [-1] 
expected returns: [[67.66004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 6. 0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 23. 29.  8.  2.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  1.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6] -> size -> 48 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: -7.103268623352051
desired expected reward: 90.40911865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[61.240723]
 [68.02347 ]
 [65.79046 ]
 [49.511124]
 [64.023346]
 [70.64193 ]
 [64.98869 ]
 [65.1755  ]
 [54.561317]
 [63.363052]
 [60.801407]
 [70.93028 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 6. 0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 29. 23. 29.  8.  2.  8.  4.  4.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  1.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6] -> size -> 48 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -5.7196946144104
desired expected reward: 61.940345764160156



buy possibilites: [-1] 
expected returns: [[15.135874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 6. 0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 23. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  1.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6] -> size -> 48 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -44 

action type: buy - action 29.0
Learning step: -5.118218898773193
desired expected reward: 60.05729675292969






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  1.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  6  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 23. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 2. 0. 0.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29 29] -> size -> 29 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 2. 0. 0.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29 29] -> size -> 29 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 2. 0. 0.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29 29] -> size -> 29 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 2. 0. 0.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29 29] -> size -> 29 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [3. 8. 2. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.878447]
 [26.038696]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 2. 0. 0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6
  3  6  2 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  4.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -5.472307205200195
desired expected reward: 9.663566589355469



action possibilites: [-1] 
expected returns: [[7.8932114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  4.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: trash_cards_n_from_hand - action 5
Learning step: -4.811283111572266
desired expected reward: 8.966326713562012





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[3.2353723]
 [1.0145118]
 [7.365548 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  1. 11.  4.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -4.58929967880249
desired expected reward: 3.3039116859436035






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  1. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 11.  4.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16. 29.  3.  0.  8.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
adversary owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 4.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16. 29.  3.  0.  8.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
adversary owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 4.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16. 29.  3.  0.  8.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
adversary owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 4.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [16. 29.  3.  0.  8.] 
adversary cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
adversary owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [16. 29.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.  8.] 
expected returns: [[39.623516]
 [38.482147]
 [39.272022]
 [39.15702 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  3.  0.  8.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3
  6 29 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1] -> size -> 51 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1.0
Learning step: -4.785211563110352
desired expected reward: 2.5803375244140625



action possibilites: [-1] 
expected returns: [[63.18193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1] -> size -> 51 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -97 

action type: trash_cards_n_from_hand - action 2
Learning step: -5.269322395324707
desired expected reward: 31.548995971679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[44.937435]
 [33.192867]
 [59.84784 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29.  0.] 
cards in discard: [29. 25.  6. 14.  1.  8.  1.  3. 29. 25.  0.  1.  6.  6.  6.  0.  8.  3.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1] -> size -> 51 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -97 

action type: take_action - action -1
Learning step: -6.901904582977295
desired expected reward: 56.280025482177734






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
adversary victory points: -2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
adversary victory points: -2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 29. 22. 29.  8.  2.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
adversary victory points: -2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 21. 29.  8.  2.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
adversary victory points: -2
player victory points: 10 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.681015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 21. 29.  8.  2.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29  3] -> size -> 53 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: buy - action -1.0
Learning step: -8.5620698928833
desired expected reward: 51.28578567504883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[34.842915]
 [35.942085]
 [35.200985]
 [33.636402]
 [32.972614]
 [35.272606]
 [37.370872]
 [35.693905]
 [40.32224 ]
 [35.696697]
 [33.735146]
 [34.26225 ]
 [35.0585  ]
 [33.33437 ]
 [34.683266]
 [37.68949 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 20. 29. 21. 29.  8.  2.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29  3] -> size -> 53 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: take_action - action -1.0
Learning step: -7.262585639953613
desired expected reward: 27.41843032836914



buy possibilites: [-1] 
expected returns: [[2.8147967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 20. 29. 21. 29.  8.  1.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  8.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29  3] -> size -> 53 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -130.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -438.0 

action type: buy - action 6.0
Learning step: -23.48529624938965
desired expected reward: 9.487306594848633






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  3.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11
  8 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3
  1  1  1 29  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 21. 29.  8.  1.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 14.  6. 29.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 21. 29.  8.  1.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 14.  6. 29.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 29. 21. 29.  8.  1.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 14.  6. 29.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  1.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 14.  6. 29.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
adversary victory points: -3
player victory points: 10 





Player: 0 
cards in hand: [25. 29. 14.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 14. 29.] 
expected returns: [[6.2508736]
 [4.406806 ]
 [1.1375391]
 [1.6363251]
 [1.1375391]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 14.  6. 29.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  1.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3] -> size -> 53 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: buy - action -1
Learning step: -6.957752227783203
desired expected reward: -4.142955780029297



action possibilites: [-1] 
expected returns: [[62.60797]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  6. 29.  3.  1.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0   20    0    0    0    0    0    0    0
    0    2] 
sum of rewards: -116 

action type: take_action - action 25.0
Learning step: -4.611660957336426
desired expected reward: -0.20486164093017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[54.703384]
 [58.573296]
 [57.804306]
 [63.961098]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  6. 29.  3.  1.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  4.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: take_action - action -1
Learning step: -7.681128025054932
desired expected reward: 54.926841735839844



buy possibilites: [-1] 
expected returns: [[72.51818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  6. 29.  3.  1.] 
cards in discard: [6. 0. 0. 0. 0. 0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 10
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -130    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -110 

action type: buy - action 8.0
Learning step: -6.758556365966797
desired expected reward: 51.04574966430664






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 1. 6. 1. 8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6  8] -> size -> 28 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 1. 6. 1. 8.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6  8] -> size -> 28 
adversary victory points: -3
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 1. 6. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[42.08553]
 [40.80885]
 [40.80885]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 1. 8.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  0  3  1 14 16  0  8 25  8  8  1 25  6  0  6 29  0  6  3  6
 29 29  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1
Learning step: -9.093690872192383
desired expected reward: 63.42449188232422



action possibilites: [-1] 
expected returns: [[13.551952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -97 

action type: trash_cards_n_from_hand - action 10
Learning step: -6.085008144378662
desired expected reward: 24.713539123535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[10.250828]
 [12.308666]
 [11.86186 ]
 [14.878443]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 20. 29. 20. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -97 

action type: take_action - action -1
Learning step: -5.2369513511657715
desired expected reward: 8.315000534057617



buy possibilites: [-1] 
expected returns: [[14.524115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  3.  3.  0.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -78 

action type: buy - action 3.0
Learning step: -4.188640594482422
desired expected reward: 8.12001895904541






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [29.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8. 16.  6.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8. 16.  6.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8. 16.  6.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  8. 16.  6.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8  3] -> size -> 26 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [25.  8. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 16.] 
expected returns: [[20.440447]
 [24.720263]
 [19.440033]
 [18.909765]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 16.  6.  0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  8  1 25  0  6 29  0  6  3  6 29 29  6
  8  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  2.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6  0] -> size -> 55 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -106 

action type: buy - action -1
Learning step: -5.536391735076904
desired expected reward: 8.987722396850586



action possibilites: [-1] 
expected returns: [[26.806467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6  0] -> size -> 55 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -70 

action type: gain_card_n - action 6
Learning step: -4.01421594619751
desired expected reward: 18.333011627197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.508127]
 [29.429537]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  8. 25. 29. 14.  6. 29.  3.  1.  3.  8.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 11.] 
adversary cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6  0] -> size -> 55 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -5.029313087463379
desired expected reward: 21.77715301513672






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 29. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8
 11  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1
  1  1 29  3  3  6  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11.] 
cards in discard: [ 6.  1.  0. 11.  6. 10.  0. 29.  6.  3.  1. 16.  0.  1.  0.  1.  1. 11.
  0.  8.  1.  4. 29.  3. 11.  3.  0. 10.  0.  3.  8.  0. 29.  0.  6.  3.
  0.  3. 11. 11.  3.  0. 29.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0. 29.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[37.4548  ]
 [31.596453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0] -> size -> 55 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -5.479353904724121
desired expected reward: 23.950199127197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[29.401098]
 [32.23833 ]
 [31.339705]
 [37.1615  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  3.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0] -> size -> 55 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -5.916539192199707
desired expected reward: 31.538272857666016



buy possibilites: [-1] 
expected returns: [[-36.070454]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  6.  0.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  2.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0] -> size -> 55 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -88 

action type: buy - action 8.0
Learning step: -6.778570652008057
desired expected reward: 24.561134338378906






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  1. 10.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  2.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  8.  3.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  1. 11.] 
cards in discard: [] 
cards in deck: 49 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  2.  8.  1.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  8.  3.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [14.] 
cards in deck: 49 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  8.  3.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [14.] 
cards in deck: 49 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  4.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  8.  3.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1.] 
cards in discard: [14. 11.] 
cards in deck: 49 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  3.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  8.  3.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [29.  0.  8.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[ 0.25496674]
 [-2.3037872 ]
 [-2.2374005 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  3.  1.] 
cards in discard: [ 8.  0. 29.  3.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  3.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11] -> size -> 57 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -3.0198309421539307
desired expected reward: -39.09028625488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-0.4153149 ]
 [ 1.4705255 ]
 [ 1.0593779 ]
 [ 2.3905694 ]
 [ 0.47044158]
 [ 0.32643127]
 [ 2.1843746 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  3.  1.] 
cards in discard: [ 8.  0. 29.  3.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  3.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11] -> size -> 57 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.781785488128662
desired expected reward: -4.526814937591553



buy possibilites: [-1] 
expected returns: [[42.81132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  3.  1.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11] -> size -> 57 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -78 

action type: buy - action 11.0
Learning step: -3.0562732219696045
desired expected reward: -0.6657118797302246






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29.  1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6. 14.  6.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0.  6. 14.  6.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  6. 14.  6.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [29.  0.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[-1.8993778]
 [-6.609313 ]
 [-3.2451675]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6. 14.  6.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 3. 1. 3.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -7.018178462982178
desired expected reward: 35.79314422607422



action possibilites: [-1. 14.] 
expected returns: [[7.0278444]
 [1.3017144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6.  0.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 3. 1. 3.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: discard_n_cards - action 0
Learning step: -3.272998094558716
desired expected reward: -11.639849662780762





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[3.4667468]
 [5.2932205]
 [4.4629455]
 [7.403825 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  0.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 3. 1. 3.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -4.023631572723389
desired expected reward: 3.004210948944092



buy possibilites: [-1] 
expected returns: [[-3.7745934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  0.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 3. 1. 3.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -106.0 

action type: buy - action 0.0
Learning step: -5.558265686035156
desired expected reward: -2.0915184020996094






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 1. 3.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  8.  0. 25.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 3.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  2.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  8.  0. 25.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 1. 3.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  8.  0. 25.  1.] 
adversary cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 6.  8.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[24.212273]
 [21.91579 ]
 [25.020817]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 25.  1.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.070841312408447
desired expected reward: -7.845434665679932



action possibilites: [-1] 
expected returns: [[52.354286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 1. 3. 0.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: -3.8230698108673096
desired expected reward: 21.19774627685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[43.64345 ]
 [48.741573]
 [46.038673]
 [45.69628 ]
 [50.571266]
 [47.040127]
 [47.0913  ]
 [36.739174]
 [44.985306]
 [42.982883]
 [50.60392 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 1. 3. 0.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 20. 29. 19. 29.  8.  0.  8.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -5.361602306365967
desired expected reward: 46.99268341064453



buy possibilites: [-1] 
expected returns: [[78.644424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 1. 3. 0.] 
cards in discard: [ 8.  0. 29.  3.  6.  0. 11. 29.  0.  8.  3.  1.  0.  0. 29.  6. 14.  6.
  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: -44 

action type: buy - action 16.0
Learning step: -2.7153146266937256
desired expected reward: 42.9809684753418






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 16. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  2.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 16. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1.  0. 16. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 1.  0. 16. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 25.] 
expected returns: [[-12.972994]
 [-11.485183]
 [-11.918291]
 [-14.308108]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16. 29. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 16.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -9.011128425598145
desired expected reward: 69.63329315185547



action possibilites: [-1] 
expected returns: [[18.707935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16. 29. 16.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 16.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action 25.0
Learning step: -2.663666248321533
desired expected reward: -16.971771240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[13.932948]
 [23.30188 ]
 [18.573612]
 [24.853424]
 [20.278957]
 [15.843711]
 [23.416801]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16. 29. 16.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 16.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -4.2595534324646
desired expected reward: 14.448381423950195



buy possibilites: [-1] 
expected returns: [[10.932934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16. 29. 16.  6.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 11.  0. 16.  1.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -106.0 

action type: buy - action 0.0
Learning step: -5.750657081604004
desired expected reward: 8.182304382324219






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0. 16.  1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0. 16.  1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11] -> size -> 60 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  8. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0. 16.  1.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0] -> size -> 31 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [1. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.374846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  6.  8.  0.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -5.293212890625
desired expected reward: 5.639720916748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.33177853]
 [ 2.3506727 ]
 [ 2.0945625 ]
 [-1.9427408 ]
 [ 1.1567178 ]
 [ 3.540722  ]
 [ 1.2097611 ]
 [ 4.391032  ]
 [ 1.2438998 ]
 [-1.3542919 ]
 [ 0.18497849]
 [ 1.2491407 ]
 [-1.9653184 ]
 [ 0.49299622]
 [ 4.2766156 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 20. 29. 19. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  6.  8.  0.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.875929832458496
desired expected reward: -2.5010838508605957



buy possibilites: [-1] 
expected returns: [[40.69289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [10. 11.  6.  8.  0.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -83.0 

action type: buy - action 3.0
Learning step: -3.3391377925872803
desired expected reward: -1.244584321975708






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [10. 11.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  6.  8.  0.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  8. 29.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  6.  8.  0.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  3.  8. 29.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 11.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[1.5721722]
 [3.3013644]
 [2.0843415]
 [1.9726534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  8. 29.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  6.  6.  3.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -6.228829383850098
desired expected reward: 34.46406173706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[0.7871549]
 [1.6999102]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  8. 29.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3.  6.  6.  3.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.298245906829834
desired expected reward: -2.7260756492614746



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [29.  3.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6.  6.  3.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29. 25.  0.  8.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  6.  3.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14] -> size -> 61 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29. 25.  0.  8.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  6.  6.  3.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29. 25.  0.  8.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.] 
adversary owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [ 6. 29. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[14.26315 ]
 [10.717174]
 [14.710948]
 [10.706675]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 25.  0.  8.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8
  3 29  8 11  0 16  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0] -> size -> 62 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -3.9719295501708984
desired expected reward: -3.6430306434631348



action possibilites: [-1] 
expected returns: [[27.305908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 25.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0] -> size -> 62 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 2
Learning step: -3.1570308208465576
desired expected reward: 7.271246910095215





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.84682 ]
 [26.344978]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29. 25.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0] -> size -> 62 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -4.087308406829834
desired expected reward: 23.218599319458008






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  6. 29.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.  8.  6. 29. 25.] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0] -> size -> 62 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  6. 29.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.  8.  6. 29. 25.] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  6. 29.] 
adversary cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.  8.  6. 29. 25.] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [ 0.  0. 14.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[21.321918 ]
 [ 4.3446918]
 [12.811078 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  6. 29.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.  8.  6. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29.  4.  0.  0.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -5.234297275543213
desired expected reward: 21.110681533813477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 9.9963255]
 [14.498948 ]
 [12.8242445]
 [20.639793 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  6. 29.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.  8.  6. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 20. 29. 18. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29.  4.  0.  0.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -4.9579572677612305
desired expected reward: 16.363948822021484



buy possibilites: [-1] 
expected returns: [[13.256764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  6. 29.] 
cards in discard: [ 0. 25.  1.  0. 16. 29. 16.  6.  3.  1.  0.  0.  0.  6.  3. 11.  3.  8.
 29.  8.  6. 29. 25.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29.  4.  0.  0.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -66 

action type: buy - action 3.0
Learning step: -3.7266697883605957
desired expected reward: 10.772268295288086






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [29. 29.  4.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  4.  0.  0.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3  3] -> size -> 32 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4.  0.  0.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3  3] -> size -> 32 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  4.  0.  0.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0] -> size -> 63 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  1.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3  3] -> size -> 32 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  4.  0.  0.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8] -> size -> 64 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [14.  3.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3  3] -> size -> 32 
adversary victory points: 1
player victory points: 8 





Player: 0 
cards in hand: [14.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[-12.014611]
 [-16.066809]
 [-11.892399]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3
 29  8 11  0 16  0  3  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  1. 11. 11. 10.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8. 29. 29.  4.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8] -> size -> 64 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -4.655162334442139
desired expected reward: 8.601602554321289



action possibilites: [-1] 
expected returns: [[17.066933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29
  8 11  0 16  0  3  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  1. 11. 11. 10.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8. 29. 29.  4.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8] -> size -> 64 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: trash_cards_n_from_hand - action 0
Learning step: -1.73064386844635
desired expected reward: -13.437649726867676





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.937867]
 [16.21006 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29
  8 11  0 16  0  3  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  1. 11. 11. 10.] 
adversary cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8. 29. 29.  4.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8] -> size -> 64 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1
Learning step: -3.216888427734375
desired expected reward: 13.850044250488281






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [29.  1. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 11. 11. 10.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8. 29. 29.  4.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 16.  6.] 
adversary cards in discard: [ 8. 14.  3.  3.] 
adversary owned cards: [ 0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29
  8 11  0 16  0  3  3] -> size -> 31 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 11. 11. 10.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8. 29. 29.  4.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8] -> size -> 64 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 20. 29. 17. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 16.  6.] 
adversary cards in discard: [ 8. 14.  3.  3.] 
adversary owned cards: [ 0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29
  8 11  0 16  0  3  3] -> size -> 31 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 11. 11. 10.] 
cards in discard: [14. 11. 10. 11.  0.  3.  3.  1. 15.  8.  0.  0. 29.  1.  8.  3.  8.  3.
  1.  3. 11.  0.  0.  0.  0.  1. 14.  1. 11.  0. 16.  1. 10. 11.  6.  8.
  0.  0. 29.  3.  6.  6.  3.  0. 11.  3.  0.  0.  6.  0.  8. 29. 29.  4.
  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8  3] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 16. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 16.  6.] 
adversary cards in discard: [ 8. 14.  3.  3.] 
adversary owned cards: [ 0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29
  8 11  0 16  0  3  3] -> size -> 31 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [29.  3. 29. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 16.] 
expected returns: [[-13.094441]
 [-11.812274]
 [-11.812274]
 [-11.125841]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 16.  6.] 
cards in discard: [ 8. 14.  3.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29
  8 11  0 16  0  3  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 16. 29.  8.  0.  7.  1.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8  3] -> size -> 65 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -5.275267124176025
desired expected reward: 10.934789657592773



Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 3 
Gold: 1 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 2 
Workshop: 1 
Chapel: 5 
Witch: 2 
Poacher: 3 
Militia: 1 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 29.  6.] 
cards in discard: [ 8. 14.  3.  3. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  1 14 16  0 25  8  1 25  0  6 29  0  6  3  6 29 29  6  8  3 29  8
 11  0 16  0  3  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 16. 29.  8.  0.  7.  0.  0.  8.  1.  7. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0  4  1 11  3  0  3 29 29  3 29  3  1 11  8 11
  3 11 11 16 11  0 10  8  8  1  0 10 29 10  0  6  0  6  1  0  6  3  1  1
  1 29  3  3  6  0  0 14 11 15  8 11 14  0  0  8  3] -> size -> 65 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -90    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -566 

action type: gain_card_n - action 4
Learning step: -27.70352554321289
desired expected reward: -39.63300323486328



